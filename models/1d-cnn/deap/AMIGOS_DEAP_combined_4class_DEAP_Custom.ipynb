{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "lV6AUpSouNYI",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "lV6AUpSouNYI",
    "outputId": "e479380e-fbed-427b-87fd-cc146892b6da"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mounted at /content/drive\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2fac9bc9-6ec3-40ff-b741-5fe85e786b2d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-23T14:01:29.112873Z",
     "iopub.status.busy": "2024-01-23T14:01:29.112337Z",
     "iopub.status.idle": "2024-01-23T14:01:29.616892Z",
     "shell.execute_reply": "2024-01-23T14:01:29.615289Z",
     "shell.execute_reply.started": "2024-01-23T14:01:29.112827Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Archive:  Final_data.zip\n",
      "  inflating: customdata/Final_data/P1_level1_c.csv  \n",
      "  inflating: customdata/Final_data/P10_level0_c.csv  \n",
      "  inflating: customdata/Final_data/P10_level1_c.csv  \n",
      "  inflating: customdata/Final_data/P10_level2_c.csv  \n",
      "  inflating: customdata/Final_data/P10_level3_c.csv  \n",
      "  inflating: customdata/Final_data/P10_level4_c.csv  \n",
      "  inflating: customdata/Final_data/P10_level5_c.csv  \n",
      "  inflating: customdata/Final_data/P10_level6_c.csv  \n",
      "  inflating: customdata/Final_data/P11_level0 _tower.csv  \n",
      "  inflating: customdata/Final_data/P11_level0_c.csv  \n",
      "  inflating: customdata/Final_data/P11_level1_c.csv  \n",
      "  inflating: customdata/Final_data/P11_level1_tower.csv  \n",
      "  inflating: customdata/Final_data/P11_level10_tower.csv  \n",
      "  inflating: customdata/Final_data/P11_level11_tower.csv  \n",
      "  inflating: customdata/Final_data/P11_level2_c.csv  \n",
      "  inflating: customdata/Final_data/P11_level2_tower.csv  \n",
      "  inflating: customdata/Final_data/P11_level3_c.csv  \n",
      "  inflating: customdata/Final_data/P11_level3_tower.csv  \n",
      "  inflating: customdata/Final_data/P11_level4_c.csv  \n",
      "  inflating: customdata/Final_data/P11_level4_tower.csv  \n",
      "  inflating: customdata/Final_data/P11_level5_c.csv  \n",
      "  inflating: customdata/Final_data/P11_level5_tower.csv  \n",
      "  inflating: customdata/Final_data/P11_level6_tower.csv  \n",
      "  inflating: customdata/Final_data/P11_level7_tower.csv  \n",
      "  inflating: customdata/Final_data/P11_level8_tower.csv  \n",
      "  inflating: customdata/Final_data/P11_level9_tower.csv  \n",
      "  inflating: customdata/Final_data/P13_level0_c.csv  \n",
      "  inflating: customdata/Final_data/P13_level0_tower.csv  \n",
      "  inflating: customdata/Final_data/P13_level1_c.csv  \n",
      "  inflating: customdata/Final_data/P13_level1_tower.csv  \n",
      "  inflating: customdata/Final_data/P13_level2_c.csv  \n",
      "  inflating: customdata/Final_data/P13_level2_tower.csv  \n",
      "  inflating: customdata/Final_data/P13_level3_c.csv  \n",
      "  inflating: customdata/Final_data/P13_level3_tower.csv  \n",
      "  inflating: customdata/Final_data/P13_level4_c.csv  \n",
      "  inflating: customdata/Final_data/P13_level4_tower.csv  \n",
      "  inflating: customdata/Final_data/P13_level5_c.csv  \n",
      "  inflating: customdata/Final_data/P2_level0_c.csv  \n",
      "  inflating: customdata/Final_data/P2_level0_tower.csv  \n",
      "  inflating: customdata/Final_data/P2_level1_c.csv  \n",
      "  inflating: customdata/Final_data/P2_level10_tower.csv  \n",
      "  inflating: customdata/Final_data/P2_level11_tower.csv  \n",
      "  inflating: customdata/Final_data/P2_level2_c.csv  \n",
      "  inflating: customdata/Final_data/P2_level2_tower.csv  \n",
      "  inflating: customdata/Final_data/P2_level3_tower.csv  \n",
      "  inflating: customdata/Final_data/P2_level4_tower.csv  \n",
      "  inflating: customdata/Final_data/P2_level5_c.csv  \n",
      "  inflating: customdata/Final_data/P2_level5_tower.csv  \n",
      "  inflating: customdata/Final_data/P2_level6_c.csv  \n",
      "  inflating: customdata/Final_data/P2_level6_tower.csv  \n",
      "  inflating: customdata/Final_data/P2_level7_tower.csv  \n",
      "  inflating: customdata/Final_data/P2_level9_tower.csv  \n",
      "  inflating: customdata/Final_data/P3_level0_c.csv  \n",
      "  inflating: customdata/Final_data/P3_level0_tower.csv  \n",
      "  inflating: customdata/Final_data/P3_level1_c.csv  \n",
      "  inflating: customdata/Final_data/P3_level1_tower.csv  \n",
      "  inflating: customdata/Final_data/P3_level10_tower.csv  \n",
      "  inflating: customdata/Final_data/P3_level11_tower.csv  \n",
      "  inflating: customdata/Final_data/P3_level2_tower.csv  \n",
      "  inflating: customdata/Final_data/P3_level3_c.csv  \n",
      "  inflating: customdata/Final_data/P3_level3_tower.csv  \n",
      "  inflating: customdata/Final_data/P3_level4_tower.csv  \n",
      "  inflating: customdata/Final_data/P3_level5_tower.csv  \n",
      "  inflating: customdata/Final_data/P3_level6_tower.csv  \n",
      "  inflating: customdata/Final_data/P3_level7_tower.csv  \n",
      "  inflating: customdata/Final_data/P3_level8_tower.csv  \n",
      "  inflating: customdata/Final_data/P3_level9_tower.csv  \n",
      "  inflating: customdata/Final_data/P5_level0_c.csv  \n",
      "  inflating: customdata/Final_data/P5_level1_c.csv  \n",
      "  inflating: customdata/Final_data/P5_level2_c.csv  \n",
      "  inflating: customdata/Final_data/P5_level3_c.csv  \n",
      "  inflating: customdata/Final_data/P5_level4_c.csv  \n",
      "  inflating: customdata/Final_data/P5_level5_c.csv  \n",
      "  inflating: customdata/Final_data/P5_level6_c.csv  \n",
      "  inflating: customdata/Final_data/P6_level0_tower.csv  \n",
      "  inflating: customdata/Final_data/P6_level1_tower.csv  \n",
      "  inflating: customdata/Final_data/P7_level0_c.csv  \n",
      "  inflating: customdata/Final_data/P7_level0_tower.csv  \n",
      "  inflating: customdata/Final_data/P7_level1_c.csv  \n",
      "  inflating: customdata/Final_data/P7_level1_tower.csv  \n",
      "  inflating: customdata/Final_data/P7_level10_tower.csv  \n",
      "  inflating: customdata/Final_data/P7_level11_tower.csv  \n",
      "  inflating: customdata/Final_data/P7_level2_c.csv  \n",
      "  inflating: customdata/Final_data/P7_level2_tower.csv  \n",
      "  inflating: customdata/Final_data/P7_level3_c.csv  \n",
      "  inflating: customdata/Final_data/P7_level3_tower.csv  \n",
      "  inflating: customdata/Final_data/P7_level4_tower.csv  \n",
      "  inflating: customdata/Final_data/P7_level5_c.csv  \n",
      "  inflating: customdata/Final_data/P7_level5_tower.csv  \n",
      "  inflating: customdata/Final_data/P7_level6_c.csv  \n",
      "  inflating: customdata/Final_data/P7_level6_tower.csv  \n",
      "  inflating: customdata/Final_data/P7_level7_tower.csv  \n",
      "  inflating: customdata/Final_data/P7_level8_tower.csv  \n",
      "  inflating: customdata/Final_data/P7_level9_tower.csv  \n"
     ]
    }
   ],
   "source": [
    "!unzip Final_data -d customdata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6c730c07-de97-4ce1-96a6-3991c0a7a66c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-24T12:26:43.439899Z",
     "iopub.status.busy": "2024-01-24T12:26:43.439561Z",
     "iopub.status.idle": "2024-01-24T12:26:43.461094Z",
     "shell.execute_reply": "2024-01-24T12:26:43.460154Z",
     "shell.execute_reply.started": "2024-01-24T12:26:43.439871Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['P2_level1_c', 'P11_level2_tower', 'P3_level0_tower', 'P3_level1_c', 'P5_level6_c', 'P13_level1_tower', 'P3_level3_c', 'P11_level5_tower', 'P2_level6_c', 'P7_level4_tower', 'P13_level0_tower', 'P13_level2_tower', 'P6_level1_tower', 'P11_level2_c', 'P7_level10_tower', 'P11_level1_c', 'P7_level2_tower', 'P11_level9_tower', 'P11_level3_c', 'P11_level5_c', 'P5_level5_c', 'P2_level5_tower', 'P13_level3_c', 'P3_level11_tower', 'P2_level6_tower', 'P11_level10_tower', 'P7_level8_tower', 'P3_level10_tower', 'P3_level7_tower', 'P10_level6_c', 'P3_level5_tower', 'P10_level3_c', 'P13_level0_c', 'P11_level4_c', 'P13_level2_c', 'P7_level9_tower', 'P13_level4_tower', 'P2_level9_tower', 'P3_level4_tower', 'P2_level11_tower', 'P11_level8_tower', 'P7_level1_c', 'P13_level3_tower', 'P5_level3_c', 'P13_level1_c', 'P3_level9_tower', 'P11_level1_tower', 'P3_level6_tower', 'P2_level0_tower', 'P3_level2_tower', 'P11_level7_tower', 'P2_level7_tower', 'P2_level0_c', 'P6_level0_tower', 'P7_level0_c', 'P3_level0_c', 'P2_level4_tower', 'P2_level3_tower', 'P10_level1_c', 'P7_level5_c', 'P5_level1_c', 'P3_level1_tower', 'P11_level0 _tower', 'P2_level5_c', 'P10_level2_c', 'P10_level4_c', 'P7_level6_tower', 'P7_level7_tower', 'P2_level2_c', 'P13_level4_c', 'P11_level3_tower', 'P3_level3_tower', 'P7_level11_tower', 'P7_level2_c', 'P7_level3_tower', 'P5_level4_c', 'P5_level0_c', 'P3_level8_tower', 'P7_level6_c', 'P11_level11_tower', 'P11_level0_c', 'P10_level5_c', 'P1_level1_c', 'P2_level10_tower', 'P5_level2_c', 'P11_level4_tower', 'P7_level0_tower', 'P7_level1_tower', 'P2_level2_tower', 'P7_level5_tower', 'P7_level3_c', 'P10_level0_c', 'P13_level5_c', 'P11_level6_tower']\n"
     ]
    }
   ],
   "source": [
    "import glob\n",
    "import os\n",
    "filelist = glob.glob('/notebooks/customdata/Final_data/*.csv')\n",
    "#print(filelist)\n",
    "subjectnamescustom = [fr[33:-4] for fr in filelist]\n",
    "print(subjectnamescustom)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "891086dc-3a76-4c36-a52d-35c94a4a404d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy import genfromtxt\n",
    "my_data = genfromtxt('my_file.csv', delimiter=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7cceb5a1-666d-4663-a9d4-dad5d99dfacc",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-24T12:26:48.209474Z",
     "iopub.status.busy": "2024-01-24T12:26:48.208907Z",
     "iopub.status.idle": "2024-01-24T12:26:48.215582Z",
     "shell.execute_reply": "2024-01-24T12:26:48.214700Z",
     "shell.execute_reply.started": "2024-01-24T12:26:48.209438Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['P2', 'P11', 'P3', 'P3', 'P5', 'P13', 'P3', 'P11', 'P2', 'P7', 'P13', 'P13', 'P6', 'P11', 'P7', 'P11', 'P7', 'P11', 'P11', 'P11', 'P5', 'P2', 'P13', 'P3', 'P2', 'P11', 'P7', 'P3', 'P3', 'P10', 'P3', 'P10', 'P13', 'P11', 'P13', 'P7', 'P13', 'P2', 'P3', 'P2', 'P11', 'P7', 'P13', 'P5', 'P13', 'P3', 'P11', 'P3', 'P2', 'P3', 'P11', 'P2', 'P2', 'P6', 'P7', 'P3', 'P2', 'P2', 'P10', 'P7', 'P5', 'P3', 'P11', 'P2', 'P10', 'P10', 'P7', 'P7', 'P2', 'P13', 'P11', 'P3', 'P7', 'P7', 'P7', 'P5', 'P5', 'P3', 'P7', 'P11', 'P11', 'P10', 'P1', 'P2', 'P5', 'P11', 'P7', 'P7', 'P2', 'P7', 'P7', 'P10', 'P13', 'P11']\n",
      "['P1', 'P5', 'P2', 'P3', 'P7', 'P13', 'P6', 'P10', 'P11']\n"
     ]
    }
   ],
   "source": [
    "subjectlistcustom = [s[0:3] for s in subjectnamescustom]\n",
    "subjectlistcustom1 = []\n",
    "for s in subjectlistcustom:\n",
    "    if(s[-1] == '_'):\n",
    "       subjectlistcustom1.append(s[:-1])\n",
    "    else:\n",
    "        subjectlistcustom1.append(s)\n",
    "\n",
    "subjectlistuni = list(set(subjectlistcustom1))\n",
    "print(subjectlistcustom1)\n",
    "print(subjectlistuni)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "24b0b59d-9a8a-4228-8541-dddf7eda42ca",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-24T12:26:59.197079Z",
     "iopub.status.busy": "2024-01-24T12:26:59.195719Z",
     "iopub.status.idle": "2024-01-24T12:27:00.132000Z",
     "shell.execute_reply": "2024-01-24T12:27:00.130916Z",
     "shell.execute_reply.started": "2024-01-24T12:26:59.197021Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "P1\n",
      "/notebooks/customdata/Final_data/P1_level1_c.csv\n",
      "P5\n",
      "/notebooks/customdata/Final_data/P5_level6_c.csv\n",
      "/notebooks/customdata/Final_data/P5_level5_c.csv\n",
      "/notebooks/customdata/Final_data/P5_level3_c.csv\n",
      "/notebooks/customdata/Final_data/P5_level1_c.csv\n",
      "/notebooks/customdata/Final_data/P5_level4_c.csv\n",
      "/notebooks/customdata/Final_data/P5_level0_c.csv\n",
      "/notebooks/customdata/Final_data/P5_level2_c.csv\n",
      "P2\n",
      "/notebooks/customdata/Final_data/P2_level1_c.csv\n",
      "/notebooks/customdata/Final_data/P2_level6_c.csv\n",
      "/notebooks/customdata/Final_data/P2_level5_tower.csv\n",
      "/notebooks/customdata/Final_data/P2_level6_tower.csv\n",
      "/notebooks/customdata/Final_data/P2_level9_tower.csv\n",
      "/notebooks/customdata/Final_data/P2_level11_tower.csv\n",
      "/notebooks/customdata/Final_data/P2_level0_tower.csv\n",
      "/notebooks/customdata/Final_data/P2_level7_tower.csv\n",
      "/notebooks/customdata/Final_data/P2_level0_c.csv\n",
      "/notebooks/customdata/Final_data/P2_level4_tower.csv\n",
      "/notebooks/customdata/Final_data/P2_level3_tower.csv\n",
      "/notebooks/customdata/Final_data/P2_level5_c.csv\n",
      "/notebooks/customdata/Final_data/P2_level2_c.csv\n",
      "/notebooks/customdata/Final_data/P2_level10_tower.csv\n",
      "/notebooks/customdata/Final_data/P2_level2_tower.csv\n",
      "P3\n",
      "/notebooks/customdata/Final_data/P3_level0_tower.csv\n",
      "/notebooks/customdata/Final_data/P3_level1_c.csv\n",
      "/notebooks/customdata/Final_data/P3_level3_c.csv\n",
      "/notebooks/customdata/Final_data/P3_level11_tower.csv\n",
      "/notebooks/customdata/Final_data/P3_level10_tower.csv\n",
      "/notebooks/customdata/Final_data/P3_level7_tower.csv\n",
      "/notebooks/customdata/Final_data/P3_level5_tower.csv\n",
      "/notebooks/customdata/Final_data/P3_level4_tower.csv\n",
      "/notebooks/customdata/Final_data/P3_level9_tower.csv\n",
      "/notebooks/customdata/Final_data/P3_level6_tower.csv\n",
      "/notebooks/customdata/Final_data/P3_level2_tower.csv\n",
      "/notebooks/customdata/Final_data/P3_level0_c.csv\n",
      "/notebooks/customdata/Final_data/P3_level1_tower.csv\n",
      "/notebooks/customdata/Final_data/P3_level3_tower.csv\n",
      "/notebooks/customdata/Final_data/P3_level8_tower.csv\n",
      "P7\n",
      "/notebooks/customdata/Final_data/P7_level4_tower.csv\n",
      "/notebooks/customdata/Final_data/P7_level10_tower.csv\n",
      "/notebooks/customdata/Final_data/P7_level2_tower.csv\n",
      "/notebooks/customdata/Final_data/P7_level8_tower.csv\n",
      "/notebooks/customdata/Final_data/P7_level9_tower.csv\n",
      "/notebooks/customdata/Final_data/P7_level1_c.csv\n",
      "/notebooks/customdata/Final_data/P7_level0_c.csv\n",
      "/notebooks/customdata/Final_data/P7_level5_c.csv\n",
      "/notebooks/customdata/Final_data/P7_level6_tower.csv\n",
      "/notebooks/customdata/Final_data/P7_level7_tower.csv\n",
      "/notebooks/customdata/Final_data/P7_level11_tower.csv\n",
      "/notebooks/customdata/Final_data/P7_level2_c.csv\n",
      "/notebooks/customdata/Final_data/P7_level3_tower.csv\n",
      "/notebooks/customdata/Final_data/P7_level6_c.csv\n",
      "/notebooks/customdata/Final_data/P7_level0_tower.csv\n",
      "/notebooks/customdata/Final_data/P7_level1_tower.csv\n",
      "/notebooks/customdata/Final_data/P7_level5_tower.csv\n",
      "/notebooks/customdata/Final_data/P7_level3_c.csv\n",
      "P13\n",
      "/notebooks/customdata/Final_data/P13_level1_tower.csv\n",
      "/notebooks/customdata/Final_data/P13_level0_tower.csv\n",
      "/notebooks/customdata/Final_data/P13_level2_tower.csv\n",
      "/notebooks/customdata/Final_data/P13_level3_c.csv\n",
      "/notebooks/customdata/Final_data/P13_level0_c.csv\n",
      "/notebooks/customdata/Final_data/P13_level2_c.csv\n",
      "/notebooks/customdata/Final_data/P13_level4_tower.csv\n",
      "/notebooks/customdata/Final_data/P13_level3_tower.csv\n",
      "/notebooks/customdata/Final_data/P13_level1_c.csv\n",
      "/notebooks/customdata/Final_data/P13_level4_c.csv\n",
      "/notebooks/customdata/Final_data/P13_level5_c.csv\n",
      "P6\n",
      "/notebooks/customdata/Final_data/P6_level1_tower.csv\n",
      "/notebooks/customdata/Final_data/P6_level0_tower.csv\n",
      "P10\n",
      "/notebooks/customdata/Final_data/P10_level6_c.csv\n",
      "/notebooks/customdata/Final_data/P10_level3_c.csv\n",
      "/notebooks/customdata/Final_data/P10_level1_c.csv\n",
      "/notebooks/customdata/Final_data/P10_level2_c.csv\n",
      "/notebooks/customdata/Final_data/P10_level4_c.csv\n",
      "/notebooks/customdata/Final_data/P10_level5_c.csv\n",
      "/notebooks/customdata/Final_data/P10_level0_c.csv\n",
      "P11\n",
      "/notebooks/customdata/Final_data/P11_level2_tower.csv\n",
      "/notebooks/customdata/Final_data/P11_level5_tower.csv\n",
      "/notebooks/customdata/Final_data/P11_level2_c.csv\n",
      "/notebooks/customdata/Final_data/P11_level1_c.csv\n",
      "/notebooks/customdata/Final_data/P11_level9_tower.csv\n",
      "/notebooks/customdata/Final_data/P11_level3_c.csv\n",
      "/notebooks/customdata/Final_data/P11_level5_c.csv\n",
      "/notebooks/customdata/Final_data/P11_level10_tower.csv\n",
      "/notebooks/customdata/Final_data/P11_level4_c.csv\n",
      "/notebooks/customdata/Final_data/P11_level8_tower.csv\n",
      "/notebooks/customdata/Final_data/P11_level1_tower.csv\n",
      "/notebooks/customdata/Final_data/P11_level7_tower.csv\n",
      "/notebooks/customdata/Final_data/P11_level0 _tower.csv\n",
      "/notebooks/customdata/Final_data/P11_level3_tower.csv\n",
      "/notebooks/customdata/Final_data/P11_level11_tower.csv\n",
      "/notebooks/customdata/Final_data/P11_level0_c.csv\n",
      "/notebooks/customdata/Final_data/P11_level4_tower.csv\n",
      "/notebooks/customdata/Final_data/P11_level6_tower.csv\n"
     ]
    }
   ],
   "source": [
    "import scipy.io\n",
    "import numpy as np\n",
    "from numpy import genfromtxt\n",
    "data_custom = {}\n",
    "\n",
    "for sname in subjectlistuni:\n",
    "    data = []\n",
    "    lab = []\n",
    "    print(sname)\n",
    "    for sname1 in subjectnamescustom:\n",
    "        nm = sname+\"_\"\n",
    "        if(sname1.find(nm) != -1):\n",
    "            dname = \"/notebooks/customdata/Final_data/\"+sname1+\".csv\"\n",
    "            print(dname)\n",
    "            my_data = genfromtxt(dname, delimiter=',')\n",
    "            data.append(my_data[1:,4])\n",
    "            lab.append(my_data[1,-2:])\n",
    "    \n",
    "    data_custom[sname] = [data,np.vstack(lab)]       \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3b7877a4-9d01-48d4-8fc2-5da07657460c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-23T16:45:59.280011Z",
     "iopub.status.busy": "2024-01-23T16:45:59.279563Z",
     "iopub.status.idle": "2024-01-23T16:46:00.012352Z",
     "shell.execute_reply": "2024-01-23T16:46:00.011640Z",
     "shell.execute_reply.started": "2024-01-23T16:45:59.279981Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/notebooks/customdata/Final_data/P2_level1_c.csv\n",
      "/notebooks/customdata/Final_data/P11_level2_tower.csv\n",
      "/notebooks/customdata/Final_data/P3_level0_tower.csv\n",
      "/notebooks/customdata/Final_data/P3_level1_c.csv\n",
      "/notebooks/customdata/Final_data/P5_level6_c.csv\n",
      "/notebooks/customdata/Final_data/P13_level1_tower.csv\n",
      "/notebooks/customdata/Final_data/P3_level3_c.csv\n",
      "/notebooks/customdata/Final_data/P11_level5_tower.csv\n",
      "/notebooks/customdata/Final_data/P2_level6_c.csv\n",
      "/notebooks/customdata/Final_data/P7_level4_tower.csv\n",
      "/notebooks/customdata/Final_data/P13_level0_tower.csv\n",
      "/notebooks/customdata/Final_data/P13_level2_tower.csv\n",
      "/notebooks/customdata/Final_data/P6_level1_tower.csv\n",
      "/notebooks/customdata/Final_data/P11_level2_c.csv\n",
      "/notebooks/customdata/Final_data/P7_level10_tower.csv\n",
      "/notebooks/customdata/Final_data/P11_level1_c.csv\n",
      "/notebooks/customdata/Final_data/P7_level2_tower.csv\n",
      "/notebooks/customdata/Final_data/P11_level9_tower.csv\n",
      "/notebooks/customdata/Final_data/P11_level3_c.csv\n",
      "/notebooks/customdata/Final_data/P11_level5_c.csv\n",
      "/notebooks/customdata/Final_data/P5_level5_c.csv\n",
      "/notebooks/customdata/Final_data/P2_level5_tower.csv\n",
      "/notebooks/customdata/Final_data/P13_level3_c.csv\n",
      "/notebooks/customdata/Final_data/P3_level11_tower.csv\n",
      "/notebooks/customdata/Final_data/P2_level6_tower.csv\n",
      "/notebooks/customdata/Final_data/P11_level10_tower.csv\n",
      "/notebooks/customdata/Final_data/P7_level8_tower.csv\n",
      "/notebooks/customdata/Final_data/P3_level10_tower.csv\n",
      "/notebooks/customdata/Final_data/P3_level7_tower.csv\n",
      "/notebooks/customdata/Final_data/P10_level6_c.csv\n",
      "/notebooks/customdata/Final_data/P3_level5_tower.csv\n",
      "/notebooks/customdata/Final_data/P10_level3_c.csv\n",
      "/notebooks/customdata/Final_data/P13_level0_c.csv\n",
      "/notebooks/customdata/Final_data/P11_level4_c.csv\n",
      "/notebooks/customdata/Final_data/P13_level2_c.csv\n",
      "/notebooks/customdata/Final_data/P7_level9_tower.csv\n",
      "/notebooks/customdata/Final_data/P13_level4_tower.csv\n",
      "/notebooks/customdata/Final_data/P2_level9_tower.csv\n",
      "/notebooks/customdata/Final_data/P3_level4_tower.csv\n",
      "/notebooks/customdata/Final_data/P2_level11_tower.csv\n",
      "/notebooks/customdata/Final_data/P11_level8_tower.csv\n",
      "/notebooks/customdata/Final_data/P7_level1_c.csv\n",
      "/notebooks/customdata/Final_data/P13_level3_tower.csv\n",
      "/notebooks/customdata/Final_data/P5_level3_c.csv\n",
      "/notebooks/customdata/Final_data/P13_level1_c.csv\n",
      "/notebooks/customdata/Final_data/P3_level9_tower.csv\n",
      "/notebooks/customdata/Final_data/P11_level1_tower.csv\n",
      "/notebooks/customdata/Final_data/P3_level6_tower.csv\n",
      "/notebooks/customdata/Final_data/P2_level0_tower.csv\n",
      "/notebooks/customdata/Final_data/P3_level2_tower.csv\n",
      "/notebooks/customdata/Final_data/P11_level7_tower.csv\n",
      "/notebooks/customdata/Final_data/P2_level7_tower.csv\n",
      "/notebooks/customdata/Final_data/P2_level0_c.csv\n",
      "/notebooks/customdata/Final_data/P6_level0_tower.csv\n",
      "/notebooks/customdata/Final_data/P7_level0_c.csv\n",
      "/notebooks/customdata/Final_data/P3_level0_c.csv\n",
      "/notebooks/customdata/Final_data/P2_level4_tower.csv\n",
      "/notebooks/customdata/Final_data/P2_level3_tower.csv\n",
      "/notebooks/customdata/Final_data/P10_level1_c.csv\n",
      "/notebooks/customdata/Final_data/P7_level5_c.csv\n",
      "/notebooks/customdata/Final_data/P5_level1_c.csv\n",
      "/notebooks/customdata/Final_data/P3_level1_tower.csv\n",
      "/notebooks/customdata/Final_data/P11_level0 _tower.csv\n",
      "/notebooks/customdata/Final_data/P2_level5_c.csv\n",
      "/notebooks/customdata/Final_data/P10_level2_c.csv\n",
      "/notebooks/customdata/Final_data/P10_level4_c.csv\n",
      "/notebooks/customdata/Final_data/P7_level6_tower.csv\n",
      "/notebooks/customdata/Final_data/P7_level7_tower.csv\n",
      "/notebooks/customdata/Final_data/P2_level2_c.csv\n",
      "/notebooks/customdata/Final_data/P13_level4_c.csv\n",
      "/notebooks/customdata/Final_data/P11_level3_tower.csv\n",
      "/notebooks/customdata/Final_data/P3_level3_tower.csv\n",
      "/notebooks/customdata/Final_data/P7_level11_tower.csv\n",
      "/notebooks/customdata/Final_data/P7_level2_c.csv\n",
      "/notebooks/customdata/Final_data/P7_level3_tower.csv\n",
      "/notebooks/customdata/Final_data/P5_level4_c.csv\n",
      "/notebooks/customdata/Final_data/P5_level0_c.csv\n",
      "/notebooks/customdata/Final_data/P3_level8_tower.csv\n",
      "/notebooks/customdata/Final_data/P7_level6_c.csv\n",
      "/notebooks/customdata/Final_data/P11_level11_tower.csv\n",
      "/notebooks/customdata/Final_data/P11_level0_c.csv\n",
      "/notebooks/customdata/Final_data/P10_level5_c.csv\n",
      "/notebooks/customdata/Final_data/P1_level1_c.csv\n",
      "/notebooks/customdata/Final_data/P2_level10_tower.csv\n",
      "/notebooks/customdata/Final_data/P5_level2_c.csv\n",
      "/notebooks/customdata/Final_data/P11_level4_tower.csv\n",
      "/notebooks/customdata/Final_data/P7_level0_tower.csv\n",
      "/notebooks/customdata/Final_data/P7_level1_tower.csv\n",
      "/notebooks/customdata/Final_data/P2_level2_tower.csv\n",
      "/notebooks/customdata/Final_data/P7_level5_tower.csv\n",
      "/notebooks/customdata/Final_data/P7_level3_c.csv\n",
      "/notebooks/customdata/Final_data/P10_level0_c.csv\n",
      "/notebooks/customdata/Final_data/P13_level5_c.csv\n",
      "/notebooks/customdata/Final_data/P11_level6_tower.csv\n"
     ]
    }
   ],
   "source": [
    "import scipy.io\n",
    "import numpy as np\n",
    "from numpy import genfromtxt\n",
    "data_custom = {}\n",
    "#skiplist = ['P28','P08','P24','P32']\n",
    "#newsubjectname = []\n",
    "for sname in subjectnamescustom:\n",
    "    #if sname in skiplist:\n",
    "    #  continue\n",
    "    #newsubjectname.append(sname)\n",
    "    dname = \"/notebooks/customdata/Final_data/\"+sname+\".csv\"\n",
    "    print(dname)\n",
    "    my_data = genfromtxt(dname, delimiter=',')\n",
    "    #x = scipy.io.loadmat(dname)\n",
    "    #print(my_data[1:,4])\n",
    "    #print(my_data[1,-2:])\n",
    "    data_custom[sname] = [my_data[1:,4],my_data[1,-2:]]\n",
    "    #break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27e9a377-1dae-46d6-b3b5-cd5ac2dfc59e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3e484a6d-5e6a-4891-9a78-1ed6c9e36636",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-23T16:46:04.136989Z",
     "iopub.status.busy": "2024-01-23T16:46:04.135758Z",
     "iopub.status.idle": "2024-01-23T16:46:04.623218Z",
     "shell.execute_reply": "2024-01-23T16:46:04.622051Z",
     "shell.execute_reply.started": "2024-01-23T16:46:04.136954Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f6a7485f940>]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.plot(data_custom['P2_level1_c'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "84566ab2-5325-4d47-87d2-f762a145ac0d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-24T12:27:14.901664Z",
     "iopub.status.busy": "2024-01-24T12:27:14.900783Z",
     "iopub.status.idle": "2024-01-24T12:27:15.148653Z",
     "shell.execute_reply": "2024-01-24T12:27:15.147743Z",
     "shell.execute_reply.started": "2024-01-24T12:27:14.901622Z"
    }
   },
   "outputs": [],
   "source": [
    "from scipy.signal import butter, lfilter, filtfilt, welch\n",
    "from scipy import signal\n",
    "def butter_lowpass_filter(data, cutoff, fs, order=5):\n",
    "    ''' Lowpass filter '''\n",
    "    def butter_lowpass(cutoff, fs, order=5):\n",
    "        nyq = 0.5 * fs\n",
    "        normal_cutoff = cutoff / nyq\n",
    "        b, a = butter(order, normal_cutoff, btype='low', analog=False)\n",
    "        return b, a\n",
    "    b, a = butter_lowpass(cutoff, fs, order=order)\n",
    "    y = lfilter(b, a, data)\n",
    "    #b, a = signal.butter(5, 60, 'low', analog = True)\n",
    "    #y = signal.filtfilt(b, a, data)\n",
    "    return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bc512b11-0b2f-4b53-9785-c43d66981238",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-24T12:27:27.680451Z",
     "iopub.status.busy": "2024-01-24T12:27:27.679663Z",
     "iopub.status.idle": "2024-01-24T12:27:28.687298Z",
     "shell.execute_reply": "2024-01-24T12:27:28.686251Z",
     "shell.execute_reply.started": "2024-01-24T12:27:27.680414Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.fft import fft, fftfreq\n",
    "data_custom_preprocessed = {}\n",
    "for k,v in data_custom.items():\n",
    "    yi = v[0]\n",
    "    yipro = []\n",
    "    for y in yi:\n",
    "        x21 = scipy.signal.resample(y, 8564)\n",
    "        x2 = x21[250:-250]\n",
    "        ym = np.mean(x2,axis=-1)\n",
    "        ystd = np.std(x2,axis=-1)\n",
    "        z = (x2-ym)/ystd\n",
    "        #f, (ax1, ax2,ax3) = plt.subplots(1, 3, sharey=True)\n",
    "        #ax1.plot(np.arange(len(x2)),x2)\n",
    "        #ax1.set_title('Sharing Y axis')\n",
    "        #ax2.plot(np.arange(len(x2)-500),x2[250:-250])\n",
    "        z = butter_lowpass_filter(z,60,128)\n",
    "        #print(z.shape)\n",
    "        #f, (ax1, ax2) = plt.subplots(1, 2, sharey=True)\n",
    "        #ax1.plot(np.arange(len(z)),z)\n",
    "        #ax1.set_title('Sharing Y axis')\n",
    "        #ax2.plot(np.arange(len(z1)),z1)\n",
    "        #plt.plot(z)\n",
    "        #break\n",
    "        yipro.append(z)\n",
    "    yii = np.vstack(yipro)\n",
    "    yii1 = yii[:,np.newaxis,:]\n",
    "    yii2 = torch.tensor(yii1)\n",
    "    data_custom_preprocessed[k] = [yii2,v[1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "8cbd8e7b-3b7f-4d8d-80e1-c9eae822574f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-23T17:44:08.827634Z",
     "iopub.status.busy": "2024-01-23T17:44:08.826422Z",
     "iopub.status.idle": "2024-01-23T17:44:08.833137Z",
     "shell.execute_reply": "2024-01-23T17:44:08.832452Z",
     "shell.execute_reply.started": "2024-01-23T17:44:08.827586Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([11, 1, 8064])"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_custom_preprocessed['P13'][0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "941da7e8-ba31-4692-b91d-18c9f2ccfee1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-24T12:27:32.262330Z",
     "iopub.status.busy": "2024-01-24T12:27:32.261461Z",
     "iopub.status.idle": "2024-01-24T12:27:32.271326Z",
     "shell.execute_reply": "2024-01-24T12:27:32.270013Z",
     "shell.execute_reply.started": "2024-01-24T12:27:32.262296Z"
    }
   },
   "outputs": [],
   "source": [
    "data_label_custom = {}\n",
    "maxnum = 3\n",
    "for k,v in data_custom_preprocessed.items():\n",
    "    y = v[1]\n",
    "    x_label = np.zeros((y.shape[0]),dtype='int32')\n",
    "    for i in range(y.shape[0]):\n",
    "        if (y[i][0] >= 1 and y[i][1] >= 1):\n",
    "            x_label[i] = 3\n",
    "        elif (y[i][0] < 1 and y[i][1] >= 1):\n",
    "            x_label[i] = 2\n",
    "        elif (y[i][0] >= 1 and y[i][1] < 1):\n",
    "            x_label[i] = 1\n",
    "        elif (y[i][0] < 1 and y[i][1] < 1):\n",
    "            x_label[i] = 0\n",
    "\n",
    "    x_l = np.zeros((x_label.size, maxnum+1))\n",
    "    x_l[np.arange(x_label.size), x_label] = 1\n",
    "\n",
    "    x_l = torch.tensor(x_l)\n",
    "    data_label_custom[k] = x_l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "5c388fce-aad0-438f-a0bf-db83c5384da1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-23T18:02:09.397396Z",
     "iopub.status.busy": "2024-01-23T18:02:09.397124Z",
     "iopub.status.idle": "2024-01-23T18:02:10.292747Z",
     "shell.execute_reply": "2024-01-23T18:02:10.291744Z",
     "shell.execute_reply.started": "2024-01-23T18:02:09.397376Z"
    }
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "unhashable type: 'dict'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [75], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mplt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mplot\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata_label_custom\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.9/dist-packages/matplotlib/pyplot.py:2730\u001b[0m, in \u001b[0;36mplot\u001b[0;34m(scalex, scaley, data, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2728\u001b[0m \u001b[38;5;129m@_copy_docstring_and_deprecators\u001b[39m(Axes\u001b[38;5;241m.\u001b[39mplot)\n\u001b[1;32m   2729\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mplot\u001b[39m(\u001b[38;5;241m*\u001b[39margs, scalex\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, scaley\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, data\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m-> 2730\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mgca\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mplot\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2731\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mscalex\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mscalex\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mscaley\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mscaley\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2732\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mdata\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m}\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mis\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m{\u001b[49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.9/dist-packages/matplotlib/axes/_axes.py:1662\u001b[0m, in \u001b[0;36mAxes.plot\u001b[0;34m(self, scalex, scaley, data, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1419\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   1420\u001b[0m \u001b[38;5;124;03mPlot y versus x as lines and/or markers.\u001b[39;00m\n\u001b[1;32m   1421\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1659\u001b[0m \u001b[38;5;124;03m(``'green'``) or hex strings (``'#008000'``).\u001b[39;00m\n\u001b[1;32m   1660\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   1661\u001b[0m kwargs \u001b[38;5;241m=\u001b[39m cbook\u001b[38;5;241m.\u001b[39mnormalize_kwargs(kwargs, mlines\u001b[38;5;241m.\u001b[39mLine2D)\n\u001b[0;32m-> 1662\u001b[0m lines \u001b[38;5;241m=\u001b[39m [\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_lines(\u001b[38;5;241m*\u001b[39margs, data\u001b[38;5;241m=\u001b[39mdata, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)]\n\u001b[1;32m   1663\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m line \u001b[38;5;129;01min\u001b[39;00m lines:\n\u001b[1;32m   1664\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39madd_line(line)\n",
      "File \u001b[0;32m/usr/local/lib/python3.9/dist-packages/matplotlib/axes/_base.py:311\u001b[0m, in \u001b[0;36m_process_plot_var_args.__call__\u001b[0;34m(self, data, *args, **kwargs)\u001b[0m\n\u001b[1;32m    309\u001b[0m     this \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m args[\u001b[38;5;241m0\u001b[39m],\n\u001b[1;32m    310\u001b[0m     args \u001b[38;5;241m=\u001b[39m args[\u001b[38;5;241m1\u001b[39m:]\n\u001b[0;32m--> 311\u001b[0m \u001b[38;5;28;01myield from\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_plot_args\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    312\u001b[0m \u001b[43m    \u001b[49m\u001b[43mthis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mambiguous_fmt_datakey\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mambiguous_fmt_datakey\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.9/dist-packages/matplotlib/axes/_base.py:501\u001b[0m, in \u001b[0;36m_process_plot_var_args._plot_args\u001b[0;34m(self, tup, kwargs, return_kwargs, ambiguous_fmt_datakey)\u001b[0m\n\u001b[1;32m    499\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maxes\u001b[38;5;241m.\u001b[39mxaxis\u001b[38;5;241m.\u001b[39mupdate_units(x)\n\u001b[1;32m    500\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maxes\u001b[38;5;241m.\u001b[39myaxis \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 501\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43maxes\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43myaxis\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mupdate_units\u001b[49m\u001b[43m(\u001b[49m\u001b[43my\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    503\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m x\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m!=\u001b[39m y\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m]:\n\u001b[1;32m    504\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mx and y must have same first dimension, but \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    505\u001b[0m                      \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhave shapes \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mx\u001b[38;5;241m.\u001b[39mshape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m and \u001b[39m\u001b[38;5;132;01m{\u001b[39;00my\u001b[38;5;241m.\u001b[39mshape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m/usr/local/lib/python3.9/dist-packages/matplotlib/axis.py:1608\u001b[0m, in \u001b[0;36mAxis.update_units\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m   1606\u001b[0m neednew \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconverter \u001b[38;5;241m!=\u001b[39m converter\n\u001b[1;32m   1607\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconverter \u001b[38;5;241m=\u001b[39m converter\n\u001b[0;32m-> 1608\u001b[0m default \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconverter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdefault_units\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1609\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m default \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39munits \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   1610\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mset_units(default)\n",
      "File \u001b[0;32m/usr/local/lib/python3.9/dist-packages/matplotlib/category.py:116\u001b[0m, in \u001b[0;36mStrCategoryConverter.default_units\u001b[0;34m(data, axis)\u001b[0m\n\u001b[1;32m    114\u001b[0m \u001b[38;5;66;03m# the conversion call stack is default_units -> axis_info -> convert\u001b[39;00m\n\u001b[1;32m    115\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m axis\u001b[38;5;241m.\u001b[39munits \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 116\u001b[0m     axis\u001b[38;5;241m.\u001b[39mset_units(\u001b[43mUnitData\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m    117\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    118\u001b[0m     axis\u001b[38;5;241m.\u001b[39munits\u001b[38;5;241m.\u001b[39mupdate(data)\n",
      "File \u001b[0;32m/usr/local/lib/python3.9/dist-packages/matplotlib/category.py:192\u001b[0m, in \u001b[0;36mUnitData.__init__\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m    190\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_counter \u001b[38;5;241m=\u001b[39m itertools\u001b[38;5;241m.\u001b[39mcount()\n\u001b[1;32m    191\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m data \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 192\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mupdate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.9/dist-packages/matplotlib/category.py:225\u001b[0m, in \u001b[0;36mUnitData.update\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m    223\u001b[0m \u001b[38;5;66;03m# check if convertible to number:\u001b[39;00m\n\u001b[1;32m    224\u001b[0m convertible \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m--> 225\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m val \u001b[38;5;129;01min\u001b[39;00m \u001b[43mOrderedDict\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfromkeys\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[1;32m    226\u001b[0m     \u001b[38;5;66;03m# OrderedDict just iterates over unique values in data.\u001b[39;00m\n\u001b[1;32m    227\u001b[0m     _api\u001b[38;5;241m.\u001b[39mcheck_isinstance((\u001b[38;5;28mstr\u001b[39m, \u001b[38;5;28mbytes\u001b[39m), value\u001b[38;5;241m=\u001b[39mval)\n\u001b[1;32m    228\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m convertible:\n\u001b[1;32m    229\u001b[0m         \u001b[38;5;66;03m# this will only be called so long as convertible is True.\u001b[39;00m\n",
      "\u001b[0;31mTypeError\u001b[0m: unhashable type: 'dict'"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(data_label_custom)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "njT3xEyzuOSC",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2024-01-21T19:55:18.294674Z",
     "iopub.status.busy": "2024-01-21T19:55:18.294070Z",
     "iopub.status.idle": "2024-01-21T19:55:40.973243Z",
     "shell.execute_reply": "2024-01-21T19:55:40.972658Z",
     "shell.execute_reply.started": "2024-01-21T19:55:18.294651Z"
    },
    "id": "njT3xEyzuOSC",
    "outputId": "d85411f6-4f18-49ad-87f7-ea614f2e47f8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Archive:  AMIGOS.zip\n",
      "  inflating: AMIGOS/Data_Preprocessed_P01.mat  \n",
      "  inflating: AMIGOS/Data_Preprocessed_P02.mat  \n",
      "  inflating: AMIGOS/Data_Preprocessed_P03.mat  \n",
      "  inflating: AMIGOS/Data_Preprocessed_P04.mat  \n",
      "  inflating: AMIGOS/Data_Preprocessed_P05.mat  \n",
      "  inflating: AMIGOS/Data_Preprocessed_P06.mat  \n",
      "  inflating: AMIGOS/Data_Preprocessed_P07.mat  \n",
      "  inflating: AMIGOS/Data_Preprocessed_P08.mat  \n",
      "  inflating: AMIGOS/Data_Preprocessed_P09.mat  \n",
      "  inflating: AMIGOS/Data_Preprocessed_P10.mat  \n",
      "  inflating: AMIGOS/Data_Preprocessed_P11.mat  \n",
      "  inflating: AMIGOS/Data_Preprocessed_P12.mat  \n",
      "  inflating: AMIGOS/Data_Preprocessed_P13.mat  \n",
      "  inflating: AMIGOS/Data_Preprocessed_P14.mat  \n",
      "  inflating: AMIGOS/Data_Preprocessed_P15.mat  \n",
      "  inflating: AMIGOS/Data_Preprocessed_P16.mat  \n",
      "  inflating: AMIGOS/Data_Preprocessed_P17.mat  \n",
      "  inflating: AMIGOS/Data_Preprocessed_P18.mat  \n",
      "  inflating: AMIGOS/Data_Preprocessed_P19.mat  \n",
      "  inflating: AMIGOS/Data_Preprocessed_P20.mat  \n",
      "  inflating: AMIGOS/Data_Preprocessed_P21.mat  \n",
      "  inflating: AMIGOS/Data_Preprocessed_P22.mat  \n",
      "  inflating: AMIGOS/Data_Preprocessed_P23.mat  \n",
      "  inflating: AMIGOS/Data_Preprocessed_P24.mat  \n",
      "  inflating: AMIGOS/Data_Preprocessed_P25.mat  \n",
      "  inflating: AMIGOS/Data_Preprocessed_P26.mat  \n",
      "  inflating: AMIGOS/Data_Preprocessed_P27.mat  \n",
      "  inflating: AMIGOS/Data_Preprocessed_P28.mat  \n",
      "  inflating: AMIGOS/Data_Preprocessed_P29.mat  \n",
      "  inflating: AMIGOS/Data_Preprocessed_P30.mat  \n",
      "  inflating: AMIGOS/Data_Preprocessed_P31.mat  \n",
      "  inflating: AMIGOS/Data_Preprocessed_P32.mat  \n",
      "  inflating: AMIGOS/Data_Preprocessed_P33.mat  \n",
      "  inflating: AMIGOS/Data_Preprocessed_P34.mat  \n",
      "  inflating: AMIGOS/Data_Preprocessed_P35.mat  \n",
      "  inflating: AMIGOS/Data_Preprocessed_P36.mat  \n",
      "  inflating: AMIGOS/Data_Preprocessed_P37.mat  \n",
      "  inflating: AMIGOS/Data_Preprocessed_P38.mat  \n",
      "  inflating: AMIGOS/Data_Preprocessed_P39.mat  \n",
      "  inflating: AMIGOS/Data_Preprocessed_P40.mat  \n"
     ]
    }
   ],
   "source": [
    "!unzip \"AMIGOS.zip\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "GPftEcnHuJrY",
   "metadata": {
    "id": "GPftEcnHuJrY"
   },
   "outputs": [],
   "source": [
    "import scipy.io\n",
    "data = scipy.io.loadmat(\"AMIGOS/Data_Preprocessed_P32.mat\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "Hz_c9Dnoua7T",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Hz_c9Dnoua7T",
    "outputId": "09a9a543-7156-4279-eda3-45021ff3edf9"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 12)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#data['joined_data'][0][19].shape\n",
    "#data['labels_selfassessment'][0][15].shape\n",
    "#data['joined_data'].shape[1]\n",
    "#data['labels_selfassessment'][0][1][0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "SI3v-4-DTC60",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 463
    },
    "id": "SI3v-4-DTC60",
    "outputId": "390a5f34-c7ad-4e73-8513-95e2c0f068e7"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10191,)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.plot(data['joined_data'][0][16][384:,16])\n",
    "data['joined_data'][0][3][384:,16].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "WFGqncuxTz4s",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 463
    },
    "id": "WFGqncuxTz4s",
    "outputId": "2877bf49-f2b1-4a12-9a31-b245c833c2f6"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7bb4a0d7ec80>]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import scipy.io\n",
    "y1 = scipy.signal.resample(data['joined_data'][0][16][:,16], 8000)\n",
    "plt.plot(y1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "81e9e46f-88cc-4ba9-a64f-347034bea365",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2024-01-24T12:27:41.010673Z",
     "iopub.status.busy": "2024-01-24T12:27:41.009847Z",
     "iopub.status.idle": "2024-01-24T12:27:41.019098Z",
     "shell.execute_reply": "2024-01-24T12:27:41.017840Z",
     "shell.execute_reply.started": "2024-01-24T12:27:41.010624Z"
    },
    "id": "81e9e46f-88cc-4ba9-a64f-347034bea365",
    "outputId": "bcb347b1-3a4c-4281-e78d-5555e64d6a27"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['AMIGOS/Data_Preprocessed_P33.mat', 'AMIGOS/Data_Preprocessed_P30.mat', 'AMIGOS/Data_Preprocessed_P13.mat', 'AMIGOS/Data_Preprocessed_P26.mat', 'AMIGOS/Data_Preprocessed_P37.mat', 'AMIGOS/Data_Preprocessed_P31.mat', 'AMIGOS/Data_Preprocessed_P10.mat', 'AMIGOS/Data_Preprocessed_P09.mat', 'AMIGOS/Data_Preprocessed_P05.mat', 'AMIGOS/Data_Preprocessed_P40.mat', 'AMIGOS/Data_Preprocessed_P35.mat', 'AMIGOS/Data_Preprocessed_P32.mat', 'AMIGOS/Data_Preprocessed_P22.mat', 'AMIGOS/Data_Preprocessed_P23.mat', 'AMIGOS/Data_Preprocessed_P17.mat', 'AMIGOS/Data_Preprocessed_P04.mat', 'AMIGOS/Data_Preprocessed_P12.mat', 'AMIGOS/Data_Preprocessed_P34.mat', 'AMIGOS/Data_Preprocessed_P29.mat', 'AMIGOS/Data_Preprocessed_P15.mat', 'AMIGOS/Data_Preprocessed_P02.mat', 'AMIGOS/Data_Preprocessed_P25.mat', 'AMIGOS/Data_Preprocessed_P18.mat', 'AMIGOS/Data_Preprocessed_P36.mat', 'AMIGOS/Data_Preprocessed_P16.mat', 'AMIGOS/Data_Preprocessed_P28.mat', 'AMIGOS/Data_Preprocessed_P03.mat', 'AMIGOS/Data_Preprocessed_P38.mat', 'AMIGOS/Data_Preprocessed_P39.mat', 'AMIGOS/Data_Preprocessed_P27.mat', 'AMIGOS/Data_Preprocessed_P01.mat', 'AMIGOS/Data_Preprocessed_P19.mat', 'AMIGOS/Data_Preprocessed_P06.mat', 'AMIGOS/Data_Preprocessed_P24.mat', 'AMIGOS/Data_Preprocessed_P11.mat', 'AMIGOS/Data_Preprocessed_P08.mat', 'AMIGOS/Data_Preprocessed_P21.mat', 'AMIGOS/Data_Preprocessed_P07.mat', 'AMIGOS/Data_Preprocessed_P14.mat', 'AMIGOS/Data_Preprocessed_P20.mat']\n",
      "['P33', 'P30', 'P13', 'P26', 'P37', 'P31', 'P10', 'P09', 'P05', 'P40', 'P35', 'P32', 'P22', 'P23', 'P17', 'P04', 'P12', 'P34', 'P29', 'P15', 'P02', 'P25', 'P18', 'P36', 'P16', 'P28', 'P03', 'P38', 'P39', 'P27', 'P01', 'P19', 'P06', 'P24', 'P11', 'P08', 'P21', 'P07', 'P14', 'P20']\n"
     ]
    }
   ],
   "source": [
    "import glob\n",
    "import os\n",
    "filelist = glob.glob('AMIGOS/*.mat')\n",
    "print(filelist)\n",
    "subjectnames = [fr[25:28] for fr in filelist]\n",
    "print(subjectnames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "74fe1cd7-c31d-44dd-8537-27f357d17096",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2024-01-24T12:27:43.767214Z",
     "iopub.status.busy": "2024-01-24T12:27:43.766709Z",
     "iopub.status.idle": "2024-01-24T12:28:15.737745Z",
     "shell.execute_reply": "2024-01-24T12:28:15.736680Z",
     "shell.execute_reply.started": "2024-01-24T12:27:43.767182Z"
    },
    "id": "74fe1cd7-c31d-44dd-8537-27f357d17096",
    "outputId": "b02ad912-56e9-45b3-dd39-d9d46bc0a2d4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "P33\n",
      "P30\n",
      "P13\n",
      "P26\n",
      "P37\n",
      "P31\n",
      "P10\n",
      "P09\n",
      "P05\n",
      "P40\n",
      "P35\n",
      "P22\n",
      "P23\n",
      "P17\n",
      "P04\n",
      "P12\n",
      "P34\n",
      "P29\n",
      "P15\n",
      "P02\n",
      "P25\n",
      "P18\n",
      "P36\n",
      "P16\n",
      "P03\n",
      "P38\n",
      "P39\n",
      "P27\n",
      "P01\n",
      "P19\n",
      "P06\n",
      "P11\n",
      "P21\n",
      "P07\n",
      "P14\n",
      "P20\n",
      "dict_keys(['P33', 'P30', 'P13', 'P26', 'P37', 'P31', 'P10', 'P09', 'P05', 'P40', 'P35', 'P22', 'P23', 'P17', 'P04', 'P12', 'P34', 'P29', 'P15', 'P02', 'P25', 'P18', 'P36', 'P16', 'P03', 'P38', 'P39', 'P27', 'P01', 'P19', 'P06', 'P11', 'P21', 'P07', 'P14', 'P20'])\n"
     ]
    }
   ],
   "source": [
    "import scipy.io\n",
    "import numpy as np\n",
    "data_am = {}\n",
    "skiplist = ['P28','P08','P24','P32']\n",
    "newsubjectname = []\n",
    "for sname in subjectnames:\n",
    "    if sname in skiplist:\n",
    "      continue\n",
    "    newsubjectname.append(sname)\n",
    "    dname = \"AMIGOS/Data_Preprocessed_\"+sname+\".mat\"\n",
    "    x = scipy.io.loadmat(dname)\n",
    "    print(sname)\n",
    "    samples = []\n",
    "    samples_labels = []\n",
    "    for i in range(x['joined_data'].shape[1]):\n",
    "        x1 = x['joined_data'][0][i]\n",
    "        x2 = scipy.signal.resample(x1[384:,16], 8064)\n",
    "        y1 = x['labels_selfassessment'][0][i][0][0:2]\n",
    "        samples.append(x2)\n",
    "        samples_labels.append(y1)\n",
    "    samples_stack = np.vstack(samples)\n",
    "    samples_labels_stack = np.vstack(samples_labels)\n",
    "    data_am[sname] = [samples_stack,samples_labels_stack]\n",
    "\n",
    "print(data_am.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "qnHCy6Wra5Fu",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2024-01-23T17:40:53.953293Z",
     "iopub.status.busy": "2024-01-23T17:40:53.952576Z",
     "iopub.status.idle": "2024-01-23T17:40:53.959076Z",
     "shell.execute_reply": "2024-01-23T17:40:53.958338Z",
     "shell.execute_reply.started": "2024-01-23T17:40:53.953266Z"
    },
    "id": "qnHCy6Wra5Fu",
    "outputId": "9d1b17db-cde0-45d9-96ac-fdac666f660f"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 352752.75757016,  340695.26701584,  345245.88159057, ...,\n",
       "         403151.38268723,  400679.04194615,  404946.0279466 ],\n",
       "       [ 471648.201222  ,  476111.50729626,  466441.52852125, ...,\n",
       "         385886.98152216,  370736.44969109,  391224.58221217],\n",
       "       [ 308871.62468535,  267035.20246687,  281191.73019391, ...,\n",
       "         418338.95394208,  409561.91839521,  423958.94748972],\n",
       "       ...,\n",
       "       [3063300.25374425, 3016321.83044657, 3027937.98976638, ...,\n",
       "        3108195.81938931, 3101347.58134486, 3112317.15638647],\n",
       "       [2968989.46665344, 2978423.46722672, 2978818.8192308 , ...,\n",
       "        2952573.08633564, 2957185.08475368, 2952653.76543327],\n",
       "       [3293220.12597169, 3088031.21347438, 3139736.03735517, ...,\n",
       "        3512094.50044457, 3481899.40552601, 3534839.09257561]])"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_am['P01'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8976cde3-bc3f-4fcb-a8af-d624fcde1675",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2024-01-24T12:28:25.607582Z",
     "iopub.status.busy": "2024-01-24T12:28:25.607203Z",
     "iopub.status.idle": "2024-01-24T12:28:25.651085Z",
     "shell.execute_reply": "2024-01-24T12:28:25.650169Z",
     "shell.execute_reply.started": "2024-01-24T12:28:25.607547Z"
    },
    "id": "8976cde3-bc3f-4fcb-a8af-d624fcde1675",
    "outputId": "35ec17fd-7d92-4bb3-a961-3339979bfbc7"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "data_cam = {}\n",
    "for k,v in data_am.items():\n",
    "    y = v[0]\n",
    "    ym = np.mean(y,axis=-1).reshape(20,1)\n",
    "    ystd = np.std(y,axis=-1).reshape(20,1)\n",
    "    z = (y-ym)/ystd\n",
    "    #print(z.shape)\n",
    "    data_cam[k] = [z,v[1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "kgzh85M-Zyyx",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 448
    },
    "execution": {
     "iopub.execute_input": "2024-01-23T17:03:38.186897Z",
     "iopub.status.busy": "2024-01-23T17:03:38.186243Z",
     "iopub.status.idle": "2024-01-23T17:03:38.291886Z",
     "shell.execute_reply": "2024-01-23T17:03:38.291173Z",
     "shell.execute_reply.started": "2024-01-23T17:03:38.186872Z"
    },
    "id": "kgzh85M-Zyyx",
    "outputId": "10010e12-e6d0-4189-ccc0-b9350a6cf1af"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f6a276410a0>]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAiIAAAGhCAYAAABceN/BAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjYuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/av/WaAAAACXBIWXMAAA9hAAAPYQGoP6dpAABog0lEQVR4nO3dd5wTdfoH8Cfbsr2wwMLCssvSey8LiCAoIPauqKCeFc96KqiIdxb4qefpKWI5BTvqKeJJk96LlKWz1IWl7lK2s9mS+f2RTEsmyUwyk5lJPu/Xi5eTZJJ84+4mT77f5/s8FoZhGAIAAADQQYTeAwAAAIDwhUAEAAAAdINABAAAAHSDQAQAAAB0g0AEAAAAdINABAAAAHSDQAQAAAB0g0AEAAAAdINABAAAAHSDQAQAAAB0o2kgMm3aNOrXrx8lJSVR06ZN6YYbbqCCggItnxIAAABMRNNAZNWqVTRx4kTauHEjLVmyhOrq6uiqq66iqqoqLZ8WAAAATMISzKZ3JSUl1LRpU1q1ahUNHTrU5/l2u51OnTpFSUlJZLFYgjBCAAAACBTDMFRRUUGZmZkUEeF9ziMqSGMiIqKysjIiImrUqJHk7TabjWw2G3f55MmT1Llz56CMDQAAANRVVFRELVu29HpO0GZE7HY7XXfddVRaWkpr166VPOfVV1+lv//9727XFxUVUXJystZDBAAAABWUl5dTVlYWlZaWUkpKitdzgxaIPProo7Rw4UJau3atx+jIdUaEfSFlZWUIRAAAAEyivLycUlJSZH1+B2Vp5vHHH6fff/+dVq9e7XWKxmq1ktVqDcaQAAAAwAA0DUQYhqG//vWvNHfuXFq5ciW1bt1ay6cDAAAAk9E0EJk4cSJ99913NG/ePEpKSqIzZ84QEVFKSgrFxcVp+dQAAABgAprmiHjacjtr1iyaMGGCz/srWWMCAAAAYzBMjkgQS5QAAACACaHXDAAAAOgGgQgAAADoBoEIAAAA6AaBCAAAAOgGgQgAAADoBoEIAAAA6AaBCAAAAOgmKL1mAAAAwFh2FJXS3O0nqU3TRLpnYLZu48CMCAAAQBg6WFxJs9cX0pK9Z3UdBwIRAACAMCbdjCV4EIgAAIAmlu07S3/5cgudr7TpPRSQYJQ2LAhEAABAEw98uYWW7jtLj367Te+hgAQ2DPHQnzZoEIgAAIDq5uWf5I43H71gmG/fIOD8kWBpBgAAQs6Tc/JFlz9aeVifgYBPFp2nRBCIAACAqqRmP95eXKDDSMAbhowxS4VABAAAVDV3+0nfJ4HuSqvriIjoTFmNruNAIAIAAKp65scdeg8BZJi2cD8REe09Xa7rOBCIAAAAgG4QiAAAgGq81QypqWsI4kjALBCIAACAavq8vtTjbZW2+iCOBLxZc7BE7yFwEIgAAIAqymvqRJez0+Npxl29ucu3fbwh2EMCD+75fLPeQ+AgEAEAAFXc/NF60eWVfxtGY7s35y4fOVcV7CGBCSAQAQAAVRwsrhRd1rtQFpgDAhEwhdp6O035dTct3nNG76EAgARbvTgRdekzl+s0EjCbKL0HAOCL3c5Q+5cXEhHR1xuP0bYpV1KjhBidRwUAQrPWFYout26coM9AwCe73RgVVVmYEQHD+2T1EdHl3q8toYqaOtpRVErHz1fTj1uKqL7BrtPoAMBuZ2i6szgWEVHLtDiKjOCXZZ4c0Y47rq3H36recl9coPcQRDAjAob3f4v2u13X7dU/RJc/WH6Q1jx/RbCGBAACy/YXiy6veX646PLt/bLo/WUHiYjoyTnbaebdfYI2NjA+zIhASCi6cEnvIQCErb2nxCXCXZNUGydaueOFu5HnpafrZ6xzu044e6UHBCJgaEdKKn2f5PTknO0ajgQAPPnX0gNeb4+JwkeNEdTUNdCOolLRda9e25lWPTdMl/Gw8NsBhnbFP1fJPnde/ikNRwIAciTERHq9vUdWanAGAm6OX6h2u27C4NbUMi1eh9HwEIiAYVW5lIOeck1nnUYCAJ6UVIh7yzw/uqPkeR2bJRERuX0jh+D5cPkhvYcgCYEIGFaXqYtFlx8Y0preva2HTqMBACn93hD3lrk3L1vyvIG56cEYDnjx2w7xrPGvEwfrNBIxBCJgCs2SY4mI6KbeLalw+liP56G7J4B+tr480mM11a4tUrjjnSdKgzQiYK09eM7tup4GWSZDIAKGtOqAuDPkl/f3F12eOc7RSKt5Sqwo0QrdPQGCZ/8Z8W6ZdMHuGFddMpO543wszwTd3Z9v0nsIHqGOCBjS+C/EnSE7ONeXWWO6NZecGfljz1m6a0ArTccGAA5bCi/KPrdTcz4QuVSLmUvgYUYEDO+jcb19n+R0WMF2XwAITGp8tF/3+3FLkcojAW/mbD6u9xC8QiAChuOaVT+mazOf9+ndKpWIHEs1ABAcj3/H1+5Z/NRQ2fc7XFKlxXDAg0m/7NJ7CF4hEAHDca38J6eVeEfntG+VDVO+AHpwXT4FY7q5d0siInpC0P9Hb8gRgZAQH+0oolRdh2RVgGD43w4UEDSjt27pTpOv7igqu683zIhASIi3OmLqasyIAATFX79X3lIh0cp/92UYY7WiD1WunckjIyyGCkKIEIiAwbj+0fz2uLyCO/HOstLVyMYHCLptU66Udd5rN3Thjo+eQ55IMOwwQc0WBCKgmotVtXT9h2tpzubjfn/bmTDrT9Hl7i1TZd0vgQtEsDQDoDXXwoGNEmJk3a9DBr+F95dtJ1UdE0ib8use7nicQUsbIBAB1fR6bQntOFFGk37ZRe8u8d6N05O1h/jqf/97fIjs+8XFOKZ8qzAjAqC5mz5a79f9MpL5JQEktwbmsW+3Us6k+bRo92mP59TW22nvab7o3GvXdw3G0BRDIAIBq7LVU86k+aLrPlh+iIokOj0q0a1liu+TnNKc9QyKy2sCek4A8E344fb+HT1l309YefWD5QfVHFJYKS6voQW7zhAR0SPfbKOvNxRKnvfQ11tElyMifO9A1AMCEQjY499tk7z+srdWKHqcswEEEZmpcUTk3gkUALR1fc8Wft3vTBm+NPij0lZPw99ZKbpuyrw9kueuLOBbZTw2rI2WwwoIAhEICMMwtKKgxPeJMryzuMDv+0Y5I307MvEBNHWy9FJA92eXZ+7Ny1FhNOHnlXm7JZeg5+W759wMzG3EHf/tqg6ajisQCEQgIG/M36faYx07zy/lfOXS5M4XtuiZHXEIgKYGT18e0P3TExyByIcrDqkxnLDjKcn3yTn5btdtPHKBOzbqsgwRAhEI0H/WHhVd/nx8X9Fl1+24njTYGdpcyP/RDG3fRNE42L8xzIgABM/dA5XvwhDml4B27IJvZT2yUvUbiAwIREA1Ewbl0IhOGZTbOIG7bvcpeW86d3y6IaDnjmSXZjAlAqCZi1W1osv+7MK4sZd/OSXg3rV4zfPDRZeX7z/LHb88bzd3fM/AbG0HFiAEIuC3L9cXii4/c1V7IiJ6ciTfw0Buu+8/Be3EWzgTT5VgJ0KqahsQjABoxHU2Q04fKFcjO2UQEVH/nEY+zgRXF6v5QHD6Td0oq1G86Pb7Z/O7ZL7bxHfczWuTrv3gAoBABPw29TdxpnZyrGMLrTCL/s7PNip+3HF+TPcK/0DPVWHnDIAWCs5UcMfXdG/u12NYoxwfO7Z61PxRqkHwJWtUF0dX8pV/GyY6x3XWisi/L3fBhEAEVHF1t2Z+3/fERXG9kZt6tVT8GJ2a8xUb6xowIwKghX/8vpc7/vt1Xbyc6Zk1mg1E5OWPAU8YvKU5q9nmCJbCiYju+WJTUMekBgQioIoP7+zt931nrSsUXW6WEqv4MWKjIymG/aZVh29aAGr7eesJ0eV0PxunxUQ6/k73C2ZXQJ5LtY7grbmX98jdJ8tpryA37/nRxt22y0IgAn75ZuMx0eVAtoZ9Lth5s/+10X4/Drs0VCtzpw4AyPfsTztUeZyii3wdErm76sDhcEklERGddikGt/XlkaLLV/97TdDGpAYEIuCXl3/lM7Jz0uO9nCk/YZXIMbPhL27tuQ5vbgBqcm1i+e1fBvj9WN0FrRvQG0qZ33dK95XxNjt1XY9MrYajGgQiELCvH3B/UxK+UR0qrvR431oV14mx9gygjSPnqkSXB7dt7Pdjtc/gm91V2tAtW4kRnZoSEVGqs7eW0KguGZL3MXqiKhECEfBDflGp6LLrFjIi8RvVtR+u9fhYCwWdI3u1Sg1oXOzaM7LxAdR1tKTK90kKNHImWlbWIBBRgv3iNriNeyD4yT193a67a0Arv7ZYBxsCEVDs9k+UFR+7vW+Wx9tenssv8cy+T1lZd1dW57IOlmYA1PWXr7b4PkmB1DjHN/rSavetpuBZjTMRn5399eXNG7tpORzVIBABxYRLH1d0bOrz/OIKz102KwRTsylx7tONSkQ7E2brUdAMQDWuOV6F08cG/Jjs1tOLCEQUueQMRDzl0u35+yhKd/6/nX1fv6CNK1CaBiKrV6+ma6+9ljIzM8lisdCvv/6q5dOBDj69p4/Pc9TqzutLJBeIYEYEQC0/bilS/THT4h0fluclim+BtAY7Q+8tPUhERBuPnJc8J8EaRVunXEmF08fSsA6+vyQahaaBSFVVFfXo0YNmzJih5dNAEO0+WSa6HBXp+VeotUuhHa1FRToCkQbMiACoRlhBedwA5VWPpbDf2qWqgIK01Qf5L3RHVM7Z0VuUlg8+ZswYGjNmjJZPAUH21uIC7vihoblez72qSwZ9suoIETma0bnWGqkT1BAY0DrwvhNREY6gqB6VVQFUUVwuXladeq1/1VRdsUszF6rqVHm8cHDfrD/1HoJmDJUjYrPZqLy8XPQPjGX1AT4qv6u/929H13bn96//WXjB7faftvCVGoUl2v3FztbsOFEa8GMBAFGRS/sFtnpxoBolOPLB/MkRKa2uFfW8CUcPX+79S6DZGCoQmTZtGqWkpHD/srI877YA/WX7KGQmLNX+3ebjbre/OHcXd/z0le0DHg+73vzVhmM+zgQAOW6eye+Q2/TiCNUel80RueDH0ky/N5bSqPdWi8qYh7qfXPJ0Jo/ppNNItGGoQGTy5MlUVlbG/SsqUj9JCvx3pERcmMzX/vTGgmp/vnbEBLpjBkApO3KJFMlIVt4DyhM2EPFnRoRtarn+8DnVxmN0z/13p95D0JShAhGr1UrJycmif2AcV/xzFXc8YVCOovsu31+s8mgA/JdfVEq5Ly6gnEnz9R6KYWnZByY+xrH9VEn7ByKiogv8UlFpdXjml8wy0bZcuQwViIB5vDxW2dTgCUGjKyKisjB9EwFjuGHGOu545srDOo7EuNq+tJA7zvSjI7Y3sWwgorBT9mVvreCO68Jkm36hS3n94SbaliuXpoFIZWUl5efnU35+PhERHT16lPLz8+n4cfd8ATAXb9t25ej35lLu+MWrOwY6HAC//d+i/XoPwfB+f+IyVR8vNsoRiNQEUAXZ9QM6VO0+xZdMiI40frl2f2i6fXfLli00fPhw7vIzzzxDRETjx4+n2bNna/nUoLLq2sB7QjAMw+WVCJvdXdejRcCPDRCI4vIaaqpiDoTZueaDpaqcwxUXw7Zj8L8v1OI9Z9UajqE9/t127vjHh/N0HIl2NJ0RGTZsGDEM4/YPQYj57Pdzu9xrN3Tljt/5o0DynGYqT/sCePPdJvcZ2ed/Du1kQKX+t0Pcbt61BlCgEpyBSFVtveykYdeaJuGoS2aK3kPQBHJEQJaDZ/lAZOkzl8u+3x39+C3YM1YcJlt9g+iN54aemVJ3A9CMcNs4a+3B8NmBIccuQQXlLya4d3UNVIqzjb2dEfeb8qb/m8tUH4fZqFXHxWhC81WB6l74mX/zbts0Ufb9ol1ySdYcOEcHi/lp3woV24C/c2sPIiJq0yS4peXB/NAoUWzpPn7Zo0+rwKseu7JG8U3bMNMBCETAJ4ZR7036L19toVHvreYuq1HIjJXm/JaVaNU09QlCUJTKSw9m5vr3zs5eaGXaQiQLy5Gq8c9BTwhEwpDSwOKwIHFN7Tfsri3UW/Nkd/LUotcMKIQZEd6KguDW/Nl2/GJQn89MhKXsu6n4Xmk0CETCzDUfrKHWkxdQflGp7PuMfJefwfjwrl6Kn/PtW7orvo8/2K1tWhZiAuPbfvwiHSmplEyCPItlAJ+W7uMDkb9e0Vbz57vTR88qIqLiCv7nNmmMY7t/v5w0zcZkFHO3n+SOh7ZrouNItIVAJMzsPunozyAs6KTEqC7NFN/n1r7SPYMykq2S1/uLzUepQyAStjYcPk83frServjnKmr/8kK32wcIEh7HdmtOV3bOCObwTKFUUHb9Ng9/u2q4Ny+biIiiZcyy9n+D/7nlOHtcVdn83/prFh+v4ovtjVdYzdpMEIiAIr76yyjx4GXqdpDkAxFMs4erOz/byB3X2xnRrIhrNd/37+hJDw11/A5aQ3Q3gj8W7DrDHWc18t7YMhANzp/NhiPnFd0v3dnDSmlVVjPqk83P+oTqjhkiBCIQJFJfepT2q/GFzV/BjEh4klqSy31xAXfc4x9/iG6LiozgAhBbvR1N8EjdxHRfvnXWc/mz0HuOiOuY2J+ZsChiqNp6LDzyZxCIhBHXkshyGk4JKyz2apXq93O7VgQseH10wGXiXbHfGJB4GJ6EW06FGIahskvSvY2EW9Hl1rMIZcFMVL2uh7waQuerxB16Y7jgMfRnRFhpIbxjhgiBSFgZ9s5K0eVOryzyeR9hx122Toc/+uY0oh1Tr6KnRraj7VOuFNURUAtmRMLbI99sk7y+9eQFNOztFaLrxg1wJEjGx/Bbvbdj9wYdKeG/rAiXBbRw4mK175OI6IBLMUX2vcMWQJ8aMzhVyjcKnTGut44j0R4CEZCtTRP5hcykpMRF01Mj21NaQoxKIxJDsmr48rUb5qJLfshTI93r17z2+15Vx6QXu52hihr/ulv/bydf2v1pif9HapLb2uGuzzZxx22bJoqW00KZcBYvPUHdxH6jQSASJg4VV/o+yeTYQKQeyaphp8YlcXHnq1d5PPe923tSkyT3N3YlFYONauOR85T74gLq9uoffs3w7BBs6x/SrrGKI3P3wJDWft2PyxFpCO28nqOCpfQWaXE6jkR7CETCwMWqWhr57irJ27y9WZX7+a1KL1wdETsT1KQ70N+nq49wx69c05mSYz2vqd/QS9ztuZVzZ8iQttp+8AbDHZ/yu4Zu/Gi9jiPxTdjeQckspjWaX9atDeHZz8e+5ZcaQ71aNAKREFfXYKdery3xePufhRc83tb9VX6XwY5XPH/DNAph8msov0GBu28FHXW7t3RUoDz0xhhZ92WTsM0+1W+22QHh1mBPycRShFutQz1PJFwgEAlxAyQ6VvpTCkTrfhNqiBEEIlieCR+uH8DtmiYRkSMw/fqB/qLbFj811O3+0ZH8VL+ZfbbmiNt1rktW3gh3yAWjcaQw5+zYeenEVeHP9vL2jsqiUREWrhyArSE0d86cr7TpPYSgQiAS4i64bH3b8cpVtOCJy7jL/1lzNNhD0gy7NEOEQCSczFpfKLosDJova9eEfnlsEOW/ciUVTh9LHZolud3/tx2niIjoq/XHNB2n1qSax+0X9CrxRbhD7pVru6gyJrmEFUSF8k+UcsdvOVtFWCwWfgtviM6ICLudhwMEIiGqtLqWcibNd7s+KTaKOjVP5i4XV0hH3nK31hlJZISFm+0x+7dbkG/2eu/BdO9WaZQa73mnFlsY64zJ+tAUV9T4XI7515IDfj02O/sQLJ6eb4FgF09KHB9gclt4Tb6c5smWY/yS+W+PD9ZxJMGBQCRE9fyHe17I5e2bUITM7rlfCr5l/vLYILWGpSmLxULREdjCG26ESY/+eGpkOyIiurqb8j5KellRUEz931hGT/6QT0REH608JHneqgMlQRyVcmyvnwgP68XCrf6xgiTVOOexnKKMZsMwDJUKtpvnNNZ+mUxvCERCDMMwkjMhRESv39BV8nqpD+3PBEs23U3UfppdnkEgEh4KzlSI3rRH+9GUMd35YWemjVYfrXAEHv/bcYpOlV6itxYVcLfJ6WZrFGxAUV0rHUwu3H1a8vp4q+N+VR7uZ2ZfrCsUXfa2AyxUIBAJMZ5KNL92fRdRlrqwvPLC3Wek7sJRuxS7lqKj0PgunDz/3x2iy/5UoGS/aZupiZowuXPQ9OWi2+4fnEN3D1QWjAiXeG7q3cLLmepKYAMKD5102W7hrtjtrFUhWJZfWFivS2aylzNDh3k+YUCWw8VVktffk5cjujwwN507fuL77aLbiivMtVYuFIWlmbCy40QZdzxhUA5Fylx6FIqLMdc0/6oDJR5zu4iI2mUk0eguzYmIqHGivIqcwu2zQ9sFLz8kyflt/2Spspy0BGdp/soQC0Q+WHZQdPmWPi11GklwIRAJMW8s2Ce6HBcdSXMlcjzu6Jcluizc5tf/DX7L732Dc9QdoMZisDQTtqZc09mv+8WZaEaEYRga/8Vmn+exS5TnKm2y/haEH+gJQSyete7QOSIi+nHLCbfbhN11Hx6aK7qNnUmpNknwKNc/XZKL7x6YrdNIgguBSAi7Z2A27XttNPVq5d68KiLCQlmN+LLBf/vJMcW995R4KnTcAHP9IWBpJnz5MxtCxH8rL1dQVEsvrScv8Hp7hwzH9uQGwVKL6xZ+KcIZkWEdgjcjsueU9NILkXiZ+dmrOohuY3fN1IbQrhmpHVDRJloWD0R4vMowMfmXnaLLo3wk7l0mmIL9fedpstU30NX/XiM6x2z9N9D4LnyoVcaf3RaqpLqnUbFfLqzR/Fu7nACLTQq1RkUE9cPPUwI9EZ+QS0Rc3RDXy6H0dz5vx0m9h6AbBCIhouhCNX2/uUh0na8viDe7JKV5+3ZiFlERWJoJF8LZgcsCaNDGBiLlNfWG7lEkr0qq4/e/QzM+yfFcpe8ZkRkrHAXFgl2XIzudT6B3nREQ5v+4YpeeQqGOyH+3nqDrP1xLT/+ww/fJIQqBSIiw1bu/SfmqGdInu5Ho8k0uTbJapJqv42MoflMC3z68S/luGRa7FbTBzhi6EF7HKYtElxc/NZTuzRMvnbLlOBKtUdTRWUX2fJVxy4VXCmrAKJmRCpWZzwY7Q3/7aYdk0HVTr+DtXtIbApEQYZEoCOSpSJBca18YHtD99cC/QRn3my0Ebv8Z8eydsOqmUlGCgL3BJI3j3r+jJ3VolkRPj2xP/XP4LxTCv/hcZ7+Y8z5mRIRbYEd0bKrqOH2JjeGLlCkJKtgvHGbPEVl1QLrcAhHRP2/rEcSR6AuBSIj4n7NfhpCc3D1Pb+APX54rGdwYHZZmwsPXG9TrC8Nu+SYyT57IiE6OiqRpCTH04yN53PXCP9n0BMfWXV8N1I6e47f8PzWyvYqj9C1SMODDJdKlB6TEhMiMyP2zt7hd99vjg6lw+lhTvv/6C4FIiPhopXTTKF8ectkWx3r2yg6S1xsdlmbCQ2tB2evcADvFCmdE9p02Zp6Ua42TRA9bbC2COZH0REfF2BOll7w+9m2fbOCOI4L8idA7m9/R99JcvtGbMF9EOOPDCpUZESldM81TyVotCERChL9/kI8Na+N23UfjertlqZsFlmbCw+vz+Xo5X93fP6DHEuZSxUZFejlTP8KlqKXPDPV4XpxgqeN0qaMw4S/bvO/GENbi8HcLtL+EAdWpMj5gEnYNnnVfP7f7sX/ntSb+O5cqa//a9V1k9wMLJeb8tAHVSE3/Xd2tuQ4jUQeWZkLf+sPnRJdbpsV7OFO+HlmpRERUpVKBrHOVNo/9U/xx7+d8EbO2TZPcbn/thq7UISOJXhjdkbvOn8Tb9hKPHSw1dfx4hU03pQqshcKMyJNz8kWXC6ePdauAHS6CV0IPNFPsoX15s5RYxY+16cURgQ5HV1xBMxO/QYF3d322SfXHTIjx3nxNLoZhqO/rS+m8s4jY4TevVmWWocJHKfN7BmbTPS5VOG/t25Lmbj/JjUtOzoFRvo3/sKXI6+1m3zVTXF5DS/ae5S7HhEnhMk/C+9WHCOEa7yvXdKafH82jz8f3lf1Nka3B0DTJShnJyoMXI2H/oOtNsvsBlHGtpTFhUI4qjxvv7F0SSMnwKls9tZ68gAtCiIjavOi9EqqW2KUZIvFSRygw+4zIey49ZeZOdG/DEU4wIxICCgWdOO8bnKM423rWhH5UeL6a2gSY9GcEbKEjI9eDAP/9/X97RJenXutffxlX8TFsF1j/Z0S6TF0seX3BmQrq0Cz4Sx7DBVtxP1t9hN69vafbOUYr4CZ35sbsPaUOna0UXe4ShgmqQpgRCTH+bPmKioygtk0TQ2K7WBQ7ZVtvrDdYo1q+/6xbfyEjE1YP/uDOXqr9zgbaRG39oXMebxv13mq/HpO1aPcZ7vjju/vIvl+jhBju+ECx9IxIaTW/XfnbvwzwY3SB+8f1Xbjjg8WVsoIjbkbEpIHI5sILeg/BUBCImNzuk57LIIejUKkvEAwbj5yn+2dvcesvZET5RaWUM2m+6LoRndQrvhXo0sxd/1E/b4U1bSG/Q6hbS/++OV/TPVPy+q838vVY+klskw2GoYKeV6sPlIiSVj3hds2YdGlG6IsJffUegu4QiJjc9uMX9R6CobBLM3V2879BaenY+Sq649ONeg9DthtmrHO7jg0e1BBIsqpU0Lvib8MCHRLnmGDptbnCHC62BsdCwayK0LuCtvPs306w5Qhqwrw+fx+dLvNe94TI3F84XMd8RccMnUZiHMgRMbkp8/g18ydHtNNxJMaApRl5Ln97pd5DCAi73VYtcc6gpsqmfEbkT5dp9iNvXu22+6SmroFiowOvUaJ0V8vhEkcuwo6iUrfbXPtTGWVp9p9/HPB5TrSJl2Z+2nJC7yEYDmZEQsjE4W31HoLuzL6tTy/echyMaOY4/5vcSWFzRC7VKZ8ROVQsTjxkg4XpN3Xjrpu1rtD/wQWgcaKVO653+ZtQs0y+mnbJWG6OMfEXjvwifhY7yiDbpfWGQMTEXNtmm7UaqpqinX/Y9Via8aiixr2fipY5DlrIVLkzdHwAMyKvCGYl/3kr36jspt4tueMjJeJgRS5h8CBV6tyXF8d24o73nRYnrAqr017drZkfo9PG8QvVPs8xa7LqlsIL9KNgRmT5s8P0G4yB4JPLxJB57S4KJd596vbqH3oPQZGlgsJPRERv3dxd9efwN0fEtVvvzX344EP4xeCnrf5Nxy/fz3dnffhy6b5Q3rQQBGxz/jzu8bxeWWkebwuGZ69U1mzPrMmqt3y8QXS5VXrgVYFDAQIRExNOrQq/iYUzNuHOdRoazOsvX4k7lN7Qq4XqzxHH1RFRNiNSrnG33jUH+SWzwW0bK76/sDbQt5s8ByKxMfr22Hn8CmXLyjGR5pwRERrcNl3vIRgGAhETm7/rNHcs/CYWziK5pRnMiEhxrUxqdK41Jd66ubsmS5BsP5NLCv///LbjlOpjERJur7X68bpdE1BdZ3BYIzqqtxXaH54SZa/rIb3tOCbKfAXNXP/23ru9l04jMR4EIhBS2KWZeizNSBLu8HCtpGu0KptERNMX7hddvq1flibP429l1am/8fkhW18eqeqYXKmxq+XV3/ZIXh+nwo4eLVzhIUCKiXSM10xLM8K/vfF52dQkyerl7PCCQMSkjPihYQRIVvXuHkEX11kT+otuM2JezSerj3DHL13dycuZgUlQoddMeqL7B8uMu9Td3eMPYW4JO8NSWl0rOic5LjqoY5LLU+wVHcUuwRrvd9YT4d+esHYKIBAxrb2nzVOWO5iQrCpfViPxzhOjr7ff7dJdVk3cjEhtvapBforgA951l5svnpZRlHpgcGu36x7/brvoshodgtWWkx5Po7pI7+aJiuBzRMzwpcz1Z49tu2IIREyq6AJfffCbB/TpEWFEXLIqZkTcuG7btVgs9PYt/A4Um8HzR+I0TKiMd+aIMAyRTeZ0v5x8m86ZydzxNoVVkIX1NLID2F3R2GWmptJWT2sNWDdm3sTBossrnxvusQgcm6xKpF7ApqXpi8RLjC0bYbeMEAIRk3rkm63ccf/W+vSIMCL2mx1mRNxd8c9V3HFeriNjX9hfRO4HcLAcEjRqu72vNrkhLGGOhNw8kf1n+PHd1Ft6J0+8IHg6VVajaEwbj5znjt+9zf9dca7VWAvOiGdTu/vZv0Ztwmq5Y7s193pulKAcvRn+1j8VLDE+NDSXhrVv4uXs8IMS7yEAhcx47JStGb4lBVtJhY07/vedjox94Vq10QKRke/yXWu1rhocGWGh2OgIqqmzU3VtA8nZWPnvZQe54+dGdZA8R/iNflVBicddIFJWFvA1RHq3CqzOR8u0ODpx0TGL6pr0+t9HBgX02GraOHkEnau0UdcW3oOjaMGMSJ3dTnFkzGRbIqJdJ8SVYl/UMNfJrPAJBiEFdUTkEWbss1P3rr1HjMQ1n0ULbMJqlcyiZsJiY8mxvpM9f96mrKjZxiP8LotAd8yIKr5+tF50m5G+yDRLifUZhBCJG/TVGSyAdnXth2v1HoLhGec3EPySGm/MbHe9IFlVmrfALC7G8f8skB0jWgtGQ7Z4K1tdVfn/B7YOiVG1y0jSewiqslgsXMKnUWsG1dbb6W6X1gkbJ4/QaTTGhkDEhLYLkt66yfj2EE6wfVfa+sN8vkEPl5yA1LgYInLf0hluuC28fvSbMbpGCTGS1392b98gj0Q9bJ6IUWuJPP1jvltScLOUWJ1GY2wIREzoRsHU6nQN+m6YGVdZFTMiIn/5ki+T/vDlbUS3pTk/pC5UaVuuXIlVB0q4Y0/5F2qLE2zh9aVSYeEzpbR4/DFd3bfCXtk5Q/XnCRY2T8SIMyKl1bU0f+dp0XWYvfYMgYjJtVC5C6nZRTvXu42WeKk3YY2QEZ3E1SobOd8gL1YZZ0Zk/Bd88ae7B2hXP0SIL2rmOwj4dftJ7riLYIuuWu6bxb/+h4cqb3Yn5aNx4uJqT45op8rj6iWaW4Y11t/6oeJK6vmPJW7XY1nGMwQiJmO2XiHBxiYNSrW6D1euBZ+sUeIdBmxezbebjpERpQTpm2R8jPwckR/+LOKOp1zT2eu5uX5U0fyzkF9+VauQm8ViobZNE7nLTyvseGs0bMKq0QKRke+ukrzen15B4cLYGVbg5vO1R7njeJ07ZhoRm8BmwNla3fy4hf/QbJ+R6Hb7f50t6gvPVwdtTN4UXdBnHGzCqZwcEWGxsYG53jf7vn1rD7p5pmM5lWEYxYm3LdPUm/Vc+szldL7SJlmO3mzYrfpGSkw/dr5K8vr1k64ISsK1WSFEM5m3Fxdwx18/0N/LmeGJzRFBHRHeCz/v4o4fHdbGy5nG8H+CKpTCPilaU5IjooSwueC5SuXLX2p/gIVCEELEbzs20lb9ZfuKJa/PxBK6VwhETCzQIkehCIGId9f3cK8A+n83d9NhJJ79Lkjyu7a7/AJggUpwBiKXVN7GnBrP71g5W66suip4xs5+GqlH0qGSSrfrjrx5tQ4jMRcEIiaGqT537JtTgwkaYQWDa36Ia7lvIqLcJo7lmtYG7Agqp7iVWuIVFjQjIpo8pqOi5/jnHwU+zzHSN3wj43bNGGhp5rtNx0WXC6ePlfybA7GgBCIzZsygnJwcio2NpQEDBtDmzZt93wncmKHLpN4iBDMi+P9F9OHyQ9zxVR62arJv6EatxxAsCWxBMx85IsJOqkq3ZMqZxVxz0HgN6YzIqMmqrCVPD9V7CKaheSDyww8/0DPPPENTp06lbdu2UY8ePWjUqFFUXCy9lgaeFZyt8H1SmBO218bqDNE/lxzgjj+5p4/kOWwnUyNsedZzSS1O5ozIwt1nuOM2TdyTf735bccpn+cIlxo+vlv6ZwaCmkEG+UPfeaJUdDnUqtlqSfNA5N1336UHH3yQ7rvvPurcuTN9/PHHFB8fT1988YXWTx1yRr+3hjte9dww/QZiYMJpUFRXFfO0lMcm/dUaoNfML4J+LIF0nPVHgsztuxO/28Yd98lWlqd1sNg9h8CVMCBUc8dMqGG3nRslH+wDwewjKKNpIFJbW0tbt26lkSNH8k8YEUEjR46kDRs2uJ1vs9movLxc9A+kZacbbz3fCIQzIkZ5g9KL3KUptr6BEbZBChvJXd/TPbFWS/FcQTP5AZkWeVqfCVrGRyK/wCP2b90oSzNL9p7ljpujlLsimgYi586do4aGBsrIEK9NZ2Rk0JkzZ9zOnzZtGqWkpHD/srKytByeqSDfQZ4ICwIRlqethK7YVvU19Q26J0oKlz2C/SHM5ohUaVBePUlBU7wTF/k6KilxKAvuiZFmRFzfnxcjP0QRQ+2amTx5MpWVlXH/ioqKfN8pTKwU9N4QVkcEMcyI8P7yFd9fZv4TQzyexyZcMgxRlY4N39bqnKQpp7JqWbV/FXsrFAQ3FwXPgfoTnhmp+67rz5et8AzyaFpZtXHjxhQZGUlnz54VXX/27Flq1sy9AZPVaiWrNTSK7ajt2438trCP7+7t5czwFolAhIjcv6F1yfS8DTY6MoIiIyzUYGeopr6BUkifN9G7P9/k+yQNyVmaKRe0DmicKN3RVkrn5sm09zSWmtVkpAaXwt5DoJymMyIxMTHUp08fWrZsGXed3W6nZcuWUV5enpZPHXKW7uODubZNkY3ticViITYWCedAZMOR84rOj3XmiRill9GchwYG/TnlNL277K0V3PEVHZt6PM/VB3f14o49lQEHZdjtuw0GSEp/Zd4e7tjb7CNI07zXzDPPPEPjx4+nvn37Uv/+/em9996jqqoquu+++7R+aghTURERVNtgD+uiZsKERzlioyOpqraBLukUiLguefjq36KFOMHSjN3O+CxEdZeCrsBpguqqlV6WaYwSCJpBpLPXjBGWZoS8zT6CNM0Dkdtvv51KSkrolVdeoTNnzlDPnj1p0aJFbgms4BkSVZWJiCCiBmNM2eplRQGfU5T/ypU+z+cSVuv0+XbZ4x9/6PK8QmyyKhHRpboGrgmeJ1EKkmkbJfCByEcrD9OMu6SXV38WbF8G76IMtDQDgQlKsurjjz9Ox44dI5vNRps2baIBAwYE42kN7WJVLU1buI8OFfsuUvatS9lg8I7tymlHAEdE4l4nnlijg780Y7cz1P7lhZQzab7o+pfHdgraGIRioyKJ3XQlZwsvW5FWqfmCXjqu5mxGgr5cRklWPXoOS22BMtSumXBy08z19MmqIzTy3dU+z335193cce9WqRqOKjSwdTH0WmbQ25bCC4rvE8fNiATv/9kHyw9JlpW/Ny8naGMQioiwUHw0uzzje5dL+wz1d6/tOlnGHf/r9uAWdDObKIPkiFz/4VruGPkh/kEgooMGOyOKojcc9pxY6LosM/v+/pqNK1Swa/16LTPo7ZaP+WKBTZLk7UIL9tJMfYOd/rX0gNv19+Zlc5Ve9cCVeZexjVnrppPINfAukitopu+MSHkNH7R2apas40jMC4GIDtq8uEB0+c7PNno898BZcUlo7E/3jevAa4Bser29fUt3WefFRrP9ZoIzI/KJh2Taf1zfNSjP78m5ShsREW06qmzXkRbao1eJV+wSrJF2x6HTrn8QiBhcsD4YQomR6gsEm+sMWudMed/QKpzf6s6W16g+JilvLy4IyvP46+//2+t2nZpJ41JLYEhKV4Yr8a7jF47TZZd0e+5QgkAkyLYfv6jo/G3H+PN//yvWH+Uw4jelYFl3SPxNvmmSvJ4XO084chNmrStUe0iyWKMiaNerV+ny3HIdLgksKfGDO/laIs/+tMPtdmGCbHZ6fEDPFQ4i2RwRHb9wPDCbr1485ZrOuo3D7BCIBNmNH62XvF7YX0LoVcE3s64tsGYsh9HagwfTp2v4JY/WjeU3RmznbBvQN6eR6mNy5frNv3D6WCp4fQwlGXzZceS7q7jjuwe2Unz/js34pRapnTOv/sYXxVr8FHqV+BJtgDoiwmq59w3K0W0cZodAREfCUu2j/uV79wzIw2fTh1cgUlPXQKsFPYkWPXWZ7PuyVUKbJWvfYsFTfogRsP8ffAUafbOVB2y+ekT9tJWvIcImD4Nn/BcOY+SCIT/EfwhEgqiiRlw9Mq9NY+64SqJuwSXBdUq6d4a7cJ0RufJfq0SXrVHyP8zYnSpS22nVNn3hfu74/Tt6av58SnSTOet4dbfmih/bdZdNSYWNOz5faXM9HXzgk9L1+TsvuiA9iw3KIRAJom6v8tUjv39woM8W38Ltjb88NkizcYWacN01U3TB/8S5GGdxrtqG4P4/u75ni6A+ny9sdVVfBc3U2GJcdqmWOz5fVevlTJAS5fyd1Sspfasgf2/i8Da6jCFUIBDRycBc31O7nwqmsNthK59s4TojIjTrvn6Kzmc/WG1BmBExsniujojvgmb+mDSmI3e8/wxfVXlePt+99Y5+WZo8d6jRu7LqD3/yVXBv6t1SlzGECgQiOmGnaXOb8AmF5S5LN+CfcNw1U+yy7XZ4B/mdYYmCtzSzoqCYO+7e0njJ1+yMiGtBM7WWToQdex//bjt3vKOIr6h690D5zfTCmd5fOIQdrnMVJIaDOwQiQeJpPfGHh/K44/9u4ZPVsD/df+FYR+SjlYcDuj/bN+VQcaWPMwNz36w/ueN/39HLy5n6iHB+QVh76Jzo+rnb+RmLKzv737CznYeEVeHzdZFZ+yXcRRukxDuR9lV2Qx0CkSB5Y/4+7vjZK9tzx8IS3P/4nd+qOzPAD5ZwpncSmx5mry/kjpc/e7ni+xc7EyeFywVqc13uaJkWp9lz+Wv78VLJ64U7fd640f/qr64fWOU1dbRb0F9G6hyQFumc+dS7xDsEDoFIkGSm8m+69w1p7fP8rzYc03I4IU3vKdtgc92NldtEeTM2YY2LQJwsvUSfrz1KlRI5Fq4zVFF+dq/V0qA26dyxMHAS7nCRWyROjrs+20jXfLDW94ngRs8vHMJaOMLlNvCP8d4JQtQX645yx4letuLWSexayEGVRUWM0pUzWNQIWlPjHTu4PC0dyDV4+nJ67fe9NPDNZW632U1Qwly47FJ6SZucrR5Zqdzx7pPlott+nThYk+cMRezfuR5fOM6W84HpeBQyCxgCEQMQFp66WF3rljD4n/HKdkCEu0gDVFwMJuFywu19/dtxwXXfVam3kdSMyHUz+G/+6yZdocrzqM1isVDjRMdyaWk1v6W2f2vHLjc1Zo6+fsBzB+2egiAFvONzwYL/hUOYSzW0XWMvZ4IcCESC4JKPmgQdBFtz//G/vVwHUJaviowgFm45Ikv3neWO7xygvPQ4kaPXCxGRrU69N3XXgFpY56RFqvHyQ1js39+K/fwOHzZr41Y/Az0hdNBWB5tgrccXjtec+Xx9stOQ06MCBCJB8Nfv+W16/7m3r9vtwl/k33eeputnrOMu5+Wmu50P3oVbjoiQv9+o2SqsgdQRsbv8/y7QMPE1GN75gy8ouOnoBSIit8RSf82TWILZ94/Rqjx2uIjU8QtHwVnH77awqBn4D4FIEAi/sY6UsfVPmBj3/UMDNRlTKAunGZFDxep82MdGO94KpNrTy1FRU0e5Ly4QXXfth6GXhHmmrMb3STL0yEql4R2acJfnPzGE4mLQX0aJKJ2WZoS/A0PbN/FyJsiFBiYQcsKpjsieU3yy43cPDvD7cYQzIgzDKJ5unrWuUPL62no7xURFiDrXmo1wFuT1ALbuupp1n+dcEfAtSqelmTcX8KUYnh/VIajPHaowI2IQ/7q9h9t1wqqrIF849Zp5ae5u7rh3qzS/H4edESHyr9/MQQ+F0N5fdoAYhhEl9/UwYEVVb+bvOs0dt07H36RR6DXz+cfeM9wxis+pA4GIxtYc5Nuy//WKth7Pu0Gi+deCJ+S3cQdeOO2aEe5OCaR1vLBTb40fCatHSqQDkRkrDlPryeIlmydHtlP8+HoSFhdEq3fjYGc+pUoeaEn494FEVXUgENHYPZ9v5o6fGtne43lSv9CBfLCEM76OSOgHImqJjrQQ+yto82MLr+tOL28ub2/sAlBSs5NgPNH4Ow8ZCESCKNLHt6nNL40gIqK0+GjaNuXKYAwpJIXzrhl/WSwWimXzRPyYEREWeBrc1vtOL19/B3rrmcUvcR0/L90jCvSnd4n3sd2a6/K8oQiBiIYYhZUkmybFUuH0sbT9lauoUUKMRqMKfcedDQaFa7mhSDglHUj/E5bVmSfiz4yI0Fu3mHtGQVjJ+O0/CnQcCXijR46I8LleHNspaM8b6hCIaGh7USl3nNXIuAWcQs38nY7kQmEBrVD00Qo+d6F9RuAVP9miZv7kiAi1SI2jO/tLF1br3So1oMcOBuEy6f92nOKOsVXTWPQo8S4sxdAsWb2eQ+EOgYiGDgt2Crx1s7m/JZpJ/5xGeg8hKGauOsQd91PhNbM5SUpnRM4L8kPYUuhvepih+fnRQX6OTn+vXNNZ7yGAAFdHJIi74x7+eit3bPQlRjNBIKKhwvNV3PHA3PD4cDSCm3o7diCN7OS7eJyZBTpz4crfMu/sUhgR0UOX5RKRY1YhSuKN2sy7DNBqwVjYHJGGMKgXFOoQiGhohmDq3MxvwGYTqcM3pVDgb5n3efnSyxeH3rxa1M030M6+AEJRSEoPGQhENOJvqWwIHLbv+sffMu8rCvjmcDFR4reUJc9cTrf0aUlE5qsfAsbG54gE5wuHsMLuA0NaB+U5wwVKvGvkCUGjOwiuKG5bX3jMiFymUhtyf2dEjvnY4vr2Ld3puVEdKMPEyX1v39Jd7yGAi2Bv07/mA7530tNXeq4JBcphRkQjf+zls6tRITW4wqHpnbCi6hs3dFPlMWP92L4r3KLeONEqeY7FYjFdEDLrvn7ccYvUOLq1b5aOowEp0c4vHAzj3vlZawloUKgqBCIaqKipE13ujH4EQcU2w9Kr0FEwzNl8nDtuJah7EQh2RkRJEuwlwTLOlGtCp67C8A5NuYD2nVux482IIiP5vLu6IOeDIedPXVia0UC3V//QewhhLRxmRF6fv8/3SQqxSzJny+W3uv9+cxF3fE33TNXHpKetL19Jxy9UUzeTNekLF8JdWVr/rR8T7IAE9WFGRGOjuoT2FlIjYpPYwiVHRC1ssab/rDkq+z6v/b6XOw61ugop8dEIQgyMzQUj0j5P5Okf8rnjfjn+d7kGaQhEVFbusizz0bg+Oo0kfEWGwYyIFtgeMb1MUP0UQDgjUq/xMuy246XcscLOHSADlmZUcqm2gUa9t1pU3Iko9L4lmkG0M0ckVOsLCLfX3urcGquGga3Tad2h85TbJEG1xwTQSkSEhSIsRHYmuDWDLmuHUv9qw4yISjq9ssgtCOnUHEmqegiFgmY7T5TS0LdWUNEF962xwnoGA3K9d7pVItpZA6S2PjQDOAg97PJMMGc/b+7TImjPFS4QiKjgTJl0ct/vfx0S5JEAkaDiokl3zVysqqXrPlxHxy9U02VvrXC7fd/pcu5YzRyk6Ehl9VeEb/5m7iED5hWpw996yzR1dqkBD0szAbpU20ADpy2TvA3LMvpgvyWZbWmmwc5Qpa2eer22xOt5U+bt4Y6TYqNVe/4YhUm+p8v47sbxqKsAOoiKtBDVafu3fqo0tLt4GwECkQBNWyi9jXLD5CuCPBJgcaWfTbRrZv3hc/TA7C2iuhysmroGrjOulpTOiFTX8mPt2CxJkzEBeMNv1dfub/3qf6/hjp8cgTYFWsDSTIC+2nBMdPmtm7vTnr+PouYpcTqNCMzYDOuhr7ZKBiFERB+v4psnuu7KUhMbiNTKnOb+dftJ7hgFnkAPkRHaFy8sreb/5h4amqvZ84QzBCIB2HTkvOjy/93cjW7rl0UJVkw06YlbmjFRjoiwZLur95Ye5I7HfbaJO3712s6qjoFNVq2T2WvGU+AEECzRQW5wifd2bSAQCcDtn24UX+7XSqeRgFAodt8tqbAREdEuwY6ZO/qr+/vG5ojUylyambWuUNXnB1CKzcND8UJzQyDip/WHzuk9BPCAXZoJdv8JLfV7Y6nbm63aeSPst73KGs+zMwBGEg7tHMIBAhE/3fPFZtHldk0TdRoJuGKb3unRlVMta54f7nbdmwvU7y8jxO58qVHQfRdAT1EaFy9cWVDMHf/0SJ4mzwEIRPxitzNuEfi8xwfrNBpwJdw2bYZZkb2nykWX174wnLIaudcqEC6FDGnbWPVxsN13bTK67wp3JI3shH5KoA+tawZNmPUnd9wrK1WT5wAEIn7ZXHjB7br4GCQxGUV0ZPC6cqrho5WHRJfZgklv3tjN431m3ddP9XFYncmqNhkzIiWVNu747Vu6qz4WADm0rKLMuDSVYWdfQH34P+sHYcdRIqIHhrTWaSQgRTQjYoKdM7/vPM0dPzasDXd814BW1D+nkeR9ojV4U4zhSrz7flO/WOXY0pgQE0lpCTGqjwVADjY40OILx0zBtnnQFgIRP+xxmUp/8epOOo0EpAjbgxt9RsT1Q//50R1Fl38M4ro0tzQjIxBZsMsRPFXVIp8E9MMlpmvwheOtRQXcMQr2aQuBiApQyt1YIiMsxNbXMnp11dnrj/o8Z8KgHNHl7VOu1GQs7NJMvUQOlCtslwQjiAzSrpnXbuiq6eOHOwQiCqHvgDnwVUKN/YGZX1TKHafFS/eNefW6LtQi1VGp951be2i2FMIuzRD5Xp5Zd9ixfb1NkwRNxgIgB5sPpnaOSHG5uJFpPw9LpKAOZFgqtGx/sejyqueG6TMQ8MoaGUG19XZZ+Q56KauuowW7znCX5z7meefVuklXEMMwmpZStwoCkXOVNsmdO6zdJx3Lk4dLqjQbD4AvkRpVURYuOSbH4mNSa5gRUaC+wU5Tft0tui47Hd8IjcgabfwZkf9uOyG67O2Dn0j7fi7CXQErD5Ro+lwAatCqoNkLP+/kjh++vI2XM0ENCEQUmDJPHIT87ar2Oo0EfImJlL8DRC/TXAqUGSnXqHPzZFnnvX9HT20HAuCFVg0uNx/lSzQ8ikBEcwhEFPh+c5Ho8uNXoCW0UXEN3Aw8IyJ88/zq/v46joSX29gxw+frGyZbhbVHy1SthwTgUZQGOSL7z4h3RUYY6AtCqEIgIpNrcRvMhhibltv6tDC0fRO9h0BEgiRfLzNJ5yttVO1cQ2+abA3KuACkaNFpe/R7a7jjZ67E+3wwIBCRac6f4tmQB4fm6jQSkIP9QDXqjIgwsE03UEEwrqhZg+f6IMI6OqgoDHpSO0fE9QvnEyMw6x0MCERk+sSlyh5b/AmMiQ1E/Pmm9P3m43Tlu6uouKLG98l+OlhcyR3/8fRQzZ5HKb66quf/b2p3/QXwV6TKnbbPVdaq8jigDAIRmTKSY7njP18aqeNIQA527VjpjAjDMDT5l110sLiS+r+xTIuhERHRVf9azR2nJxpneSNGRv2VPyV6LQHogSvxrtLSzHpnfRwiout6ZKrymOCbZoHIG2+8QYMGDaL4+HhKTU3V6mmCZpMgi7pJknE+OEAavzSj7A3KLDklWpHTb+btxQUebwMIJi4XTKWlmZOCgpX/vK2HKo8JvmkWiNTW1tKtt95Kjz76qFZPETS7T5bpPQRQyN+Ki4Xnw7tAl5LGdwB640u8q/P7Kuwvo0VjSZCmWabZ3//+dyIimj17tlZPETTvLT3IHaOktTmw2fRKZzhWFogr59bW20Wlz9U2pG1jzR7bH3wg4jlZtXFiDNbSwRD4LxzhPZNpdoZKebfZbGSz2bjL5eXlXs4OnqX7znLHEwa31nEkIJe/u2beXLBfdLm0upaaCvKD1HBJUD76dYM105KTI4IgBIxCzRLvVbZ67vjlseioHkyGmnuaNm0apaSkcP+ysrL0HpKbqzpn6D0EkIH7phTg9l0tPnQ3Hj3PHbdMi1P98QOhpCLtTb1baD0cAK/U3L47f+dp7vjGXvjdDiZFgcikSZPIYrF4/bd//37fD+TB5MmTqaysjPtXVFTk+05B1hSJqqYQ5Weyqquz5epv4V24i3/DizLYOjRfR8Tz/ze2E/D4vJxgDAnAIzUrqz4v6C/TyEC1fcKBoqWZZ599liZMmOD1nNxc/wt9Wa1WslqN9UHvGmlr3XgM1BHt5/ZdVzV1nnMl/BVh4N8hX8mqDMNwOwsS0ZUUdMb1mlF5txve54NL0TtJkyZNqEkTY5SiDpZNR877PgkMJ5pdO1YwZSvcusf6fedpGtOtuWrjIuKr9Box8dlXIHJGMEPUKB7fGkFfkX78nYPxaPaV5vjx43ThwgU6fvw4NTQ0UH5+PhERtW3blhITE7V6WtWptT8dgis6yvGNRsk21D/2nHG7bv6u0zRDtVGJ3T0wW6NH9h+frCo9E7SjqJQ7TsP0NeiMnflUq8Q7EdFfhmBDQrBpFoi88sor9OWXX3KXe/XqRUREK1asoGHDhmn1tKqLFWzd/GJCXx1HAkpEy9j94SolLlqr4XDsgjfM3q3SNH8+pdgZkZo66f9v/916IpjDAfCKK/Ee4BJsSQW/W/OO/q0CeixQTrNMudmzZxPDMG7/zBSEEBGdr+J3TVzRETtmzIL9QK1TMCNSdMGxNJMUG8UlZKrtXBX/hte2qfFmBveedmyZ9xRwdG6eHMzhAHil1q6Zhbv5BPLkOOQ+BZuxUvYN6Og5R6XNm7Cdy1SsfsyI/GvpASIiqqipp79e0ZaISPWAZOEufvknwWq8N7w1B0q83r54j6OmDnaPgRGwu84CzRF5Zd4e7jg9Ab/bwYZAxIdftjm+GWanGy+xEDwLtFR5c2cAovZyzdTf9vg+SUdTr+3i9faCsxVERFQsmMoG0EtkhDr1gqQeE4IHgYgPh0scMyLHwrwHidkEGojEOVvda7F918hapccTEVGO878ARsZt38WmAlNDIOJF2aU67jguJlLHkYBS/iSrCsVGO+5/KcwCESWVVQH0xi7NqLlrBoIPgYgXv+88xR0/P7qjjiMBpZTOiAjfyCaN6ajJjIhwLP+515g7sPjKqghEwPjULmjWMytVlccBZRCIePHS3N3ccTC2doJ65DRvE9p1sow7vqNfFsU6AxE1Z0QWCeqUDGlnrK67LKszELFJBHAMw7/Z98023tZjCD/80oz/gbPwC8L0m7sFPCZQznhp+wAqUDoj8tGKQ9xxqqBiaE2dnWrqGrjAJBBPfL+dO1bj8bTA/n+rqKl3u+3ERb7y7OPOXUUAeopSoaDZ24v5/mhJsfjCqQfMiEBIUprrIKwXQ+SYAWMf41xleO4QKauuE13ec6qcOx7UxpgzOhBe2BLvgTS3/GzNUe5Yq/pB4B0CERkaJ2JfudlwBc1kLs1sPXZRdNlisVCC1bk8U6t8eaamroFWHSjhljPsJkmmy0zh34hr6sWvu1lKLHccE4W3DtBftEoFzUBfWJrxQLge/q/be+g4EvCHr1LlQp62ZsfHRNHF6jqq8iMQ6ThlEXe85OmhFG/A4mVSIiIsFBcdSZfqGsjm8v9u/eFzOo0KQBpX4j2AHBHQnzneHXWw/jDfdbdvdiMdRwL+SHPmeVyorvVxJtHDX2/ljkd14cv4s8Fotc09X8Ibm8tMwpX/Wq3o/nqLjY6gS3UNbjMiby0q0GlEANLUyBFJiImkqtoGemJEO7WGBQphftWDbYKperamBJhHfIz87bf7z1RwxxcFeRGnyhwt7xdJdOX1pt/rS73ebvQdWGwireuMCIDRRDlzRALZvsvOeHZrkaLKmEA5fMJ68M8lB7hjiwUlf80mTkEgIvTgZblu1ynd4VIuseNE6OdH8xQ9XrCxr9d1RgTAaCID3L57spTfCbbvdLmXM0FLCEQgJLEFyeoaGEUtwq/szC/NXN8zk4iUNXgT5hZJGdO1GbVtmiT78fRg5fJrEIiAsQW6NLNbUD+odWP0E9MLAhEfbkTXXVMSzmJ4+0AVBg59XIp0xUYpn1W5aeZ60eWWaeLtgO/e1lP2Y+mFXao6XVqj80gAvOOWZvwMRH74s4g7vqZ7c1XGBMohEJGQX1TKHSeaZLcDiFmjIohdUfNUHfWuzzbSnZ9t5C4PapMuup3NDZKz84a1/XgpdzxhUA6teX646HYz9Syatb5Q7yEAeBVoiffl+4u5YyzB6wefshLum7WZO06Kxf8iM7JYHNtQq2sbqKbWPZB4c8E+0c4oIqL7B7cWXY6NUVbm/aJLUbRXr+uiZMiGkWSNogpbvWiZSgg1RMAoAs0RAWPAO4oE4c6JO/u30nEkEIg4L0mXn64+4nZdWkKM6HJCjCMIrZZZR+RfSw94vX1grjm2gV/dzTFFbRUEHMKCbEueHhr0MQFIiUb33ZCAr/s+ZDWK13sI4Cf2m7trZdSiC9Wy7s9uAb5UK6+OiDBPVZjg+s0DA+i3HSfpjRvN0VCLXZIS/n8ru8QH58IKqwB64gqaNTDEMAyWV0wKgQiErNPOOiBbj12kHoL23sJOu97EO2dE/KmsumHyCO54SLvGhu22K4XbvitYknr0W77omzXKPHkuENrYHBEiIjtDFKkgDhH2ofrgzl5qDgsUwtKMi1IZlTjBXM5XiZvWnRLUDvCG7TVTLXNG5OuNx7jjyAjzfjNLsLIBGP+6Nx65oNdwADyKEkQeSvNEhM0sm2OWT1cIRFwsFlTRvKNflo4jgUANbd+EiIiyG4nrA7w+f5/buQueuMztOm5GxBZe9TTYBG1fhdkA9MZu3yVSvnOmQvD73btVmpczQWsIRFz8vvM0d3z/kNZezgSjS3DmeLj2fpHSOTPZ4/2Vdt8dn5et6HyjSYp1lKCvQCACBieceVRaS0TYcTvCxDOYoQA5Ii6EfUDaZxi7AiZ4x+c6iKdsm6fEcvkjPz6c53Falq35USVjaUaYtT+2e6Zf4zUKbkZEkKAKYETCHBGlO2dmrDik9nDATwhEBBiGEc2IgLmxgYTr9ls2CHn2yvbUv7XnLbVsroSc7bsVNfyHdk9BYqwZJXMzIvxryki20tlyG90z0NyzPRBaIiIsFGFxJKrWK2jlQCTuMwP6wtKMQIXCdu9gbCcuOt5ovtt8TPL2A8WVXu8fHyM/WXVlQQl3bPaCX+yMiHBp5my5I7Hvik5NdRkTgCdRkYGVeQf9mfsdU2UXKvkdM2gJbX6rDziCA/ZDlEi8JfWxYW283p9NVq2ps/uc9v141WF/h2k47IxIuXNGRPjaK5E3AgbDLs/4W9QswURtF0IVAhGBtxbv547nTRys40hADSM6un97Py4oZtaxmfccoHjBG5SvWRG2UVwoYGdEaursVNdgpy/WHuVu87aUBaAHvqiZf2XeHxrq/QsJaA+BiMCCXfzWXWRRm9/NfVoSEVH/HP7D88VfdnHHvqowWqMiuDc5uTtnzFw/hCXsr1R+qY4W7ObzplLjo6XuAqAbf8q8Hz1XxR2PRddd3YVlILLu0Dnq/MoiuumjdXoPBTTE9poRNq3bItiy54vFYqH4aHbnjPdAhK3c+v4dPZUN0oCiIiMo2RmMFFfY6IwzuZcIVVXBeIRl3uU6eo7PD7OaPKcrFITlT6DBzji6sipo7w7mEysRiCgV76yuWuUjkflchSMPpXlKnN/PZSRNnL1ySqvruF1GAEbkT47Iy3N3c8doT6O/sAxEpNiRcR1ypJq3sfrlyKukyHbg9RbMMAxDxRWOD+tQaQjH1tMpQy0RMDi2zLuSEu+nBMF1qHx5MLOwDkSEoccFQY8ZX0mMYA5SPVNYfxbKW6Lhipp5mRG5UFXLTQs3SbR6PM9MkuPEO2eIiK7u1kyv4QB4xJZ593f7bijkdZldWAYiUlNxhwU1Jb56oH8QRwNaYQOR0uo6t4z6JKu8Wn7sjIi3omanSvlvV2avIcJiZ0SOn+d3GT1yOXYXgPGwgYTSXjNgHKHxrqmCA2f57ZdNk0Jjej3cCesDbD12UVRDZPb9/WQ9RrxVujqrkHDbd6hgg7gPBWWw0+Jj9BoOgEeB1BHpgDYehoBAxGnKvD16DwFUliiY9YiNjqT1h89xl3tlycsRkVNd1VciqxmxxeCEWqZhLR2Mh80RqVOQI8IqOBs69X/MLKwDEYbBVF4oE25DrW+w06/bT3G3ya0Tw1ZXrbJ5nhHZdrzU/0Ea1F0DWrld56vuCoAeIp05Ig1+LM1Mvbaz2sMBP4RlIGIhvKGGCzbgKK2uo4G56Yrvzy7vXJLRbyaU9GyZqvcQAGSJZnNEZC7NCL+ANkrAcqMRhGUg4kr4i/nsle11HAmorbTasevj520nyO78OUuVfvckjp0RkVFZ9bXru/gxQmPqnS1eunr3th46jQTAOy5ZVebSTKVgKbVjs2RNxgTKIBAhog1HznPH4wfn6DcQUB37JtUiNY7emL+PiIiW7S+Wff+EGN/JquwqT//WymdcjIotBse6oWcLnUYC4B2bIyI3WfViFb8lvQNKNRgCAhEiWrCL76URH40S1qHkjn5ZRESUFBvNFSVTUtI53spu35Vemim7VEfs+1+o9WHZMfUq6peTRu/e1gO9l8CwuDoiMnNE2JpRLVKRfG0U8oophBjXnLtvNh7njqMiEZuFErY3Sk09P6MxeUxH2feP5wqaSc+ICJtnhdr21pS4aPrpkUF6DwPAqyiFSzMXqxyBSKh9cTAzfOpCSLM6y7yfr7Rx1ylpfMcGIpfqpGdESir4xw2VYmYAZhKpMFm19JIjEAm1Lw5mFtbvnNi9G/pinTMiZ8v5gCEnPUH2/RN8bN/ddbIsgNEBQKCinV8AauvlzYj8Z81RIiIqPF/l40wIlrAORFxd1q6x3kMAlbEzIqsEBbqkamR4IqegGRFRtxYpfowOAAIVp7DL9p5T5UREdOLiJc3GBMqEZSAiTBERbt19aWyn4A8GNLVJsCOKlakgSY1PVpV+k2PXm9lOvwAQXNHOvL66emVT3Eq28YO2wv7dc3tRKXfMZl9D6GjVKD6g+/vavnuy1PGtakjbJgE9DwD4JzpSWbJq71apRER0a98srYYECoX1Jy9DDE34YjN3uW3TRB1HA1q4o7/8ZRgpcdyuGemlmeXOmiRZjbAVEEAP7BfIOpnbd9mWDEmxYblp1JDCOhAhIiqvCa/S3eEm0Mx4NlnVVm93K5gkzBs5U14T0PMAgH+4GZEG3zMip0r5vJCUOGzfNYrwDEQESSJ5fvQfAfMI9M0m3soXuHNNWK0UBLFjujYP6HkAwD9RkfK375Zd4quqoo6IcYRnIOLEMEQHiyuJiOjtW7rrPBrQgmsS6ZRrlHXbjImM4OoUuOaJsP1nkqxR1Lqx/C3BAKAeLllVxoxIjWBnTcu0wPLHQD1hHYgUV9jonLPQVeMkq86jAS24tq6/Ny9b8f3jPSSssnkjwlkTAAguNhCRU+L9xo/Waz0c8ENYByLCaTr0mAld858YQkRED1+ey71pKcEXNRMvzVxwbt0VFksDgOBiS7zXydw1A8YTlmnDFnJv4NUvp5EOI4Fg6JKZQoXTx/p9f08zIv9edjCgcQFA4KIUzIiAMYX1jIgQuouCJ+zSi2uy6pFzKBENoDd214ycHBEwJgQiAD7Ex0hXV2WXZgBAP0rriBARvYwq2oaCQATAh3gfRc0GtMayHoBe4mIcH2M1PnrN2AXbe9s0QfFKIwnLQMSCVRhQIMEqnazaJTOZiIgeGdYm6GMCAIckq6MeSEVNndfzKgR/v/3x5cFQwjIQAVAikd0147I0U+EsaJYci8JIAHphO2zX+liaWbL3LHcch12ShqJZIFJYWEgPPPAAtW7dmuLi4qhNmzY0depUqq013rr6LX1a6j0EMLBEZ0+KCpd2AOXOb2ApcWG5+QzAECKcU9zCTupS5uWf5O+DzQmGotk76P79+8lut9Mnn3xCbdu2pd27d9ODDz5IVVVV9M4772j1tH65a0BgjdEgtEktzdTW26m02hGIYEYEQD/sUvv+MxVez8MsiHFpFoiMHj2aRo8ezV3Ozc2lgoICmjlzpu6BiGss3D4jSZdxgDkkOrfvVgoCkWd+zOeOk9E8C0A3+UWlss7rnJlMf+w9S7lox2A4QZ1TLisro0aNPCcJ2Ww2stn4KpXl5eXBGBYlWjG1Dp7FS1RWFWboW6OQagWgF3Zm0pf3ljoKEKL+j/EE7R300KFD9MEHH9DDDz/s8Zxp06ZRSkoK9y8rK0uTsew7HZwAB0IDG2jUCgomnSyt4Y5d+9kAQPBEId/D9BQHIpMmTSKLxeL13/79+0X3OXnyJI0ePZpuvfVWevDBBz0+9uTJk6msrIz7V1RUpPwVyXAUETEoYHWuLdvq+ECkZVocERG67gLoLDud76LbYPecsJqR7GhseltfbE4wGsVrEs8++yxNmDDB6zm5ubnc8alTp2j48OE0aNAg+vTTT73ez2q1ktWqfRdcfIMFJdgZEVs9vxzDbgVEUAugrzHdmtMLP+8iIkeZ98gI6aTUnPQEOltuo7w26cEcHsigOBBp0qQJNWnSRNa5J0+epOHDh1OfPn1o1qxZFBGBtXQwHz4Q4WdEoiIsVG9n8O0KQGcxgo7adQ12ivWwO2bT0QuOc+rRHM9oNMvSPHnyJA0bNoyys7PpnXfeoZKSEu62Zs2aafW0spRfkpfcBEBEFOMMRM6W84nU9c4p4DHdmusyJgBwiBYEInI68BZX1Pg8B4JLs0BkyZIldOjQITp06BC1bCn+1uir8IzWbIKkw07Nk3UcCZgB++t6rtJGdjtDR8/zyzGoTQCgr8gIC0VYiOyM5w689YLrb+2rzSYI8J9mayUTJkwghmEk/+ktQpAj8voNXXQcCZjBJUFp96raejpSgkAEwEjYWZFaD4FItWC7fWo86v4YTVgmbQhTVaOQtwI+DOvA50SVVteJmms1SojRY0gAIMDmidR5WJqptjkCkagIiyinBIwhLCt5RQr2nUdiDzr4ECV44/pi3VH6ZRvfs6JJkva7vADAu+ioCCKb56WZi9WOHmep8dHYNWlAYRmICH8NE1BVFRSYta5QdNlThj4ABE90pONdvbbeQyBSxQYimME0orCcoxJO3qEgFShx/+DWeg8BAFxEc0sz0oHIBeeMSCMEIoYUnoGIARJmwVyeGtmOiBxLMwBgLL5yRIqdW++R02VMYRmIYI0QlKoW7JwBAGNha/14WpopqXQEImyZdzCWsAxEumSidggo0yQRb2AARuVraYbtnJ0ch627RhSWgQh2yoBSg9qiPwWAUXHJqh4CkcoaRyCSiM0JhhSWgQhSRECpLpkpbtf98tggHUYCAK4uOHfFeGrf8ct2x5Z7LLEaU1gGIgBq6N0qTe8hAAARFZ6vJiKirzce83re3O0nvd4O+gjLQAQTIuCPHx4ayB3v+8doHUcCAFJ6ZaV6vf36npnBGQgoggUzAJkG5KbT0WlXY9cVgMHc3jeLfthSRE2TY72eN6YrumUbUXjOiCBJBPyEIATAeNjtuzaJ7bvCnTSnyy4FbUwgX1gGIvExmAgCAAgV3rbvsjtmiIgGtWkctDGBfGH5iXxznxa0eM8ZuqwdfikBAMzOW0GzSmcNkdjoCIqLQW8oIwrLQMQaFUlf3t9f72EAAIAKvAUi5TWOLb2JVhQzM6qwXJoBAIDQEeOl++65SkeNkbR4BCJGhUAEAABMjZ0RkcoRqXDOiKDhnXEhEAEAAFNju+/avCSrJsWGZSaCKSAQAQAAU4v2kiPy87YTRER0uKQqqGMC+RCIAACAqcV42b77Z+FFIiI6eg6BiFEhEAEAAFPztmsmytltvU82ekMZFQIRAAAwNaszENl1sszttnq7o5J2x2ZJQR0TyIdABAAATG17USkREVUIqqi62nu6PEijAaUQiAAAgKlFeOkB5VyZoedGdQjSaEApBCIAAGBqN/du4fG2DGdH3iRUVjUsBCIAAGBq1ihHD5nYaPePtNNlNURE6DNjYAhEAADA1KzOAMRWbyeGYbjr2aqqRPzuGTAeBCIAAGBq7IwIwxDVNfCBSLkgeTUlDkszRoVABAAATI3dvktEZKtv4I5r6vjjNPSaMSwEIgAAYGriQIQvalZtcwQizVNigz4mkA+BCAAAmJrFYpGsrlpV61iaiUeiqqEhEAEAANNjZ0WEMyJs590EKzrvGhkCEQAAMD02YVWYI1J2ybFrBomqxoZABAAATI+bEanjZ0TYQCQZgYihIRABAADTE9YSYbGBSCoCEUNDIAIAAKaXEOPIAxEWMcPSjDkgEAEAANNLdCakVtUiR8RsEIgAAIDpcUszdQhEzAaBCAAAmB6brFrbIJEjEo9AxMgQiAAAgOnFsNt3BbtmSqtriQi7ZowOgQgAAJgeG3SsP3yOu67skqOgGZZmjA2BCAAAmN6ag44AZOm+YiIiYhiGyrmlGTS8MzIEIgAAEHJs9XYuXyQpFiXejQyBCAAAmF6/nDTR5UpbPXfM1hgBY0IgAgAApte9Zaro8k9bTnDHkRGWII8GlEAgAgAApndDzxaiy/PyT+o0ElAKgQgAAJhegtWxfZfNB9l/pkLP4YACCEQAAMD04p15INW1DcQwDN03OIeIiNJQzMzwEIgAAIDpxTtnRBrsDNXU2SnKmRdya98sPYcFMiAQAQAA00sU7Iw5eq6KKmocu2aSrNgxY3T4CQEAgOlFCHbGfLm+kCprnYEIaogYHn5CAAAQUg6VVFKCcyYkMRY5IkaHpRkAAAgpafHRVFHjKO+OGRHjQyACAAAhIdkZdAzMTedzRBCIGB4CEQAACAldW6QQEdG6Q+foUHElERElY2nG8BCIAABASFh/+DwREa0oKNF5JKAEAhEAAAgJqRLFy7pkJuswElACgQgAAISEvtlpbtdZLGh4Z3SaBiLXXXcdtWrVimJjY6l58+Z0zz330KlTp7R8SgAACFPjBmTrPQTwg6aByPDhw+nHH3+kgoIC+vnnn+nw4cN0yy23aPmUAAAQpvLapOs9BPCDpvuann76ae44OzubJk2aRDfccAPV1dVRdDQymQEAQD2x0ZGiy9np8TqNBJQI2gbrCxcu0LfffkuDBg3yGITYbDay2Wzc5fLy8mANDwAAQsw3DwzQewggg+bJqi+88AIlJCRQeno6HT9+nObNm+fx3GnTplFKSgr3LysLXRMBAMA/LdPi9B4CyKA4EJk0aRJZLBav//bv38+d/9xzz9H27dvpjz/+oMjISLr33nuJYRjJx548eTKVlZVx/4qKivx/ZQAAEHY2TL6CRnbKoJV/G4YdMyZhYTxFBR6UlJTQ+fPnvZ6Tm5tLMTExbtefOHGCsrKyaP369ZSXl+fzucrLyyklJYXKysooORl7wQEAAMxAyee34hyRJk2aUJMmTfwamN1uJyIS5YEAAABA+NIsWXXTpk30559/0pAhQygtLY0OHz5MU6ZMoTZt2siaDQEAAIDQp1myanx8PP3yyy80YsQI6tChAz3wwAPUvXt3WrVqFVmtVq2eFgAAAExEsxmRbt260fLly7V6eAAAAAgB6DUDAAAAukEgAgAAALpBIAIAAAC6QSACAAAAukEgAgAAALpBIAIAAAC6QSACAAAAukEgAgAAALpBIAIAAAC60ayyqhrYxsDl5eU6jwQAAADkYj+32c9xbwwdiFRUVBARUVZWls4jAQAAAKUqKiooJSXF6zkWRk64ohO73U6nTp2ipKQkslgsqj52eXk5ZWVlUVFRESUnJ6v62EaA12duofz6Qvm1EeH1mR1enzoYhqGKigrKzMykiAjvWSCGnhGJiIigli1bavocycnJIfnLxsLrM7dQfn2h/NqI8PrMDq8vcL5mQlhIVgUAAADdIBABAAAA3YRtIGK1Wmnq1KlktVr1Hoom8PrMLZRfXyi/NiK8PrPD6ws+QyerAgAAQGgL2xkRAAAA0B8CEQAAANANAhEAAADQDQIRAAAA0E1YBiIzZsygnJwcio2NpQEDBtDmzZv1HpKk1atX07XXXkuZmZlksVjo119/Fd3OMAy98sor1Lx5c4qLi6ORI0fSwYMHRedcuHCBxo0bR8nJyZSamkoPPPAAVVZWis7ZuXMnXXbZZRQbG0tZWVn01ltvaf3SaNq0adSvXz9KSkqipk2b0g033EAFBQWic2pqamjixImUnp5OiYmJdPPNN9PZs2dF5xw/fpzGjh1L8fHx1LRpU3ruueeovr5edM7KlSupd+/eZLVaqW3btjR79mytXx7NnDmTunfvzhUNysvLo4ULF4bEa5Myffp0slgs9NRTT3HXmfk1vvrqq2SxWET/OnbsGBKvjXXy5Em6++67KT09neLi4qhbt260ZcsW7nYzv7/k5OS4/fwsFgtNnDiRiMz/82toaKApU6ZQ69atKS4ujtq0aUOvvfaaqK+LqX5+TJiZM2cOExMTw3zxxRfMnj17mAcffJBJTU1lzp49q/fQ3CxYsIB56aWXmF9++YUhImbu3Lmi26dPn86kpKQwv/76K7Njxw7muuuuY1q3bs1cunSJO2f06NFMjx49mI0bNzJr1qxh2rZty9x5553c7WVlZUxGRgYzbtw4Zvfu3cz333/PxMXFMZ988ommr23UqFHMrFmzmN27dzP5+fnM1VdfzbRq1YqprKzkznnkkUeYrKwsZtmyZcyWLVuYgQMHMoMGDeJur6+vZ7p27cqMHDmS2b59O7NgwQKmcePGzOTJk7lzjhw5wsTHxzPPPPMMs3fvXuaDDz5gIiMjmUWLFmn6+n777Tdm/vz5zIEDB5iCggLmxRdfZKKjo5ndu3eb/rW52rx5M5OTk8N0796defLJJ7nrzfwap06dynTp0oU5ffo096+kpCQkXhvDMMyFCxeY7OxsZsKECcymTZuYI0eOMIsXL2YOHTrEnWPm95fi4mLRz27JkiUMETErVqxgGMb8P7833niDSU9PZ37//Xfm6NGjzE8//cQkJiYy77//PneOmX5+YReI9O/fn5k4cSJ3uaGhgcnMzGSmTZum46h8cw1E7HY706xZM+btt9/mristLWWsVivz/fffMwzDMHv37mWIiPnzzz+5cxYuXMhYLBbm5MmTDMMwzEcffcSkpaUxNpuNO+eFF15gOnTooPErEisuLmaIiFm1ahXDMI7XEh0dzfz000/cOfv27WOIiNmwYQPDMI5ALSIigjlz5gx3zsyZM5nk5GTu9Tz//PNMly5dRM91++23M6NGjdL6JblJS0tj/vOf/4TUa6uoqGDatWvHLFmyhLn88su5QMTsr3Hq1KlMjx49JG8z+2tjGMff+JAhQzzeHmrvL08++STTpk0bxm63h8TPb+zYscz9998vuu6mm25ixo0bxzCM+X5+YbU0U1tbS1u3bqWRI0dy10VERNDIkSNpw4YNOo5MuaNHj9KZM2dEryUlJYUGDBjAvZYNGzZQamoq9e3blztn5MiRFBERQZs2beLOGTp0KMXExHDnjBo1igoKCujixYtBejVEZWVlRETUqFEjIiLaunUr1dXViV5fx44dqVWrVqLX161bN8rIyBCNvby8nPbs2cOdI3wM9pxg/rwbGhpozpw5VFVVRXl5eSH12iZOnEhjx451G0covMaDBw9SZmYm5ebm0rhx4+j48eNEFBqv7bfffqO+ffvSrbfeSk2bNqVevXrRZ599xt0eSu8vtbW19M0339D9999PFoslJH5+gwYNomXLltGBAweIiGjHjh20du1aGjNmDBGZ7+cXVoHIuXPnqKGhQfTLRUSUkZFBZ86c0WlU/mHH6+21nDlzhpo2bSq6PSoqiho1aiQ6R+oxhM+hNbvdTk899RQNHjyYunbtyj13TEwMpaamuo1Nydg9nVNeXk6XLl3S4uVwdu3aRYmJiWS1WumRRx6huXPnUufOnUPitRERzZkzh7Zt20bTpk1zu83sr3HAgAE0e/ZsWrRoEc2cOZOOHj1Kl112GVVUVJj+tRERHTlyhGbOnEnt2rWjxYsX06OPPkpPPPEEffnll6IxhsL7y6+//kqlpaU0YcIE7nnN/vObNGkS3XHHHdSxY0eKjo6mXr160VNPPUXjxo0TjdEsPz9Dd9+F8DBx4kTavXs3rV27Vu+hqKpDhw6Un59PZWVl9N///pfGjx9Pq1at0ntYqigqKqInn3ySlixZQrGxsXoPR3XsN0siou7du9OAAQMoOzubfvzxR4qLi9NxZOqw2+3Ut29fevPNN4mIqFevXrR79276+OOPafz48TqPTl2ff/45jRkzhjIzM/Ueimp+/PFH+vbbb+m7776jLl26UH5+Pj311FOUmZlpyp9fWM2ING7cmCIjI92yo8+ePUvNmjXTaVT+Ycfr7bU0a9aMiouLRbfX19fThQsXROdIPYbwObT0+OOP0++//04rVqygli1bctc3a9aMamtrqbS01G1sSsbu6Zzk5GTNP1BiYmKobdu21KdPH5o2bRr16NGD3n///ZB4bVu3bqXi4mLq3bs3RUVFUVRUFK1atYr+/e9/U1RUFGVkZJj+NQqlpqZS+/bt6dChQyHx82vevDl17txZdF2nTp245adQeX85duwYLV26lP7yl79w14XCz++5557jZkW6detG99xzDz399NPc7KTZfn5hFYjExMRQnz59aNmyZdx1drudli1bRnl5eTqOTLnWrVtTs2bNRK+lvLycNm3axL2WvLw8Ki0tpa1bt3LnLF++nOx2Ow0YMIA7Z/Xq1VRXV8eds2TJEurQoQOlpaVpNn6GYejxxx+nuXPn0vLly6l169ai2/v06UPR0dGi11dQUEDHjx8Xvb5du3aJ/piWLFlCycnJ3JtsXl6e6DHYc/T4edvtdrLZbCHx2kaMGEG7du2i/Px87l/fvn1p3Lhx3LHZX6NQZWUlHT58mJo3bx4SP7/Bgwe7bZc/cOAAZWdnE5H5319Ys2bNoqZNm9LYsWO560Lh51ddXU0REeKP78jISLLb7URkwp+fqqmvJjBnzhzGarUys2fPZvbu3cs89NBDTGpqqig72igqKiqY7du3M9u3b2eIiHn33XeZ7du3M8eOHWMYxrE9KzU1lZk3bx6zc+dO5vrrr5fcntWrVy9m06ZNzNq1a5l27dqJtmeVlpYyGRkZzD333MPs3r2bmTNnDhMfH6/59rpHH32USUlJYVauXCnaZlddXc2d88gjjzCtWrVili9fzmzZsoXJy8tj8vLyuNvZLXZXXXUVk5+fzyxatIhp0qSJ5Ba75557jtm3bx8zY8aMoGyxmzRpErNq1Srm6NGjzM6dO5lJkyYxFouF+eOPP0z/2jwR7pphGHO/xmeffZZZuXIlc/ToUWbdunXMyJEjmcaNGzPFxcWmf20M49hyHRUVxbzxxhvMwYMHmW+//ZaJj49nvvnmG+4cM7+/MIxjR2SrVq2YF154we02s//8xo8fz7Ro0YLbvvvLL78wjRs3Zp5//nnuHDP9/MIuEGEYhvnggw+YVq1aMTExMUz//v2ZjRs36j0kSStWrGCIyO3f+PHjGYZxbNGaMmUKk5GRwVitVmbEiBFMQUGB6DHOnz/P3HnnnUxiYiKTnJzM3HfffUxFRYXonB07djBDhgxhrFYr06JFC2b69Omavzap10VEzKxZs7hzLl26xDz22GNMWloaEx8fz9x4443M6dOnRY9TWFjIjBkzhomLi2MaN27MPPvss0xdXZ3onBUrVjA9e/ZkYmJimNzcXNFzaOX+++9nsrOzmZiYGKZJkybMiBEjuCDE7K/NE9dAxMyv8fbbb2eaN2/OxMTEMC1atGBuv/12UY0NM7821v/+9z+ma9eujNVqZTp27Mh8+umnotvN/P7CMAyzePFihojcxsww5v/5lZeXM08++STTqlUrJjY2lsnNzWVeeukl0TZbM/38LAwjKMUGAAAAEERhlSMCAAAAxoJABAAAAHSDQAQAAAB0g0AEAAAAdINABAAAAHSDQAQAAAB0g0AEAAAAdINABAAAAHSDQAQAAAB0g0AEAAAAdINABAAAAHSDQAQAAAB08//GW92TpSPs0wAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(data_cam['P01'][0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "56JG3ogz-LUE",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2024-01-24T12:28:29.085638Z",
     "iopub.status.busy": "2024-01-24T12:28:29.085303Z",
     "iopub.status.idle": "2024-01-24T12:28:29.208848Z",
     "shell.execute_reply": "2024-01-24T12:28:29.208084Z",
     "shell.execute_reply.started": "2024-01-24T12:28:29.085611Z"
    },
    "id": "56JG3ogz-LUE",
    "outputId": "d239a446-2b69-4f9c-f45e-c880f8c64511"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 8064])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "data_c1d = {}\n",
    "BLOCK_SIZE=640\n",
    "BLOCK_STRIDE=60\n",
    "for k,v in data_cam.items():\n",
    "    datablocki = []\n",
    "    v1 = v[0]\n",
    "    v1 = v1[:,np.newaxis,:]\n",
    "    #print(v1.shape)\n",
    "    data_c1d[k] = torch.tensor(v1)\n",
    "print(data_c1d['P01'][0].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ce1ed7be-a882-45ec-810d-6b1c43af0af3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-22T10:04:28.619802Z",
     "iopub.status.busy": "2024-01-22T10:04:28.618700Z",
     "iopub.status.idle": "2024-01-22T10:04:28.688356Z",
     "shell.execute_reply": "2024-01-22T10:04:28.687618Z",
     "shell.execute_reply.started": "2024-01-22T10:04:28.619762Z"
    },
    "id": "ce1ed7be-a882-45ec-810d-6b1c43af0af3"
   },
   "outputs": [],
   "source": [
    "data_c2 = {}\n",
    "for k,v in data_cam.items():\n",
    "    y = v[1]\n",
    "    x_label = np.zeros((y.shape[0]),dtype='float64')\n",
    "    for i in range(y.shape[0]):\n",
    "        if (y[i][0] > 5):\n",
    "            x_label[i] = 1\n",
    "        else:\n",
    "            x_label[i] = 0\n",
    "\n",
    "    x_l = x_label\n",
    "    x_l = x_l.reshape(-1,1)\n",
    "    x_l = torch.tensor(x_l)\n",
    "    data_c2[k] = x_l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "fa943a48-8252-4c85-ab48-4e6cb0c101a4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-21T20:26:35.503245Z",
     "iopub.status.busy": "2024-01-21T20:26:35.502318Z",
     "iopub.status.idle": "2024-01-21T20:26:35.509003Z",
     "shell.execute_reply": "2024-01-21T20:26:35.508226Z",
     "shell.execute_reply.started": "2024-01-21T20:26:35.503218Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1.],\n",
       "        [1.],\n",
       "        [0.],\n",
       "        [1.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [0.],\n",
       "        [1.],\n",
       "        [0.],\n",
       "        [1.]], dtype=torch.float64)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_c2['P02']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "Pm5zhOqDgK79",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-24T12:28:32.862158Z",
     "iopub.status.busy": "2024-01-24T12:28:32.861696Z",
     "iopub.status.idle": "2024-01-24T12:28:32.871490Z",
     "shell.execute_reply": "2024-01-24T12:28:32.870391Z",
     "shell.execute_reply.started": "2024-01-24T12:28:32.862117Z"
    },
    "id": "Pm5zhOqDgK79"
   },
   "outputs": [],
   "source": [
    "data_c2 = {}\n",
    "maxnum = 3\n",
    "for k,v in data_cam.items():\n",
    "    y = v[1]\n",
    "    x_label = np.zeros((y.shape[0]),dtype='int32')\n",
    "    for i in range(y.shape[0]):\n",
    "        if (y[i][1] > 5 and y[i][0] > 5):\n",
    "            x_label[i] = 3\n",
    "        elif (y[i][1] <= 5 and y[i][0] > 5):\n",
    "            x_label[i] = 2\n",
    "        elif (y[i][1] > 5 and y[i][0] <= 5):\n",
    "            x_label[i] = 1\n",
    "        elif (y[i][1] <= 5 and y[i][0] <= 5):\n",
    "            x_label[i] = 0\n",
    "\n",
    "    x_l = np.zeros((x_label.size, maxnum+1))\n",
    "    x_l[np.arange(x_label.size), x_label] = 1\n",
    "\n",
    "    x_l = torch.tensor(x_l)\n",
    "    data_c2[k] = x_l\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "6d8e2d1b-cc85-483f-843a-8d7c4b9c5ec8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-22T10:14:03.574101Z",
     "iopub.status.busy": "2024-01-22T10:14:03.573139Z",
     "iopub.status.idle": "2024-01-22T10:14:03.578258Z",
     "shell.execute_reply": "2024-01-22T10:14:03.577561Z",
     "shell.execute_reply.started": "2024-01-22T10:14:03.574074Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([20, 4])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_c2['P01'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "48a74ab5-e71d-441a-b786-630c4abc3685",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-24T13:22:18.537887Z",
     "iopub.status.busy": "2024-01-24T13:22:18.537511Z",
     "iopub.status.idle": "2024-01-24T13:22:18.569104Z",
     "shell.execute_reply": "2024-01-24T13:22:18.567802Z",
     "shell.execute_reply.started": "2024-01-24T13:22:18.537859Z"
    },
    "id": "48a74ab5-e71d-441a-b786-630c4abc3685"
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'torchsummary'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [50], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorchsummary\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m summary\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mnn\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnn\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mnn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mfunctional\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mF\u001b[39;00m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'torchsummary'"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torchsummary import summary\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "#from torchinfo import Summary\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.c1=nn.Conv1d(1, 34, 10,stride=1)\n",
    "        self.mp1=nn.MaxPool1d(2)\n",
    "        self.norm1 = nn.BatchNorm1d(34)\n",
    "        self.d = nn.Dropout(p=0.63)\n",
    "        self.c2=nn.Conv1d(34, 30, 10,stride=1)\n",
    "        self.mp2=nn.MaxPool1d(2)\n",
    "        self.c3=nn.Conv1d(30, 10, 10,stride=1)\n",
    "        self.norm3 = nn.BatchNorm1d(10)\n",
    "        self.mp3=nn.MaxPool1d(2)\n",
    "        self.ft = nn.Flatten()\n",
    "\n",
    "        self.n1 = nn.Linear(20070,110)\n",
    "        #self.n1 = nn.Linear(19590,110)\n",
    "        self.normfc1=nn.BatchNorm1d(110)\n",
    "        self.d = nn.Dropout(p=0.63)\n",
    "        #self.d = nn.Dropout()\n",
    "        self.n2 = nn.Linear(110,100)\n",
    "        self.n3 = nn.Linear(100,4)\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.d(self.norm1(F.tanh(self.c1(x))))\n",
    "        #x=F.tanh(self.c1(x))\n",
    "        x = self.mp2(F.tanh(self.c2(x)))\n",
    "        #print(x.shape)\n",
    "        x = self.mp3(F.tanh(self.c3(x)))\n",
    "\n",
    "        #print(x.shape)\n",
    "        x = self.ft(x)\n",
    "        #print(x.shape)\n",
    "        x = F.tanh(self.n1(x))\n",
    "        x=self.normfc1(x)\n",
    "        #x=self.norm3(x)\n",
    "        x=self.d(x)\n",
    "\n",
    "        #x = F.softmax(self.n2(x),dim=-1)\n",
    "        x = F.tanh(self.n2(x))\n",
    "        #x = F.sigmoid(self.n3(x))\n",
    "\n",
    "        x = (self.n3(x))\n",
    "        #print(x.shape)\n",
    "        return x\n",
    "\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "#criterion = nn.BCELoss()\n",
    "Net.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "624818a4-e9ca-4f32-9930-8ade33ca95df",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "execution": {
     "iopub.execute_input": "2024-01-21T20:39:25.503661Z",
     "iopub.status.busy": "2024-01-21T20:39:25.503127Z",
     "iopub.status.idle": "2024-01-21T20:39:41.152046Z",
     "shell.execute_reply": "2024-01-21T20:39:41.151535Z",
     "shell.execute_reply.started": "2024-01-21T20:39:25.503640Z"
    },
    "id": "624818a4-e9ca-4f32-9930-8ade33ca95df",
    "outputId": "7b50a269-a030-4ad0-b013-e506e2fb1233"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 0:\n",
      "  Train: index=[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23\n",
      " 24 25 26 27 28 29 30 31 32 33 34 35]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_203/3472248682.py:38: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1960: UserWarning: nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\n",
      "  warnings.warn(\"nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/60, Train Loss: 0.6609741449356079\n",
      "Epoch 2/60, Train Loss: 0.6968510746955872\n",
      "Epoch 3/60, Train Loss: 0.7063091397285461\n",
      "Epoch 4/60, Train Loss: 0.7129724025726318\n",
      "Epoch 5/60, Train Loss: 0.6755002737045288\n",
      "Epoch 6/60, Train Loss: 0.677463948726654\n",
      "Epoch 7/60, Train Loss: 0.7001715302467346\n",
      "Epoch 8/60, Train Loss: 0.641160249710083\n",
      "Epoch 9/60, Train Loss: 0.6524507403373718\n",
      "Epoch 10/60, Train Loss: 0.6981868147850037\n",
      "Epoch 11/60, Train Loss: 0.7125951051712036\n",
      "Epoch 12/60, Train Loss: 0.6761418581008911\n",
      "Epoch 13/60, Train Loss: 0.6650707125663757\n",
      "Epoch 14/60, Train Loss: 0.6498364806175232\n",
      "Epoch 15/60, Train Loss: 0.6750850081443787\n",
      "Epoch 16/60, Train Loss: 0.7362504005432129\n",
      "Epoch 17/60, Train Loss: 0.6782377362251282\n",
      "Epoch 18/60, Train Loss: 0.6005708575248718\n",
      "Epoch 19/60, Train Loss: 0.6484631896018982\n",
      "Epoch 20/60, Train Loss: 0.6615355610847473\n",
      "Epoch 21/60, Train Loss: 0.7476146817207336\n",
      "Epoch 22/60, Train Loss: 0.6450007557868958\n",
      "Epoch 23/60, Train Loss: 0.6990272998809814\n",
      "Epoch 24/60, Train Loss: 0.6960132718086243\n",
      "Epoch 25/60, Train Loss: 0.6487043499946594\n",
      "Epoch 26/60, Train Loss: 0.6940182447433472\n",
      "Epoch 27/60, Train Loss: 0.7425288558006287\n",
      "Epoch 28/60, Train Loss: 0.7695755958557129\n",
      "Epoch 29/60, Train Loss: 0.6488133072853088\n",
      "Epoch 30/60, Train Loss: 0.6783266067504883\n",
      "Epoch 31/60, Train Loss: 0.6386670470237732\n",
      "Epoch 32/60, Train Loss: 0.6566615700721741\n",
      "Epoch 33/60, Train Loss: 0.6245983242988586\n",
      "Epoch 34/60, Train Loss: 0.6381314396858215\n",
      "Epoch 35/60, Train Loss: 0.6594816446304321\n",
      "Epoch 36/60, Train Loss: 0.6990213394165039\n",
      "Epoch 37/60, Train Loss: 0.7033595442771912\n",
      "Epoch 38/60, Train Loss: 0.72736656665802\n",
      "Epoch 39/60, Train Loss: 0.6317784190177917\n",
      "Epoch 40/60, Train Loss: 0.695755660533905\n",
      "Epoch 41/60, Train Loss: 0.5978154540061951\n",
      "Epoch 42/60, Train Loss: 0.7467979788780212\n",
      "Epoch 43/60, Train Loss: 0.6905636191368103\n",
      "Epoch 44/60, Train Loss: 0.6623584628105164\n",
      "Epoch 45/60, Train Loss: 0.6861650347709656\n",
      "Epoch 46/60, Train Loss: 0.6978986859321594\n",
      "Epoch 47/60, Train Loss: 0.69769287109375\n",
      "Epoch 48/60, Train Loss: 0.6886689066886902\n",
      "Epoch 49/60, Train Loss: 0.6211285591125488\n",
      "Epoch 50/60, Train Loss: 0.7211494445800781\n",
      "Epoch 51/60, Train Loss: 0.645512580871582\n",
      "Epoch 52/60, Train Loss: 0.6711452603340149\n",
      "Epoch 53/60, Train Loss: 0.6328474283218384\n",
      "Epoch 54/60, Train Loss: 0.6318807005882263\n",
      "Epoch 55/60, Train Loss: 0.6630229353904724\n",
      "Epoch 56/60, Train Loss: 0.7082170844078064\n",
      "Epoch 57/60, Train Loss: 0.6603700518608093\n",
      "Epoch 58/60, Train Loss: 0.6021323204040527\n",
      "Epoch 59/60, Train Loss: 0.6721572875976562\n",
      "Epoch 60/60, Train Loss: 0.6605284214019775\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import confusion_matrix,classification_report\n",
    "from sklearn import preprocessing\n",
    "import matplotlib.pyplot as plt\n",
    "#subjectnames\n",
    "file_list_num = np.arange(len(newsubjectname))\n",
    "kf = KFold(n_splits=12)\n",
    "torch.manual_seed(42)\n",
    "torch.cuda.manual_seed(42)\n",
    "modellist = []\n",
    "modelid = 1\n",
    "#file_list_num\n",
    "#for i, (train_index, test_index) in enumerate(kf.split(file_list_num)):\n",
    "#for train_index in file_list_num:\n",
    "train_index = file_list_num\n",
    "print(f\"Fold {i}:\")\n",
    "print(f\"  Train: index={train_index}\")\n",
    "#print(f\"  Test:  index={test_index}\")\n",
    "net = Net()\n",
    "net.to(device)\n",
    "optimizer = optim.Adam(net.parameters(), lr=0.000001)\n",
    "epochs = 60\n",
    "batch_sz = 20\n",
    "train_loss_epoch = []\n",
    "val_loss_epoch = []\n",
    "for epoch in range(epochs):\n",
    "  train_loss = []\n",
    "  for tr in train_index:\n",
    "    v = data_c1d[newsubjectname[tr]]\n",
    "    l = data_c2[newsubjectname[tr]]\n",
    "    #print(v[0].shape)\n",
    "    net.train()\n",
    "    for i in range(0,len(v),batch_sz):\n",
    "      #print(v[i].shape)\n",
    "      #for j in range(0,v[i].shape[0],batch_sz):\n",
    "      #print(newsubjectname[tr])\n",
    "      optimizer.zero_grad()\n",
    "      outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
    "      #print(\"Expout {}\",outputs.shape)\n",
    "      #print(\"Actual {}\",l[i:i+batch_sz].shape)\n",
    "      #print(l[i].shape)\n",
    "      loss = criterion(outputs, l[i:i+batch_sz].to(device, dtype=torch.float))\n",
    "      loss.backward()\n",
    "      train_loss.append(loss)\n",
    "      optimizer.step()\n",
    "  print(f'Epoch {epoch + 1}/{epochs}, Train Loss: {loss.item()}')\n",
    "  train_loss_epoch.append(torch.stack(train_loss).mean().cpu().detach().numpy())\n",
    "\n",
    "  '''\n",
    "  for tr in test_index:\n",
    "      net.eval()\n",
    "      v = data_c1d[newsubjectname[tr]]\n",
    "      l = data_c2[newsubjectname[tr]]\n",
    "      net.eval()\n",
    "      with torch.no_grad():\n",
    "          for i in range(0,len(v),batch_sz):\n",
    "            #print(v[i].shape)\n",
    "            #for j in range(0,v[i].shape[0],batch_sz):\n",
    "            optimizer.zero_grad()\n",
    "            outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
    "            #print(outputs.shape)\n",
    "            #print(l[i].shape)\n",
    "            #outputs1 = torch.softmax(outputs,dim=-1)\n",
    "            loss = criterion(outputs, l[i:i+batch_sz].to(device, dtype=torch.float))\n",
    "            val_loss.append(loss)\n",
    "            #loss.backward()\n",
    "            actualoutput.append(torch.round(outputs.cpu()))\n",
    "            expectedoutput.append(l[i:i+batch_sz])\n",
    "            #actualoutput.append(torch.argmax(torch.softmax(outputs.cpu(),dim=1),dim=1))\n",
    "            #expectedoutput.append(torch.argmax(l[i:i+batch_sz],dim=1).numpy())\n",
    "  val_loss_mean = torch.stack(val_loss).mean().cpu().detach().numpy()\n",
    "  val_loss_epoch.append(val_loss_mean)\n",
    "  expectedoutput = np.concatenate( expectedoutput, axis=0 )\n",
    "  actualoutput = np.concatenate( actualoutput, axis=0 )\n",
    "  print(expectedoutput.shape)\n",
    "  print(actualoutput.shape)\n",
    "  print(classification_report(expectedoutput,actualoutput))\n",
    "  print(confusion_matrix(expectedoutput,actualoutput))\n",
    "  print(f'Validation Loss for {subjectnames[tr]} = {val_loss_mean}')\n",
    "  #break\n",
    "  '''\n",
    "#plt.figure(figsize=(10,7))\n",
    "#print(len(train_loss_epoch))\n",
    "#plt.plot(np.arange(epochs),train_loss_epoch,label='Train')\n",
    "#plt.plot(np.arange(epochs),val_loss_epoch,label='Validation')\n",
    "#plt.legend()\n",
    "#path = \"Model\"+str(modelid) +\".pt\"\n",
    "#path = \"ModelAMIGOS_Aro.pt\"\n",
    "#modelid = modelid+1\n",
    "#print(path)\n",
    "#torch.save(net.state_dict(), path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "5P36UViqRcul",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5P36UViqRcul",
    "outputId": "e071c001-0c26-4c44-ee20-9a315b022829"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-27-7929d1561c85>:33: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs_val = netValence(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "<ipython-input-27-7929d1561c85>:35: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs_aro = netArousal(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.39      0.22      0.28        41\n",
      "           2       0.56      0.12      0.20        42\n",
      "           3       0.24      0.52      0.33        27\n",
      "           4       0.36      0.50      0.42        50\n",
      "\n",
      "    accuracy                           0.33       160\n",
      "   macro avg       0.39      0.34      0.31       160\n",
      "weighted avg       0.40      0.33      0.31       160\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-27-7929d1561c85>:33: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs_val = netValence(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "<ipython-input-27-7929d1561c85>:35: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs_aro = netArousal(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.50      0.17      0.25        42\n",
      "           2       1.00      0.10      0.18        30\n",
      "           3       0.34      0.83      0.48        41\n",
      "           4       0.40      0.36      0.38        47\n",
      "\n",
      "    accuracy                           0.38       160\n",
      "   macro avg       0.56      0.36      0.32       160\n",
      "weighted avg       0.52      0.38      0.33       160\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-27-7929d1561c85>:33: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs_val = netValence(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "<ipython-input-27-7929d1561c85>:35: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs_aro = netArousal(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.21      0.19      0.20        31\n",
      "           2       0.57      0.12      0.20        34\n",
      "           3       0.29      0.53      0.37        43\n",
      "           4       0.48      0.40      0.44        52\n",
      "\n",
      "    accuracy                           0.34       160\n",
      "   macro avg       0.39      0.31      0.30       160\n",
      "weighted avg       0.39      0.34      0.32       160\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-27-7929d1561c85>:33: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs_val = netValence(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "<ipython-input-27-7929d1561c85>:35: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs_aro = netArousal(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.36      0.12      0.19        32\n",
      "           2       0.67      0.05      0.10        39\n",
      "           3       0.30      0.67      0.42        39\n",
      "           4       0.52      0.62      0.56        50\n",
      "\n",
      "    accuracy                           0.39       160\n",
      "   macro avg       0.46      0.37      0.32       160\n",
      "weighted avg       0.47      0.39      0.34       160\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-27-7929d1561c85>:33: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs_val = netValence(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "<ipython-input-27-7929d1561c85>:35: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs_aro = netArousal(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.44      0.10      0.16        42\n",
      "           2       0.33      0.07      0.12        28\n",
      "           3       0.21      0.77      0.33        26\n",
      "           4       0.48      0.36      0.41        64\n",
      "\n",
      "    accuracy                           0.31       160\n",
      "   macro avg       0.37      0.32      0.25       160\n",
      "weighted avg       0.40      0.31      0.28       160\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-27-7929d1561c85>:33: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs_val = netValence(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "<ipython-input-27-7929d1561c85>:35: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs_aro = netArousal(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.56      0.18      0.27        28\n",
      "           2       0.00      0.00      0.00        22\n",
      "           3       0.31      0.71      0.43        48\n",
      "           4       0.55      0.35      0.43        62\n",
      "\n",
      "    accuracy                           0.38       160\n",
      "   macro avg       0.35      0.31      0.28       160\n",
      "weighted avg       0.40      0.38      0.34       160\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-27-7929d1561c85>:33: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs_val = netValence(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "<ipython-input-27-7929d1561c85>:35: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs_aro = netArousal(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "<ipython-input-27-7929d1561c85>:33: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs_val = netValence(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "<ipython-input-27-7929d1561c85>:35: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs_aro = netArousal(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.17      0.03      0.05        33\n",
      "           2       0.00      0.00      0.00        37\n",
      "           3       0.27      0.76      0.39        41\n",
      "           4       0.37      0.29      0.32        49\n",
      "\n",
      "    accuracy                           0.29       160\n",
      "   macro avg       0.20      0.27      0.19       160\n",
      "weighted avg       0.22      0.29      0.21       160\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.26      0.20      0.23        25\n",
      "           2       1.00      0.14      0.24        37\n",
      "           3       0.20      0.55      0.29        33\n",
      "           4       0.50      0.34      0.40        65\n",
      "\n",
      "    accuracy                           0.31       160\n",
      "   macro avg       0.49      0.30      0.29       160\n",
      "weighted avg       0.52      0.31      0.31       160\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import confusion_matrix,classification_report\n",
    "from sklearn import preprocessing\n",
    "import matplotlib.pyplot as plt\n",
    "#subjectnames\n",
    "batch_sz = 20\n",
    "file_list_num = np.arange(len(subjectnames))\n",
    "modelid = 1\n",
    "netValence = Net()\n",
    "valmodelname = \"Valence_Model4\"+\".pt\"\n",
    "netValence.load_state_dict(torch.load(valmodelname))\n",
    "netValence.to(device)\n",
    "netArousal = Net()\n",
    "aromodelname = \"Model5\"+\".pt\"\n",
    "netArousal.load_state_dict(torch.load(aromodelname))\n",
    "netArousal.to(device)\n",
    "for i in range(0,32,4):\n",
    "\n",
    "    #optimizer = optim.Adam(net.parameters(), lr=0.000001)\n",
    "    expectedoutput = []\n",
    "    actualoutput = []\n",
    "    for tr in file_list_num[i:i+4]:\n",
    "        #net.eval()\n",
    "        v = data_c1d[subjectnames[tr]]\n",
    "        l = data_c3[subjectnames[tr]]\n",
    "        netValence.eval()\n",
    "        netArousal.eval()\n",
    "        with torch.no_grad():\n",
    "            for i in range(0,len(v),batch_sz):\n",
    "              #print(v[i].shape)\n",
    "              #for j in range(0,v[i].shape[0],batch_sz):\n",
    "              #optimizer.zero_grad()\n",
    "              outputs_val = netValence(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
    "              outputs_val1 = torch.round(outputs_val)\n",
    "              outputs_aro = netArousal(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
    "              outputs_aro1 = torch.round(outputs_aro)\n",
    "\n",
    "              #print(outputs_val1)\n",
    "              for j in range(0,outputs_aro1.shape[0]):\n",
    "                res = 0\n",
    "                if (outputs_val1[j][0] >= 1 and outputs_aro1[j][0] >= 1):\n",
    "                    res = 4\n",
    "                elif (outputs_val1[j][0] < 1 and outputs_aro1[j][0] >= 1):\n",
    "                    res = 3\n",
    "                elif (outputs_val1[j][0] >= 1 and outputs_aro1[j][0] < 1):\n",
    "                    res = 2\n",
    "                elif (outputs_val1[j][0] < 1 and outputs_aro1[j][0] < 1):\n",
    "                    res = 1\n",
    "                actualoutput.append(res)\n",
    "              #loss = criterion(outputs, l[i:i+batch_sz].to(device, dtype=torch.float))\n",
    "              #val_loss.append(loss)\n",
    "              #loss.backward()\n",
    "              #print(outputs.shape)\n",
    "              #print(l[i:i+batch_sz])\n",
    "              expectedoutput.append(l[i:i+batch_sz])\n",
    "              #actualoutput.append(actualoutput)\n",
    "      #val_loss_mean = torch.stack(val_loss).mean().cpu().detach().numpy()\n",
    "      #val_loss_epoch.append(val_loss_mean)\n",
    "    expectedoutput = np.concatenate( expectedoutput, axis=0 )\n",
    "      #actualoutput = np.concatenate( actualoutput, axis=0 )\n",
    "      #print(actualoutput)\n",
    "    #print(expectedoutput)\n",
    "    #print(actualoutput)\n",
    "    print(classification_report(expectedoutput,actualoutput))\n",
    "      #print(f'Validation Loss for {subjectnames[tr]} = {val_loss_mean}')\n",
    "      #break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9XuinMzzRq3R",
   "metadata": {
    "id": "9XuinMzzRq3R"
   },
   "outputs": [],
   "source": [
    "rm -rf Model*.pt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "8-a4aWI1C7If",
   "metadata": {
    "id": "8-a4aWI1C7If"
   },
   "outputs": [],
   "source": [
    "data_c3 = {}\n",
    "for k,v in data_c.items():\n",
    "    y = data_c[k][1]\n",
    "    x_label = np.zeros((y.shape[0]),dtype='int8')\n",
    "    for i in range(y.shape[0]):\n",
    "        if (y[i][0] > 5 and y[i][1] > 5):\n",
    "            x_label[i] = 4\n",
    "        elif (y[i][0] <= 5 and y[i][1] > 5):\n",
    "            x_label[i] = 3\n",
    "        elif (y[i][0] > 5 and y[i][1] <= 5):\n",
    "            x_label[i] = 2\n",
    "        elif (y[i][0] <= 5 and y[i][1] <= 5):\n",
    "            x_label[i] = 1\n",
    "    #x_l = np.zeros((x_label.size, x_label.max()+1))\n",
    "    #x_l[np.arange(x_label.size), x_label] = 1\n",
    "    #\n",
    "    #print(x_l.shape)\n",
    "    #x_l = x_l.reshape(-1,1,4)\n",
    "    #x_l = np.repeat(x_l, 117, axis=1)\n",
    "    #print(x_l.shape)\n",
    "    x_l = torch.tensor(x_label)\n",
    "    data_c3[k] = x_l\n",
    "    #print(data_c3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "538f2018-fa74-4426-9c36-d56fbeea2f5d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-24T12:28:48.245793Z",
     "iopub.status.busy": "2024-01-24T12:28:48.245273Z",
     "iopub.status.idle": "2024-01-24T12:28:48.255737Z",
     "shell.execute_reply": "2024-01-24T12:28:48.254863Z",
     "shell.execute_reply.started": "2024-01-24T12:28:48.245739Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['DEAP/s21.dat', 'DEAP/s25.dat', 'DEAP/s07.dat', 'DEAP/s22.dat', 'DEAP/s32.dat', 'DEAP/s10.dat', 'DEAP/s04.dat', 'DEAP/s23.dat', 'DEAP/s30.dat', 'DEAP/s06.dat', 'DEAP/s31.dat', 'DEAP/s16.dat', 'DEAP/s15.dat', 'DEAP/s08.dat', 'DEAP/s28.dat', 'DEAP/s17.dat', 'DEAP/s26.dat', 'DEAP/s02.dat', 'DEAP/s19.dat', 'DEAP/s18.dat', 'DEAP/s03.dat', 'DEAP/s29.dat', 'DEAP/s24.dat', 'DEAP/s05.dat', 'DEAP/s14.dat', 'DEAP/s12.dat', 'DEAP/s11.dat', 'DEAP/s27.dat', 'DEAP/s20.dat', 'DEAP/s09.dat', 'DEAP/s13.dat', 'DEAP/s01.dat']\n",
      "['s21', 's25', 's07', 's22', 's32', 's10', 's04', 's23', 's30', 's06', 's31', 's16', 's15', 's08', 's28', 's17', 's26', 's02', 's19', 's18', 's03', 's29', 's24', 's05', 's14', 's12', 's11', 's27', 's20', 's09', 's13', 's01']\n"
     ]
    }
   ],
   "source": [
    "import glob\n",
    "import os\n",
    "filelistd = glob.glob('DEAP/*.dat')\n",
    "print(filelistd)\n",
    "subjectnamesd = [fr[5:8] for fr in filelistd]\n",
    "print(subjectnamesd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "dcb43263-e6f0-4f6f-97fd-ffd8fe6efb21",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-24T12:28:50.364288Z",
     "iopub.status.busy": "2024-01-24T12:28:50.363921Z",
     "iopub.status.idle": "2024-01-24T12:29:05.881361Z",
     "shell.execute_reply": "2024-01-24T12:29:05.880135Z",
     "shell.execute_reply.started": "2024-01-24T12:28:50.364257Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['s21', 's25', 's07', 's22', 's32', 's10', 's04', 's23', 's30', 's06', 's31', 's16', 's15', 's08', 's28', 's17', 's26', 's02', 's19', 's18', 's03', 's29', 's24', 's05', 's14', 's12', 's11', 's27', 's20', 's09', 's13', 's01'])\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "datad = {}\n",
    "for sname in subjectnamesd:\n",
    "    dname = \"DEAP/\"+sname+\".dat\"\n",
    "    f = open(dname, 'rb')\n",
    "    x = pickle.load(f, encoding='latin1')\n",
    "    datad[sname] = x\n",
    "print(datad.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "9e192455-a6bc-45f1-b641-9fde46b3586c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-24T12:30:13.098235Z",
     "iopub.status.busy": "2024-01-24T12:30:13.097859Z",
     "iopub.status.idle": "2024-01-24T12:30:13.185716Z",
     "shell.execute_reply": "2024-01-24T12:30:13.184638Z",
     "shell.execute_reply.started": "2024-01-24T12:30:13.098197Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "data_de = {}\n",
    "for k,v in datad.items():\n",
    "    y = datad[k]['data'][:,36,:]\n",
    "    ym = np.mean(y,axis=-1).reshape(40,1)\n",
    "    ystd = np.std(y,axis=-1).reshape(40,1)\n",
    "    z = (y-ym)/ystd\n",
    "    data_de[k] = [z,datad[k]['labels']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b1f12cea-e417-4f5d-b827-53bc3a41b517",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-24T12:30:19.234079Z",
     "iopub.status.busy": "2024-01-24T12:30:19.233698Z",
     "iopub.status.idle": "2024-01-24T12:30:19.348331Z",
     "shell.execute_reply": "2024-01-24T12:30:19.347287Z",
     "shell.execute_reply.started": "2024-01-24T12:30:19.234050Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 8064])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "data_de1 = {}\n",
    "for k,v in data_de.items():\n",
    "    datablocki = []\n",
    "    v1=np.vstack(v[0])\n",
    "    v1 = v1[:,np.newaxis,:]\n",
    "    data_de1[k] = torch.tensor(v1)\n",
    "print(data_de1['s01'][0].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "79b2bfa1-9d78-4f7d-b0f0-17c05654fbaa",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-24T12:30:21.863873Z",
     "iopub.status.busy": "2024-01-24T12:30:21.863487Z",
     "iopub.status.idle": "2024-01-24T12:30:21.874447Z",
     "shell.execute_reply": "2024-01-24T12:30:21.873430Z",
     "shell.execute_reply.started": "2024-01-24T12:30:21.863845Z"
    }
   },
   "outputs": [],
   "source": [
    "data_del = {}\n",
    "ximax = 3\n",
    "for k,v in data_de.items():\n",
    "    y = data_de[k][1]\n",
    "    x_label = np.zeros((y.shape[0]),dtype='int64')\n",
    "    for i in range(y.shape[0]):\n",
    "        if (y[i][0] > 5 and y[i][1] > 5):\n",
    "            x_label[i] = 3\n",
    "        elif (y[i][0] <= 5 and y[i][1] > 5):\n",
    "            x_label[i] = 2\n",
    "        elif (y[i][0] > 5 and y[i][1] <= 5):\n",
    "            x_label[i] = 1\n",
    "        elif (y[i][0] <= 5 and y[i][1] <= 5):\n",
    "            x_label[i] = 0\n",
    "    x_l = np.zeros((x_label.size, ximax+1))\n",
    "    x_l[np.arange(x_label.size), x_label] = 1\n",
    "    #x_l = x_label\n",
    "    #\n",
    "    #print(x_l.shape)\n",
    "    x_l = x_l.reshape(-1,4)\n",
    "\n",
    "    x_l = torch.tensor(x_l)\n",
    "    data_del[k] = x_l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3510574e-92c7-4f83-8ea3-b1c842ec8792",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-22T10:36:12.597926Z",
     "iopub.status.busy": "2024-01-22T10:36:12.597240Z",
     "iopub.status.idle": "2024-01-22T10:36:12.603447Z",
     "shell.execute_reply": "2024-01-22T10:36:12.602820Z",
     "shell.execute_reply.started": "2024-01-22T10:36:12.597899Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([40, 4])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_del['s01'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "00a549ca-dc77-4ef8-a2ce-948a31cb944d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-21T21:26:54.344614Z",
     "iopub.status.busy": "2024-01-21T21:26:54.343936Z",
     "iopub.status.idle": "2024-01-21T21:26:55.114174Z",
     "shell.execute_reply": "2024-01-21T21:26:55.113433Z",
     "shell.execute_reply.started": "2024-01-21T21:26:54.344580Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 20:\n",
      "  Train: index=[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23\n",
      " 24 25 26 27 28 29 30 31]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_410/3061022090.py:39: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1960: UserWarning: nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\n",
      "  warnings.warn(\"nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.45      1.00      0.62       572\n",
      "         1.0       0.00      0.00      0.00       708\n",
      "\n",
      "    accuracy                           0.45      1280\n",
      "   macro avg       0.22      0.50      0.31      1280\n",
      "weighted avg       0.20      0.45      0.28      1280\n",
      "\n",
      "[[572   0]\n",
      " [708   0]]\n",
      "Validation Loss for s01 = 0.6970333456993103\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.9/dist-packages/sklearn/metrics/_classification.py:1334: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.9/dist-packages/sklearn/metrics/_classification.py:1334: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.9/dist-packages/sklearn/metrics/_classification.py:1334: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import confusion_matrix,classification_report\n",
    "from sklearn import preprocessing\n",
    "import matplotlib.pyplot as plt\n",
    "#subjectnames\n",
    "file_list_numd = np.arange(len(subjectnamesd))\n",
    "net = Net()\n",
    "net.to(device)\n",
    "optimizer = optim.Adam(net.parameters(), lr=0.000001)\n",
    "torch.manual_seed(42)\n",
    "torch.cuda.manual_seed(42)\n",
    "expectedoutputdeap = []\n",
    "actualoutputdeap = []\n",
    "val_loss = []\n",
    "expectedoutput = []\n",
    "actualoutput = []\n",
    "test_index = file_list_numd\n",
    "print(f\"Fold {i}:\")\n",
    "print(f\"  Train: index={test_index}\")\n",
    "#print(f\"  Test:  index={test_index}\")\n",
    "#net = Net()\n",
    "#net.to(device)\n",
    "#optimizer = optim.Adam(net.parameters(), lr=0.000001)\n",
    "#epochs = 60\n",
    "batch_sz = 20\n",
    "train_loss_epoch = []\n",
    "val_loss_epoch = []\n",
    "\n",
    "for tr in test_index:\n",
    "    net.eval()\n",
    "    v = data_de1[subjectnamesd[tr]]\n",
    "    l = data_del[subjectnamesd[tr]]\n",
    "    net.eval()\n",
    "    with torch.no_grad():\n",
    "        for i in range(0,len(v),batch_sz):\n",
    "          #print(v[i].shape)\n",
    "          #for j in range(0,v[i].shape[0],batch_sz):\n",
    "          optimizer.zero_grad()\n",
    "          outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
    "          #print(outputs.shape)\n",
    "          #print(l[i:i+batch_sz].shape)\n",
    "          loss = criterion(outputs, l[i:i+batch_sz].to(device, dtype=torch.float))\n",
    "          val_loss.append(loss)\n",
    "          actualoutputdeap.append(torch.round(outputs.cpu()))\n",
    "          expectedoutputdeap.append(l[i:i+batch_sz])\n",
    "          #actualoutput.append(torch.argmax(torch.softmax(outputs.cpu(),dim=1),dim=1))\n",
    "          #expectedoutput.append(torch.argmax(l[i:i+batch_sz],dim=1).numpy())\n",
    "val_loss_mean = torch.stack(val_loss).mean().cpu().detach().numpy()\n",
    "val_loss_epoch.append(val_loss_mean)\n",
    "expectedoutputdeap = np.concatenate( expectedoutputdeap, axis=0 )\n",
    "actualoutputdeap = np.concatenate( actualoutputdeap, axis=0 )\n",
    "#print(expectedoutput.shape)\n",
    "#print(actualoutput.shape)\n",
    "print(classification_report(expectedoutputdeap,actualoutputdeap))\n",
    "print(confusion_matrix(expectedoutputdeap,actualoutputdeap))\n",
    "print(f'Validation Loss for {subjectnamesd[tr]} = {val_loss_mean}')\n",
    "#break\n",
    "\n",
    "#plt.figure(figsize=(10,7))\n",
    "#print(len(train_loss_epoch))\n",
    "#plt.plot(np.arange(epochs),train_loss_epoch,label='Train')\n",
    "#plt.plot(np.arange(epochs),val_loss_epoch,label='Validation')\n",
    "#plt.legend()\n",
    "#path = \"Model\"+str(modelid) +\".pt\"\n",
    "#path = \"ModelAMIGOS_Aro.pt\"\n",
    "#modelid = modelid+1\n",
    "#print(path)\n",
    "#torch.save(net.state_dict(), path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "44278dac-15a4-400c-8676-184267c3942e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-23T13:09:55.482803Z",
     "iopub.status.busy": "2024-01-23T13:09:55.482444Z",
     "iopub.status.idle": "2024-01-23T13:12:25.217524Z",
     "shell.execute_reply": "2024-01-23T13:12:25.213432Z",
     "shell.execute_reply.started": "2024-01-23T13:09:55.482775Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 20:\n",
      "  Train: index=[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23\n",
      " 24 25 26 27 28 29 30 31 32 33 34 35]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_96/1313612177.py:43: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100, Train Loss: 1.5232149362564087\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_96/1313612177.py:68: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/tmp/ipykernel_96/1313612177.py:88: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.08      0.01      0.02        74\n",
      "           1       0.19      0.32      0.23        73\n",
      "           2       0.22      0.22      0.22       106\n",
      "           3       0.39      0.41      0.40       147\n",
      "\n",
      "    accuracy                           0.27       400\n",
      "   macro avg       0.22      0.24      0.22       400\n",
      "weighted avg       0.25      0.27      0.25       400\n",
      "\n",
      "[[ 1 28 17 28]\n",
      " [ 3 23 23 24]\n",
      " [ 3 35 23 45]\n",
      " [ 5 38 43 61]]\n",
      "Validation Loss for s21 = 1.366054892539978\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_96/1313612177.py:43: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/100, Train Loss: 1.360924482345581\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_96/1313612177.py:68: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/tmp/ipykernel_96/1313612177.py:88: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.13      0.14      0.13        74\n",
      "           1       0.16      0.32      0.21        73\n",
      "           2       0.23      0.22      0.22       106\n",
      "           3       0.45      0.24      0.31       147\n",
      "\n",
      "    accuracy                           0.23       400\n",
      "   macro avg       0.24      0.23      0.22       400\n",
      "weighted avg       0.28      0.23      0.24       400\n",
      "\n",
      "[[10 35 16 13]\n",
      " [13 23 22 15]\n",
      " [21 47 23 15]\n",
      " [31 41 40 35]]\n",
      "Validation Loss for s21 = 1.3570306301116943\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_96/1313612177.py:43: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/100, Train Loss: 1.378825068473816\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_96/1313612177.py:68: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/tmp/ipykernel_96/1313612177.py:88: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.19      0.45      0.26        74\n",
      "           1       0.21      0.19      0.20        73\n",
      "           2       0.21      0.18      0.19       106\n",
      "           3       0.48      0.21      0.29       147\n",
      "\n",
      "    accuracy                           0.24       400\n",
      "   macro avg       0.27      0.26      0.24       400\n",
      "weighted avg       0.31      0.24      0.24       400\n",
      "\n",
      "[[33 15 15 11]\n",
      " [26 14 22 11]\n",
      " [58 18 19 11]\n",
      " [60 20 36 31]]\n",
      "Validation Loss for s21 = 1.3509998321533203\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_96/1313612177.py:43: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/100, Train Loss: 1.3844245672225952\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_96/1313612177.py:68: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/tmp/ipykernel_96/1313612177.py:88: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.19      0.50      0.27        74\n",
      "           1       0.20      0.16      0.18        73\n",
      "           2       0.21      0.18      0.19       106\n",
      "           3       0.47      0.18      0.26       147\n",
      "\n",
      "    accuracy                           0.23       400\n",
      "   macro avg       0.27      0.26      0.23       400\n",
      "weighted avg       0.30      0.23      0.23       400\n",
      "\n",
      "[[37 13 14 10]\n",
      " [29 12 20 12]\n",
      " [66 14 19  7]\n",
      " [65 20 36 26]]\n",
      "Validation Loss for s21 = 1.3501675128936768\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_96/1313612177.py:43: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/100, Train Loss: 1.3959131240844727\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_96/1313612177.py:68: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/tmp/ipykernel_96/1313612177.py:88: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.18      0.50      0.27        74\n",
      "           1       0.18      0.14      0.15        73\n",
      "           2       0.20      0.15      0.17       106\n",
      "           3       0.45      0.19      0.27       147\n",
      "\n",
      "    accuracy                           0.23       400\n",
      "   macro avg       0.25      0.24      0.22       400\n",
      "weighted avg       0.29      0.23      0.22       400\n",
      "\n",
      "[[37 13 14 10]\n",
      " [32 10 17 14]\n",
      " [66 14 16 10]\n",
      " [66 20 33 28]]\n",
      "Validation Loss for s21 = 1.342175006866455\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_96/1313612177.py:43: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6/100, Train Loss: 1.45297372341156\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_96/1313612177.py:68: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/tmp/ipykernel_96/1313612177.py:88: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.18      0.50      0.27        74\n",
      "           1       0.16      0.14      0.15        73\n",
      "           2       0.22      0.15      0.18       106\n",
      "           3       0.50      0.20      0.29       147\n",
      "\n",
      "    accuracy                           0.23       400\n",
      "   macro avg       0.27      0.25      0.22       400\n",
      "weighted avg       0.30      0.23      0.23       400\n",
      "\n",
      "[[37 15 12 10]\n",
      " [34 10 17 12]\n",
      " [68 14 16  8]\n",
      " [66 24 27 30]]\n",
      "Validation Loss for s21 = 1.3465596437454224\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_96/1313612177.py:43: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7/100, Train Loss: 1.3328428268432617\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_96/1313612177.py:68: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/tmp/ipykernel_96/1313612177.py:88: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.18      0.50      0.26        74\n",
      "           1       0.18      0.15      0.16        73\n",
      "           2       0.20      0.13      0.16       106\n",
      "           3       0.48      0.20      0.28       147\n",
      "\n",
      "    accuracy                           0.23       400\n",
      "   macro avg       0.26      0.25      0.22       400\n",
      "weighted avg       0.29      0.23      0.22       400\n",
      "\n",
      "[[37 15 11 11]\n",
      " [36 11 14 12]\n",
      " [69 14 14  9]\n",
      " [66 21 31 29]]\n",
      "Validation Loss for s21 = 1.350050926208496\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_96/1313612177.py:43: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8/100, Train Loss: 1.3837321996688843\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_96/1313612177.py:68: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/tmp/ipykernel_96/1313612177.py:88: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/tmp/ipykernel_96/1313612177.py:43: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.18      0.50      0.27        74\n",
      "           1       0.18      0.16      0.17        73\n",
      "           2       0.19      0.11      0.14       106\n",
      "           3       0.43      0.19      0.26       147\n",
      "\n",
      "    accuracy                           0.22       400\n",
      "   macro avg       0.25      0.24      0.21       400\n",
      "weighted avg       0.27      0.22      0.22       400\n",
      "\n",
      "[[37 15  9 13]\n",
      " [34 12 13 14]\n",
      " [68 16 12 10]\n",
      " [66 23 30 28]]\n",
      "Validation Loss for s21 = 1.34157133102417\n",
      "Epoch 9/100, Train Loss: 1.3168014287948608\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_96/1313612177.py:68: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/tmp/ipykernel_96/1313612177.py:88: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.18      0.53      0.27        74\n",
      "           1       0.19      0.16      0.18        73\n",
      "           2       0.17      0.08      0.11       106\n",
      "           3       0.47      0.23      0.31       147\n",
      "\n",
      "    accuracy                           0.23       400\n",
      "   macro avg       0.25      0.25      0.22       400\n",
      "weighted avg       0.29      0.23      0.23       400\n",
      "\n",
      "[[39 13  9 13]\n",
      " [35 12 12 14]\n",
      " [69 16  9 12]\n",
      " [68 23 22 34]]\n",
      "Validation Loss for s21 = 1.3397036790847778\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_96/1313612177.py:43: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10/100, Train Loss: 1.2848080396652222\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_96/1313612177.py:68: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/tmp/ipykernel_96/1313612177.py:88: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.19      0.53      0.28        74\n",
      "           1       0.18      0.16      0.17        73\n",
      "           2       0.16      0.09      0.12       106\n",
      "           3       0.43      0.18      0.26       147\n",
      "\n",
      "    accuracy                           0.22       400\n",
      "   macro avg       0.24      0.24      0.21       400\n",
      "weighted avg       0.27      0.22      0.21       400\n",
      "\n",
      "[[39 13 10 12]\n",
      " [34 12 13 14]\n",
      " [68 18 10 10]\n",
      " [68 24 28 27]]\n",
      "Validation Loss for s21 = 1.3390028476715088\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_96/1313612177.py:43: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11/100, Train Loss: 1.437317132949829\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_96/1313612177.py:68: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/tmp/ipykernel_96/1313612177.py:88: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.18      0.50      0.26        74\n",
      "           1       0.19      0.16      0.18        73\n",
      "           2       0.16      0.08      0.10       106\n",
      "           3       0.45      0.24      0.31       147\n",
      "\n",
      "    accuracy                           0.23       400\n",
      "   macro avg       0.24      0.24      0.21       400\n",
      "weighted avg       0.27      0.23      0.22       400\n",
      "\n",
      "[[37 12 10 15]\n",
      " [34 12 12 15]\n",
      " [69 16  8 13]\n",
      " [67 24 21 35]]\n",
      "Validation Loss for s21 = 1.3319637775421143\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_96/1313612177.py:43: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12/100, Train Loss: 1.3874033689498901\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_96/1313612177.py:68: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/tmp/ipykernel_96/1313612177.py:88: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.18      0.50      0.26        74\n",
      "           1       0.19      0.16      0.18        73\n",
      "           2       0.16      0.09      0.12       106\n",
      "           3       0.41      0.19      0.26       147\n",
      "\n",
      "    accuracy                           0.22       400\n",
      "   macro avg       0.24      0.24      0.20       400\n",
      "weighted avg       0.26      0.22      0.21       400\n",
      "\n",
      "[[37 12 11 14]\n",
      " [34 12 12 15]\n",
      " [69 16 10 11]\n",
      " [67 23 29 28]]\n",
      "Validation Loss for s21 = 1.334141492843628\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_96/1313612177.py:43: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13/100, Train Loss: 1.390348196029663\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_96/1313612177.py:68: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/tmp/ipykernel_96/1313612177.py:88: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.18      0.50      0.27        74\n",
      "           1       0.18      0.18      0.18        73\n",
      "           2       0.17      0.09      0.12       106\n",
      "           3       0.43      0.19      0.26       147\n",
      "\n",
      "    accuracy                           0.22       400\n",
      "   macro avg       0.24      0.24      0.21       400\n",
      "weighted avg       0.27      0.22      0.21       400\n",
      "\n",
      "[[37 14 10 13]\n",
      " [34 13 12 14]\n",
      " [68 18 10 10]\n",
      " [65 26 28 28]]\n",
      "Validation Loss for s21 = 1.338241457939148\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_96/1313612177.py:43: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14/100, Train Loss: 1.3310455083847046\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_96/1313612177.py:68: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/tmp/ipykernel_96/1313612177.py:88: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/tmp/ipykernel_96/1313612177.py:43: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.19      0.55      0.28        74\n",
      "           1       0.18      0.14      0.15        73\n",
      "           2       0.17      0.10      0.13       106\n",
      "           3       0.43      0.18      0.26       147\n",
      "\n",
      "    accuracy                           0.22       400\n",
      "   macro avg       0.24      0.24      0.21       400\n",
      "weighted avg       0.27      0.22      0.21       400\n",
      "\n",
      "[[41 10 10 13]\n",
      " [37 10 12 14]\n",
      " [70 16 11  9]\n",
      " [69 21 30 27]]\n",
      "Validation Loss for s21 = 1.3335562944412231\n",
      "Epoch 15/100, Train Loss: 1.4889132976531982\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_96/1313612177.py:68: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/tmp/ipykernel_96/1313612177.py:88: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.19      0.55      0.28        74\n",
      "           1       0.18      0.14      0.16        73\n",
      "           2       0.16      0.08      0.11       106\n",
      "           3       0.47      0.22      0.30       147\n",
      "\n",
      "    accuracy                           0.23       400\n",
      "   macro avg       0.25      0.25      0.21       400\n",
      "weighted avg       0.28      0.23      0.22       400\n",
      "\n",
      "[[41 11  9 13]\n",
      " [37 10 12 14]\n",
      " [72 15  9 10]\n",
      " [69 19 26 33]]\n",
      "Validation Loss for s21 = 1.333701252937317\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_96/1313612177.py:43: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16/100, Train Loss: 1.4178032875061035\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_96/1313612177.py:68: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/tmp/ipykernel_96/1313612177.py:88: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.19      0.55      0.28        74\n",
      "           1       0.20      0.15      0.17        73\n",
      "           2       0.18      0.10      0.13       106\n",
      "           3       0.48      0.22      0.30       147\n",
      "\n",
      "    accuracy                           0.24       400\n",
      "   macro avg       0.26      0.26      0.22       400\n",
      "weighted avg       0.30      0.24      0.23       400\n",
      "\n",
      "[[41 10 10 13]\n",
      " [37 11 12 13]\n",
      " [72 15 11  8]\n",
      " [68 20 27 32]]\n",
      "Validation Loss for s21 = 1.3328561782836914\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_96/1313612177.py:43: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17/100, Train Loss: 1.393535852432251\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_96/1313612177.py:68: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/tmp/ipykernel_96/1313612177.py:88: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/tmp/ipykernel_96/1313612177.py:43: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.19      0.55      0.28        74\n",
      "           1       0.18      0.15      0.17        73\n",
      "           2       0.17      0.10      0.13       106\n",
      "           3       0.44      0.18      0.25       147\n",
      "\n",
      "    accuracy                           0.22       400\n",
      "   macro avg       0.25      0.25      0.21       400\n",
      "weighted avg       0.27      0.22      0.21       400\n",
      "\n",
      "[[41 11 10 12]\n",
      " [36 11 13 13]\n",
      " [71 16 11  8]\n",
      " [67 22 32 26]]\n",
      "Validation Loss for s21 = 1.3341606855392456\n",
      "Epoch 18/100, Train Loss: 1.3798311948776245\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_96/1313612177.py:68: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/tmp/ipykernel_96/1313612177.py:88: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/tmp/ipykernel_96/1313612177.py:43: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.19      0.54      0.28        74\n",
      "           1       0.18      0.15      0.16        73\n",
      "           2       0.16      0.10      0.13       106\n",
      "           3       0.44      0.18      0.25       147\n",
      "\n",
      "    accuracy                           0.22       400\n",
      "   macro avg       0.24      0.24      0.21       400\n",
      "weighted avg       0.27      0.22      0.21       400\n",
      "\n",
      "[[40 11 11 12]\n",
      " [36 11 13 13]\n",
      " [71 16 11  8]\n",
      " [66 23 32 26]]\n",
      "Validation Loss for s21 = 1.3303396701812744\n",
      "Epoch 19/100, Train Loss: 1.3317105770111084\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_96/1313612177.py:68: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/tmp/ipykernel_96/1313612177.py:88: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.19      0.55      0.28        74\n",
      "           1       0.20      0.16      0.18        73\n",
      "           2       0.16      0.10      0.13       106\n",
      "           3       0.46      0.18      0.25       147\n",
      "\n",
      "    accuracy                           0.23       400\n",
      "   macro avg       0.25      0.25      0.21       400\n",
      "weighted avg       0.28      0.23      0.21       400\n",
      "\n",
      "[[41 11 11 11]\n",
      " [37 12 12 12]\n",
      " [71 16 11  8]\n",
      " [67 21 33 26]]\n",
      "Validation Loss for s21 = 1.3414312601089478\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_96/1313612177.py:43: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20/100, Train Loss: 1.391959309577942\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_96/1313612177.py:68: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/tmp/ipykernel_96/1313612177.py:88: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.19      0.54      0.28        74\n",
      "           1       0.19      0.16      0.18        73\n",
      "           2       0.17      0.10      0.13       106\n",
      "           3       0.45      0.20      0.27       147\n",
      "\n",
      "    accuracy                           0.23       400\n",
      "   macro avg       0.25      0.25      0.22       400\n",
      "weighted avg       0.28      0.23      0.22       400\n",
      "\n",
      "[[40 12  9 13]\n",
      " [36 12 12 13]\n",
      " [70 16 11  9]\n",
      " [65 22 31 29]]\n",
      "Validation Loss for s21 = 1.3363065719604492\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_96/1313612177.py:43: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 21/100, Train Loss: 1.2739685773849487\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_96/1313612177.py:68: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/tmp/ipykernel_96/1313612177.py:88: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.19      0.54      0.28        74\n",
      "           1       0.18      0.16      0.17        73\n",
      "           2       0.19      0.10      0.13       106\n",
      "           3       0.43      0.20      0.28       147\n",
      "\n",
      "    accuracy                           0.23       400\n",
      "   macro avg       0.25      0.25      0.22       400\n",
      "weighted avg       0.28      0.23      0.22       400\n",
      "\n",
      "[[40 12  7 15]\n",
      " [35 12 11 15]\n",
      " [68 18 11  9]\n",
      " [64 24 29 30]]\n",
      "Validation Loss for s21 = 1.33707857131958\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_96/1313612177.py:43: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 22/100, Train Loss: 1.444475769996643\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_96/1313612177.py:68: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/tmp/ipykernel_96/1313612177.py:88: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.19      0.54      0.28        74\n",
      "           1       0.18      0.16      0.17        73\n",
      "           2       0.18      0.10      0.13       106\n",
      "           3       0.43      0.19      0.26       147\n",
      "\n",
      "    accuracy                           0.23       400\n",
      "   macro avg       0.25      0.25      0.21       400\n",
      "weighted avg       0.27      0.23      0.22       400\n",
      "\n",
      "[[40 11  9 14]\n",
      " [36 12 11 14]\n",
      " [68 18 11  9]\n",
      " [63 25 31 28]]\n",
      "Validation Loss for s21 = 1.3395650386810303\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_96/1313612177.py:43: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 23/100, Train Loss: 1.4776731729507446\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_96/1313612177.py:68: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/tmp/ipykernel_96/1313612177.py:88: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.19      0.55      0.28        74\n",
      "           1       0.20      0.16      0.18        73\n",
      "           2       0.20      0.11      0.14       106\n",
      "           3       0.44      0.19      0.27       147\n",
      "\n",
      "    accuracy                           0.23       400\n",
      "   macro avg       0.26      0.26      0.22       400\n",
      "weighted avg       0.29      0.23      0.22       400\n",
      "\n",
      "[[41 10  9 14]\n",
      " [37 12 10 14]\n",
      " [71 16 12  7]\n",
      " [68 21 30 28]]\n",
      "Validation Loss for s21 = 1.3384349346160889\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_96/1313612177.py:43: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 24/100, Train Loss: 1.3041068315505981\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_96/1313612177.py:68: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/tmp/ipykernel_96/1313612177.py:88: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.19      0.57      0.29        74\n",
      "           1       0.21      0.16      0.18        73\n",
      "           2       0.18      0.10      0.13       106\n",
      "           3       0.45      0.20      0.27       147\n",
      "\n",
      "    accuracy                           0.23       400\n",
      "   macro avg       0.26      0.26      0.22       400\n",
      "weighted avg       0.29      0.23      0.22       400\n",
      "\n",
      "[[42 10  9 13]\n",
      " [37 12 10 14]\n",
      " [71 16 11  8]\n",
      " [69 19 30 29]]\n",
      "Validation Loss for s21 = 1.3373844623565674\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_96/1313612177.py:43: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 25/100, Train Loss: 1.3178534507751465\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_96/1313612177.py:68: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/tmp/ipykernel_96/1313612177.py:88: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.19      0.55      0.29        74\n",
      "           1       0.18      0.15      0.17        73\n",
      "           2       0.17      0.10      0.13       106\n",
      "           3       0.43      0.18      0.26       147\n",
      "\n",
      "    accuracy                           0.23       400\n",
      "   macro avg       0.24      0.25      0.21       400\n",
      "weighted avg       0.27      0.23      0.21       400\n",
      "\n",
      "[[41 10  9 14]\n",
      " [37 11 11 14]\n",
      " [70 17 11  8]\n",
      " [65 22 33 27]]\n",
      "Validation Loss for s21 = 1.3378249406814575\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_96/1313612177.py:43: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 26/100, Train Loss: 1.4470902681350708\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_96/1313612177.py:68: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/tmp/ipykernel_96/1313612177.py:88: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.19      0.55      0.29        74\n",
      "           1       0.19      0.16      0.18        73\n",
      "           2       0.21      0.12      0.16       106\n",
      "           3       0.45      0.20      0.28       147\n",
      "\n",
      "    accuracy                           0.24       400\n",
      "   macro avg       0.26      0.26      0.23       400\n",
      "weighted avg       0.29      0.24      0.23       400\n",
      "\n",
      "[[41 10  9 14]\n",
      " [37 12 10 14]\n",
      " [69 16 13  8]\n",
      " [64 24 29 30]]\n",
      "Validation Loss for s21 = 1.337867021560669\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_96/1313612177.py:43: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 27/100, Train Loss: 1.3557045459747314\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_96/1313612177.py:68: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/tmp/ipykernel_96/1313612177.py:88: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.20      0.57      0.30        74\n",
      "           1       0.21      0.19      0.20        73\n",
      "           2       0.21      0.13      0.16       106\n",
      "           3       0.48      0.20      0.28       147\n",
      "\n",
      "    accuracy                           0.25       400\n",
      "   macro avg       0.28      0.27      0.24       400\n",
      "weighted avg       0.31      0.25      0.24       400\n",
      "\n",
      "[[42 10 10 12]\n",
      " [35 14 12 12]\n",
      " [66 19 14  7]\n",
      " [63 24 31 29]]\n",
      "Validation Loss for s21 = 1.3375166654586792\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_96/1313612177.py:43: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 28/100, Train Loss: 1.427163004875183\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_96/1313612177.py:68: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/tmp/ipykernel_96/1313612177.py:88: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.20      0.57      0.30        74\n",
      "           1       0.21      0.19      0.20        73\n",
      "           2       0.20      0.12      0.15       106\n",
      "           3       0.47      0.20      0.28       147\n",
      "\n",
      "    accuracy                           0.24       400\n",
      "   macro avg       0.27      0.27      0.23       400\n",
      "weighted avg       0.30      0.24      0.23       400\n",
      "\n",
      "[[42 10 10 12]\n",
      " [35 14 11 13]\n",
      " [66 19 13  8]\n",
      " [63 24 31 29]]\n",
      "Validation Loss for s21 = 1.336465835571289\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_96/1313612177.py:43: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 29/100, Train Loss: 1.4607257843017578\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_96/1313612177.py:68: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/tmp/ipykernel_96/1313612177.py:88: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.21      0.57      0.30        74\n",
      "           1       0.21      0.21      0.21        73\n",
      "           2       0.20      0.12      0.15       106\n",
      "           3       0.48      0.20      0.29       147\n",
      "\n",
      "    accuracy                           0.25       400\n",
      "   macro avg       0.28      0.27      0.24       400\n",
      "weighted avg       0.31      0.25      0.24       400\n",
      "\n",
      "[[42 11 10 11]\n",
      " [33 15 12 13]\n",
      " [66 19 13  8]\n",
      " [62 25 30 30]]\n",
      "Validation Loss for s21 = 1.3372416496276855\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_96/1313612177.py:43: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 30/100, Train Loss: 1.358583927154541\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_96/1313612177.py:68: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/tmp/ipykernel_96/1313612177.py:88: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.20      0.57      0.29        74\n",
      "           1       0.22      0.19      0.21        73\n",
      "           2       0.20      0.11      0.14       106\n",
      "           3       0.46      0.20      0.28       147\n",
      "\n",
      "    accuracy                           0.24       400\n",
      "   macro avg       0.27      0.27      0.23       400\n",
      "weighted avg       0.30      0.24      0.23       400\n",
      "\n",
      "[[42  9 10 13]\n",
      " [35 14 11 13]\n",
      " [68 17 12  9]\n",
      " [66 23 28 30]]\n",
      "Validation Loss for s21 = 1.3332672119140625\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_96/1313612177.py:43: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 31/100, Train Loss: 1.4645766019821167\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_96/1313612177.py:68: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/tmp/ipykernel_96/1313612177.py:88: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.20      0.57      0.30        74\n",
      "           1       0.22      0.21      0.21        73\n",
      "           2       0.22      0.13      0.16       106\n",
      "           3       0.48      0.20      0.28       147\n",
      "\n",
      "    accuracy                           0.25       400\n",
      "   macro avg       0.28      0.28      0.24       400\n",
      "weighted avg       0.31      0.25      0.24       400\n",
      "\n",
      "[[42 10 10 12]\n",
      " [34 15 12 12]\n",
      " [66 19 14  7]\n",
      " [66 23 29 29]]\n",
      "Validation Loss for s21 = 1.3418529033660889\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_96/1313612177.py:43: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 32/100, Train Loss: 1.330344319343567\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_96/1313612177.py:68: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/tmp/ipykernel_96/1313612177.py:88: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.20      0.57      0.30        74\n",
      "           1       0.22      0.21      0.21        73\n",
      "           2       0.21      0.12      0.15       106\n",
      "           3       0.47      0.20      0.28       147\n",
      "\n",
      "    accuracy                           0.25       400\n",
      "   macro avg       0.27      0.27      0.24       400\n",
      "weighted avg       0.31      0.25      0.24       400\n",
      "\n",
      "[[42 10 10 12]\n",
      " [34 15 11 13]\n",
      " [66 19 13  8]\n",
      " [66 24 28 29]]\n",
      "Validation Loss for s21 = 1.3418599367141724\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_96/1313612177.py:43: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 33/100, Train Loss: 1.3950233459472656\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_96/1313612177.py:68: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/tmp/ipykernel_96/1313612177.py:88: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.21      0.57      0.31        74\n",
      "           1       0.23      0.23      0.23        73\n",
      "           2       0.21      0.13      0.16       106\n",
      "           3       0.47      0.19      0.27       147\n",
      "\n",
      "    accuracy                           0.25       400\n",
      "   macro avg       0.28      0.28      0.24       400\n",
      "weighted avg       0.31      0.25      0.24       400\n",
      "\n",
      "[[42 10 10 12]\n",
      " [32 17 12 12]\n",
      " [65 20 14  7]\n",
      " [61 28 30 28]]\n",
      "Validation Loss for s21 = 1.3436951637268066\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_96/1313612177.py:43: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 34/100, Train Loss: 1.3912070989608765\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_96/1313612177.py:68: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/tmp/ipykernel_96/1313612177.py:88: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.20      0.57      0.30        74\n",
      "           1       0.22      0.21      0.21        73\n",
      "           2       0.21      0.13      0.16       106\n",
      "           3       0.48      0.20      0.28       147\n",
      "\n",
      "    accuracy                           0.25       400\n",
      "   macro avg       0.28      0.28      0.24       400\n",
      "weighted avg       0.31      0.25      0.24       400\n",
      "\n",
      "[[42 10 11 11]\n",
      " [33 15 12 13]\n",
      " [66 19 14  7]\n",
      " [65 23 30 29]]\n",
      "Validation Loss for s21 = 1.3389211893081665\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_96/1313612177.py:43: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 35/100, Train Loss: 1.3450068235397339\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_96/1313612177.py:68: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/tmp/ipykernel_96/1313612177.py:88: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.20      0.57      0.29        74\n",
      "           1       0.20      0.16      0.18        73\n",
      "           2       0.18      0.11      0.14       106\n",
      "           3       0.48      0.20      0.29       147\n",
      "\n",
      "    accuracy                           0.24       400\n",
      "   macro avg       0.26      0.26      0.23       400\n",
      "weighted avg       0.30      0.24      0.23       400\n",
      "\n",
      "[[42  9 11 12]\n",
      " [37 12 12 12]\n",
      " [68 17 12  9]\n",
      " [64 22 31 30]]\n",
      "Validation Loss for s21 = 1.3356077671051025\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_96/1313612177.py:43: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 36/100, Train Loss: 1.4202024936676025\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_96/1313612177.py:68: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/tmp/ipykernel_96/1313612177.py:88: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.20      0.57      0.29        74\n",
      "           1       0.23      0.19      0.21        73\n",
      "           2       0.20      0.12      0.15       106\n",
      "           3       0.47      0.20      0.28       147\n",
      "\n",
      "    accuracy                           0.24       400\n",
      "   macro avg       0.27      0.27      0.23       400\n",
      "weighted avg       0.30      0.24      0.23       400\n",
      "\n",
      "[[42  9 11 12]\n",
      " [36 14 11 12]\n",
      " [68 16 13  9]\n",
      " [65 23 30 29]]\n",
      "Validation Loss for s21 = 1.3391045331954956\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_96/1313612177.py:43: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 37/100, Train Loss: 1.4802887439727783\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_96/1313612177.py:68: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/tmp/ipykernel_96/1313612177.py:88: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.20      0.57      0.29        74\n",
      "           1       0.19      0.16      0.18        73\n",
      "           2       0.21      0.11      0.15       106\n",
      "           3       0.46      0.21      0.29       147\n",
      "\n",
      "    accuracy                           0.24       400\n",
      "   macro avg       0.27      0.26      0.23       400\n",
      "weighted avg       0.30      0.24      0.23       400\n",
      "\n",
      "[[42  9 11 12]\n",
      " [37 12  8 16]\n",
      " [68 18 12  8]\n",
      " [66 24 26 31]]\n",
      "Validation Loss for s21 = 1.3452842235565186\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_96/1313612177.py:43: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 38/100, Train Loss: 1.379934310913086\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_96/1313612177.py:68: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/tmp/ipykernel_96/1313612177.py:88: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.20      0.57      0.29        74\n",
      "           1       0.19      0.15      0.17        73\n",
      "           2       0.20      0.11      0.14       106\n",
      "           3       0.47      0.21      0.29       147\n",
      "\n",
      "    accuracy                           0.24       400\n",
      "   macro avg       0.26      0.26      0.22       400\n",
      "weighted avg       0.30      0.24      0.23       400\n",
      "\n",
      "[[42  9 11 12]\n",
      " [37 11 10 15]\n",
      " [69 17 12  8]\n",
      " [67 22 27 31]]\n",
      "Validation Loss for s21 = 1.345179557800293\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_96/1313612177.py:43: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 39/100, Train Loss: 1.5341004133224487\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_96/1313612177.py:68: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/tmp/ipykernel_96/1313612177.py:88: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.19      0.55      0.29        74\n",
      "           1       0.20      0.18      0.19        73\n",
      "           2       0.19      0.11      0.14       106\n",
      "           3       0.47      0.18      0.26       147\n",
      "\n",
      "    accuracy                           0.23       400\n",
      "   macro avg       0.26      0.26      0.22       400\n",
      "weighted avg       0.29      0.23      0.22       400\n",
      "\n",
      "[[41  9 12 12]\n",
      " [36 13 12 12]\n",
      " [69 18 12  7]\n",
      " [67 26 27 27]]\n",
      "Validation Loss for s21 = 1.347269058227539\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_96/1313612177.py:43: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 40/100, Train Loss: 1.3843803405761719\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_96/1313612177.py:68: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/tmp/ipykernel_96/1313612177.py:88: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.20      0.55      0.29        74\n",
      "           1       0.19      0.16      0.18        73\n",
      "           2       0.18      0.11      0.14       106\n",
      "           3       0.45      0.18      0.26       147\n",
      "\n",
      "    accuracy                           0.23       400\n",
      "   macro avg       0.25      0.25      0.22       400\n",
      "weighted avg       0.28      0.23      0.22       400\n",
      "\n",
      "[[41  9 12 12]\n",
      " [35 12 13 13]\n",
      " [68 18 12  8]\n",
      " [65 25 30 27]]\n",
      "Validation Loss for s21 = 1.3452262878417969\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_96/1313612177.py:43: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 41/100, Train Loss: 1.3632949590682983\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_96/1313612177.py:68: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/tmp/ipykernel_96/1313612177.py:88: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.20      0.57      0.29        74\n",
      "           1       0.20      0.18      0.19        73\n",
      "           2       0.20      0.13      0.16       106\n",
      "           3       0.50      0.18      0.27       147\n",
      "\n",
      "    accuracy                           0.24       400\n",
      "   macro avg       0.27      0.27      0.23       400\n",
      "weighted avg       0.31      0.24      0.23       400\n",
      "\n",
      "[[42  9 14  9]\n",
      " [36 13 11 13]\n",
      " [68 19 14  5]\n",
      " [65 25 30 27]]\n",
      "Validation Loss for s21 = 1.3465783596038818\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_96/1313612177.py:43: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 42/100, Train Loss: 1.4738821983337402\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_96/1313612177.py:68: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/tmp/ipykernel_96/1313612177.py:88: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.20      0.57      0.29        74\n",
      "           1       0.20      0.18      0.19        73\n",
      "           2       0.21      0.13      0.16       106\n",
      "           3       0.47      0.17      0.25       147\n",
      "\n",
      "    accuracy                           0.23       400\n",
      "   macro avg       0.27      0.26      0.22       400\n",
      "weighted avg       0.30      0.23      0.22       400\n",
      "\n",
      "[[42  9 13 10]\n",
      " [36 13 11 13]\n",
      " [69 18 14  5]\n",
      " [68 24 30 25]]\n",
      "Validation Loss for s21 = 1.3469454050064087\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_96/1313612177.py:43: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 43/100, Train Loss: 1.4378993511199951\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_96/1313612177.py:68: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/tmp/ipykernel_96/1313612177.py:88: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.19      0.55      0.29        74\n",
      "           1       0.21      0.18      0.19        73\n",
      "           2       0.22      0.15      0.18       106\n",
      "           3       0.47      0.17      0.25       147\n",
      "\n",
      "    accuracy                           0.24       400\n",
      "   macro avg       0.27      0.26      0.23       400\n",
      "weighted avg       0.31      0.24      0.23       400\n",
      "\n",
      "[[41  9 15  9]\n",
      " [36 13 12 12]\n",
      " [68 15 16  7]\n",
      " [67 24 31 25]]\n",
      "Validation Loss for s21 = 1.3450263738632202\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_96/1313612177.py:43: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 44/100, Train Loss: 1.386623501777649\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_96/1313612177.py:68: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/tmp/ipykernel_96/1313612177.py:88: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.19      0.55      0.29        74\n",
      "           1       0.19      0.16      0.18        73\n",
      "           2       0.22      0.13      0.16       106\n",
      "           3       0.48      0.20      0.28       147\n",
      "\n",
      "    accuracy                           0.24       400\n",
      "   macro avg       0.27      0.26      0.23       400\n",
      "weighted avg       0.30      0.24      0.23       400\n",
      "\n",
      "[[41  9 12 12]\n",
      " [37 12 11 13]\n",
      " [68 17 14  7]\n",
      " [66 25 27 29]]\n",
      "Validation Loss for s21 = 1.3457776308059692\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_96/1313612177.py:43: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 45/100, Train Loss: 1.3557099103927612\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_96/1313612177.py:68: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/tmp/ipykernel_96/1313612177.py:88: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/tmp/ipykernel_96/1313612177.py:43: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.19      0.55      0.29        74\n",
      "           1       0.19      0.16      0.18        73\n",
      "           2       0.22      0.12      0.16       106\n",
      "           3       0.46      0.20      0.28       147\n",
      "\n",
      "    accuracy                           0.24       400\n",
      "   macro avg       0.27      0.26      0.23       400\n",
      "weighted avg       0.30      0.24      0.23       400\n",
      "\n",
      "[[41  9 12 12]\n",
      " [37 12  8 16]\n",
      " [69 17 13  7]\n",
      " [66 25 26 30]]\n",
      "Validation Loss for s21 = 1.3464325666427612\n",
      "Epoch 46/100, Train Loss: 1.3788312673568726\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_96/1313612177.py:68: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/tmp/ipykernel_96/1313612177.py:88: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/tmp/ipykernel_96/1313612177.py:43: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.20      0.54      0.29        74\n",
      "           1       0.20      0.18      0.19        73\n",
      "           2       0.22      0.14      0.17       106\n",
      "           3       0.48      0.20      0.29       147\n",
      "\n",
      "    accuracy                           0.24       400\n",
      "   macro avg       0.27      0.27      0.23       400\n",
      "weighted avg       0.31      0.24      0.24       400\n",
      "\n",
      "[[40  9 14 11]\n",
      " [35 13 11 14]\n",
      " [66 17 15  8]\n",
      " [64 25 28 30]]\n",
      "Validation Loss for s21 = 1.3418914079666138\n",
      "Epoch 47/100, Train Loss: 1.4390630722045898\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_96/1313612177.py:68: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/tmp/ipykernel_96/1313612177.py:88: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/tmp/ipykernel_96/1313612177.py:43: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.19      0.55      0.29        74\n",
      "           1       0.19      0.16      0.18        73\n",
      "           2       0.22      0.14      0.17       106\n",
      "           3       0.46      0.18      0.25       147\n",
      "\n",
      "    accuracy                           0.23       400\n",
      "   macro avg       0.26      0.26      0.22       400\n",
      "weighted avg       0.30      0.23      0.22       400\n",
      "\n",
      "[[41  9 14 10]\n",
      " [36 12 11 14]\n",
      " [67 17 15  7]\n",
      " [67 25 29 26]]\n",
      "Validation Loss for s21 = 1.3510302305221558\n",
      "Epoch 48/100, Train Loss: 1.3369157314300537\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_96/1313612177.py:68: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/tmp/ipykernel_96/1313612177.py:88: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/tmp/ipykernel_96/1313612177.py:43: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.19      0.54      0.28        74\n",
      "           1       0.20      0.16      0.18        73\n",
      "           2       0.23      0.16      0.19       106\n",
      "           3       0.47      0.18      0.26       147\n",
      "\n",
      "    accuracy                           0.24       400\n",
      "   macro avg       0.27      0.26      0.23       400\n",
      "weighted avg       0.30      0.24      0.23       400\n",
      "\n",
      "[[40  9 14 11]\n",
      " [35 12 12 14]\n",
      " [68 15 17  6]\n",
      " [65 24 31 27]]\n",
      "Validation Loss for s21 = 1.344150185585022\n",
      "Epoch 49/100, Train Loss: 1.3386683464050293\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_96/1313612177.py:68: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/tmp/ipykernel_96/1313612177.py:88: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/tmp/ipykernel_96/1313612177.py:43: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.19      0.54      0.28        74\n",
      "           1       0.20      0.16      0.18        73\n",
      "           2       0.24      0.16      0.19       106\n",
      "           3       0.49      0.20      0.28       147\n",
      "\n",
      "    accuracy                           0.24       400\n",
      "   macro avg       0.28      0.27      0.23       400\n",
      "weighted avg       0.32      0.24      0.24       400\n",
      "\n",
      "[[40  9 15 10]\n",
      " [36 12 11 14]\n",
      " [69 14 17  6]\n",
      " [66 24 28 29]]\n",
      "Validation Loss for s21 = 1.3461822271347046\n",
      "Epoch 50/100, Train Loss: 1.4473263025283813\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_96/1313612177.py:68: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/tmp/ipykernel_96/1313612177.py:88: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.19      0.53      0.28        74\n",
      "           1       0.19      0.16      0.18        73\n",
      "           2       0.23      0.14      0.18       106\n",
      "           3       0.47      0.22      0.30       147\n",
      "\n",
      "    accuracy                           0.24       400\n",
      "   macro avg       0.27      0.26      0.23       400\n",
      "weighted avg       0.30      0.24      0.24       400\n",
      "\n",
      "[[39  9 14 12]\n",
      " [36 12  8 17]\n",
      " [68 16 15  7]\n",
      " [62 25 28 32]]\n",
      "Validation Loss for s21 = 1.3420357704162598\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_96/1313612177.py:43: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 51/100, Train Loss: 1.3523458242416382\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_96/1313612177.py:68: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/tmp/ipykernel_96/1313612177.py:88: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/tmp/ipykernel_96/1313612177.py:43: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.19      0.54      0.28        74\n",
      "           1       0.19      0.15      0.17        73\n",
      "           2       0.22      0.13      0.16       106\n",
      "           3       0.46      0.21      0.29       147\n",
      "\n",
      "    accuracy                           0.24       400\n",
      "   macro avg       0.26      0.26      0.23       400\n",
      "weighted avg       0.30      0.24      0.23       400\n",
      "\n",
      "[[40  9 14 11]\n",
      " [36 11 10 16]\n",
      " [69 14 14  9]\n",
      " [65 24 27 31]]\n",
      "Validation Loss for s21 = 1.3457462787628174\n",
      "Epoch 52/100, Train Loss: 1.3588125705718994\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_96/1313612177.py:68: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/tmp/ipykernel_96/1313612177.py:88: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/tmp/ipykernel_96/1313612177.py:43: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.19      0.54      0.29        74\n",
      "           1       0.18      0.15      0.17        73\n",
      "           2       0.23      0.14      0.17       106\n",
      "           3       0.47      0.22      0.30       147\n",
      "\n",
      "    accuracy                           0.24       400\n",
      "   macro avg       0.27      0.26      0.23       400\n",
      "weighted avg       0.30      0.24      0.24       400\n",
      "\n",
      "[[40  9 14 11]\n",
      " [36 11 10 16]\n",
      " [67 15 15  9]\n",
      " [63 25 27 32]]\n",
      "Validation Loss for s21 = 1.3478063344955444\n",
      "Epoch 53/100, Train Loss: 1.4894720315933228\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_96/1313612177.py:68: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/tmp/ipykernel_96/1313612177.py:88: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/tmp/ipykernel_96/1313612177.py:43: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.20      0.54      0.29        74\n",
      "           1       0.17      0.15      0.16        73\n",
      "           2       0.22      0.13      0.16       106\n",
      "           3       0.48      0.21      0.29       147\n",
      "\n",
      "    accuracy                           0.24       400\n",
      "   macro avg       0.26      0.26      0.23       400\n",
      "weighted avg       0.30      0.24      0.23       400\n",
      "\n",
      "[[40  9 14 11]\n",
      " [36 11 10 16]\n",
      " [68 17 14  7]\n",
      " [61 28 27 31]]\n",
      "Validation Loss for s21 = 1.342966079711914\n",
      "Epoch 54/100, Train Loss: 1.3452303409576416\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_96/1313612177.py:68: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/tmp/ipykernel_96/1313612177.py:88: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/tmp/ipykernel_96/1313612177.py:43: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.19      0.54      0.29        74\n",
      "           1       0.19      0.16      0.18        73\n",
      "           2       0.21      0.13      0.16       106\n",
      "           3       0.44      0.19      0.27       147\n",
      "\n",
      "    accuracy                           0.23       400\n",
      "   macro avg       0.26      0.26      0.22       400\n",
      "weighted avg       0.29      0.23      0.23       400\n",
      "\n",
      "[[40  9 14 11]\n",
      " [34 12 10 17]\n",
      " [68 16 14  8]\n",
      " [64 26 29 28]]\n",
      "Validation Loss for s21 = 1.3455488681793213\n",
      "Epoch 55/100, Train Loss: 1.3044630289077759\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_96/1313612177.py:68: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/tmp/ipykernel_96/1313612177.py:88: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.19      0.54      0.28        74\n",
      "           1       0.17      0.14      0.15        73\n",
      "           2       0.22      0.14      0.17       106\n",
      "           3       0.43      0.19      0.26       147\n",
      "\n",
      "    accuracy                           0.23       400\n",
      "   macro avg       0.25      0.25      0.22       400\n",
      "weighted avg       0.28      0.23      0.22       400\n",
      "\n",
      "[[40  9 14 11]\n",
      " [35 10 10 18]\n",
      " [68 15 15  8]\n",
      " [65 25 29 28]]\n",
      "Validation Loss for s21 = 1.3451762199401855\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_96/1313612177.py:43: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 56/100, Train Loss: 1.3549668788909912\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_96/1313612177.py:68: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/tmp/ipykernel_96/1313612177.py:88: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.19      0.54      0.28        74\n",
      "           1       0.15      0.11      0.13        73\n",
      "           2       0.21      0.13      0.16       106\n",
      "           3       0.43      0.20      0.28       147\n",
      "\n",
      "    accuracy                           0.23       400\n",
      "   macro avg       0.25      0.25      0.21       400\n",
      "weighted avg       0.28      0.23      0.22       400\n",
      "\n",
      "[[40  8 14 12]\n",
      " [35  8 11 19]\n",
      " [70 14 14  8]\n",
      " [66 22 29 30]]\n",
      "Validation Loss for s21 = 1.3410522937774658\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_96/1313612177.py:43: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 57/100, Train Loss: 1.3957834243774414\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_96/1313612177.py:68: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/tmp/ipykernel_96/1313612177.py:88: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.19      0.54      0.28        74\n",
      "           1       0.20      0.16      0.18        73\n",
      "           2       0.23      0.15      0.18       106\n",
      "           3       0.43      0.18      0.26       147\n",
      "\n",
      "    accuracy                           0.24       400\n",
      "   macro avg       0.26      0.26      0.23       400\n",
      "weighted avg       0.29      0.24      0.23       400\n",
      "\n",
      "[[40  9 14 11]\n",
      " [34 12 10 17]\n",
      " [68 14 16  8]\n",
      " [66 25 29 27]]\n",
      "Validation Loss for s21 = 1.3499150276184082\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_96/1313612177.py:43: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 58/100, Train Loss: 1.4516782760620117\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_96/1313612177.py:68: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/tmp/ipykernel_96/1313612177.py:88: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.19      0.54      0.28        74\n",
      "           1       0.19      0.15      0.17        73\n",
      "           2       0.22      0.13      0.16       106\n",
      "           3       0.42      0.19      0.26       147\n",
      "\n",
      "    accuracy                           0.23       400\n",
      "   macro avg       0.25      0.25      0.22       400\n",
      "weighted avg       0.28      0.23      0.22       400\n",
      "\n",
      "[[40  9 13 12]\n",
      " [35 11  9 18]\n",
      " [69 14 14  9]\n",
      " [67 24 28 28]]\n",
      "Validation Loss for s21 = 1.3484680652618408\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_96/1313612177.py:43: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 59/100, Train Loss: 1.3193386793136597\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_96/1313612177.py:68: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/tmp/ipykernel_96/1313612177.py:88: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.19      0.54      0.29        74\n",
      "           1       0.18      0.15      0.17        73\n",
      "           2       0.21      0.14      0.17       106\n",
      "           3       0.45      0.20      0.27       147\n",
      "\n",
      "    accuracy                           0.24       400\n",
      "   macro avg       0.26      0.26      0.22       400\n",
      "weighted avg       0.29      0.24      0.23       400\n",
      "\n",
      "[[40  9 15 10]\n",
      " [35 11 10 17]\n",
      " [67 16 15  8]\n",
      " [64 24 30 29]]\n",
      "Validation Loss for s21 = 1.3517009019851685\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_96/1313612177.py:43: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 60/100, Train Loss: 1.3536171913146973\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_96/1313612177.py:68: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/tmp/ipykernel_96/1313612177.py:88: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.19      0.51      0.28        74\n",
      "           1       0.17      0.15      0.16        73\n",
      "           2       0.20      0.13      0.16       106\n",
      "           3       0.47      0.21      0.29       147\n",
      "\n",
      "    accuracy                           0.23       400\n",
      "   macro avg       0.26      0.25      0.22       400\n",
      "weighted avg       0.29      0.23      0.23       400\n",
      "\n",
      "[[38 10 16 10]\n",
      " [34 11 11 17]\n",
      " [67 17 14  8]\n",
      " [61 25 30 31]]\n",
      "Validation Loss for s21 = 1.3522104024887085\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_96/1313612177.py:43: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 61/100, Train Loss: 1.2413394451141357\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_96/1313612177.py:68: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/tmp/ipykernel_96/1313612177.py:88: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.20      0.54      0.29        74\n",
      "           1       0.19      0.15      0.17        73\n",
      "           2       0.21      0.15      0.18       106\n",
      "           3       0.47      0.20      0.28       147\n",
      "\n",
      "    accuracy                           0.24       400\n",
      "   macro avg       0.27      0.26      0.23       400\n",
      "weighted avg       0.30      0.24      0.23       400\n",
      "\n",
      "[[40  9 15 10]\n",
      " [35 11 12 15]\n",
      " [67 15 16  8]\n",
      " [62 24 32 29]]\n",
      "Validation Loss for s21 = 1.3557754755020142\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_96/1313612177.py:43: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 62/100, Train Loss: 1.362406611442566\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_96/1313612177.py:68: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/tmp/ipykernel_96/1313612177.py:88: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.19      0.51      0.28        74\n",
      "           1       0.18      0.14      0.15        73\n",
      "           2       0.21      0.15      0.17       106\n",
      "           3       0.46      0.20      0.28       147\n",
      "\n",
      "    accuracy                           0.23       400\n",
      "   macro avg       0.26      0.25      0.22       400\n",
      "weighted avg       0.29      0.23      0.23       400\n",
      "\n",
      "[[38 10 16 10]\n",
      " [34 10 13 16]\n",
      " [69 13 16  8]\n",
      " [61 24 33 29]]\n",
      "Validation Loss for s21 = 1.3525029420852661\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_96/1313612177.py:43: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 63/100, Train Loss: 1.4767866134643555\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_96/1313612177.py:68: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/tmp/ipykernel_96/1313612177.py:88: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.19      0.50      0.27        74\n",
      "           1       0.13      0.10      0.11        73\n",
      "           2       0.21      0.15      0.18       106\n",
      "           3       0.46      0.22      0.30       147\n",
      "\n",
      "    accuracy                           0.23       400\n",
      "   macro avg       0.25      0.24      0.21       400\n",
      "weighted avg       0.28      0.23      0.23       400\n",
      "\n",
      "[[37 10 15 12]\n",
      " [35  7 13 18]\n",
      " [67 15 16  8]\n",
      " [60 23 31 33]]\n",
      "Validation Loss for s21 = 1.3491894006729126\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_96/1313612177.py:43: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 64/100, Train Loss: 1.3621740341186523\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_96/1313612177.py:68: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/tmp/ipykernel_96/1313612177.py:88: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.19      0.51      0.28        74\n",
      "           1       0.16      0.12      0.14        73\n",
      "           2       0.22      0.17      0.19       106\n",
      "           3       0.46      0.18      0.26       147\n",
      "\n",
      "    accuracy                           0.23       400\n",
      "   macro avg       0.26      0.25      0.22       400\n",
      "weighted avg       0.29      0.23      0.22       400\n",
      "\n",
      "[[38  9 17 10]\n",
      " [34  9 14 16]\n",
      " [66 16 18  6]\n",
      " [63 24 33 27]]\n",
      "Validation Loss for s21 = 1.3508623838424683\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_96/1313612177.py:43: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 65/100, Train Loss: 1.341933250427246\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_96/1313612177.py:68: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/tmp/ipykernel_96/1313612177.py:88: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.19      0.51      0.28        74\n",
      "           1       0.14      0.11      0.12        73\n",
      "           2       0.21      0.15      0.18       106\n",
      "           3       0.47      0.21      0.29       147\n",
      "\n",
      "    accuracy                           0.23       400\n",
      "   macro avg       0.25      0.25      0.22       400\n",
      "weighted avg       0.29      0.23      0.23       400\n",
      "\n",
      "[[38 10 16 10]\n",
      " [35  8 12 18]\n",
      " [68 15 16  7]\n",
      " [61 24 31 31]]\n",
      "Validation Loss for s21 = 1.3554949760437012\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_96/1313612177.py:43: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 66/100, Train Loss: 1.3175429105758667\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_96/1313612177.py:68: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/tmp/ipykernel_96/1313612177.py:88: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.19      0.53      0.28        74\n",
      "           1       0.12      0.08      0.10        73\n",
      "           2       0.24      0.19      0.21       106\n",
      "           3       0.46      0.20      0.28       147\n",
      "\n",
      "    accuracy                           0.23       400\n",
      "   macro avg       0.25      0.25      0.22       400\n",
      "weighted avg       0.29      0.23      0.23       400\n",
      "\n",
      "[[39  8 16 11]\n",
      " [36  6 14 17]\n",
      " [67 13 20  6]\n",
      " [60 23 35 29]]\n",
      "Validation Loss for s21 = 1.350942850112915\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_96/1313612177.py:43: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 67/100, Train Loss: 1.3374305963516235\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_96/1313612177.py:68: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/tmp/ipykernel_96/1313612177.py:88: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.19      0.51      0.27        74\n",
      "           1       0.12      0.08      0.10        73\n",
      "           2       0.23      0.18      0.20       106\n",
      "           3       0.45      0.20      0.27       147\n",
      "\n",
      "    accuracy                           0.23       400\n",
      "   macro avg       0.25      0.24      0.21       400\n",
      "weighted avg       0.28      0.23      0.22       400\n",
      "\n",
      "[[38  8 16 12]\n",
      " [36  6 13 18]\n",
      " [68 13 19  6]\n",
      " [61 24 33 29]]\n",
      "Validation Loss for s21 = 1.3500993251800537\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_96/1313612177.py:43: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 68/100, Train Loss: 1.3774054050445557\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_96/1313612177.py:68: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/tmp/ipykernel_96/1313612177.py:88: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/tmp/ipykernel_96/1313612177.py:43: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.20      0.53      0.28        74\n",
      "           1       0.14      0.10      0.11        73\n",
      "           2       0.22      0.18      0.20       106\n",
      "           3       0.45      0.20      0.27       147\n",
      "\n",
      "    accuracy                           0.23       400\n",
      "   macro avg       0.25      0.25      0.22       400\n",
      "weighted avg       0.29      0.23      0.23       400\n",
      "\n",
      "[[39  8 16 11]\n",
      " [34  7 15 17]\n",
      " [68 12 19  7]\n",
      " [59 23 36 29]]\n",
      "Validation Loss for s21 = 1.3552920818328857\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 69/100, Train Loss: 1.435598373413086\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_96/1313612177.py:68: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/tmp/ipykernel_96/1313612177.py:88: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.19      0.50      0.27        74\n",
      "           1       0.13      0.10      0.11        73\n",
      "           2       0.21      0.18      0.19       106\n",
      "           3       0.44      0.19      0.27       147\n",
      "\n",
      "    accuracy                           0.23       400\n",
      "   macro avg       0.25      0.24      0.21       400\n",
      "weighted avg       0.28      0.23      0.22       400\n",
      "\n",
      "[[37  8 18 11]\n",
      " [34  7 15 17]\n",
      " [66 14 19  7]\n",
      " [59 23 37 28]]\n",
      "Validation Loss for s21 = 1.3530389070510864\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_96/1313612177.py:43: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 70/100, Train Loss: 1.3690317869186401\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_96/1313612177.py:68: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/tmp/ipykernel_96/1313612177.py:88: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.18      0.49      0.27        74\n",
      "           1       0.15      0.11      0.13        73\n",
      "           2       0.24      0.19      0.21       106\n",
      "           3       0.45      0.20      0.28       147\n",
      "\n",
      "    accuracy                           0.23       400\n",
      "   macro avg       0.26      0.25      0.22       400\n",
      "weighted avg       0.29      0.23      0.23       400\n",
      "\n",
      "[[36  8 18 12]\n",
      " [34  8 14 17]\n",
      " [66 13 20  7]\n",
      " [59 25 33 30]]\n",
      "Validation Loss for s21 = 1.3541322946548462\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_96/1313612177.py:43: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 71/100, Train Loss: 1.3525530099868774\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_96/1313612177.py:68: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/tmp/ipykernel_96/1313612177.py:88: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.18      0.46      0.26        74\n",
      "           1       0.14      0.11      0.12        73\n",
      "           2       0.21      0.18      0.19       106\n",
      "           3       0.42      0.18      0.26       147\n",
      "\n",
      "    accuracy                           0.22       400\n",
      "   macro avg       0.24      0.23      0.21       400\n",
      "weighted avg       0.27      0.22      0.22       400\n",
      "\n",
      "[[34  9 19 12]\n",
      " [34  8 14 17]\n",
      " [63 16 19  8]\n",
      " [57 26 37 27]]\n",
      "Validation Loss for s21 = 1.3560209274291992\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_96/1313612177.py:43: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 72/100, Train Loss: 1.3604484796524048\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_96/1313612177.py:68: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/tmp/ipykernel_96/1313612177.py:88: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.18      0.47      0.27        74\n",
      "           1       0.15      0.11      0.13        73\n",
      "           2       0.22      0.20      0.21       106\n",
      "           3       0.44      0.18      0.26       147\n",
      "\n",
      "    accuracy                           0.23       400\n",
      "   macro avg       0.25      0.24      0.21       400\n",
      "weighted avg       0.28      0.23      0.22       400\n",
      "\n",
      "[[35  9 19 11]\n",
      " [33  8 16 16]\n",
      " [65 12 21  8]\n",
      " [57 24 39 27]]\n",
      "Validation Loss for s21 = 1.349756121635437\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_96/1313612177.py:43: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 73/100, Train Loss: 1.3597830533981323\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_96/1313612177.py:68: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/tmp/ipykernel_96/1313612177.py:88: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.18      0.46      0.26        74\n",
      "           1       0.15      0.11      0.13        73\n",
      "           2       0.23      0.18      0.20       106\n",
      "           3       0.43      0.22      0.29       147\n",
      "\n",
      "    accuracy                           0.23       400\n",
      "   macro avg       0.25      0.24      0.22       400\n",
      "weighted avg       0.28      0.23      0.23       400\n",
      "\n",
      "[[34  8 17 15]\n",
      " [34  8 12 19]\n",
      " [65 13 19  9]\n",
      " [57 24 34 32]]\n",
      "Validation Loss for s21 = 1.3465046882629395\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_96/1313612177.py:43: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 74/100, Train Loss: 1.3684860467910767\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_96/1313612177.py:68: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/tmp/ipykernel_96/1313612177.py:88: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.18      0.46      0.26        74\n",
      "           1       0.14      0.11      0.12        73\n",
      "           2       0.21      0.17      0.19       106\n",
      "           3       0.42      0.20      0.27       147\n",
      "\n",
      "    accuracy                           0.22       400\n",
      "   macro avg       0.24      0.23      0.21       400\n",
      "weighted avg       0.27      0.22      0.22       400\n",
      "\n",
      "[[34  9 18 13]\n",
      " [34  8 13 18]\n",
      " [64 15 18  9]\n",
      " [57 24 37 29]]\n",
      "Validation Loss for s21 = 1.3529609441757202\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_96/1313612177.py:43: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 75/100, Train Loss: 1.3131999969482422\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_96/1313612177.py:68: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/tmp/ipykernel_96/1313612177.py:88: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.18      0.47      0.27        74\n",
      "           1       0.18      0.14      0.16        73\n",
      "           2       0.22      0.18      0.20       106\n",
      "           3       0.43      0.20      0.28       147\n",
      "\n",
      "    accuracy                           0.23       400\n",
      "   macro avg       0.26      0.25      0.22       400\n",
      "weighted avg       0.29      0.23      0.23       400\n",
      "\n",
      "[[35  8 18 13]\n",
      " [33 10 13 17]\n",
      " [65 13 19  9]\n",
      " [57 24 36 30]]\n",
      "Validation Loss for s21 = 1.3519244194030762\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_96/1313612177.py:43: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 76/100, Train Loss: 1.300172209739685\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_96/1313612177.py:68: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/tmp/ipykernel_96/1313612177.py:88: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.19      0.49      0.27        74\n",
      "           1       0.14      0.11      0.12        73\n",
      "           2       0.21      0.16      0.18       106\n",
      "           3       0.45      0.20      0.28       147\n",
      "\n",
      "    accuracy                           0.23       400\n",
      "   macro avg       0.25      0.24      0.21       400\n",
      "weighted avg       0.28      0.23      0.22       400\n",
      "\n",
      "[[36  9 17 12]\n",
      " [34  8 14 17]\n",
      " [65 17 17  7]\n",
      " [58 25 34 30]]\n",
      "Validation Loss for s21 = 1.3556703329086304\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_96/1313612177.py:43: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 77/100, Train Loss: 1.3180750608444214\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_96/1313612177.py:68: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/tmp/ipykernel_96/1313612177.py:88: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.18      0.46      0.26        74\n",
      "           1       0.13      0.11      0.12        73\n",
      "           2       0.22      0.18      0.20       106\n",
      "           3       0.46      0.20      0.28       147\n",
      "\n",
      "    accuracy                           0.23       400\n",
      "   macro avg       0.25      0.24      0.21       400\n",
      "weighted avg       0.28      0.23      0.22       400\n",
      "\n",
      "[[34 10 18 12]\n",
      " [34  8 16 15]\n",
      " [64 16 19  7]\n",
      " [57 26 35 29]]\n",
      "Validation Loss for s21 = 1.3555519580841064\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_96/1313612177.py:43: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 78/100, Train Loss: 1.324057698249817\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_96/1313612177.py:68: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/tmp/ipykernel_96/1313612177.py:88: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.19      0.50      0.28        74\n",
      "           1       0.15      0.12      0.14        73\n",
      "           2       0.22      0.19      0.21       106\n",
      "           3       0.47      0.20      0.28       147\n",
      "\n",
      "    accuracy                           0.24       400\n",
      "   macro avg       0.26      0.25      0.22       400\n",
      "weighted avg       0.30      0.24      0.23       400\n",
      "\n",
      "[[37  9 17 11]\n",
      " [33  9 16 15]\n",
      " [63 16 20  7]\n",
      " [57 25 36 29]]\n",
      "Validation Loss for s21 = 1.3569163084030151\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_96/1313612177.py:43: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 79/100, Train Loss: 1.2869837284088135\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_96/1313612177.py:68: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/tmp/ipykernel_96/1313612177.py:88: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.20      0.53      0.29        74\n",
      "           1       0.16      0.12      0.14        73\n",
      "           2       0.24      0.19      0.21       106\n",
      "           3       0.48      0.22      0.30       147\n",
      "\n",
      "    accuracy                           0.25       400\n",
      "   macro avg       0.27      0.26      0.24       400\n",
      "weighted avg       0.31      0.25      0.25       400\n",
      "\n",
      "[[39  8 15 12]\n",
      " [34  9 14 16]\n",
      " [64 15 20  7]\n",
      " [57 24 34 32]]\n",
      "Validation Loss for s21 = 1.3530583381652832\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_96/1313612177.py:43: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 80/100, Train Loss: 1.3435570001602173\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_96/1313612177.py:68: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/tmp/ipykernel_96/1313612177.py:88: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/tmp/ipykernel_96/1313612177.py:43: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.20      0.53      0.28        74\n",
      "           1       0.14      0.10      0.11        73\n",
      "           2       0.23      0.18      0.20       106\n",
      "           3       0.45      0.20      0.28       147\n",
      "\n",
      "    accuracy                           0.24       400\n",
      "   macro avg       0.25      0.25      0.22       400\n",
      "weighted avg       0.29      0.24      0.23       400\n",
      "\n",
      "[[39  8 15 12]\n",
      " [35  7 14 17]\n",
      " [66 14 19  7]\n",
      " [60 22 35 30]]\n",
      "Validation Loss for s21 = 1.3560677766799927\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 81/100, Train Loss: 1.3422973155975342\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_96/1313612177.py:68: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/tmp/ipykernel_96/1313612177.py:88: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.18      0.46      0.26        74\n",
      "           1       0.14      0.11      0.12        73\n",
      "           2       0.21      0.18      0.19       106\n",
      "           3       0.46      0.20      0.28       147\n",
      "\n",
      "    accuracy                           0.23       400\n",
      "   macro avg       0.25      0.24      0.21       400\n",
      "weighted avg       0.29      0.23      0.23       400\n",
      "\n",
      "[[34 10 18 12]\n",
      " [33  8 16 16]\n",
      " [65 15 19  7]\n",
      " [57 24 36 30]]\n",
      "Validation Loss for s21 = 1.3571058511734009\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_96/1313612177.py:43: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 82/100, Train Loss: 1.4292372465133667\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_96/1313612177.py:68: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/tmp/ipykernel_96/1313612177.py:88: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/tmp/ipykernel_96/1313612177.py:43: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.19      0.50      0.28        74\n",
      "           1       0.14      0.11      0.12        73\n",
      "           2       0.23      0.18      0.20       106\n",
      "           3       0.47      0.22      0.30       147\n",
      "\n",
      "    accuracy                           0.24       400\n",
      "   macro avg       0.26      0.25      0.22       400\n",
      "weighted avg       0.29      0.24      0.24       400\n",
      "\n",
      "[[37  8 16 13]\n",
      " [33  8 16 16]\n",
      " [65 15 19  7]\n",
      " [57 25 33 32]]\n",
      "Validation Loss for s21 = 1.3578388690948486\n",
      "Epoch 83/100, Train Loss: 1.3256138563156128\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_96/1313612177.py:68: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/tmp/ipykernel_96/1313612177.py:88: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/tmp/ipykernel_96/1313612177.py:43: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.18      0.46      0.26        74\n",
      "           1       0.13      0.11      0.12        73\n",
      "           2       0.22      0.18      0.20       106\n",
      "           3       0.45      0.20      0.28       147\n",
      "\n",
      "    accuracy                           0.23       400\n",
      "   macro avg       0.25      0.24      0.21       400\n",
      "weighted avg       0.28      0.23      0.23       400\n",
      "\n",
      "[[34 10 18 12]\n",
      " [32  8 16 17]\n",
      " [64 16 19  7]\n",
      " [56 26 35 30]]\n",
      "Validation Loss for s21 = 1.356910228729248\n",
      "Epoch 84/100, Train Loss: 1.4603030681610107\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_96/1313612177.py:68: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/tmp/ipykernel_96/1313612177.py:88: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.18      0.46      0.26        74\n",
      "           1       0.14      0.11      0.12        73\n",
      "           2       0.24      0.19      0.21       106\n",
      "           3       0.48      0.23      0.31       147\n",
      "\n",
      "    accuracy                           0.24       400\n",
      "   macro avg       0.26      0.25      0.23       400\n",
      "weighted avg       0.30      0.24      0.24       400\n",
      "\n",
      "[[34 10 18 12]\n",
      " [32  8 15 18]\n",
      " [63 16 20  7]\n",
      " [57 24 32 34]]\n",
      "Validation Loss for s21 = 1.3560450077056885\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_96/1313612177.py:43: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 85/100, Train Loss: 1.3368724584579468\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_96/1313612177.py:68: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/tmp/ipykernel_96/1313612177.py:88: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/tmp/ipykernel_96/1313612177.py:43: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.19      0.51      0.28        74\n",
      "           1       0.16      0.12      0.14        73\n",
      "           2       0.23      0.18      0.20       106\n",
      "           3       0.45      0.20      0.27       147\n",
      "\n",
      "    accuracy                           0.24       400\n",
      "   macro avg       0.26      0.25      0.22       400\n",
      "weighted avg       0.29      0.24      0.23       400\n",
      "\n",
      "[[38  8 16 12]\n",
      " [35  9 13 16]\n",
      " [65 15 19  7]\n",
      " [59 24 35 29]]\n",
      "Validation Loss for s21 = 1.35835599899292\n",
      "Epoch 86/100, Train Loss: 1.2782659530639648\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_96/1313612177.py:68: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/tmp/ipykernel_96/1313612177.py:88: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/tmp/ipykernel_96/1313612177.py:43: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.18      0.46      0.26        74\n",
      "           1       0.16      0.14      0.15        73\n",
      "           2       0.20      0.16      0.18       106\n",
      "           3       0.45      0.20      0.27       147\n",
      "\n",
      "    accuracy                           0.23       400\n",
      "   macro avg       0.25      0.24      0.21       400\n",
      "weighted avg       0.28      0.23      0.22       400\n",
      "\n",
      "[[34 10 18 12]\n",
      " [33 10 14 16]\n",
      " [64 17 17  8]\n",
      " [58 24 36 29]]\n",
      "Validation Loss for s21 = 1.3577299118041992\n",
      "Epoch 87/100, Train Loss: 1.3259254693984985\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_96/1313612177.py:68: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/tmp/ipykernel_96/1313612177.py:88: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/tmp/ipykernel_96/1313612177.py:43: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.18      0.45      0.26        74\n",
      "           1       0.16      0.14      0.15        73\n",
      "           2       0.22      0.20      0.21       106\n",
      "           3       0.50      0.22      0.30       147\n",
      "\n",
      "    accuracy                           0.24       400\n",
      "   macro avg       0.27      0.25      0.23       400\n",
      "weighted avg       0.31      0.24      0.24       400\n",
      "\n",
      "[[33 11 20 10]\n",
      " [32 10 16 15]\n",
      " [62 16 21  7]\n",
      " [53 25 37 32]]\n",
      "Validation Loss for s21 = 1.353609323501587\n",
      "Epoch 88/100, Train Loss: 1.32947838306427\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_96/1313612177.py:68: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/tmp/ipykernel_96/1313612177.py:88: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.19      0.50      0.28        74\n",
      "           1       0.15      0.11      0.12        73\n",
      "           2       0.22      0.20      0.21       106\n",
      "           3       0.50      0.20      0.28       147\n",
      "\n",
      "    accuracy                           0.24       400\n",
      "   macro avg       0.27      0.25      0.22       400\n",
      "weighted avg       0.30      0.24      0.23       400\n",
      "\n",
      "[[37 10 19  8]\n",
      " [34  8 17 14]\n",
      " [64 14 21  7]\n",
      " [58 23 37 29]]\n",
      "Validation Loss for s21 = 1.35636305809021\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_96/1313612177.py:43: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 89/100, Train Loss: 1.3079051971435547\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_96/1313612177.py:68: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/tmp/ipykernel_96/1313612177.py:88: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.19      0.47      0.27        74\n",
      "           1       0.16      0.12      0.14        73\n",
      "           2       0.22      0.19      0.20       106\n",
      "           3       0.49      0.22      0.30       147\n",
      "\n",
      "    accuracy                           0.24       400\n",
      "   macro avg       0.26      0.25      0.23       400\n",
      "weighted avg       0.30      0.24      0.24       400\n",
      "\n",
      "[[35 11 18 10]\n",
      " [33  9 16 15]\n",
      " [64 14 20  8]\n",
      " [55 23 37 32]]\n",
      "Validation Loss for s21 = 1.3483011722564697\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_96/1313612177.py:43: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 90/100, Train Loss: 1.4159194231033325\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_96/1313612177.py:68: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/tmp/ipykernel_96/1313612177.py:88: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.18      0.46      0.26        74\n",
      "           1       0.14      0.11      0.12        73\n",
      "           2       0.22      0.19      0.20       106\n",
      "           3       0.48      0.21      0.29       147\n",
      "\n",
      "    accuracy                           0.23       400\n",
      "   macro avg       0.26      0.24      0.22       400\n",
      "weighted avg       0.29      0.23      0.23       400\n",
      "\n",
      "[[34 11 19 10]\n",
      " [33  8 17 15]\n",
      " [64 14 20  8]\n",
      " [55 24 37 31]]\n",
      "Validation Loss for s21 = 1.35740327835083\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_96/1313612177.py:43: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 91/100, Train Loss: 1.4044253826141357\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_96/1313612177.py:68: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/tmp/ipykernel_96/1313612177.py:88: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.18      0.46      0.26        74\n",
      "           1       0.16      0.14      0.15        73\n",
      "           2       0.21      0.18      0.19       106\n",
      "           3       0.50      0.21      0.30       147\n",
      "\n",
      "    accuracy                           0.23       400\n",
      "   macro avg       0.26      0.25      0.23       400\n",
      "weighted avg       0.30      0.23      0.24       400\n",
      "\n",
      "[[34 12 19  9]\n",
      " [33 10 16 14]\n",
      " [62 17 19  8]\n",
      " [55 24 37 31]]\n",
      "Validation Loss for s21 = 1.3598101139068604\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_96/1313612177.py:43: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 92/100, Train Loss: 1.3262112140655518\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_96/1313612177.py:68: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/tmp/ipykernel_96/1313612177.py:88: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.19      0.46      0.27        74\n",
      "           1       0.16      0.14      0.15        73\n",
      "           2       0.21      0.19      0.20       106\n",
      "           3       0.49      0.20      0.29       147\n",
      "\n",
      "    accuracy                           0.23       400\n",
      "   macro avg       0.26      0.25      0.23       400\n",
      "weighted avg       0.30      0.23      0.23       400\n",
      "\n",
      "[[34 12 20  8]\n",
      " [32 10 16 15]\n",
      " [60 18 20  8]\n",
      " [54 24 39 30]]\n",
      "Validation Loss for s21 = 1.3613977432250977\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_96/1313612177.py:43: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 93/100, Train Loss: 1.3387686014175415\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_96/1313612177.py:68: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/tmp/ipykernel_96/1313612177.py:88: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.19      0.46      0.27        74\n",
      "           1       0.16      0.15      0.16        73\n",
      "           2       0.19      0.16      0.17       106\n",
      "           3       0.48      0.20      0.29       147\n",
      "\n",
      "    accuracy                           0.23       400\n",
      "   macro avg       0.26      0.24      0.22       400\n",
      "weighted avg       0.29      0.23      0.23       400\n",
      "\n",
      "[[34 12 20  8]\n",
      " [32 11 16 14]\n",
      " [58 21 17 10]\n",
      " [55 24 38 30]]\n",
      "Validation Loss for s21 = 1.3621586561203003\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_96/1313612177.py:43: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 94/100, Train Loss: 1.294637680053711\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_96/1313612177.py:68: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/tmp/ipykernel_96/1313612177.py:88: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.19      0.47      0.27        74\n",
      "           1       0.14      0.11      0.12        73\n",
      "           2       0.22      0.20      0.21       106\n",
      "           3       0.48      0.20      0.29       147\n",
      "\n",
      "    accuracy                           0.23       400\n",
      "   macro avg       0.26      0.25      0.22       400\n",
      "weighted avg       0.29      0.23      0.23       400\n",
      "\n",
      "[[35 11 18 10]\n",
      " [33  8 17 15]\n",
      " [63 14 21  8]\n",
      " [54 23 40 30]]\n",
      "Validation Loss for s21 = 1.3605782985687256\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_96/1313612177.py:43: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 95/100, Train Loss: 1.282664179801941\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_96/1313612177.py:68: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/tmp/ipykernel_96/1313612177.py:88: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.19      0.47      0.27        74\n",
      "           1       0.15      0.12      0.13        73\n",
      "           2       0.20      0.17      0.18       106\n",
      "           3       0.47      0.20      0.28       147\n",
      "\n",
      "    accuracy                           0.23       400\n",
      "   macro avg       0.25      0.24      0.22       400\n",
      "weighted avg       0.29      0.23      0.23       400\n",
      "\n",
      "[[35 12 17 10]\n",
      " [32  9 18 14]\n",
      " [62 16 18 10]\n",
      " [55 24 38 30]]\n",
      "Validation Loss for s21 = 1.3589166402816772\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_96/1313612177.py:43: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 96/100, Train Loss: 1.4159339666366577\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_96/1313612177.py:68: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/tmp/ipykernel_96/1313612177.py:88: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.19      0.47      0.27        74\n",
      "           1       0.16      0.12      0.14        73\n",
      "           2       0.23      0.20      0.21       106\n",
      "           3       0.48      0.21      0.29       147\n",
      "\n",
      "    accuracy                           0.24       400\n",
      "   macro avg       0.26      0.25      0.23       400\n",
      "weighted avg       0.30      0.24      0.24       400\n",
      "\n",
      "[[35 11 18 10]\n",
      " [33  9 15 16]\n",
      " [63 14 21  8]\n",
      " [56 23 37 31]]\n",
      "Validation Loss for s21 = 1.3625742197036743\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_96/1313612177.py:43: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 97/100, Train Loss: 1.3196262121200562\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_96/1313612177.py:68: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/tmp/ipykernel_96/1313612177.py:88: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.18      0.45      0.26        74\n",
      "           1       0.16      0.12      0.14        73\n",
      "           2       0.24      0.22      0.23       106\n",
      "           3       0.48      0.22      0.30       147\n",
      "\n",
      "    accuracy                           0.24       400\n",
      "   macro avg       0.26      0.25      0.23       400\n",
      "weighted avg       0.30      0.24      0.24       400\n",
      "\n",
      "[[33 11 20 10]\n",
      " [33  9 16 15]\n",
      " [60 13 23 10]\n",
      " [54 23 38 32]]\n",
      "Validation Loss for s21 = 1.356074571609497\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_96/1313612177.py:43: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 98/100, Train Loss: 1.2641769647598267\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_96/1313612177.py:68: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/tmp/ipykernel_96/1313612177.py:88: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.19      0.45      0.26        74\n",
      "           1       0.18      0.15      0.16        73\n",
      "           2       0.25      0.22      0.23       106\n",
      "           3       0.46      0.21      0.29       147\n",
      "\n",
      "    accuracy                           0.24       400\n",
      "   macro avg       0.27      0.26      0.24       400\n",
      "weighted avg       0.30      0.24      0.25       400\n",
      "\n",
      "[[33 12 17 12]\n",
      " [31 11 15 16]\n",
      " [61 13 23  9]\n",
      " [53 25 38 31]]\n",
      "Validation Loss for s21 = 1.3624770641326904\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_96/1313612177.py:43: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 99/100, Train Loss: 1.4348547458648682\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_96/1313612177.py:68: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/tmp/ipykernel_96/1313612177.py:88: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/tmp/ipykernel_96/1313612177.py:43: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.19      0.45      0.26        74\n",
      "           1       0.19      0.15      0.17        73\n",
      "           2       0.25      0.22      0.23       106\n",
      "           3       0.44      0.22      0.29       147\n",
      "\n",
      "    accuracy                           0.25       400\n",
      "   macro avg       0.27      0.26      0.24       400\n",
      "weighted avg       0.30      0.25      0.25       400\n",
      "\n",
      "[[33 13 16 12]\n",
      " [31 11 14 17]\n",
      " [60 12 23 11]\n",
      " [54 23 38 32]]\n",
      "Validation Loss for s21 = 1.360675573348999\n",
      "Epoch 100/100, Train Loss: 1.3344166278839111\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_96/1313612177.py:68: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/tmp/ipykernel_96/1313612177.py:88: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.19      0.46      0.27        74\n",
      "           1       0.18      0.14      0.15        73\n",
      "           2       0.24      0.21      0.22       106\n",
      "           3       0.45      0.22      0.29       147\n",
      "\n",
      "    accuracy                           0.24       400\n",
      "   macro avg       0.26      0.26      0.23       400\n",
      "weighted avg       0.30      0.24      0.24       400\n",
      "\n",
      "[[34 11 17 12]\n",
      " [32 10 16 15]\n",
      " [60 12 22 12]\n",
      " [53 24 38 32]]\n",
      "Validation Loss for s21 = 1.359056830406189\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x7fd0a4370310>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA0MAAAJGCAYAAACZel7oAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjYuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/av/WaAAAACXBIWXMAAA9hAAAPYQGoP6dpAAD7W0lEQVR4nOzdd5hcZfn/8feU7b1kS3rvhUCooYPSO9KbVBVQxIqiYkV+IqKCoF+VonQEBJVeAwFCIAnpve9uNtt7mzm/P545M7vZNm13Zjef13Xl2tmdM2fObtrcc9/P53FYlmUhIiIiIiKyn3HG+gJERERERERiQcWQiIiIiIjsl1QMiYiIiIjIfknFkIiIiIiI7JdUDImIiIiIyH5JxZCIiIiIiOyXVAyJiIiIiMh+yR3rC4gWr9dLSUkJGRkZOByOWF+OiIiIiIjEiGVZ1NfXM3LkSJzO3vs/w6YYKikpYcyYMbG+DBERERERiRM7d+5k9OjRvd4/bIqhjIwMwHzDmZmZMb4aERERERGJlbq6OsaMGeOvEXozbIohezQuMzNTxZCIiIiIiPS7fEYBCiIiIiIisl9SMSQiIiIiIvslFUMiIiIiIrJfGjZrhkRERERE+uLxeGhvb4/1ZUgUJCQk4HK5Ij6PiiERERERGdYsy6KsrIyamppYX4pEUXZ2NkVFRRHtMapiSERERESGNbsQKigoIDU1NaIXzxJ7lmXR1NREeXk5AMXFxWGfS8WQiIiIiAxbHo/HXwjl5eXF+nIkSlJSUgAoLy+noKAg7JE5BSiIiIiIyLBlrxFKTU2N8ZVItNm/p5GsA1MxJCIiIiLDnkbjhp9o/J6qGBIRERERkf2SiiERERERkf3A+PHjuffee2N9GXFFxZCIiIiISBxxOBx9/rrjjjvCOu8nn3zC9ddfH92LHeKUJiciIiIiEkdKS0v9t5966il+/OMfs379ev/X0tPT/bcty8Lj8eB29/+yfsSIEdG90GFAnSERERERkThSVFTk/5WVlYXD4fB/vm7dOjIyMnj55Zc56KCDSEpK4v3332fz5s2cddZZFBYWkp6ezsEHH8wbb7zR5bz7jsk5HA7++te/cs4555CamsqUKVN48cUXB/m7jS0VQyIiIiKy37Asi6a2jpj8siwrat/H97//fX7961+zdu1a5s6dS0NDA6eeeipvvvkmy5Yt4+STT+aMM85gx44dfZ7npz/9KRdccAGff/45p556KpdeeilVVVVRu854pzE5EREREdlvNLd7mPnjV2Py3Gt+dhKpidF5+f2zn/2ML3zhC/7Pc3NzmTdvnv/zn//85zz//PO8+OKL3HTTTb2e56qrruLiiy8G4Fe/+hV/+MMfWLJkCSeffHJUrjPeqTMkIiIiIjLELFiwoMvnDQ0NfPvb32bGjBlkZ2eTnp7O2rVr++0MzZ071387LS2NzMxMysvLB+Sa45E6QyIiIiKy30hJcLHmZyfF7LmjJS0trcvn3/72t3n99de5++67mTx5MikpKZx//vm0tbX1eZ6EhIQunzscDrxeb9SuM96pGBIRERGR/YbD4YjaqFo8+eCDD7jqqqs455xzANMp2rZtW2wvagjQmJyIiIiIyBA3ZcoUnnvuOZYvX86KFSu45JJL9qsOT7hUDEWZZVl8tqOaRRv3xvpSRERERGQ/cc8995CTk8MRRxzBGWecwUknncSBBx4Y68uKew4rmhl/MVRXV0dWVha1tbVkZmbG7DpeWLabW55azuSCdF7/5tE4HI6YXYuIiIjI/q6lpYWtW7cyYcIEkpOTY305EkV9/d4GWxuE3Bl67733OOOMMxg5ciQOh4MXXngh6Md+8MEHuN1uDjjggC5fv/POOzn44IPJyMigoKCAs88+u8suu0PJCTMKSE10sam8gSVb95+MdhERERGRoSbkYqixsZF58+Zx//33h/S4mpoarrjiCk444YRu97377rvceOONfPTRR7z++uu0t7fzxS9+kcbGxlAvL+YykhM464CRADz2cd9RhiIiIiIiEjshR2mccsopnHLKKSE/0Ve+8hUuueQSXC5Xt27SK6+80uXzhx9+mIKCAj799FOOPvrokJ8r1i45ZBxPLNnJy6tKqWiYSX56UqwvSURERERE9jEoAQoPPfQQW7Zs4Sc/+UlQx9fW1gJmJ93etLa2UldX1+VXvJgzOot5o7No91g8++muWF+OiIiIiIj0YMCLoY0bN/L973+ff/7zn7jd/TeivF4vt9xyCwsXLmT27Nm9HnfnnXeSlZXl/zVmzJhoXnbELj10HACPf7wDr3dYZFSIiIiIiAwrA1oMeTweLrnkEn76058yderUoB5z4403smrVKp588sk+j7vtttuora31/9q5c2c0LjlqTp9XTEaymx1VTby/qSLWlyMiIiIiIvsY0O136+vrWbp0KcuWLeOmm24CTOfHsizcbjevvfYaxx9/vP/4m266if/85z+89957jB49us9zJyUlkZQUv2txUhPdnHfgaB5evI3HPt7O0VNHxPqSRERERESkkwEthjIzM1m5cmWXr/3pT3/irbfe4tlnn2XChAmA2aj05ptv5vnnn+edd97xf32ou+TQsTy8eBtvrC2nrLaFoixl24uIiIiIxIuQi6GGhgY2bdrk/3zr1q0sX76c3Nxcxo4dy2233cbu3bt59NFHcTqd3db9FBQUkJyc3OXrN954I48//jj//ve/ycjIoKysDICsrCxSUlLC/d5ibmphBoeMz2XJtiqe+mQn3zhxSqwvSUREREREfEJeM7R06VLmz5/P/PnzAbj11luZP38+P/7xjwEoLS1lx47Q9td54IEHqK2t5dhjj6W4uNj/66mnngr18uLOpYeNBeDJT3bQ4fHG+GpEREREZH9w7LHHcsstt/g/Hz9+PPfee2+fj3E4HN22wAlHtM4zGELuDB177LFYVu/paA8//HCfj7/jjju44447unytr/MNdSfPLiI3LZHS2hbeXr+XL8wsjPUliYiIiEgcO+OMM2hvb++2FyfAokWLOProo1mxYgVz584N+pyffPIJaWlp0bxM7rjjDl544QWWL1/e5eulpaXk5ORE9bkGyqDsM7Q/S3K7+NJBJgzisY+3x/hqRERERCTeXXPNNbz++uvs2tV9v8qHHnqIBQsWhFQIAYwYMYLU1NRoXWKfioqK4jrorDMVQ4Pg4kPMqNy7G/ays6opxlcjIiIiIvHs9NNPZ8SIEd0mrhoaGnjmmWc4++yzufjiixk1ahSpqanMmTOHJ554os9z7jsmt3HjRo4++miSk5OZOXMmr7/+erfHfO9732Pq1KmkpqYyceJEfvSjH9He3g6YabCf/vSnrFixAofDgcPh8F/vvmNyK1eu5PjjjyclJYW8vDyuv/56Ghoa/PdfddVVnH322dx9990UFxeTl5fHjTfe6H+ugTSgaXJijM9P46gp+SzaWMETS3bw3ZOnx/qSRERERPZPlgXtMXpzOiEVHI5+D3O73VxxxRU8/PDD/PCHP8The8wzzzyDx+Phsssu45lnnuF73/semZmZ/Pe//+Xyyy9n0qRJHHLIIf2e3+v1cu6551JYWMjHH39MbW1tl/VFtoyMDB5++GFGjhzJypUrue6668jIyOC73/0uF154IatWreKVV17hjTfeAEz42b4aGxs56aSTOPzww/nkk08oLy/n2muv5aabbupS7L399tsUFxfz9ttvs2nTJi688EIOOOAArrvuun6/n0ioGBoklx46lkUbK3h66U5uOXEqiW415UREREQGXXsT/GpkbJ77ByWQGNy6nauvvprf/OY3vPvuuxx77LGAGZE777zzGDduHN/+9rf9x9588828+uqrPP3000EVQ2+88Qbr1q3j1VdfZeRI87P41a9+xSmnnNLluNtvv91/e/z48Xz729/mySef5Lvf/S4pKSmkp6fjdrspKirq9bkef/xxWlpaePTRR/1rlu677z7OOOMM7rrrLgoLzXr6nJwc7rvvPlwuF9OnT+e0007jzTffHPBiSK/IB8kJMwopyEiioqGN19aUxfpyRERERCSOTZ8+nSOOOIK///3vAGzatIlFixZxzTXX4PF4+PnPf86cOXPIzc0lPT2dV199NehE57Vr1zJmzBh/IQRw+OGHdzvuqaeeYuHChRQVFZGens7tt98ecmr02rVrmTdvXpfwhoULF+L1elm/fr3/a7NmzcLlcvk/Ly4upry8PKTnCoc6Q4MkweXkooPH8Ie3NvHYRzs4fW703pEor2vh8121HD+9AKez/9ariIiIyH4rIdV0aGL13CG45ppruPnmm7n//vt56KGHmDRpEscccwx33XUXv//977n33nuZM2cOaWlp3HLLLbS1tUXtUj/88EMuvfRSfvrTn3LSSSeRlZXFk08+yW9/+9uoPUdnCQkJXT53OBx4vQO/LY06Q4PoSwvGAPDR1kpaOzxRO+/3n1vJtY8uZfHmyqidU0RERGRYcjjMqFosfgWxXqizCy64AKfTyeOPP86jjz7K1VdfjcPh4IMPPuCss87isssuY968eUycOJENGzYEfd4ZM2awc+dOSktL/V/76KOPuhyzePFixo0bxw9/+EMWLFjAlClT2L69azJyYmIiHk/fr2lnzJjBihUraGxs9H/tgw8+wOl0Mm3atKCveaCoGBpEo3NSSElwYVlQUtMStfOu2FkDwA4l1YmIiIgMG+np6Vx44YXcdtttlJaWctVVVwEwZcoUXn/9dRYvXszatWu54YYb2LNnT9DnPfHEE5k6dSpXXnklK1asYNGiRfzwhz/scsyUKVPYsWMHTz75JJs3b+YPf/gDzz//fJdjxo8fz9atW1m+fDkVFRW0trZ2e65LL72U5ORkrrzySlatWsXbb7/NzTffzOWXX+5fLxRLKoYGkcPhYHROCgC7qqNTuFQ2tFLZaFqi1U3Ra42KiIiISOxdc801VFdXc9JJJ/nX+Nx+++0ceOCBnHTSSRx77LEUFRVx9tlnB31Op9PJ888/T3NzM4cccgjXXnstv/zlL7scc+aZZ/LNb36Tm266iQMOOIDFixfzox/9qMsx5513HieffDLHHXccI0aM6DHeOzU1lVdffZWqqioOPvhgzj//fE444QTuu+++0H8YA8BhWZYV64uIhrq6OrKysqitrSUzMzPWl9OrLz+0hLfX7+XOc+f49x+KxEdbKrnoL6ated1RE/jhaTMjPqeIiIjIcNHS0sLWrVuZMGECycnJsb4ciaK+fm+DrQ3UGRpko3PMwrlodYY27qn3365qHPiNqUREREREhgsVQ4MsMCbXHJXzbdgT2L23RmNyIiIiIiJBUzE0yMbkms7QziiFHWwsD3SGtGZIRERERCR4KoYGWbQ7Qxu7dIY0JiciIiIiEiwVQ4PMXjNUXt9KS3tkew11TpIDdYZEREREejNMMsOkk2j8nqoYGmQ5qQmkJroAKKmJrDu0sdx0hdJ856ttbsfj1V90EREREVtCQgIATU3aj3G4sX9P7d/jcLijdTESHHuvoQ17GthV3czEEelhn8tOkjtwXA6LNlbgtaCuuZ2ctMRoXa6IiIjIkOZyucjOzqa8vBww+944HI4YX5VEwrIsmpqaKC8vJzs7G5fLFfa5VAzFwOicVH8xFAm7MzRzZCbLd9RQ39pBdVObiiERERGRToqKigD8BZEMD9nZ2f7f23CpGIqBMb4QhZ0R7jW0wdcZmlKQQXZagq8YUoiCiIiISGcOh4Pi4mIKCgpob9drpeEgISEhoo6QTcVQDAQ2Xo2wM+RLkptamE5OaiI7q5q115CIiIhIL1wuV1ReQMvwoQCFGAjEa4ffGeqcJDe5IJ3sVDMap86QiIiIiEhwVAzFQDQ6Q/Z6odE5KaQmuslJNSka1Y3qDImIiIiIBEPFUAzYnaG9Eew1ZBdDUwszAMjxd4ZUDImIiIiIBEPFUAxkpyaQnmSWa4XbHbJjtacUmmjuHI3JiYiIiIiERMVQDNh7DUH464Y6J8kB5KSZMTkFKIiIiIiIBEfFUIwEiqHwOkObygNJckCnAAUVQyIiIiIiwVAxFCORhChUNbZR0WCKnkkj7DE5O0BBY3IiIiIiIsFQMRQjkYzJ2euFRuekkOZbe6QABRERERGR0KgYipFIxuQ27JMkB5CTZoqhmqZ2LMuKwhWKiIiIiAxvKoZiJDAmF35naEpBuv9r9phcm8dLU1t4cd0iIiIiIvsTFUMxMsZXDFU0tNEcYvGycY/pDE3p1BlKSXCR6Da/nRqVExERERHpn4qhGMlMcZPhW++zuya07tDGctMZspPkwMR1292hGu01JCIiIiLSLxVDMeJwOBjlWze0M4R1Qz0lydnsEIWqRnWGRERERET6o2IohsKJ1+4pSc6Wbcdra0xORERERKRfKoZiyJ8oVxX8mJydJNc5PMGW2ylRTkRERERE+qZiKIbG5IbeGdq0x14vlNHtvmztNSQiIiIiEjQVQzEUzsarG3pIkrMpQEFEREREJHgqhmIonI1X7SS5nsbkFKAgIiIiIhI8FUMxZAcoVDa20dTW0e/xnZPkJvdQDGlMTkREREQkeCqGYigrJYGMZJMIF0x3qK8kOYDcNI3JiYiIiIgES8VQjAXitftfN9RXkhyoMyQiIiIiEgoVQzE2JoR1Q30lyUFgzZA6QyIiIiIi/VMxFGOhbLxqJ8n1tF4IAmlyDa0dtHV4o3SFIiIiIiLDk4qhGAslXnujb0yut85QZnICToe5XaNRORERERGRPqkYirFg47WrG9uoaGgFeu8MOZ0OslJMd6hao3IiIiIiIn1SMRRj9pjczqq+O0MbfOuFRmX3nCRny0lTiIKIiIiISDBUDMXY6FzTGapuaqehtfe9hgIjcj13hWyBEAUVQyIiIiIifVExFGOZyQn+0bbdfYzKbewnSc5mhyhoTE5EREREpG8qhuJAMCEK/SXJ2ey9hqoa1RkSEREREemLiqE40F+IQklNM5/uqAZg5sjMPs9ld4Y0JiciIiIi0jcVQ3GgvxCFP761kbYOL4dOyGVmcd/FkN0Z0piciIiIiEjfVAzFgb46Q1v2NvD00l0AfPfkaTgcjj7PlZumAAURERERkWCoGIoDY3ydoV013TtD97y+AY/X4oTpBRw0LrffcylAQUREREQkOCqG4oAdr71vZ2h1SS3/+bwUgG99cVpQ5wqMyUXWGapoaOWWJ5exZGtVROcREREREYlXve/eKYNmVLYphmqa2qlvaScj2XR37n51PQBnzhvZb3CCzd5nqDrCNLn/e28LLywvob6lg0Mm9N+REhEREREZatQZigMZyQlk+8bbdteY7tAn26p4e/1eXE4H3/zC1KDPZY/J1Ta34/VaYV2PZVn+jlRFQ2tY5xARERERiXcqhuKEHaKws6oZy7L4zSumK3TBgjFMyE8L+jz2mJzXgrqW8NYNrdhV6y/KKrVfkYiIiIgMUyqG4sTobF+IQnUT727Yy5JtVSS6nXz9hMkhnSfR7SQ9yUw/hhui8N/PS/y3KxtUDImIiIjI8KRiKE6M8YUo7Khq4je+tUJXHj6O4qyUkM+V7U+UC72QsSyL//pG5ACa2z00tXWEfB4RERERkXinYihO2BuvPr9sN6tL6khPcvPVY0PrCtkiCVH4bEcNJbUtpCW6SHSZPx7qDomIiIjIcKRiKE7Ya4ZqfKNt1x41wb+BaqiyI9hryO4KnTizkLx08/xVWjckIiIiIsOQiqE4YXeGwCTCXXPkhLDPZXeGakIck/N6Lf630hRDp88dqWJIRERERIY1FUNxYlROYG3QjcdN9u81FI6cMNcMfbajmrK6FjKS3Bw1JZ/ctCRA8doiIiIiMjxp09U4kZ7k5qKDx1Ba28Jlh42L6Fw5vvG6UMfk7L2FvjCzkOQEF3lp6gyJiIiIyPClYiiO/Pq8uVE5Tzhjcp1H5E6bWwzgL4a015CIiIiIDEcakxuG7ACFUDo6n2yrory+lYxkN0dNGQFArm/NkNLkRERERGQ4UjE0DAU6Q8GPyf3X1xU6aVYRiW7zxyLft2aoqlFrhkRERERk+FExNAz59xkKckzO47X438oyIDAiB/ijvTUmJyIiIiLDkYqhYSgnLbDPkGVZ/R6/ZGsVFQ2tZKUksHBSvv/reRqTExEREZFhTMXQMGR3hto6vDS3e/o9/r8rSwA4aVahf0QOIM83JlepMTkRERERGYZUDA1DqYkuEl3mt7a/EIUOj5dXVpkRudPnjuxynx2g0NLupamtYwCuVEREREQkdlQMDUMOh8OfKNdfiMLHW6uoaGgjJzWBwyfldbkvLdFFkq9TpFE5ERERERluVAwNU8GGKNgbrZ48u4gEV9c/Dg6HQ3sNiYiIiMiwpWJomLI7Q9V9dIbMiJxvo9U5I3s8Ji9d8doiIiIiMjyFXAy99957nHHGGYwcORKHw8ELL7wQ9GM/+OAD3G43BxxwQLf77r//fsaPH09ycjKHHnooS5YsCfXSpBM7Frumj87Qh1sqqW5qJy8tkcMm5vZ5ngqNyYmIiIjIMBNyMdTY2Mi8efO4//77Q3pcTU0NV1xxBSeccEK3+5566iluvfVWfvKTn/DZZ58xb948TjrpJMrLy0O9PPHJtsfkGnvvDL22eg8AJ80uwu3q+Y+CPSbXXxCDiIiIiMhQE3IxdMopp/CLX/yCc845J6THfeUrX+GSSy7h8MMP73bfPffcw3XXXceXv/xlZs6cyYMPPkhqaip///vfQ7088cnxj8n1XsS8v6kCgOOmFfR6jL3XkIohERERERluBmXN0EMPPcSWLVv4yU9+0u2+trY2Pv30U0488cTARTmdnHjiiXz44Ye9nrO1tZW6urouvySgvwCFnVVNbK1oxOV09DoiB5Dr22uookFrhkRERERkeBnwYmjjxo18//vf55///Cdut7vb/RUVFXg8HgoLC7t8vbCwkLKysl7Pe+edd5KVleX/NWbMmKhf+1DWX4CC3RU6cGw2GckJvZ5HnSERERERGa4GtBjyeDxccskl/PSnP2Xq1KlRPfdtt91GbW2t/9fOnTujev6hzu4M9RagsGjjXgCOnDyiz/P4o7UVoCAiIiIiw0z3Vk0U1dfXs3TpUpYtW8ZNN90EgNfrxbIs3G43r732GkceeSQul4s9e/Z0eeyePXsoKirq9dxJSUkkJSUN5OUPaTlpvY/JebwWH2yqBOCoqfl9nidXAQoiIiIiMkwNaGcoMzOTlStXsnz5cv+vr3zlK0ybNo3ly5dz6KGHkpiYyEEHHcSbb77pf5zX6+XNN9/sMWxBguMPUOghTW7l7lpqm9vJSHYzd1RWn+fJ9+0zVNnYimVZ0b9QEREREZEYCbkz1NDQwKZNm/yfb926leXLl5Obm8vYsWO57bbb2L17N48++ihOp5PZs2d3eXxBQQHJycldvn7rrbdy5ZVXsmDBAg455BDuvfdeGhsb+fKXvxzBt7Z/s8fkGlo7aOvwkugO1L2LNpgRuYWT8nuN1LbZnaGWdi9NbR7Skga0mSgiIiIiMmhCfmW7dOlSjjvuOP/nt956KwBXXnklDz/8MKWlpezYsSOkc1544YXs3buXH//4x5SVlXHAAQfwyiuvdAtVkOBlpiTgcIBlQU1zGwUZyf77FvnCE46c0veIHEBqoovkBCct7V6qGttUDImIiIjIsOGwhsnsU11dHVlZWdTW1pKZmRnry4kLB/zsNWqa2nntm0cztTADMJ2iA376Gh1ei/e+cxxj81L7Pc/CX7/F7ppmnv/aEcwfmzPQly0iIiIiEpFga4NB2WdIYsO/11Cn8IOPt1TS4bUYm5saVCEEClEQERERkeFJxdAwltPDXkOLNgY/Imez9xqqVDEkIiIiIsOIiqFhzN8Z6hSvbe8vdHQIxVCu9hoSERERkWFIxdAwlr1PMVRS08zmvY04HXD4pOCLITteu6qxNfoXKSIiIiISIyqGhjF7TK7GNyb3vm9Ebt6YbLJSEoI+jzpDIiIiIjIcqRgaxnLSugYovOcbkTtqcvBdIehUDGnNkIiIiIgMIyqGhrHsTgEKXq/FB779hY6aOiKk8+SnK01ORERERIYfFUPDWG6nNUOrS+qobmonPcnNAWOyQztPmlkzVNmgNUMiIiIiMnyoGBrGOgcoLNpkRuQOm5hHgiu03/a8TmNyw2SPXhERERERFUPDWU5aIEBh0QbfiFwIkdo2e5+h1g4vjW2e6F2giIiIiEgMqRgaxux9hmqa2vh0ezUQXjGUmugmOcH8UalSopyIiIiIDBMqhoYxO0DBa0Gbx8uo7BQm5KeFda48e92Q9hoSERERkWFCxdAwluR2kZbo8n9+1JR8HA5HWOeyR+W015CIiIiIDBcqhoY5O0QB4MgwRuRsdoiC4rVFREREZLhQMTTM2SEKDgcsnBR+MWTHa1doTE5EREREhgkVQ8OcHaIwZ1QWOWmJ/RzdO3tMTgEKIiIiIjJcqBga5kZkmI5OOClynWlMTkRERESGG3esL0AG1teOncyI9CRuOGZSROfJ9RVDFSqGRERERGSYUDE0zE0uSOe2U2dEfJ78dNNhqtKaIREREREZJjQmJ0GxO0OK1hYRERGR4ULFkATFv89QYxuWZcX4akREREREIqdiSIKS54vWbuvw0tjmifHViIiIiIhETsWQBCUl0UVKgguAygatGxIRERGRoU/FkASt86iciIiIiMhQp2JIgpanEAURERERGUZUDEnQ8hSvLSIiIiLDiIohCZp/41V1hkRERERkGFAxJEGzx+SqtGZIRERERIYBFUMSNDtAQcWQiIiIiAwHKoYkaLm+vYYqFK0tIiIiIsOAiiEJmjpDIiIiIjKcqBiSoClaW0RERESGExVDErTcTgEKlmXF+GpERERERCKjYkiCludbM9Tm8dLQ2hHjq4mdprYOvvrPT/nHR9tjfSkiIiIiEgEVQxK0lEQXqYkuYP8elfvfyjJeXlXGA29vivWliIiIiEgEVAxJSOwQhcr9OETh7fXlAJTXt+L1alxQREREZKhSMSQhseO1K/fTeO0Oj5f3Nuw1t73Wfl0UioiIiAx17lhfgAwteWmRxWu/u2Evq0tqyU1NJCctkbw08zE3NZGslAScTkc0LzfqPttRQ31LYL3UnroWRmQkxfCKRERERCRcKoYkJP547TCKoZqmNq595BPaPT2PljkdMH9sDk9cdxiJ7vhsWtojcrby+hYgKzYXIyIiIiIRic9XnBK3ctPD32toxa5a2j0WWSkJnDC9gPljsxmXl0pGsqnJvRZ8ur2a9WX1Ub3maHp7nSmGElymg7Wnbv8cFxQREREZDtQZkpDk+9YMVTWGXgR8vrMGgGOnjeD3F83vcl9bh5fzHljMyt21lNY2M2d0/HVbSmubWVdWj8MBJ84o5OVVZeypa4n1ZYmIiIhImNQZkpDkRjAmt2JXLQBzR2d3uy/R7WRUdgoApbXxWWC8vc4EJ8wfk820ogxAnSERERGRoUydIQlJuGNylmWxYlcNAPN66foUZSUDcVwM+dYLHTetgHxfaEK5OkMiIiIiQ5aKIQlJYEwutGKorK6FvfWtuJwOZo3suRgq9hVDZbXNkV3kAGjt8PDBpgoAjpte4AtOgD31KoZEREREhioVQxISf2eosRXLsnA4govCXuFbLzS1MIOURFePxxTH8ZjcJ1uraWrzMCIjiZnFmf6va0xOREREZOjSmiEJiR2t3e6xqG/t6OfoAHu90AFjeg9GKI7jMTl7RO7YqSNwOh3+kb6KhlbaPd5YXpqIiIiIhEnFkIQkOcFFmq+zE8q6Ibsz1FN4gq0o0x6Ta8Gyet6LKFb864WmFwCQm5qI2+nAskxBJCIiIiJDj4ohCZk9KhdsvLbXa7HS1xma10cxVJiZjMMBbR5vyGuSBtL2yka27G3E5XRw5JR8AJxOBwW+EAWNyomIiIgMTSqGJGR5vhCFYDtDWysbqW/tIDnBydTC9F6PS3Q7yU83546nUbl31ptI7QXjcshMTvB/vcDXydJeQyIiIiJDk4ohCVleiHsN2SNys0Zm4Xb1/UcuHtcN7TsiZyvMVLy2iIiIyFCmYkhClucfkwuuGPo8iBE5W2DdUHzEaze3efhwcyVg9hfqrNDfGdKYnIiIiMhQpGJIQpbrG5MLNjhgua8zNK+PJDlbvHWGPtpSSWuHl5FZyd1G/Ao1JiciIiIypKkYkpDZY3LBdIbaOrysKa0DgusMxdteQ/5I7ekF3fZU8gco1KszJCIiIjIUqRiSkIUyJre+rJ62Di9ZKQmMy0vt9/hAZyj2Y3KWZfHWOlMMHb/PiBwEOkNaMyQiIiIyNKkYkpAVZ5nuzZqSun43HF2xqwaAuaOzunVWetJ5r6FY27y3kV3VzSS6nBwxOa/b/RqTExERERnaVAxJyBaMzyE/PYnKxjbeXFve57Gf+4qhYEbkAEZ2GpOL9car7/hG5A6dmEtqorvb/XbhVt3UTku7Z1CvTUREREQip2JIQpbgcnL+QaMBeHrpzj6PXbHTJMnNHd1/eAJAgS+uurXDS3VTewRXGTl7RG7fFDlbZoqbJLf5K7Q3yHVDFQ2tcTECKCIiIiIqhiRMFywwxdA768t7HWlrbO1gY3k9AAeMyQ7qvEluF/m+NUmxLBrqW9r5ZFsV0H1/IZvD4QhpVM7jtTjzj+9zwm/fZfPehuhdrIiIiIiERcWQhGXiiHQOmZCL14JnP+25O7Rqdy1ey4yTFfiKhmAUZcV+3dCHmytp91iMz0tlQn5ar8fZG68Gs9dQSU0zJbUtNLV5+O6zn+PxxnYMUERERGR/p2JIwnbRwWMAeGrpTrw9vLC3N1sNdkTOZgc0lMSwGLKDHw6d0D04obOCEDpDnbtBn26v5uHF28K+PhERERGJnIohCdsps4vJSHKzs6qZD7dUdrvfLijmBTkiZyv2d4ZiNya3crfZG2l2P4VcYYavGKoPphhqBCArJQGA37y6jm0VjZFcpoiIiIhEQMWQhC0l0cVZ80cC8NQn3UflVoSYJGcr8u81FJvOkGVZrNptulpzRvVTDPnG5MqDGJPb4usMXXroWBZOzqOl3ct3n/28x66aiIiIiAw8FUMSkQsXjAXgldVl1DQFNmGtamxjZ5Xp7MwJeUwutmuGSmpbqGpsw+10ML0oo89jQwlQsMfkJhek8+tz55Ka6GLJtioe/XBbxNcsIiIiIqFTMSQRmT0qk5nFmbR1eHlh2W7/1+2u0MT8NP9YWLDsNUOx6gyt9F37lMIMkhNcfR5b4A9Q6P9at/jG5CaOSGdMbiq3nTIdgLteWc+OyqYIrlhEREREwqFiSCLicDi46BATpPDkJzv9G6V+HuL+Qp0V+8fkmmOy8epK/4hcZr/H2p2h/sbk6lvaKfftRTRxhEmnu/TQcRw2MZfmdg/f/dcKjcuJiIiIDDIVQxKxs+aNItHtZF1ZvT9BLtzwBAgUGC3tXmqbB3/jVTs8YU4Qa53sa61v7aCxtaPX4+yu0IiMJDKTTafM6XRw13lzSUlw8dGWKh5bsiPCKxcRERGRUKgYkohlpSZw6uwiwMRsW5bF575iaG6I4QkAyQkuctPsjVcHd1QulPAEgPQkN+lJbqDvUTl7vdDEffYsGpeXxndPngbAr/+3ll3VGpcTERERGSwqhiQqLvDtOfTi8hI2722gosEEEMwa2f+oWU86j8oNplDCE2wFQWy8aneGJhWkd7vvysPHc/D4HBrbPHz/XytjMhooIiIisj9SMSRRcdiEPMblpdLQ2sGd/1sHwLSi/gMIelMco3jtlb4xv2DCE2z2XkPlfew1tKWi584QmHG5/3f+PJLcTt7fVMGa0rpQL1tEREREwqBiSKLC6XRwwQLTHXpzXTkQ3oicrShG8dqrQghPsBUGkSi3ubz3zhDAhPw0ZvvG8rZVaFROREREZDCoGJKoOf+g0Tgdgc8PGBN6kpwtVvHaK0NYL2QL7DXU85icx2uxtdJXDOX3XAwBjMkx3/NOrRsSERERGRQqhiRqCjOTOX56gf/zSDpDsVgz1Dk8YXYIxVBBPxuv7q5upq3DS6LbyShfwdOTMbmpAOysUjEkIiIiMhhUDElU2aNyqYkupvQyEhaMohisGSqpbaHSF54wozj0Mbne9hra7FsvNCEvDVfn1tk+Rvs7Q4MbGiEiIiKyvwq5GHrvvfc444wzGDlyJA6HgxdeeKHP499//30WLlxIXl4eKSkpTJ8+nd/97nddjvF4PPzoRz9iwoQJpKSkMGnSJH7+858rVWsIOmFGId88cSp3nTcXtyv8WtsekyurbRm0PwfhhCdApzG5XgIUNpf7whNGdA9P6GxMjukM7VJnSERERGRQuEN9QGNjI/PmzePqq6/m3HPP7ff4tLQ0brrpJubOnUtaWhrvv/8+N9xwA2lpaVx//fUA3HXXXTzwwAM88sgjzJo1i6VLl/LlL3+ZrKwsvv71r4f+XUnMuJwOvnHilIjPY4/JNbV5qGvuICs1IeJz9iec8AQIpMntqTOFm8PRtfuzpcK3XmhE350ye0xuV3UzXq+Fs48ukoiIiIhELuRi6JRTTuGUU04J+vj58+czf/58/+fjx4/nueeeY9GiRf5iaPHixZx11lmcdtpp/mOeeOIJlixZEurlyTCRnOAiJzWB6qZ2SuuaB6UYCic8AQL7DLW0e6lr6SArpeu1btkbXGeoOCsZl9NBm8fL3oZWf8dJRERERAbGoK8ZWrZsGYsXL+aYY47xf+2II47gzTffZMOGDQCsWLGC999/v8+iq7W1lbq6ui6/ZHgpGsREuXDDE8AUbtm+Yq2nEIXNe4PrDLldTn9HTCEKIiIiIgNv0Iqh0aNHk5SUxIIFC7jxxhu59tpr/fd9//vf56KLLmL69OkkJCQwf/58brnlFi699NJez3fnnXeSlZXl/zVmzJjB+DZkEBUP4l5Dpb7wBFeI4Qm2zqNyndW1tLO33gQr9NcZgsC6IcVri4iIiAy8QSuGFi1axNKlS3nwwQe59957eeKJJ/z3Pf300zz22GM8/vjjfPbZZzzyyCPcfffdPPLII72e77bbbqO2ttb/a+fOnYPxbcgg8sdr1wx8upo9IjelID2k8ARbgX/j1a6Jclt8XaERGUlkJPc/6udPlKtSopyIiIjIQAt5zVC4JkyYAMCcOXPYs2cPd9xxBxdffDEA3/nOd/zdIfuY7du3c+edd3LllVf2eL6kpCSSkpIG5+IlJooHMV57VZjrhWyFvew1ZK8XmhREVwi015CIiIjIYIrJPkNer5fW1sA76E1NTTidXS/F5XLh9XoH+9Ikjthrhsp62cw0muzO0NzR4RZD9l5DXa91sz88Ibg9l8bk2nsNqRgSERERGWghd4YaGhrYtGmT//OtW7eyfPlycnNzGTt2LLfddhu7d+/m0UcfBeD+++9n7NixTJ8+HTD7FN19991dIrPPOOMMfvnLXzJ27FhmzZrFsmXLuOeee7j66qsj/f5kCBuszpBlWf49hkINT7AFOkM9j8n1F55g8+81pI1XRURERAZcyMXQ0qVLOe644/yf33rrrQBceeWVPPzww5SWlrJjxw7//V6vl9tuu42tW7fidruZNGkSd911FzfccIP/mD/+8Y/86Ec/4mtf+xrl5eWMHDmSG264gR//+MeRfG8yxHVeM9TT/j3REml4AkBBRs8br9rFUDDhCRAYkyutbaHD441o41oRERER6VvIxdCxxx6LZVm93v/www93+fzmm2/m5ptv7vOcGRkZ3Hvvvdx7772hXo4MY0W+YqixzUN9aweZQQQQhCPS8AToPCYX6Ax5vBZbK00xNDnIztCI9CQS3U7aOryU1rb4iyMRERERiT697SxxKzXR7d/AdCDjtSMNT4DAmFx5fQter3mzYHd1M20dXhLdTkZmpwR1HqfT0SlRTuuGRERERAaSiiGJa/aoXMkAxmvbnaE5YYYngInOdjig3WNR3dQGBMITJuSl4XIGP+I3WnsNiYiIiAwKFUMS1wZ641XLsvydoXDDEwASXE7y0syonJ1+ZxdDkwqCWy9kG6O9hkREREQGhYohiWt2vHa4iXLbKhr5xX/WsKm8vsf7y+paqGgw4QkzwwxPsO27bmizHZ6QH9x6IZu9TmiXOkMiIiIiA0rFkMS1SDpDHq/FVx/7jL++v5Vz7l/Moo17ux1jR2pHEp5g23fj1S1hd4bsMTl1hkREREQGkoohiWv+NUO1oRcGTyzZwdrSOgDqWzu46qFP+OdH27scE43wBJvdGbL3GtpSEW5nSAEKIiIiIoNBxZDEtWLfmFyonaGapjbufm09AD88dQbnHjgKj9fi9hdW8fP/rMHjS3z7PArhCbbOew3VtbSzt94URcHuMWSzO0Pl9a20tHsivi4RERER6VnI+wyJDKaiMMfk7nl9AzVN7UwrzODLC8fjcjqYmJ/G3a9t4G/vb2V7ZSO/v2h+VMITbP547boW/2arBRlJZIS4P1J2agJpiS4a2zzsqm5mckFonSURERERCY46QxLX7DG5+tYO6lvag3rM2tI6/zjcT86cidvlxOFwcNPxU7jvkvkkup28sbacM+97P2rhCdB1TG5zuVkvFGpXCMDhcPhDFBSvbby1bg/XP7qUyobW/g8WERERCZKKIYlraUluMpNNAzOY7pBlWdzx4mq8Fpw2p5gjJuV3uf/0uSN58vrDyE9P9Ke9RSM8AboGKGyp8IUnjAivq2PvNbRLIQoA/PndLby2Zg+vrC6L9aWIiIjIMKJiSOJecQjx2v9bWcbHW6tITnBy26nTezzmwLE5PP+1hUwtNIXKgeNyonKdBb7OUEVDKxv22J2h8IohO0Rhl0IUgECAhopDERERiSatGZK4V5SVzPo99f12hprbPPzyv2sA+Ooxk/3dlZ6MyU3lX189gldWlXHCjMKoXGdeWhIupwOP1+KTbVUATApjTA46x2v3XwxVNrTy5tpyzjlwFAmu4ff+htdr+X/vVQyJiIhINKkYkrg3MtuMn/XXGXrg3c2U1LYwKjuFG46Z2O95M5IT+NKCMVG5RgCX08GI9CTK6lqoaTLrm8Idk/OvGarq/8X/HS+t4aUVJQBccHD0vp94UdHYSrvHpP9pI1oRERGJpuH3NrIMO0WZ9phc74XBzqomHnx3MwC3nzYjKmuAwlHoC3wASHQ7GZmdEtZ5Ruf49hrq58W/x2vx3gazmez2qsawniveldYEimB1hkRERCSaVAxJ3LMT5frqDP3yv2tp6/ByxKQ8Tp5dNFiX1k1hRpL/9sT8NFxOR1jnsTtDNU3tfaborS2to7bZ3F9R3xbWc8W7zkXwXu29JCIiIlGkYkjiXl97DVmWxX8+L+GV1WW4nA5+csYsHI7wCpBosBPlILxYbVt6kpucVLM/UV/dkMWbK/y3K4Zp7HRJTdff99016g6JiIhIdGjNkMQ9e81QSacOQWNrB88v280/PtzO+j31AFx+2DimFWXE5Bpt9l5DEP56IduY3FSqm2rZWdXEjF72QfpgU6X/dkXj8O8MgSkOI/3ZioiIiICKIRkCinzR2vUtHazcVcu/PtvFvz7dRX1rBwApCS7OP2g03z15WiwvE4CCKHWGwCTKfb6rlp29dIbaOrz+1DqAivph2hnapyOoEAURERGJFhVDEvfSk9xkJLmpb+3gjPve9399Qn4alx02jvMPGk1WSkIMrzCg85hcpN2L0b69hnb2stfQ57tqaGrz4HY66PBaVDa2YllWTMcEB0KpbyyuMDOJPXWtClEQERGRqFExJEPC+Pw0Vu6uxeGAE6YXcPnh4zlqcj7OMAMKBkrnMbkJ+ZF1hux9knrrhNgjckdNyeft9XtpaffS2OYhPWl4/bW2gzMOHp/Lfz4vVTEkIiIiUTO8XjXJsHXnuXP4aEslJ80q8ietxaOJ+elML8pgdE4qGcmRdavG2PHavew1ZIcnnDizkI+2VNHc7qGyoXVYFUMdHi976kwxdMgEUwz11ikTERERCdXwedUkw9rsUVnMHpUV68voV6LbycvfOCoqo2r+jVerm7qNvzW3eVi2owaAIyblk5eeyK7qZioaWhmXF1lHKp6U17fitSDB5eCAMdmA9hoSERGR6FG0tkiURWvNzijfhq1NbR6qm7ruNbR0exVtHi8js5IZn5dKfroZz6toGF6JcnaSXGFmMmN9xWFFg/YaEhERkehQMSQSp5ITXP41SPuOhi3ebNYLHT4pH4fD0akYGl6JcvYeQ8VZyWSlJPhHANUdEhERkWhQMSQSx8bkBEblOrOLoSMm5QGQn54IQEX98OwMFWel4HA4GO1bR6V4bREREYkGFUMicWx0DyEKtc3trNxVA8ARk+1iyHSGKhuHaWfIt/FuoBhSZ0hEREQip2JIJI51DlGwLdlahdeCiflpFPs2pM2zO0PDbEzO7gyN9H2fgbhxFUMiIiISORVDInHMPybXac2QHal9uG9EDhjGAQqBNUOAxuREREQkqlQMicSx0bnmxf/uTp2Qxb7NVhdOzvd/bbh2huwxuZHZ6gyJiIhI9GmfIZE4NqbTi3+v16KysY31e+oBOGxioDM0wl4zNIw6Q60dHn9x170zpGJIREREIqfOkEgcK85KxuV00ObxUl7fykdbTFdoRnEmuWmJ/uPyfMVQbXM7bR3emFxrtO2pNYVQktvp/17t4lB7DYmIiEg0qBgSiWNul9PfFdlZ3eRfL7Sw03ohgOyUBFxOs9lrVePw6A4FYrWT/RvZZqa4yfDvNaR1QyIiIhIZFUMica5ziIJ/f6HJXYshp9NBXtrwWjcUCE9I8X/N4XAwyo4bj+Go3Lqyum4b4YqIiMjQo2JIJM6N8YUofLyliu2VTbicDg4en9vtOHtUbu8wKYZK7M6Qb48hW6xDFDaV13PGH9/nor98hGVZMbkGERERiQ4VQyJxzu4M/efzEgDmjc4iIzmh23H5vkS54RKiUGonyXXqDEHs47X//sE22j0Wu2uaFeQgIiIyxKkYEolz9sarjW0mMOCISfk9HhfYa2h4dIZKe+0MxS5Rrrqxjec+2+X/fHVJ7aBfg4iIiESPiiGROGePydmO2Cc8wRboDA2PYqik185Q7MbkHl+yg5b2QFrf6pK6Qb8GERERiR4VQyJxzn7xD5DodnLguJwej8vzd4ZiNybX7vFy8xPL+NELqyI+V3+dod2DPCbX7vHy6IfbAJg/NhtQMSQiIjLUqRgSiXMj0pNIdJu/qgvG5ZCc4OrxuHgYk3tm6S5eWlHCPz7aTl1Le9jnaW7zUN1kHl+8T2cosNdQG81tg7fX0P9WlrKnrpURGUl896TpAKzarTE5ERGRoUzFkEicczod/m7Iwsk9rxcCyEu3o7Vj0xlqbvNw7xsb/J/v8UVjh8PuCqUlushMdne5r/NeQ7trBqc7ZFkWf3t/KwBXHDaOuaOzcDigvL6VvfXDYyxRRERkf6RiSGQIOHPeSIoykzlj7shejxnh6wzFas3QQ4u3Ut6pMCiNqBgyjy3qtOGqzeFwMNoXKjFYew19ur2az3fVkuh2csmhY0lLcjMhPw1QiIKIiMhQpmJIZAi45cSpfPSDExibl9rrMfaYXGVjG17v4O5/U9vUzoPvbAYgxTfGV1YXfjFUUmOKnJHZKT3eP9iJcn//wHSFzjlglH9t1uyRWYDWDYmIiAxlKoZEhoncNDMm5/Fa1DSHv14nHH96dxN1LR1MK8zg9LnFAJRFoTNUnJXc4/2DudfQruomXllVBsDVR07wf33WyExAnSEREZGhTMWQyDCR6HaSlWI2Yx3MUbnS2mYe/mAbAN89eZq/mxPZmJwvSS6rt86QL167auA7Q48s3obXgiMn5zOtKMP/9dmjTGdo1W51hkRERIYqFUMiw4gdorB3EIuh37+xkdYOLwePz+H46QX+bs6eiMbkfHsMZce2M9TQ2sGTn+wE4Oojx3e5z+4M7ahqiig5T0RERGJHxZDIMOJfNzRIiXKbyht4eqkpFr5/ynQcDgdFvmJoYDtDg7Nm6NmlO6lv6WBifhrHTi3ocl92aiKjfF2wNVo3JCIiMiSpGBIZRvL98dqD0xn67Wvr8Vpw4oxCDhqXC+Avhspqwy9USvvtDJkxucrGNpraOsJ+nr54vRYPLd4GwJcXjsfpdHQ7xu4Oab8hERGRoUnFkMgwMpidoeU7a3h5VRkOB3znpGn+rxdnmm5JdVM7Le2hb4pa39JOfaspcHrrDGWlJJDh239o9wB1h95aV872yiYyk92ce+DoHo+Z5UuUU2dIRERkaFIxJDKM5KWZYmigO0OWZXHXy+sAOHf+6C7BApkpbpITzD8t4awbssfrMpPdpCW5ez3OH6IwQMWQvcnqxYeM7fU6Zo/ydYaUKCciIjIkqRgSGUbyM+wxuYHtDC3aWMGHWypJdDn55hemdLnP4XD4OzrhrBvqb48h20CGKGwqb+DDLZW4nA6uOGJ8r8fZnaHNexvD6oKJiIhIbKkYEhlG7DG5gewMeb0Wd71iukKXHz7O36HprCgz/ES5/vYYsg1kiMKyHdUALBiX4w9J6ElhZhL56Yl4vBbryuqjfh0iIiIysFQMRVvp5/D0FfDvG2N9JbIfGowAhfc27mV1SR3pSW5uPG5yj8dEkihX6usMFffTGRozgGNyG8sbAJjeafyvJw6Hg5kj7f2GNConIiIy1KgYijZvO6z5N6x/BSwr1lcj+5nBCFB47OMdAHxpwWhy0xJ7PCaQKBfGmJzvMSOD7gxFf0xuva/LM7WfYggCiXKrFaIgIiIy5KgYiraCmeBwQlMFNOyJ9dXIfibPVww1t3tobI1+5HRpbTNvrjV/ri89dGyvxxVHUAz1t8eQbSADFDbsMcXQtML+i6HZvs7QaoUoiIiIDDkqhqItIQXyfAvKy1bG9lpkv5OW6PInuQ1Ed+jJJTvxWnDohFwmF/ReKBT61gyVhrNmyLfHUHEvewzZRvk6Q5WNbVEt/Opa2v3jfVOCKIbsztC6snraPd6oXYeIiIgMPBVDA6FojvlY9nlsr0P2Ow6Hwx+vvTfK64Y6PF6e+mQnAJf00RWCQGdoT4idIcuy/IXIyH46Q1kpCWTaew3VRK87tNHXFSrKTCYrJaHf48fmppKR5Katw8vmvQ1Ruw4REREZeCqGBoK/GFoV2+uQ/VJ+hr1uKLrF0FvryimrayE3LZGTZxf1eaydJlde30JHCN2S2uZ2mn0R1UX9rBmCzqNy0Vs3tGGPKWimFKYHdbzT6WCGrzu0avf+sW7orXV7+HBzZawvQ0REJGIqhgZC0WzzUWNyEgP5aQOz11Dn4IQkt6vPY/PSk3A7HXit0DpUJb4Rudy0RJIT+n4OGJh4bTs8IZj1QrZAiELf64Z2VTf5Y7uHqnVldVz98FKue3QpXq9CYkREZGhTMTQQiuaaj5WboK0xttci+51Aolz0OkM7q5p4b+NeAC45pO8ROQCX0+FfNxRKiEIgPKH/rhAMTIjCxvLgk+RsgRCF3jtDtU3tnH3/B5z/4IfsrIp+At5g+ceH2wFoaO2gviX6IR0iIiKDScXQQEgvgPRCwILytbG+GtnP5GdEf6+hJ5bswLLgqCn5jMtLC+oxhZmmKAulGCrxb7ja93oh20DEa68vM2NyU0PpDI0ynaE1JXW9dkvufm09FQ1teLzWkE2eq29p5/llu/2f1zQPXIS7iIjIYFAxNFAK7VE5hSjI4LIDFKI1JtfW4eXppSY4oa847X3ZBU0oG6/aG66O7CdJzhbtMbmqxjZ/ETmlILg1QwCTR6ST5HbS0NrBjh66Pqt21/LYx9v9n2/eOzQ7xs99tpumNo//85qm9hhejYiISORUDA0Uf4iC1g3J4LIDFKLVGXptTRkVDW0UZCRxwozCoB9nByDsCSFeuzTkzlB0x+Ts/YVG56SQluQO+nFul5PpvrG6Vft0fbxeix//exVeC3/s+WCmzoUSYNEXy7L4x0fbu3yttlnFkIiIDG0qhgaKEuUkRgIBCtEphh73BSdcdPAYElzB/5NhJ8qF0hkqCbUzlGuKpqoo7TUUymar+5o1qud1Q89+tovPdtSQlujieydPB2DLIHSGLMvi/97bwuw7XuWhD7ZGfL4Pt1SyqbyB1ESXPzCiRsWQiIgMcSqGBopdDO1ZDV5P38eKRJE/Wrsx8jG5zXsbWLy5EqcDLgwiOKEzuzMUWoBCaJ2hzOQE/15A0dhryC6GQglPsAUS5QLFUG1TO3e9vA6Ab5w4hcMn5QGwZW8DljVwSWztHi8/eH4Vv/zfWlravby8sizic/7T1xU6Z/4o/3iiOkMiIjLUqRgaKHmTwZ0C7Y1QFfm7siLByvN1hmqa2mmPcETqCV9X6LhpBYzKDq5AsdmJcGVBjsl5vZa/cAo2TQ6iG6KwwR+eEPx6IdssO1Fud62/0Lnn9fVUNrYxuSCdLy+cwPi8NBwOqGvpiEqx2pO6lnaufvgTnliyw/+1dWV1ERVfZbUtvLp6DwCXHz7OX4DWNilAQUREhjYVQwPF6YLCmeb2Hq0bksGTk5qI02FuV0Xwgrul3cOzn+0C4NLDQusKAYFo7bqWoF6IVza20ebx4nAEt+GqzS6GdlZF1hmyLIsNdqx2GGNy04sycDkdVDa2saeuldUltf41Nj87cxYJLifJCS5/UTkQo3I7q5o470+LWbSxgpQEF3+69EBcTgd1LR1BF6U9eWLJDjxei0PG5zK9KJPs1EDBLSIiMpSpGBpIhdp8VQaf0+kg15cot7c+/HVDL68qpaapnVHZKRwztSDkx9vFUFuHl+ogXjTbewyNSE8KaW3ShHzTxVnvG3EL1976Vmqa2nE6YNKI0DtDyQkuJvset3J3LT/592q8Fpw2t5gjJuf7j5voOybaIQrLdlRzzp8+YGN5A4WZSTzzlcM5dU4xE/NNFPq6svB+Pu0er7/LdNnh4wACnSGNyYmIxKfWBvj7KfDvm0J/7LYPYOlD4I1OAE+8UzE0kJQoJzGSn27euY9kFOuxjwLBCS671RSCRLfTfx12odOXkhrfiFyI43izfXv8rNod2d49djE1Pi+N5ARXWOew9xv67WvrWbq9mtREF7efNqPLMXZxsiWKxdB/Py/lor98REVDGzOLM3nhxoXM9gU6TPOtf1ofZjH02uo9lNe3kp+exMmzioBAMaQABRGRKLAss6QimmtJP3sUdiyGZf+AhvLgH+f1wFOXwX9ugVe+H91rilMqhgZS0VzzUYlyMshG2PHaYXaG1pTUsXR7NS6ngwsPHhP2dYQSomAXTCNDGJEDmON70b+utJ62jvDfxdqwJ/TNVvdlrxuyuzA3Hz+lWxjEJN/+RdEak3tjzR5ufPwzWju8nDijgGe+cniX55weYTH0j4+2AXDxIWNIdJv/MrJT1RkSEYlYRyssewweOAL+cIApQtrDH2n287TDh/cHPt/6XvCPLV0OzVXm9pI/wzt3Rn49cU7F0ECy1wzVl0BjRWyvRfYreRHGa//hzY0AnDK7iILM0IqTzooyzYvyYNarhJokZxubm0pmsps2j9efBheODWX2eqHQR+RsdqIcwMQRaVxz5IRux0yyO0MV0SmG/reqFIAz543kz5cv6LY/0rQic01rS+u6PbY/G/bU89GWKlxOB5d02nA3O8X8+arVmiERkdA1V8Oi38K9c+DfX4PyNebr6/4Dj19gRtwiseo5qNsV+DyUYmjLO+ZjupkE4N274MM/RXY9cU7F0EBKyoDciea2RuVkEOWnhx+vvXJXLa+sLsPpgFtOnBLRdRRlmesIpjMU6h5DNofD4R8Ji2RUzh+eEEastm3myEzcvpHCn545y99J6cxeM7SjqimiTpZte6VJ0fvirMIexxntztDmvQ0hpwvacdonzijoUqQGxuSUJiciErTqbfDy9+CeWfDmz6BhD2SMhC/8DC56AhLTYeu78I+zTcEUDsuCxX8wt8ceYT6GVAy9az4e9S047nZz+9XbTAdrmFIxNND8+w1pVE4GT156+GNyv319PQBnHzCKyQXhFwYQ6PIEs/FquJ0hCIzKrQyzGLIsi41RGJPLTE7gvkvmc88F8zhqyogejynMTCIt0YXHa7GjKvI48G2+DtP4vLQe7x+dk0J6kpt2j8XWELpRDa0dPPfZbgAuP2x8l/s0JiciEgLLgvfuhj/Mh48fNNuuFM6Bc/4C31gBC78B00+FK/4Nydmw6xN4+PTQ1vrYNr9pXnMmpMG5fwGHC6q3Qs2O/h/b3gI7Pza3Jx4DR38bDvcFMLx4E6x9KfTrGQJUDA20QoUoyOCzgwsqQuwMLd1WxTvr9+JyOvhGhF0hgCLfiN2efsbkvF6LTeWmGBmbmxry80TaGSqpbaGhtYMEl6PXoiJYJ88u5twDR/d6v8PhYMII8xyRJsrVtbT7u3/j8nr+uTkcDv/oXyiJcs8v201DawcTR6SxcHJel/syfZ2hlnYvLe3aVFpEpFeWBa//CN76OVhemHgcXP48fGURzLsQ3ImBY0cvgC+/DOmFpqD5+8nBFTGdfeDrCh10JWSPgVEHmc+D6Q7t/Bg6WsyIXP5UcDjgi7+A+ZeZa3/2atj8dmjXMwSoGBpoSpSTGMgPszP029c2AHDBgtGMi7AogECAQn+doS0VjdQ2t5PkdvrTz0Jhd4bWltWHtdGsvV5oYn56j6Nt0TYxPzohCtsrTGcpPz2RjOSEXo+z1w2tLwtu3ZBlWfzjw20AXHboOByOruN3GUlu/15WdeoOiYj0zOsxqWyL/2g+P+lOuOIFmHS8KTR6UjjTFERZY6Fqs4nHrtgY3POVLDNjdg4XHPY187WJx5iPwRRDW98NPMa+PocDzvgDzDgTPG3w5KWwa2lw1zNEhPy//nvvvccZZ5zByJEjcTgcvPDCC30e//7777Nw4ULy8vJISUlh+vTp/O53v+t23O7du7nsssv8x82ZM4elS4fBD9suhio2RCchRCQIgTVDwRdDizdV8OGWShJdTm46PvKuEASfJvfZDjMbPW90dljFyLi8VDKS3bR1hBeiYD9mSgThCaGw9zGKNF57W2XfI3K2UBPlVu2uY8OeBlISXJx3UPcul9PpULy2iEhfPO3w/A3w6cOAA878Ixz+teAemzcJrn7FdGfqdpkOUTBvqttdodnnma4QwISjzcet7/Ufk22HJ0w4puvXnS4476+mq9XeCP88D0pXBPe9DAEhv+pobGxk3rx53H///f0fDKSlpXHTTTfx3nvvsXbtWm6//XZuv/12/vKXv/iPqa6uZuHChSQkJPDyyy+zZs0afvvb35KTkxPq5cWfzJGQkgPeDti7LtZXI/uJPHufoYY2vN7+9wiwLIu7XzNrhS45dCyjQtzrpzf2mFxDawf1Lb2/aP5suymG5o/LDut5HA6HP8lt9e7QU9PsPYamRbBeKBQTR0QnUW67rxjqr4tnd9vWlgZXDC3ebNIvF07O8xc9+/IXQ0qUExHpqr0Fnr4CVj4DTjec/zc48IrQzpE1ynSIiuZCU4VZQ1SyvPfjq7fBmhfM7YVfD3x99CHgSoL6Uqjc1Pvjm2tMZwkC3aTO3Elw4T/N+Vpq4JEzhk2HKORi6JRTTuEXv/gF55xzTlDHz58/n4svvphZs2Yxfvx4LrvsMk466SQWLVrkP+auu+5izJgxPPTQQxxyyCFMmDCBL37xi0yaNCnUy4s/DodG5WTQ2cVQh9eiro8ixPb2+nI+21FDcoKTrx0bvb93aUluMpJN1HNf64bsztCBY8N/AySSEIVAZ2iQi6EIO0NbfWNy43tZL2SzO0O7a5r7LEptH281e0wcNjGv12OyUn3x2uoMiYgEtDaYeOz1/wN3Mlz0uOnUhCMtH658CUYfbAqQR88MFCz7+vB+s65n0vGB150ACckw9lBz2+789GT7B+bxeZMhq5d1r0npcNm/YOzh0FILj54F2z4I5zuLK4O+ZmjZsmUsXryYY44JVJ0vvvgiCxYs4Etf+hIFBQXMnz+f//u//+vzPK2trdTV1XX5FbfszVeVKCeDJMntItNXhPS315DXa/nXCl15+PiI9hXqSXE/64bqWtrZ6AtPiKQYmh1mMeTpFN4QznqlcEzw7TVU3dROVRjx5za7MzQ+v+/OUHZqor9L198Yocdr8YmvGDp0Qh/FkL8zpHhtERHAdFf+cY5Ze5OYDpc+C1NPiuycKdlw2XO+jkwtPHIW7P606zGNlfDZP8zthd/ofo7Oo3K9sSO19x2R21dypimIJhwNbQ1mZG6IhyoMWjE0evRokpKSWLBgATfeeCPXXnut/74tW7bwwAMPMGXKFF599VW++tWv8vWvf51HHnmk1/PdeeedZGVl+X+NGTNmML6N8BTONh/VGZJBZK8b2lvf94vVV1eXsbqkjvQkN185Jvrd2MLMvtcNLd9Rg2XBmNwURmQkhf08/hCF0jo6QghR2FnVREu7lyS3M6wku3CkJroZ6SsSI+kObau0O0P9h13YhV5/iXJrSuqob+0gI8nNzE6byO4rOyX+47UbWzu457X1rAsyOEJix7Is/15jIkOS1wtPXQa7lph47Cv+DROOis65kzPh8udgzGHQWguPnt11RO2Tv0JHs3nzvadixv7atkXmOnvSOTyhP4lpcMnTMPkL5nkfvxDWvxLStxRPBq0YWrRoEUuXLuXBBx/k3nvv5YknnvDf5/V6OfDAA/nVr37F/Pnzuf7667nuuut48MEHez3fbbfdRm1trf/Xzp07B+PbCI9/TG5V/4vXRKIkmBAFj9fintdNV+jqIyeQk5bY67HhKu4nRCEaI3JgCoL0JDetHV5/pykYdqdkckF6j5uWDpSJIyJLlKtvafd3/cbl91/EBRui8NGWSgAOnpDb589jKOw19NKKEv7w1ibufnV9rC9F+vH7NzdyxK/f4vU1e2J9KSLh+fA+U2wkpMFV/zEx2dGUlAGXPWs2Um2tMwXRziXQ1gRL/myOWfiNnlPqRh4IiRlmI9eeppTqy3zr2h0wPsgCLiEFLnoMpp8OnlZ46lJY8+9wv7uYGrRiaMKECcyZM4frrruOb37zm9xxxx3++4qLi5k5c2aX42fMmMGOHb1nqyclJZGZmdnlV9zKnwquRFPNh5oXLxIme91QX/HaL60oYWN5A1kpCVxz5IQBuY4i3yaqZb2sGfpsRw0AB42LrBhyOgMhCqGMym0Y5PAE2yR7r6GK8DpD231doby0RDL7iNW2BdsZ+nirKYYOm5jb53FDIUDB3sfJ7qBJ/FpdYrp34aRBisRc2SqzjxDAyb/qumYnmpIy4NJnYNyR0FYP/zgXXvkeNFVC9liYeXbPj3O5YdwR5nZPo3L2iFzxXEjt+9/+LtxJ8KWHYfb5JijsmS/D50+H8h3FhZjsM+T1emltDbxAW7hwIevXd33nbsOGDYwbN26wL21guBNhxDRzW6NyMkgCnaGex+TaPV7ufcN0ha4/emKvqWGRKupjTM7rtVgWpc4QBEblQtl8dcMe84J5sMITbJF2huxiqLfNVvflL4ZK67B66VB7vJY/PKGv9UIQKIbiuTNk/4x2Vzf3+j1LfLD/HLVqE18Zatpb4LnrzR48U0+GA68c2OdLSodLnzYdnLZ6+OxR8/XDbzJFT2/6WjfkH5E7NvTrcSXAuX+BAy4Dy2N+FvY1DREhF0MNDQ0sX76c5cuXA7B161aWL1/u7+LcdtttXHFFID7w/vvv56WXXmLjxo1s3LiRv/3tb9x9991cdtll/mO++c1v8tFHH/GrX/2KTZs28fjjj/OXv/yFG2+8McJvL47YIQoqhmSQ+DtDvQQo/POj7WyrbCIvLZGrjhg/YNfRV4DC5r0N1Ld0kJLg8o9xRWLO6NBDFPydoaLB2WPIFmmi3LYgwxNs9hhgXUtHr126taV11Ld0kJ7k9nfZepPtS5OL532G7GKoud0TUVCFDLxaX4exWcWQDDVv/RzKV0NqvtlLqLfNVKPJXrNjFy8pOTD/sj4f4i+Gtn9g9kCyWVbw4Qm9cbrM977gGvP9J8XxtFYP+ighe7Z06VKOO+44/+e33norAFdeeSUPP/wwpaWlXcbbvF4vt912G1u3bsXtdjNp0iTuuusubrjhBv8xBx98MM8//zy33XYbP/vZz5gwYQL33nsvl156aSTfW3yxW6ZKlJNBYneGKhq6vwjcWtHIXa+Yfa+++YWppCWF/E9B0OyNV3uK1rbXC80dnYXbFXmjevY+IQr9nbPd4/WPUk2NUWdoe2UT7R4vCSF+/9sqgttw1ZbkdjEhP41N5Q2sK6unOKv7XlL2eqEF43P6/dnFe2fIsiy2VwW6bruqm8lLDz+gQwaW/eeopT348BPZj7S3mJGswSg0QrH1PRNpDXDWfZBeMHjPnZgKFz8Ji/8IYw41BVJfCmeboqm52sRzjznEfL1qi9nY1ZVoIrPD5XTCab81RdmoA8M/TwyE/Aro2GOP7XPc4OGHH+7y+c0338zNN9/c73lPP/10Tj/99FAvZ+jwJ8p9HtvrkP1Gfi+dIY/X4ltPL6el3cuRk/O55JCxA3od9phcZWMbLe0ekhNc/vs+9W22emCE64VsE3whCg2tHWza28D0or7fndpe2Ui7xyIt0RW1jWaDVZyZTHKCk5Z2LzurmvzFUbC2+TdcDT4Bb3pRBpvKG1hfVs9x07r/px3M/kI2f4BCnEZrl9e3dnlhvau6mXljsmN3QdKnmmbz50idIelm9Qvwr2sgdxIccDHMvdBsaB9rzTXw/FcBy4zGTTtl8K8hIQWO+W5wxzqdZrRu7YtmLM4uhuy9h0YfYgqsSDgcQ64QghitGdovFfmKoZod5i+QyADzrxnapzP010Vb+GxHDRlJbu46fy7OAU5Qy05NIMlt/qkpr+tamNnhCdFYLwQmRMGOg165q/9RufVlgfVCjkF+x9HpdDAxP/x1Q3YowIQgx+Sg70Q5r9diiX+9UP8LaP0BCnHaGbI7Z7Zd1QpRiFct7R5/4apiSLqo2gov3mwW51eshzfugN/NMsEBK5+F9hjGsf/vO6ajkjMBTvpV7K4jFD2tG7KLoWAitYcpFUODJSUHsnzvwO9ZHdtrkf1CYEwuUIBs2FPv32D1R2fMHJRuiMPh8I/KdV6rUtvU7t/sdP7Y7Kg9XyghCvZ6oamFg7teyOZfNxRiolxjawd7fSmB44IckwOY5uuU9ZQot66sntrmdtISXf5xw77Y+wzVNbfj9cZfOMH2qq7Fz65q7WETr+o6FdQKUBiiLAt2fAzPXAV/PRGWPQbeCH8vPe3wr2tNjPSYw8yalLFHgOWFzW+abtHdU+HFr0Ptrqh8G0Fb9S9Y+TQ4nCY8ICk2/4eEzF5jtONjM3ro9Zo48M737YcGbqGAdFc0G2p3mBCF8QtjfTUyzNkBCk1tHpraOkhwObn16eW0ebycML2ALx00etCupSgzme2VTZTWBl6QLttpRuTG56X6C7dosIuhYEIUAsXQ4K4XsoWbKGePyOWmJYaUAmh3hjaV13dbp2SvFzpofG5Q65cyfc/rtaC+tWPA0gjDtd33M0pJcNHc7mG3NvSMW53XnakzNMR0tMGaF+CjP5l1KLZdn8BHD8AXfwaTjg/v3G//CnYvheQsOO//THT0gVeYNS4rnoQVT5hpm88egZLP4IZFg7OmqK4E/vNNc/uobwfGzYaCvMmQUQz1pbDzY/Ozba42exCNHHrjbdGiztBg8m++qkQ5GXjpSW7/eFplQxt/enszq3bXkZWSwJ3nzhnUsbCeNl6N9oicze5qrPGFKPQl1sWQf6+hEBPlQo3Vto3KTiEt0UW7x2LrPmNkwe4vZEtOcJGcYP581cXhqJw9RniIb+RPY3Lxq/OoZXObiqEhobEC3v0N3DsHnrvOFEKuJFOsHH87JGXBnpXwj3Pgn+eFPhGz5R14/3fm9hl/MIWQLXciHPcD+PoKuPI/4E4xr6t2fhy1b69PL38XWmph5Pzg1+vEC4ej66icHak9fmHfsdzDnIqhweRPlFMxJAPP4XD4Oy7vbNjLH9/aCMDPzppFgS/UYLAU9jAmZ+8vND9K4Qm2iflppCW6aGn3srmPjktLu8f/gnlaFGK9wxHumiF/rHYII3Jg1ilN7WHzVW8I+wt1lp3ii9eOw41Xd/h+b4+cnA+YMTntNRSfajv9+VGaXJxrroH/fRfumQlv/wIayiC9yBRAt64xo2xHfwe+sRwO+xo4E2DTG/DgkfDvG6GutP/naKyA524ALDjoKph1ds/HOZ0w4SiYc575fOnfo/It9snrhc1vm9un/tbssTPUdC6GIo3UHiZUDA0mfzG0Btr0LqUMPDtR7uf/WUOH1+LUOUWcOW/wU3iK99l41eu1WO7vDGVH9bmcTgezRvY/KrdlbyMer0VWSgIFGbGJXJ7g6wxVNrZ1eUHYn1BjtTsLhCjU+b+2obyemqZ2UhJczB3d/3ohWyBEIb4S5SzL8heMh08yxV1Tm4fqEH7Gj3+8g3c37B2Q65OuOneGWjQmFz1b3oX7DoZXfhD5uSzLBBbcdzAs+TN4Wk1n5Ny/wi0rTQGUlh84PjUXTr4TbvwYZp5l1vks+yf88UB4/SfQVNX787zwNVNk5U+Dk+7s/9oWXG0+rn4BGisj/lb7VL0V2hpMF6x43sA+10Cxi6Hdn8L2xeb2fhyeACqGBlf2OMgcDd52s+mVyACz91Vp6/CSn57Iz8+aPeipaQBFvj1t7I1XN5Y3UN/aQWqii2kDMKI2O4gQhTfW7gFMeEIsfiZgRhnt6PHNIYQo2B2t8fmhx6DaceOdE+U+2hzYXyiU/Y6y7HjtOBuTq25qp76lAzCbzdrFbrCjcpvKG/jB8yu59anlA3WJ0kmtiqHosiz4+M9mRK1iA3x0P1RuDv98lZvNuf51DTSWQ94UuPwFuO5tmPslcCf2/ti8SXDBo3D1aya6ub0JPrgX7p0Lb99pxs06+/hB2PiqKTbO/3twUc8jDzSFiacVlj8W/vcZDHuvyIIZQ3esLHss5IwHywMdzZA2AgpmxvqqYkrF0GByOGDyCeb2pjdjey2yX7A7QwC/PGdOzDad3HfjVXuz1Xmjs6Oy2eq+5oz2xWv3Ugyt2l3rHxu86OCB3WepP/5EuRBG5ezOUChJcrZpPYzJhbK/UGd2oly8jcnZ4QnFWckkJ7gYnWOK8d1BJsrZhWJlYxtNbR0Dc5Hi13mvKgUoRKijFV68yaxrsTxm7Q6Y4iicc71zF/zpcNjytilQjvshfPUDmHRcaGEFYw+Fa14zm4QWzoG2enj316YoWnQPtDVC6Qp4/cfm+JN+GdiSpD8OByy4xtz+9CEzytYfy4KP/wLLnwj+ewAo8xVDwV5bvOo8FjfhmPjbzHaQqRgabHYxtFnFkAw8Oxjg3PmjOGlWUcyuww5QKK9vxeO1/JutHhTl9UI2O1FuTUkdnn1in5vbPHzjyWW0eyxOmV3EuQeOGpBrCFagGAquM9TU1kG5L1Z7QgRjcruqm6lvaceyOq8XCi48wWaPycVbZ8gOmBiba95VHp1jPgYbr9050GLfvbEk+uIyTa65pnvXIt7Vl8HDp5lxNIcTvvhLuOARc9/yx0L7frYvhgeOgHd+ZTouk46Hr31oAgPcYb6p5nCYjUlveA++9DDkT4WWGnjzp/D7efDkpeBpg2mnwcHXhnbuOedDUqZJmrNDAfqy9iV4+Tvw76+ZNLVg2Z2hwjmhXV+8sUflYL8fkQMVQ4NvwjHgcJnWdc2OWF+NDHOXHz6OJ68/jP93/tyYXkd+ehIupwOP16KiodXfGTpwXPaAPN+E/HRSE02k8r5JbXe+vJbNexspyEjiV+cMbqpeT+wQhWAT5ewX+tmpCf4xtVBkpyZSmGlezGzYU8/G8gaqGttITnAyd3R2iOeK72LIXlNld4aCHZPrUgzVD+NiqKXWRCPHWNc1Q97YB13sWQN/OAD+dERc/HyCsutT+MuxJtI6ORsu+xcccZPZO2bEDLPOZdk/gztX7S6zqWnlJkgvNONqlz1nRt6iwemEWefA1z6Cc/5sRrYa90LtTsgYCWfdF3qnIjEN5l1kbi/9W9/HtjbAK983ty0vlCwP/nnsNOAh3xk6GvD9jPfz8ATQPkODLyUbRh8MOz8yo3ILvhzrK5JhLMntCnn0aSC4nA4KMpIorW1hbWmdfyRs/piB6Qy5nA5mFmeydHs1K3fV+jtkb68r59EPtwPw2wvmkZPWx6z7IAl1TC6S8ATbtKJM9tTtZV1Zvb9zdtC4HBLdob0/lp1qp8nF1wtGe0xubF54nSF7M2AIjHYOOxUbzYvn4gPgqv/EdExm32K6tcNLcoIrRhezy0RBN1ebX7s+if2+gNXbzfiYw2k2cN/3V+0ueO1208EZMR0uejxQuDgccNhX4KVvmPU4h34FnP38bN/8mVlLMuZQuPQZsxfNQHC6TAEz+zxY/jisfxmO+Y4JXwjHQV+GJX+Bdf8zqXWZxT0f9+5dULc78PnuT83YX3+aq03BBlA4xIuh9AI450HTicsZF+uriTl1hmJBo3KyH7LXDb2yqgwwEdgDWYzM3mfz1cqGVr7z7OcAXL1wAkdNGTFgzx2KSb6NV7dXNnUb6euJPzwhxD2GOgskytXz8RbfeqEQIrVtmXE6Jrdv9Pgof2eo/2LI67W6FKbDthhadI/pFmx/H9b9d3Ce8/174Y8LoGprly/vu+Ys5L2G2qO0oW5zDfzzfKgvCXxtyzvROXck3vyp2dh09XOm67Hobnjth2bE68mLzbiXp9WMl137RvcOztwLISXXTKOsf7nv59r9GXz+lLl9yl0DVwh15kqAg66ES56EUQeFf57CmTD2cLNWatk/ej5mzxqzQSzARF8B1Hmz2L7YeyVljTVvbA918y4y+0KJiqGYmOQrhra8C574ehEhMlDs1LRXV5tiaH6UN1vd15xOiXKWZfG9f62koqGVqYXpfPfkaQP63KEYmZ1CkttJm8cb1BiX3fUIJzzBZhdD60rr/ZutHhpGBzFeAxR2VHXdlLbzmFx/I1ildS1d1q0MyzG5mp2w8unA52//KrhF55Foa4L37obKjebd+0723bS3pSOEYmjbB/CrkfDfb0V2fR2tZs3K3rWQUQzH+Maotrwd2XkjVbPTREaDCS845vtwyA0w5wKY/AUYtcCMwR3/I7jwn5DUQzpnQorZrwfgowd6fy7LMh0mgLkXmejsocYfpPAwePYJP7Es8+fE2wHTTw9smLr7s+DOPVzCE6QbjcnFwsgDzLs0zVWwaymMOzzWVyQy4OzOkL3Xy0CtF7LN8e2Xs7qkjsc+3sEba/eQ6HJy74XzYzeC0wOX08GE/DTWldWzZW9jv0XOVt+Y3IT8SMbkzAumT3dU4/FaJLmdzBsT+jvA8Rig0NDaQUWDGduzi6FR2aYYamzzUNvc7h/v68nm8q5rt8qHY2do8R/NC8LRB8PeDVC+GtY8b8aVBsr6/5kEMYCVz8AXfubfsLKmOYLO0KcPmXUfn/zVfD/2upFQeL3w/A2mS5aY4RsNyzZpZ7s/NR2jWHUCPn7QdDomHBN48R6Og6+FD35vvsfSz6G4h3Wk6/5rtv1wJ8MJPwr/uWJp5pnwSp4Zg9v4Gkw/NXDfiidgx2JISIWTf23G8RxO0wnsa6zOZq8XGuojctKNOkOx4HQF5lM1Kif7CTtRznbgAHeGJo1IJyXBhCjc8aIZb/jOSdOYOTJzQJ83HPa6oWBCFOxwgHERjMlNLkj3B1qA+b1IcodeIMZjgILdOctLSyQj2VxfcoKLEf69hvoeqbLXC7mcZg3NnuGWJtdYAZ89am4f9wM4/EZz++07u7+THk326BWYxfK+7SUsy/L/+fH9yGlpD7JL1dEKG14NfP6fW01xF6rXbofVz4MzAS76p9kgPXsM5E02hda290M/ZzS01MKnvjS4I26O7FxZo2DW2eb2xw92v7+jLRBrffiNkDU6sueLFXcSHHCpud05SKGpCl7zFXjHfM/8/iammTVWACVBdIf22OEJQzxJTrpRMRQr9qjcpjdiex0ig6QwM1AMpSe5/aEGA8XldPgLnw6vxRGT8rjmyAkD+pzhCiTK9R2i0NzmoczXqYgkQCHJ7erSWQo3ZCM7xQ5QiKdiqOdiMdhEObsgnefrLO6pH2adoY8fNIvjiw8wayYO+6pZhF+50XRsBkJDeWBvvSlfNB9XmP1dGlo7/EV5vm8ftKDjtbe8A611ZqxtwjHQ3gjPXBXaGqLF95lNSQHOfsCkr9nsNSWxGpX77B+mm5Y/LfCaIRKHftV8XPkMNOztet/Sv0PVZrMB55HfjPy5YskOptr0ZmB92ls/h6YKU/wc9rXAsaMONB/7G5XzdED5OnNbY3LDjoqhWJl0vPlYshwaK2N6KSKDoTgrxX/7gDHZ/nfeB5K9bigz2c1vL5iHcxCeMxzB7jW0vcoUS1kpCRGHT9ijcgCHTgwvvckek2tu99AayjqPAbStlzVV9qhcf50huxg6YlI+AHuHU2eotT6wXueoW03SWHImLPyG+dq7vx6YdayrnjOjXiMPNGtbwCzkb672d4WS3E5/p7El2GJozYvm44wz4Nz/g7QCM/L38veCe/zKZ00QAcAXfg5zv9T1fv8ERwyKIU9HoINz+I0mjjpSYw42a4w8bWa80NZcbX7vwXQLe1p3NJTkTvS9xrLgs0dM7PhS3/d72m/B3enfzpF2MfRp3+es3GhCKhLTIXv8QFy1xJCKoVjJLPbNnVqxX6ApMgg6j8kdODZ7UJ7zkkPHcuiEXO675MAuxVi8mehLlNtS0XdnaFtF5Elytum+zlyi28kBY7LDOkdGstufyBwvo3I7eu0MBRevbXfnjphkumX1rR00tg7g+NhgWvqQGb3Km2wWkNsOud50BKq3mYjjaPv8SfNx3kVmxKhglnlhufp5f1cxKyWBFN9avqCKIU8HrPel4M04EzIK4bz/AxzmBfDKZ3t/bEcrvPULs04ITNx0T2No4480+wJWbR78fQHXvGBinNNGmDS4aDnM1x365K+BPZTeu9sURCOmw/xhki624Grz8bN/wH9uASyYd7H5Pe3M7gyVLDMBC73xrxeaFZ3CVOKKfkdjye4ObdK6IRn+CjIDu5bPHzew64VsUwszeOqGwzl6anzEaPfG7gztrW+lvqX3oqK3rkc47PS4o6fkhx0o4XQ6yPSty6mNk1G5wM8o9DG52uZ29vrS4+aOySY10fxchkWiXEcrfOgbB1t4S9e9ZhLT4Mhbze13/585Nlr2bjAvNJ1uE9DgcMABF5v7VjzpT5LLTk3w/zkMakxu+/vmBXxqnolTBjPidvR3zO2XvgGVm7s/bucSePAoeO83JkRi3iVw0q963mcpOSsQ9TyYEduWBR/eZ24ffB0kJPd9fChmnmXGChv2mHVSVVsD3cIv/gJcwyRXa+op5vtsqoCyz83v5Rd+1v24glngSoKWGqja0vv5FJ4wrKkYiqXO+w3FesdtkQGW5HZx8PgcRmQksWCQiqGhIjM5wb/Af1N576NydjjA+AiS5GyHTMjl3zcu5O4vzYvoPPEWohBYM9T1ZzQ6iL2G7BG5osxk0pPc/nVuw2KvoRVPQEMZZIzsudOw4Grz4rFuVyBgIRrsrtDkEyHNjB4y50smxWvnx7SVbwRMZ8hfDAWTJmePyE0/resL+GO+B+MWmj2UnrkS2n2/d22N8PL34W9fhIr1ZqTugkfhnAf63oQ0FqNy2xebAtKdDAdfE91zuxJMshyY/XbeuMOMzU08zvweDRcuNxx4ZeDzE35sNhrdlzsxEIjQ17qhPXastsIThiMVQ7E09nAT8diwJ/AXTWQYe+K6w3j/e8f5U74kYK5vfdMzn+7q9ZhojskBzBuT3WfMdDDiaa+hlnYPpbU9B0zYY3K7q5t73WvIjtWeVGAeW+ArUId8Z8jrMbHKAEfc1HXNhC0hGY7+trn93t3R2cjU64XPffsZzb0g8PWMIv9kRP6W5wHISkkMjMl19JMm5/XCuv+Y2zPO6nqfyw3n/dV0jMpWmjVBm9+GPx0GHz+AGZe6BG782HRJ+mMHKmx9d+D3YrLZXaF5FwUKyGg66Mum0CpdbsbxcMAXf95zd2woW/BlM2Y44WjzPffGPyrXRzFkd4ZUDA1LKoZiyZ0E448ytzUqJ/sBt8sZVoTz/uCGY8yu8U9/spOdVT2Pcm2LYmcoWjLjaK8h++eWkeQmJ7VrwW0HKNS3dlDX3PMaIHu90CTfGq4CX2doyO81tOYFMwKUktP13fJ9zb8CssaaDtInf+v9uGDt+NCse0nKhGmndr1vnhmVG7vzRRx4fZ0h85Kkpb/O0M6PzZuISVnmhe6+MkfCOb7Rr0/+Cv8426z5yRoDl/3LdINSgwwNGX2wWTTfVBmIVg5XR5sZG+xrEqRikwmXADjsxsierzdpeV2L0/mXDs8X+RlF8K31cPkLfXf/7FHI3jpD9XtMHDwOKJgR7auUOKBiKNbsUTlFbIvs1w6ZkMtRU/Lp8Frc99ambvf31fWIJbuztO/GmbHgH5HLT8Wxz7vcKYku8tPNte7sZd2QPaI4ucAUQ4W+ztCQHpOzLHj/d+b2oV+BpPTej3UnwjG+NTfv/w5a+9/3qk/2iNzMMyFhnwCT6adBUiaZraUc4lhPdmoCKYlBBiis9Y3ITTul5y4XwJQTu0ZEH3wdfO3D0EfBXAmBRfeRjsr991a4/2B4/AITVtGTj/4EWDD1ZBgxNbLn68uhXzWjiglpcNztA/c8seZ09V0IQSBRrnRFz3tt2UVw3iSzvk6GHRVDsWb/w7zjo8j/4xGRIe2WE82Ln2c/28W2fZLldthdj+TuXY9YssfkapvaYnwl/QdMjOonUc6ONrc7Q4E1Q0N4TG7Tm2bEJyHNpMb1Z97FJpq4qQKW/Dn8521vgdX/NrfnXtT9/oQU/yag57ne67pmqK9iyLJg7Uvm9owz+r6G426Hs+6Ha9+E0+4OPzLaHpWLJETB64V1vvS7ja/B/YfBot8GEt3AbAxqp/kdflP4zxWMwplw1X/hmtdMuu3+LG+y6V52NMPetd3vL9N6oeFOxVCs5U6E7HHgbY/dLtciEhcOGpfDsdNG4PFa/OGtjV3u2+orjibkp3XresRSVhyNyfk7Q7k9r6myQxR213Qvhto6vGz3FZyBMTl7zdAQ7gzZXaGDrgpuNMyVAMd839z+4A8mijscG16G1lozmjZuYc/H+EblTnV9TF5SR3DFUMkyM3qXkBaYrOiNyw3zL4PRC8L5DgLszVd3fBgIZAhV+WporjLrhMcfZV54v/kzePBI2PaBOeaTv5mvF83tHgE9EMYdoQ1EwURljzzA3O5pVE5JcsOeiqFYczg0Kicifrd+wXSHXli2259uBoEkuWjEakeTnSYXF2NyVXbARM8/o77itXdUNeLxWr4UOVMEFWTYa4aGWGeocrOJ0X74dBNB7UwwG3cGa875kD/NxA1/HGZ3aMVTvnN9qfd9WcYeTrmriHRHC9Or3+20z1AfQQX2iNyUL3QfvRsoI6aZpL2OFlMQhWPLu+bjuCPgypfMmqbUfJNs9/Cp8MLXAhHXR9w8/MIM4t3IPkIUlCQ37KkYigf2qNxmhSiI7O/mjs7mxBmFeC34w5uB7tC2yugmyUVLPAUo2AXj2F5+RqOze4/XttcLTRoR6LzZRVHcrxnyesyo9es/hvsOgT8eCK/+ALYtMvcf9S3IGhX8+ZwuOPZ75vbi+6C5JrTraayETa+b231tGOpw8HqC6bpM2P1S/5uuWlYgUnvmmaFdUyQcjshH5bb6iqEJx5jzzbsQbl4aSDlb/hg0lkPmKJh1TqRXLKGyE+V2f9r16+0tUOH7d1idoWFLxVA8GH+U2ZCuakvfm36JyH7hlhOnAPDiihI27qkH8K8hiqfwBIifaO12j9df5PTeGep9zdC+SXIQSJNrbPPQ0NpzAl0oPF6L6sYor60qWQ6/mwV/P8nEZ1esN/+fTDgGTv41fH05HHdb6OedeQ6MmGFG3T76U2iPXf2c2dC0eB4UTO/z0Be8Jg0uZ89icjx7gT72GSpfA1WbzSaZU74Y2jVFyh6V2xJGiIKn3ewdBDDxmMDXU3LgjHvhmtcDL7SPutWMKsrgshPl9qzpGiu/dy1YHkjJNSmFMiypGIoHyZkw5lBzWxHbIvu92aOyOHlWEZYF975h3pW018OMz4+vzpCdJhfrzlBJTTMer0VygtO/P9C++hqTC+wxFCiG0pPcpPkSzqIRr33r08s5+Jdv+Nd/Rcyy4H/fhvpSSM4yI2nn/Q2+sxmufBEO+yrkTgjv3E5noIj68E9mcX+wVvhS5HoKTtjHutY8lnin4bC8TN3zCgAtHb0UQ3ZXaNLx4YchhMvuDJV+bjpfodj9mdkENiUHCnsYtRpzCFz/LnxjRWBDVBlcmaPMRryWJ7BGCDrtLzRbo4vDmIqheGGvG9r8VmyvQ0Tiwje/MBWHA/67spTlO2soqe276xEr0QpQeHrpTq74+xKqwuyc2GOEY3NTcTp7ftEyylcM1bd0dLvezfskydmimSi3dFs1HV6LNSV1EZ8LgA2vwq5PwJ0CNy4xm43OOR9SsqNz/ulnmI5FW31gI9D+VGyC3UvB4TLX0ocOj5f61g6e85j99ibs/jdg9d4ZWhuDETlbRiEUzASswMhbsLa+Zz6OP6r39VMuN+SMj+QKJRIOR8+jcnaSXE9FrAwbKobixSRfMbTlHVj1LzMDLiL7rWlFGZw2x0Tefu/Zz7Ess5loblov+6rEiB2gUNvcjtXXZpIAL90Cv5sNDXu7fPnV1WV871+f896Gvby6uiys69gRRMBEaqKbPN/Pb3enUTnLsvxjcpMLuj4+WolyHq/lX3tUHY0Ycq8X3vqFuX3o9WaDyWhzOuFYX3fo4z8H1xH53BecMOl4SC/o89C6FjN6+F/PYViuJDLqN3OKc0nPa4YqNpkxOafb7C8UC+GOytnFU+cROYk/PW2+6g9P0Hqh4UzFULwommuSStqb4Nmr4U+Hw+fPqCgS2Y/dcuIUHA5Y71s31NNmorFmd4Y8XqvvdTVejxmfqt1pYpd9Vu2u5ZYnl2PXUfY4YKiCDZgY1cOo3J66VhpaO3A5HYzN7VoM2Z2hSBPlKhta6fCabzIq64bWvGA2g0zKhIW3RH6+3kw/zfz/1NYAi//Q97GlKwKJaH0FJ/jU2EVhUiYOX2jAA4m/55fV3zFvDHYuru2u0ISjzbhZLEzyFUOb3+l6bX1pb4adH5vbE1QMxbV9E+UsS3sM7SdUDMULpxOu/A8c+wMz+12xHp67Fu4/1ESU9rQrsogMa5MLMjhrXmDRbryNyAEkJ7hIcpv/SvoMUajaYvZQAf9i8j11LVz7yFKa2z2k+tbm7KwKrxgKJMn1/TMKrBsKdIbsEblxuakkurv+t2ivP4o0Ua60NvD4qkg7Q54OePtX5vbhNwa3f1C4HA447ofm9pK/dOvq+ZUsh0fONHHcow8OapTNHlXMTEmAU3/DnplfptVKYLZnDTx6Fjx0qomktqxAMTQjBiNytnFHmJjy2h3Bhx3t+Ag8bZAx0mzuKfFr5HzzsXKTSVCs2WECRJwJJmpehi0VQ/EkJdvEmd6y0uycnZwNlRvh+evh/kNgzb9jfYUiMsi+fsIU7CUw8VgMQddRuV51XpS87QOa2zxc9+hSyupamFyQzs/PMmMo26vCCxfYHmRnqKdEOf96oYL0bsf71wzVR9YZ6lwMRdwZ+vwp839DSi4c9rXIzhWMqSeZd83bm+CDe7vfX7LcFC92IXTZc+DuOcSiM3tvquzUBEjOpOLIn3JU67086TzVJMbtWAyPnmmS8kqWAQ6Yfno0v7PQJKYFwo6CHZXzR2ofrQX48S4tL7Buq2RZYERuxDRwx9d4skSXiqF4lJwFx3zHFEUn/Nj8h1e1GZ6+Evasjt7zbP8QHjgysLhTROLOxBHpXH7YOACOmJQX46vpWVAhCvYLC4DaHfzy8Vf4fFctOakJ/O3KBcwelQXAjjDG5Lxey7/h6rjcYDtDgecJ7DHUvRgq8I/JRdYZ6txZqu6pg9ZaD9s+MGuB+tLRBu/+2tw+8haTRjrQHA447gfm9id/g/o9gftKlpmCpaUGRh9iCqEgr6nO9+fF/vOTkuCinBx+6b0KvrEcDrkeXImBMbNxR0D6iOh8T+GadKz5uDnYYsj3/6vWCw0NnUfl/OEJWi803KkYimfJmWazvFs+970bZZn/LKPBsuB/3zEz50v/Hp1zisiAuOPMWSz54QkcMTk/1pfSo+wU865pn2NyZau6fNq4YREJLgd/vnwB4/LSGJNripS6lo7AWpIgldW10Nbhxe10MDI7uc9j+xqTmzSieyFVmGEHKESxM9TT9/fy9+HhU+Hpy6Gtj4Lws0fM+E56IRx8XUTXFJLJJ5quT0dzoDu0+zNfR6jW/B912b9CKs7sPy92ZzG586armSPh1N+YfZIOuR6yx8KRt0bzOwqPHaKwdVH/4+vNNb6OFqYzJPHPnyj3GZR9bm5rvdCwp2JoKEjKCPwDXPJZ38cGa8OrphACM+IgInHL4XBQkNH3i/xYygpmTM7XGarMOQCAQ5zruPPcuRwywax3SU10M8JXeOwIcd2QPSI3JjcVt6vv/9bsMbndNZ2KoXLfhqs9jMkV+KO1W/pPy+tDWW3g+XqMD9/ue6Nr3X/gkdOhobz7MW1N8N7d5vbR34HEQdxzat/u0Lr/wT/O9hVCh4VcCEHgz0vnzhBAu8eiw+PrkGWNMkXRLSthyolR+VYiMnK+CXBorYW1/Yyub18MlhdyJ0HW6MG5PolM50Q5JcntN1QMDRU95d+Hy7Jg0d2Bz6u3mnewRETCYL+YrWnupaPTVAV1uwH45d4jATgpfRPnH9T1BeLYXPPiPtREOX94Qm7/xcGobNMZqm1up66lnYbWDsp8I2w9jsn5CrSmNk/faXn96NwZ6tZBa6kz/w6DWSu6+1P4vxOgfF3X4z75KzSUQdZYOPDKsK8lbBOPM4WPpxWevNgUQmMPh8ueDWsTVPvnkOXrLNqdIYCWjn7GBWPF6Qqs03r7zr67Q4rUHnqK54HDCfUlUL3NfE17DA17KoaGCnuOtWKD+Q8oElvfMxv1uZIg1Td2Y7eDRURClG2vGeptTM4XnlDqLOSNjnl4cZDbshPqu+4pNM5XzITcGaoKLjwBIC3JTY6vk7W7upnNvvVCIzKS/EXdvsdnJLmByEblyjqtGWpo7aC1o9O2CfY70Jmj4Lq3IHeiSSz72xdNxDSYgun935nbx34vNgu6O3eHwBRClz4TViEE3TtDSZ2S/Hrca2iQeLwWVz20hGse/gSvt4du4KFfMWt5KzfCyqd7P9EWOzxBxdCQkZgGI6YHPs8oNsEKMqypGBoq0keYmWkIzCCHy+4KHXgFjDvcd87lkZ1TRPZb/QYo+F7sr2gfSx1peEbMMl/f3nUN5Bi7GAqzM9TXhquddU6U62u9kG1EZmTx2pZlUVbb9bFdukN20l7RXMibBNe8YTowrbXwz/Pgs3/ARw9AcxXkTYG5F4V1HVEx4Wg4/Cazj9Cl4XWEbLW+TqK9ZsjpdJCcYF6WNLfFrhhaV1bHO+v38ua6clbu7uHNx+RME14B8M6dJtRiXw3lsHetuT3+qAG7VhkA9iQOaL3QfkLF0FDin2WNYFRu5xLTGXK6YeE3oPgA8/XSFRFfnojsn+wXs70GKPjCE9Z6x1KQkUTCRN+LQ99+Q7ZxeeF1hrZVNHV5fH86J8rZxdDkHtYL2QozItt4taapnVbf2JfdZeoSolC6z0LttDy44t8w+3zwdsCLNwXexDruNnC5w7qOqHA44KRfwrl/gaTef2bB2LczBPuEKMTIp9ur/bffWtfD2i0w4RXphSbMYtk/ut9vp8gVzVFnYagZ2akYUpLcfkHF0FDSeWFfuOzFt/MuguwxMPIA83np8kiuTET2Y1mpZmSr986Q6XystcYya2QmjF9ovr5POubYMMbkLMvyHx98Z8gUQ2ZMzhee0MN6IVthhJ0he71QXloihVmmsOoSomCPKRfPDXwtIRnO+6sJSgCzcWfhHJh5TljXEI/8aXKdiqEUfzEUuzVDn2wLohhKTIWjvm1uv/cbaG/uev9WjcgNWV06QyqG9gcqhoaSSIuh0s9h46tmcaAdUWp3hio3mZl0EZEQBQIUeiiGPO2wdz0Aa6xxzBqZBWOPMPftXQuNlf5Dx/o6OyW1zbQFuYC+srGNhtYOHA788dz9sUMUdlU3s2lv73sM2eyNV8NdM1RWZ14oF2Ulk+srHKsbfT+rjjYo941TFc3t+kCHA46/Hc75s/mZnfF7cA6f/7bt4jmzh2KoOZadoW1V/tsrd9f2XgQfdCVkjob6Ulj6UNf7tF5o6CqYBQm+N1bs10gyrA2ff1X3B51TTupKQn/8ot+aj7POMXPpAGn55h9zUIiCiIQlEKDQw9qJig3gaaPRkcoua4TpDKXlwYgZ5v4dgVG5EelJpCS4sKyum6L2xV4vNDIrhSS3q5+jDbNmyCK3bBFtlduBnmO1/deVEZ3OUHFWsn+ksMr+WVWsB2+72WzbXhe6r3kXwdUvw+iDwnr+eGUXz/bPBCApxsXQ7ppmSmpbcDkdTC8y66He7q075E6CY75rbi/6LbSawprqbVCz3Yyj2+tyZehwJ8JFj8F5fwu8VpJhTcXQUJKYFngBEWp3aO8GWOPbE+Gob3W9zz8qp3VDIhK6PgMU7PVCnjGAw3SGAMb5ukOd1g05HI6QR+XsGO5g1wsBjM5N4QbXf/hV4094wHU3qYkuijN738fJ3xkKc83QHl8xVJiZTG6ab4Nae0zOv15orukE7Sda2j3+7l9Wl86Q039/LCz1dYVmFmdy2pxiAN7srRgCOOASk/7XVAFL/my+Zq8XGnVQRAETEkOTjoM558f6KmSQqBgaauxZ1lA3X33/HsCCaadB4ayu9xXP851zeaRXJyLhsqzu6w6GCPud/cY2D+2efcbbfOuFVnvHkpHk9q/XCawber/L4WNDDFHYWmEnyQVfDI2tfJ/vuZ8EYJZzO8fl7MXp7L0QCYzJRd4ZyvEVQ/7O0H66y729XsjldJCeFAiEiHWAgh2ecNC4HI6fUQDA+xsrer8eVwIce5u5/cHvzZ59GpETGVJUDA014STKVW+Dz317IRz9re73+xPllkdwYSISNk8HPHkJ/GYybHwj1lcTsozkBH9To1t3yO4MWeOYMTIzUHSM8xVDZSu77J02NsR47TUlZq3j9KLM4C527wZSX7wBp8OixTJF3NnuD/t8SIF/TK4Vy+ph35l+2HsMFWWldFozZBdDnWK19yOdk+QcnTpiKTEuhpb6whMOHp/LzOJMijKTaW738NGWyt4fNPs8szdNSy18eH+gMzTh6EG4YhGJlIqhocZfDC0Db5BpOx/8HiyP2T18VA8z5/aYXMXGwMyziAye138M6/8HbQ3w7NXm72Ik6krMWOxrt8NjXxrwAsvldPgjo7vFa+8JxGrPGtmpYMkogtxJgAU7PvJ/2e7wbA+yM7Sm1BRDM0cGUQw118CTF0NrHavcs7it/VoADml8x3TmelHgS5NrbvdQ39oR1HV11tOaoeqmdvNvuL8Y2t86Q749hvbZ6DY50bdmKAb7DNW3tLOuzPx5WjA+B4fD4e8O9ZoqB+B0BTajff930FgO7hQYc8hAX7KIRIGKoaGmYIb5R7a1Fqo29398XSks+6e5ffS3ez4mvQAyRgJW4D9mERkcK56Cj+43t3Mnmb/bT1wEzdV9P85mWbDjY/jgD/DU5XDPTLhnBjx9BSz+I2x8DZ66FHZ+MnDfA5Dtj9fuFKJQvwca9+LFyXprTGC9kM2/bigQsW1vvLoziGKoqrGN0toWHA6YUdxPMeT1wL+uMcmZWWN4eNRPecV7ME1WElktu/vstqcmuslINsVeeRghCvaGq0VZgTVD1U1tZpF9ax24EmHEtJDPO5T1lCQHkOy2AxQGP1p72Y4avJZJJbRHI0+YboqhN9eW990VnHGm6e55fW8GjD3MBCyISNxTMTTUuBICe1EEMyr30Z/M/hRjDw+MpfTEXjekUTmRwVOyDF76url99Hfg6ldMumPlJtMh8vTThWjxFU5//yK8/iNY+yLU7Tapk0VzYMHVZlSnowWeuBAqg3gDpT+1u02Rte5/Xb7cY4iCb73QdquIFpK6doYAxh9pPnbab2hcpwCF/kbSVpeY8brxeWld1p306I07YNMb5s2kix4na8Qomknmda+vW77y2T4fHm6IQn1LOw2+blJRZqc1Q41tgfVCBTPMv+1R5vVa/Hv5bkpq4m8tWk9JcgApibELUFjqWy+0YFyu/2tHTMonye1kd00zG/b0MTnhcMDxPwp8rhE5kSFDxdBQFOx+Qx1tsPxxc/uIr/edVKREOZHB1bAXnrzMFCpTToJjf2C6tBc/DgmpsPktMz7Xm70b4P9OgA2vgCsJpp8OJ94BV/0Xvr8TvvI+nP47uOgJ82ZHUyU8dn6XfX2C5mmHtS+Zkbt7Z5vxu6cug/oy/yH2i9ouY3K+9UKrvWNJdDmZvG98td0ZKl3uH9EdlZOCwwFNbR4qGnxdptrdZi1GW2OXh9vrhWb21xVa8RQs/oO5ffafoHiuP8jhJa8v+nj1c6Z71Av/uqEQQxTsOO6MZDdpSW5yOq8ZGuD1Qm+vL+cbTy7nwr986C/I4kVdpzVDncVyzZCdJHfQuJzA9SS6WDg5H+hnVA5gyhdg0vHm7+OMMwbsOkUkulQMDUXBhihsfNXEfaYXwpQv9n2sHaKgRDmRgedph2euhLpdkDcZzv1LYDPN4nnmBTuY8bnP/tH98etfhv87Hio3QuYo01G66DE48pum25LUqehISodLnoGssVC1xXSSgk2tq9hkCrJ7ZpjiZ+NrYHnNhoSWJxDMQm+dIVMMrfGOZWpROgmuff7LyR5rrsvbAbuWmMt1uxiZZQqVHVWNZlzwkTPg1R/Au3d1efjqkiDWC+3+FF682dw+6lsw+1wAxuSYDtTWrMMgORsa9nRLtuvM7gztCbEz1Hm9EOAPUGhs8+Ap8b35NEDF0LqyegB2VjXz85fWDMhzhMsumrutGYrRPkMdHi/Ld9YAJjyhs+Om2+uG9vR9EocDLn4SvrUO8qcMxGWKyABQMTQU2fHaZZ+b7k9v7LVC8y4GVz8jJPaYXMX6bu++ikiUvfoDs04mMQMuehxSsrveP+scOOZ75vZ/vhkIGPB64d3/ZwqatnoYewRc/07g34TeZBTCZc+ajT13LYHnruu9C+L1mC7QQ6fCfQeZAJbGvZBWAAtvgZs+hZN+YY5d8YQ/eMAuhnrqDK21xjGreJ/1QrYe9hsak2uKoZ0VdfDMVYH1kcv+CR2BYsQek+s2fmdr2AtPXgqeVph6Chx3u/+uI6fkc96Bo7n15Dkw80zzxVW9j8rZIQqhjsmV1gaS5MB0iFx2op7dGSoemGJoW0Xg3/Knlu7k9TX9vJgfRLW9dIZiFa29trSepjYPmclupuzTwTzeVwx9ur06kALYG3cSpOb2fYyIxBUVQ0NRzgRIyTFrgXzvvHZTV2rexQWYf1n/58wsNh0ky+t/ASMiA+Czf8CSv5jb5/6l94Xzx3zfjNp4201XpnwdPHMFvP1Lc//B18EV/zajdcEYMc2MzLkSTbHz2o+63t/WCB//Bf54kHm+7R+YtUdTTzYF261r4As/hfzJMOtcMwpUvsa/7sUek/N3htpboGID4EuSG9VLweLfb6jzuqE083Hpr2DLO6YTlTbCjPqtfQmAprYOtvhe7PfaGfrgXqgvhfxpXbtvmBfdv71gHqfNLYbZvs0V17zY6xtMhRn2mqFG+PeN8NBp5me49iUTFNELOzzB3tTV6XSQnZJALnW4GkoBR/e936LETuSbNML8PG977nMqG8LbODba7DVDWb5OmS3QGRrcAIVPfCNyB47L6bbn1KjsFKYXZeC14N0Newf1ukRk4PXTLpC45HCYUblNb5gRkJ7eFf78SVPYjDks+HZ98QFmtK50BYw9NKqXLLLf+OAPpsuRnNX9l+WB/33HHHfsD2D6qb2fx+mEsx+Eqq3mTY8HDjd/p12JcOrdcNCVoV/b+IVw9gMmVe2j+yF7DMw8G5b8GZY+BC015rjkbBO+cPC1kDWq+3lSss21r34elps1Sdkpdpqcrxjauw4sD7WkU0Zu790bO9hl91JTQCUkMzYvlYtdbzK/9Clz37l/hj2r4Z07YenfYc75rCurx7JgREYSBb5CpYvmGvj0YXP7pF9Bch+jdOOPhPQiaCgza7WmndztELszdFDZM1Dv67pv7zRWlz0WRh8Mow8x60ZGTAUCewwVZgWuMSctkaLm7eaT3ImQlNH7tWEKvw83V7Jwcr6/WAiGvVfTL8+Zw0/+vZr1e+q57bmV/Pnyg7rs7RMLvXWGYrVmyN5sdd8ROdsJMwpYV1bPm+vKOXt+D38nRGTIUmdoqBrpK4BKlnW/z7ICI3LBdIVsSpQTiUztbpPqtuFl84bEkj/De/8PXvshvHgTvPQN09GdfrpJj+tPUjpc/ASk5ptCKL3IBCSEUwjZ5pxvghYAXrkN7p1j9kZpqTEvzE+923SBTvxJz4WQbd7F5uPKZ8DT3mlMztdZ8XWtV3vG4nA4et8UNXei+b48baYgAuZ7V/Ez98Pm/uNvNx2yA68Ah8t0rMrX+dcL9VpkffaI2bepYCZMPqHvn4nTZUYToddRucLMZMY49nBRve+6Dr4WDrzSnB8H1OyAVf+CV74HDxxh1mfRqTPUqRjKTU1klmOb+SSI/YX+/O4WrnlkKf/4cHu/x9pa2j3+QmxqYQb3XDiPBJeD19bs4dlPdwV9noFS28s+Q7FIk7Msi6Xbu4cndHb89EIA3l1fTrtn8GO/RWTgqDM0VPUVorDjIxPNm5AGs84O/px2opxCFETCs+Vt8zF/qnkjoqXW96sucDu9AM66v8vIVp+yx8KVL8GaF+CgL5uR1kgtvMW8eF/6dzOGN/YIOOImMxLnDLLzMOkEs46osRw2vUFW6nygU2eo03qhCXlppPUWfe1wmHVDq58zo3KZozhkyS24HR5edSzkpKN8+6NljoRpp8C6/8CnD7Om+VKglyS5jjb46EFz+/Cb+k7StM0+Dz5+wESGtzVBYmqXuwvTk7jT/VdSaMUafySOU34T+D1sqTP/Fu/6BFY8adY4LX0IvvjzTmuGOneGEpjp9BU2QawX2lhughA+313b//fhY+/TlJHkJic1gdy0RG45cSq/eXU9P31pDYdPymN0Tmo/Zxk4/s7QPtHa/n2GBnHT1V3Vzeypa8XtdDBvdHaPxxwwJpvctESqGtv4dHs1h03MG7TrE5GBpWJoqLJH4/auN/8Rdx4BsbtCs87pd/yiCztRbu86kzaVkBKVSxXZb2z2FUMzz4aF34jeeQtnml/R4nDAKb8xI2q5E/sPYOiJyw1zL4AP74Plj5N18CFAYC2IHQ6w1hrbd9obmPG91c/Bptdh9fO4W6tZ4Z3I19uuY3m7l5REX4F20JdNMbTicTalnQjQfSNXMOeqLzEdpznnB/f9jF4A2ePMRqgbXjbFUSfFW59hrGs1zVYiHV+8h4zOxWxyJkw6zvwqnA1PXmz+HT7+dspqTXJf585QTpfO0Lx+L80uqLbs7WOfm31s943Ijc1L9Y/EfeWYSby1rpxPt1fz7WdW8Pi1h3VbHzNY/PsM7Rug4Pu9bukYvGLI7grNHpUV+LO2D5fTwbHTRvDcZ7t5a125iiGRYURjckNVeoGJpMXqOtbWWm/m+CG0ETkw77ymjTDrGvasjtaViuwfvN5AZ2jScbG9lmC43KZQCKcQss27yHzc8Aq5TvNCvbap3Yzq+jZcXesd13PB0pm9bmjXJ7B3LVZ6Ebc6v0srieysbgocN+l40ylrqWVS+etAD2NylgWL7zO3D73epHsFw+EIFEAr/9X1vrpSEt4wez79tuNLlLlG9n6eKV80cefNVbStfIFqX7pecWbgzaWCZA8THaXmkyDG5OxRu60Vjf1uRGuzwxPG5QW6Py6ng3sumEdqoouPtlTx9w+2BnWuaPN6rX73GRrMztDSbfZmqz2PyNlO8I3Kvbk2flL5RCRyKoaGMvtFTOfNV1e/AO2NkDsJxh4W2vkcjsC6oZ7WIolI78o+N2lnielmIf3+oGgOFM4BTxuFO14GzPiTVbsTWmrpwMVGa1Tv63psI6ZDqu+ddlcSjoseJyVvNBDocABmLO2gLwNwgeMN0pPcjM3dZ9RryzumEEtI8x8bNLuLtOl1E8AAprj677egtZZ1zik85Dm5772GXG446CoAvEv+CkBygpPMlMAgxiTvdpwOi1pXrok974PHa1Feb56vqS2wDqg/OypN0t5YXzKfbVxeGrefZrqM/+/V9WzYUx/U+aKpvrUDr6+my+w1Wnvw1uX4i6FewhNsR03Nx+10sHlvI9srtQWFyHChYmgo62ndUOfghHDSguxRudIVEV2ayH7H7gpNOBpcCX0fO5wcYIIUMtaZDVg7vBYtu0zc9ibvSNpI6L8Ycjhg5lngdJsNZ0cf5C9ydlQ1dT12/mV4HW4OdG7ilPzy7mNei/9oPh54eej7vRTOghEzTJiDL8Kb1c/B+v+CM4GHR3wbDy7K6/spSOZfDg4XyaVLmOrYSXFWSpf0ttGtGwHYljCp30uqaGjF4w10g7bsDe5F+LbK7p0h28WHjOG4aSNo6/DyoxcGfysFuyuUnODslo432Glytc3tbPCtyeotPMGWmZzAIRPMn6m31pUP+LWJyOBQMTSU7dsZqtgIOz8ye4PYSU+hskMUlCgnw8HKZ+HuaebjQNv8lvk4cQiMyEXTnC+Bw4Wz5FOmucsAaN9tiqE11jiKMpPJSw9iVO3U38K3N/q7M3ZHY8e+78CnF7A2+xjAdIe6KFsFm980/wYe9tUwvx/fqNyqf0FjJfzvu+bzo75FW+50gL47Q2BCLnyx6Ze43qQos2v0d1GTKYY2OCb0ezn2eiFbsOuG7CJy3L6dM8DhcPDTM2cDsHR79aCOpEFgY147jr0z/5jcIBVDn+2oxrJgfF4qIzL6/3Nqb8CqYqhnLe0eNpUHv7ZNJB6oGBrKig8w/+nX7YL6skBXaPIXwk+cssfkyteaPT9EhqqNr8PzN5i9Y97/3cA+V1uTSXEEs65lf5JeAJNNmMFFiWbfHcsOT/AGEZ5gczq7dHJ67QwBz7u+CMAB1a+ZdZK2D+83H2eeBTnjQ/kuAux1Q1vfhRe+Ak0VJj77qG9R4Ctq9gQzqrbgagDOdS1iXEbXdT7ZdesAWNkxtt/T2AEMts1BdIY8XotdvrVW4/LTejxmTG4KBRlJeLwWq0uCT6mLht72GALTLQLzojrY9VGRWOrbbLW/ETnbCTPMWONHWyppaO0YsOsaqr71zApOvOddVuysifWliARNxdBQlpRuZu0Bdi6BFU+Y26EGJ3SWNQZScsHbAeUKUZAhaucSeOpy8+cYzJ43e9YM3PNtX2xGq7LGQF7/o0/Djm9U7jTrPRx4SawwP+u11rj+R+R6YY93bd+nGLIsi2cqJrDZW0yCpynQ9asrMXseARxxc1jPCfjS9Q4y+zptfM284XTmfeBOpNC38ere+n46QwATjqUyaTSZjmaObX8v8HVPBynV6wH4pHV0v6exwxPsKbstFf0XQyU1zbR7LBJdzm5dKZvD4WDemGwAlg/yC9eaZrPH0L6x2hBIk/Na0DYI+/kEG55gm5CfRm5aIu0eyx9fPtC2VTRy7SOf+DeGjWcbfWvQlg6Ba/1/r6zjvrc2xvoyJA6oGBrq7FG5RXdDwx6zCHlq993Tg+ZwdBqV07ohGYLK18JjX4KOZtMlnWK6CL1tphkV9ojcpOPCW6s31E09BZKzKLAqOMG5jOR6s4fOWu/YsIshuzO0q6oZb6c1M7trmqlt6eBJr+lGsfTvJuTg4z+bPZPGLQyspwzX7E5x3Id9DUab8xVkhNAZcjp5O/00AA6ueCHw9cqNOD0tNFjJrGvLp7WfCOlS33PZP8dgxuTsbtro3BRcfURnH+ArhpYNcjHUZ2fIHVhD1NI2sMVQW4eXFbtqAFgwPrhiCAJx4Pbap4H24ooS3lhbzmMfB7/pbqzYv7ebQ4iBj4WKhlb+9M5m7n5tw6CPiUr8UTE01Nn/6duFy9yLwN19Djsk/kS55ZGdR2Sw1eyAf5wDLTUw+hC44JHA+rmVz5gXzQPBH6m9n43I2RKSYda5AHzP/SQOLMqtbCrJ6j9WuxfFWcm4nQ7aPN4uCWprSuoAWJ53KriSTIrf1nfNJqcQWVfINvs8SM4ynffjfuj/st0Z2tNfgILPC9YxtFoJ5NWtCazt9I0QrrPGYeH0r5/pjd0ZWjgpHzDFYH/hAnYCX0/rhTqzi6HBHmmyv+eeiqEEl8NfwA30XkOrS2ppafeSk5rApBHpQT/OTsCrHaRiqKqxrcvHeOYvhuJ83VDnn2W/gSgy7KkYGur2fQc0khE5mz9Rbnnk5xIZLI0VphCqLzWJYJc8BYlpplOamG4KpV2fRP9560qhfA3ggAnHRP/8Q8UBlwAwxbkbMF2hjGQ3o3PC27zZ7XIyyvfYzuuGVvuKoXGjR5mNpQGevRpaayFvCkw5KdzvICCjEL7xOVz3NiQGCopC/5qh1qDWs2yoT+K/3kPNJ0v/bj763rja4jLhCf29wLUDFGaNyiIj2Y1lwbZ+Yp23V5n7x+X1vF7INnd0Fg4H7KpupqIhiNG/KKnrZcNVMON7g7XXkD12dtC4nC5pf/3JilExVN1P4RxrrR0efyR6MGvbYqm609+7oMZeZVhTMTTUFcwEt28mfOSB0dml3h6T27MGOuL/nSgRWuvhsfOhcpNZt3P5c4HF+ImpMP10c9teUxJNdldo5PzQo5yHk9EHU5k0xv/pWmscM4szQ3qRuS9/iEJl92JoZnGmP6SApkrz8fAbTRBDNKRkdymEAH/aWFuHl7rmvhfPt3u87G1o5bGOE8wXVj5r9i7ydYZ2JE0Gur4o64k9kleclcxEX/eiv3ht++fVbQ+mfWQkJzDZd87B7A711RmCQIhCMIlybR1eXli22x8YEQp7vdBB40L7ezvYxVB1k/kzUtMU3/8fd/55VDS0mg2Y41TnwrJcxdB+T8XQUOdKgFELzO0DL4/OObPHQXK2mb8vH8BF5yLB8nrNWqDSFWZ8s2SZGTva/Sns+hSevNR8LTUPLn8BMkd2ffycL5mPq54DT5QToDbbI3L7WaT2vhwONhSd5v90jXds2CNytp4S5daWmmJo1shMGHOIeUMIIDUf5l0U0fP1JznB5X8h3N+oXHl9K5YFnzunYRXMNGvYVjxpxvqAvWnTgL7f7bcsy98ZKspMZpIvGa6/dUN97TG0r1iEKNgvmrN7CFCAzhuv9l8MvbyqlFueWs4p9y7ipRUlQV+DZVks3W6S5A4OYb0QBIqhwVozZBeP8T4mt2/xsymO1w1Vdyosy4PcyFiGLxVDw8EZvze/DrwyOudzOALrhjQqJ/Hg5e/Anw6DPx8NfzkG/nIs/N9x8H/Hw1+PN2tGEtPh0mchf3L3x0881rxYbqqALe9E77q8Xq0X6qRk3Fn+22siSJKz7ZsoV93Yxu4aEzU9Y2Sm+bfqqG+Zg4/5HiSEN5IXCv+6oX5eQNlrfQozU3DYHaz3fwfN1eB005Bp/pxW9fFuf3VTO20dXt95kpk4wlcM9ZEoZ1mWf2+mYIqhA2JQDNlpcpm9dIZC2WuopMb8nOtbO7j5iWV8/1+f9ztet7OqiRsf/4yKhjYSXU5mjwqtaI9VZ6i+pYOOQUjYC9e+P494DlHoUgypM7TfUzE0HORPhoOuAqer30ODZo/KRfOF4/6iZDlUbIr1VQwvG183H1PzIWMkZI6CzNFmJC5rLBTNhYufDKQr7svlhtlmgX9UR+XKV0PjXkhIM4EN+zl37jhub/8y97SfzyZrFLNGRVYM7dsZWuPrCo3NTSUz2fdCes758IMSOPT6iJ4rWPa6ofJ+Nl4t69TRYe6F5s9Ig9mUlvxpZKSb8bS+xuRKfXsM5acnkuh2BjUmV9nYRmObB4cDRucEXwyt2FnTJbVvINX6RgyzU3sO+7E7Q63t/b/wr2sxL8BH56TgcMCTn+zkjPveZ11ZXbdj61va+fXL6zjht+/yv5VlOB3wrS9O9T9fsDJT3L7vY3A7QwA1g/Sc4RhKxVCNxuSkE3esL0Di1JST4IPfw+rnzRjeETfF+oqGhoa98PeTTJfim6tNypZEprkaanyRsjd/atZyhGPOl2DJX2Ddf8wmqYn9v1Dslx2pPf7IyFMch4GslAT+6fkCAIluZ0gJXT0Zm2s6IfZ+LnaSXLeOU2LfQQHR5I/X7mdMzi5kirKSITnTFG2fPWLuLJ5LTor581LdR2fI7j4VZZnn9HeG9jZgWVaP67HsJLnizOSgXuRPK8ogye2krqWDrZWNEf+eBaPW9z33tmYolM6QPap23oGjOXRCLrc8tZxN5Q2cdd8H/Oj0mVx66Fi8FjyzdCd3v7aeigbz3EdOzuf202cwvSj0gt0/Jtcy8JuutnV4u2zuWt3YRn560oA/7/9v77zj46jv9P/MdmnVJUuyLMnd2OCKbYwxYAgOhCOUkEI4EwwhgXA2odwlwQkpv9wlhlxycAQHQkLiQEggXOh3cOFMsR1s4woYGxdc5KJi9V52d35/zHxnZldbZqUtI+3zfr300mp3NDu7O7K/zzyfz/MZCoPEUIN1QxRauugMER06QyQ8E5YAn/6xcvtv3wM+SELj+Wik4SPA16uWY72V7qMZHdQqPRYonDB0IQQAlQuBgmqgvxM48HoijswwX4glckDwlf4zynLhtA/vv5hqtcyruasfHb0D+OhUG4AwYiiFlKplcmadobGqkNHCHgCgfDaK1PcqujMk3CWl/G9CsReSpCzCmyL8Xo2aJFdtokQOAJx2G2apZWKpClFoi5ImBwBuEaBgIk2uQxUkeVlOnDelBP9z5wW46Iwx6PMFcN+Le/D1J3fgs7/chHuf/xCNnf2YVOLFEysW4KlbzhmSEAJSWyYXGppg5UQ58X4Uqr1gZmZipQvj+8g0ucF8/8U9uPw/N5rq2xsNUAyRyJz3TWXgIAC8eLu+8CORaTRMs977cvqOYzQhZmiJPrahIkl6kMKHCRjAOtADHNus3M708AQV45X+RAiWHLcDxV5FNNQ0d+tJcmkUQ2W55nqGajVXR+1jqpgLTLgAkGzAxAtQqL6u5iiL21BB5XHaMa5A2V+kUjl9xpB5tyyVIQoD/gC6VJETyxkyM2dIlMnleZRCl5IcN363YiG+9w8z4LBJ+L999dhX2448jwPf/+yZeP2uC3HJjLJhpRymcs5QqPiJ5iSmG1F6dna1EkhxrLlb63mzGsb38TTnDA3ixd0nsa+2HQfrrStoE0ncYmjDhg248sorUVFRAUmS8OKLL0bdftOmTViyZAmKi4uRlZWF6dOn48EHH4y4/f333w9JknDXXXfFe2gk0UgScOlPlAGEgQHg2a8oiV0kMk2GXqH9/81o8kSQKDEE6GLo4N+U8rvhcOxdwN+n9C+VTBv+sY0CChIshgCgSu0bOlDfofUgDDelbjhoPUMxribXhzpDAPDlPwEr3wPKZ2lXz6PFJWvOkGEfet9Q+EWKFqtt0hkCEhui0NDeq5UzhsMoICIGKLjMzxkSZXLGfdlsEr5+4ST89fbzsGhiEW46bwLe/tbFuOX8iXA5hn8NOJXOUKj4iRXFnk7E+zGtPBdelx3+gKw5lVbD+L42dfVbOpgi1QQCslaaaSzRHM3E/a9CV1cX5syZg7Vr15ra3uv1YtWqVdiwYQP27duH++67D/fddx8ef/zxQdtu27YNv/71rzF79ux4D4skC5sNuOZRZZhkfyfw9BeB5sPpPirrYhRDvW3AkQ3pO5bRQiLFUOkMoGymIu6H69xpJXIXKxcOSNCC9MwECRaRiPbG3noEZCVMoDQ3fT0TpSbT5Gq1NDmDGPLkASVTAUB3hqIsbrWeIcM+Jol47QiJciJ5z0ySnECIoX217cMui7n96Z248pFNWgR6KMI9yPU4YLeF/7vxOMxHa4u+nVzP4BboOVUFePa2xfjRVWehyJu4nr6UiqGukVMmZxymO7lUEe2HLNo3ZAxQkGVovWRESWYUM6W7KIbCc/nll+Pf/u3f8LnPfc7U9vPmzcP111+Ps846CxMmTMANN9yAyy67DBs3bgzarrOzE8uXL8dvfvMbFBbGl/lPkozDDVz3R6B8lpKc9dS1SlAAGYwokys9S/m+98W0HcqooK9DF5jlCRBDgNLIDgw/VU4kLU5iiZzAbpNwyfRSTC/PxcxhJskJRKLcWx8r/+bMGOYg1+EiAhQa2vsgy+HT1wIBOWhYajji6Rky7mOyIUQhHMdErHYcZXKVhVko9row4Je1xL6hIMsy9p5qhz8g47UPa8NuE2vGEKA7Q70m0uQ6tDK5yPtLNEL09/sCSe+pCBU/Vh68Kj7b/CynFsRhxUS5QEDW3kenXfm3pIGlchrG+Vld/RRDSWHXrl149913sXTp0qD7V65ciSuuuALLli0ztZ++vj60t7cHfZEk4skDlv9VGcjacgR4+gvKQpXoDPQCrTXK7QvuUb5//Crgt+6VPMtTtweArJSi5YxJzD5nfl75fnQT0G5+SGMQHfVA/R4AEsVQCL9dsQCv3XkB3I7ERP0LMSSSxdJZIgcoTo/bYUO/P4BdEcrKGrv64AvIsEnAmAguVqEqhrr6/eiL0BtTF7VMbvAV984+n3aFO54yOUmSgiK2h0pnn0/7nN7Y1xB2m7ae6ElygB6tbS5Nzhdzf4kmx+WAMLWSPXg1tEzOyoNXg8WQIsatKIbaewcgUuQnlSh/TwxR0BF9eADL5BJOZWUl3G43FixYgJUrV+JrX/ua9tgzzzyDnTt3Ys2aNab3t2bNGuTn52tfVVVVyThsYiS3DLjheSC7WBnG+tj5wLuPDL/3YrTQfBiADLjzgTOvUWbi9LQoi+5E7HvnU0okdCaRyBI5QUE1UL0YgAzseX5o+xCu0NjZgLc4UUc2KpAkKaHOjRBDgnQmyQFKZPhnZ1cAAP64+VjYbYSIGZPrjpioZywTaw1T+tTRO6AtRILFkLLIrGnuxkBIn4PoFyrIdsYtDhIRolBvSNjbV9uuRaIb0ZPkIpetedQ0uViuS78voAmmVDpDNpuUshAF4WDkupUyQCuXybWGc4YarCeGxHuY43ZgXKESSMJ4bR1xgQFgmVzC2bhxI7Zv347HHnsMDz30EP785z8DAI4fP44777wTTz/9NDwe8zNZVq9ejba2Nu3r+PHjyTp0YqRkCrD8OSCrCGg5qsRu/2IG8NIqfeGaqTSpJXIlU5Qhn9OvUH7e+9Lw9tvTAvz+H4CXVwG/vgA4/t7w9jeSqN2tfE+kGAKGXyrHSO2UMb44uNwrnUlygq8sHg8AePWD2rBX6nVHJyviPmw2SQtRCLcPUWaX53Eg26X3w5TneZDltMMXkLVhtALRrB76npkhESEKoaVG6/fVD9pGCL9oYs3snKEOwxXsnDA9Q8kkVX1DYuEuRLCV0+Q0Zyhb7xn65HRXxHLSdCHew4Jsp9Z/GCsqP5MIdoYYrZ1QJk6ciFmzZuHrX/867r77bvzoRz8CAOzYsQMNDQ04++yz4XA44HA48M477+Dhhx+Gw+GA3x/+g3C73cjLywv6Iili3Hzgrg+Bzz6kNKP7eoBdTwG/vhD47aeBD/4C+DLwHxbR21KsNEjjzKuV7/teAQLD+Afl9dVAR63+HL+7DPjb95WyvNFOMpwhADjzc4DNoYgtYxy6GWRZnyFFMZR0SnPdWgJYtsuOiUNY6CeauVUFmF2Zj35/AM9uG3whrk4LPoge9FAQpW9I7xcKFlSSJGGiCFEIKZXTY7XjHyg8p7JA28dQE8tCS43+L0ypnHHBHAlRJhfLGRLhCTnuyGEMySJlYkj9LMRnPiLEUJYT44uzYZOUMiuruS7CbSvM1sNY2DOkE9QzRGcoeQQCAfT1KX8cl1xyCT788EPs3r1b+1qwYAGWL1+O3bt3w25PTN05STDuHGDBzcA3NgE3v670YdicwIn3gOe/DjxlLmBjVNEoxNAU5fvECwFPgTKA9di7Q9vnx/8DvP9nZTbJPz4HzLkekAPAuw8r4vPEjoQcuiXp7wZOf6zcTrQY8hbrQiZed+joRqCzHnBmA1WLEntcZBA2m6SVys0Ymwdbihe9kbjhXMUdenrrMfgDwVe+IwmZULQQhTClT+FitQWTIoQoDCVJTpCf7dSS6nafaI379wHdzRIld1sONwVdZQbic4ZiBSh0hMwYSiWpc4aEGFKclnAllVagd8CvzRTKz3LC7bBrDqXVSuWau/QQjzEmo/IzCXGRAQC6GaAQns7OTk20AMCRI0ewe/du1NQojeOrV6/GjTfeqG2/du1avPLKKzh48CAOHjyIJ554Aj//+c9xww03AAByc3Mxc+bMoC+v14vi4mLMnDkzAS+RJBVJAsYvBr7wO+Duj4CL71PuP/b3zEucM5bJAYDdCUz/rHJ7KKVy3c3AK3cqt8+7A5h2KfC5x4Av/xnwlgKN+4EnlgHrfzw6nbiGvYrw844Bcscmfv+zr1O+b3sC6I8j/nXDz5Xvc5crSYsk6QgxdOZY61QAXDWnAvlZTpxo6cHb+4MdkHDBB+Eo9KplcmGu9mv7yAsnhsKHKGgzhobgDAGGUrma1iH9vig1WjSxCJPHeOELyHhnf/D/A8b45Uh4TM4ZEr0NkeYVJRPRo5T8nqHgMrnW7n4EAtYqOwP098Fuk5Cj9jdZNURBOENFXqMzNAr/Dx0iRmeIZXIR2L59O+bNm4d58+YBAO655x7MmzcPP/jBDwAAtbW1mjACFBdo9erVmDt3LhYsWIC1a9figQcewI9//OMEvQRiGXLLgKXfAkrPVH6u2Zze40klsqyXW4kyOcBQKvcyEIhzqNt//zPQ1QCMmQ5c9F39/un/AKzcqgwQlQPAxl8Aj180+lwirV9obnLm+Jx5NVA4QXHu3vuNud85sR048o5SYrfkzsQfEwnLshll8DhtuOys8nQfiobHaceXFlQCAJ7aEhykUNvWAyByrLZAzL4JV5amldqF2YcWr90Y6gwNvWcI0B2d94foDIkFZWmuG8vOLAMA/F9I35CxyT4SHrUsMlbPkHCdws0YSjZCgBmbzZOB7gwpn2lAxiC3zQoI0ZbncWgBKnq8trVmDbUYyuRE2mMjxZCG8fximVwELrroIsiyPOhr3bp1AIB169bh7bff1ra/4447sGfPHnR1daGtrQ07d+7E7bffDpst8lO//fbbeOihh+I9NGIVqhcr3xMpht79JfCHqxS3xIp0NwO9rcrt4sn6/ZOWKulynfXA8a3m9/fRC8BHzwOSXXGDnCELouwi4PO/Bb70pJJa17AX+O0lwP98C+gdJTHzyeoXEtidwNLvKLf//p/mouKFKzT7y0ABEyxTxT8uqsaeH12G86eWpPtQgli+SCmVe+fAaW2+D6CnqoVzdYxoPUNRnKFwgkrEARudoX5fACdbFBE2lDI5AEHx2kNpehd9F2Ny3bhUFUNvfdwQlHoX35yhWM5Q6mcMCVJRJucPyNr+S/PcmuNixUQ5/XPVUwKtOmtIvH/GAIXTHZHnhmUaRoHPaG1Chsr485TvQ+2TCaWrCVj/r8oV+d1PJ2afiUaUyOVXAU5Dn4DDDZxxuXLbbKlcZwPwqjqn6IJ/BirmRd72zKsVl2j2lwHIwHuPA2vPUZ7LzD/sHfVKr1P9XuDUbiWp7ugm4NB64MD/Ag37hhf+MBySLYYAYNaXgKLJQE+z8t5Fo24PcOA1ABJw/l3JOyYSFkeEiOp0MqHEi6XTxkCWgae3KhURsixrzlCsMrlog1dFz1BZmH1MVJ2hpq5+tKkLu5OtPQjISix1aYTZRrGYPjYXLrsNLd0Dg5LqzCDK5MryPJhbVYhirwvtvT5sO6JfxBIlStFK27JMBih09KavTC4VYqi9R5+HU5Dl0gSkFWcNiffB+FlMLrVmz1BrGGeo3x+wbD9WqqEzREgiEM5Q3QeJGcy6+2nAr1rYHzw7/P0lA61Ebsrgx+IplZNl4NW7lcV5+Szgwm/Ffm5vCXDtr4EbXwKKJinJc3+5Efjzl/UhsIKuRmDPX4GX7wAemg38YhrwyHzg0cXA40uBJz4NrLsC+OO1wJ++BPzqXOD+auD3VygJdh+9oOwz2VfQfP2KQAOSK4bsDuCie5Xbf384uqu28RfK97OuAUqmRt6OZBRfUYMU/rL9OHoH/GjrGdAa/8tiOEOFaplcc5hFWF2UUrsctwNlalLdJ2qpnHCmqouyhzznye2wa9HlQ4nYNpbJ2W0SPjW9FADwhqFUrk296hx9zpC5AIX2UR6gIBzDHLcDLodNG9TbasFEubYw5Y/CwTzV1mupRbUQkwXZStCDEJnsG1JgmhwhiSB/nDLYUg4MfyZOIABs/53+c92H+iLZSmjhCWEWyZM/BbhygPaTwMkYfT0f/AX4+FUlme+axwBH5AXDICZdBNy+Gbjw28rvH3gdWLsIePt+4PXvAo8uAf59MvBfXwV2Pgm0HlNS6tz5Sqld3jilh6bkDKBsFlA+G3B6gf5O4NgmJcHuuZuAh2YB/z5F6WlK1sDd0/uAwICSxldQnZznEMz8PFAyTSlz3PpY+G0aDylCEFDcOkJULp5einEFWWjtHsCrH9Rqjk6R16Ut6iMh5gyFOkO9A36tlGdsXvhEutBSuRotSW540eOiVG5XnCEKXX0+raSmVBWBxr4hUVLf1qO8VjPR2jF7hnpEz1D6nKH2pIohZd8iaEOIZyuXyRnFUKHXhWL1mI80WqdvSDhAomeP8drBGNPkGKBAyHCoVkvlhts3dPgtoOUI4M4DJl2s3PfhX4a3z2TQ9InyvTiMGHJ6gGmfUW7vfTHyPtpPAa+pTtBF3wHKh5Cm6PQAn/oecPvflc9goBt4ew2wZS1Qv0fZpmwWsHiVEtV9bw2wugb49ifAPXuBO98HVr0H3L4J+MZGYPVxRWBdvRZY8FUlzMDmUEIHtv0WeGQh8OF/mXOKupuBTQ8Bm9fG3t5YIpeM8AQjNrveO/TuI0BP6+BtNj0IQFY+x/JZyT0eMqKw2yQsP1cR7E9tPho1BS4UfXEbLIZERHWW0468rPCuR2i89nBmDBmZO8QQBXFV3euya70tF0wtgdthw/HmHhyo70TPgB8DfuVvP2qanNNsgIIokxudzpCxnEv5Hl48W4E29VjzQz4LK/YNtYS8r6W5yt9q6JysTIXOECGJYrxaKndsmGJIuEJzrgfm36Tc/uC5+JPZko0okysJUyYH6KVye18eLAQCAWWe0NNfBHrbgIqzgSV3D+94xpwB3PTfwFW/BCZcAJy9Qok//9YnitC57CdKVLc7N/p+bHag7Exg3g3AZx8EbnsHWH0SuOGvioPUdRr46y1KWV3z4fD7aK0BXrsXePAs4P9+CPzvd4HDb0d/3lT0Cxk563PAmBlAXxuw5dHgx1prgA+eUW5f8C+pOR4yorhuQRVcdhveP9GGv+2tAxA7SQ6I3DNknDEUqeQtNF5bE0NDDE8QCDH00al2bW6MGRpUAVdqEIHZLgfOn6KEXvzfvnrtirzDJiHbFdk1Ez1D/b5A1Bhpfc5QGqK11UV/MpPd9HIuIYYiB26kGy1AIaT8cXKpcp4eskjfkCzLQQEKALS+IZbJKRjP6Z4B/6A5aqMRiiGSHIQzdHL70GfgtJ0E9v+PcnvBV5Wr8u48oP2EtWK7/T5dCITrGQKAKcuUIZ1tNcCpXcp9vj6lXO1Xi4BnrlecG3cecM2jSi/LcLHZgLNvBG56FbjqYaUczJuANC6nR3k939ikzJWyu4FP3gR+tVjpq/Gp/1HXfQj89evAf84Ftj6quFQuVXzFCitItRiy2fXeoS2/Ck4t/PvDQMCnDNGtWpia4yEjiuIcN66YrczC+sv2EwDCBx+EIha3Xf1+9Pl0F8SMuyScIVF+VKPGalcPs0xufHE2CrKd6PcF8HGd+WRKsZAcExLeIErl3thbH5QkF62vKcsglHp9kd2hdM4ZSo0zpJbJqYv2kSCGQiPTrTZrqLtfHw6rO0OqGGqnGAoE5EEJcpkweJViiCSHkqlKH4qvV0kpGwo7/6D0HY0/HyidrizChcNipSCF1mNKf4sjC8irDL+NKxuYeqlye/fTwMb/UHpvXr4DaDyg9O2cfzewapvyWkcCDpcyV+qfNgMTlyqf9fofA7++EHjqWuCx85WSRtmvPH7D88DX1yu/u/81oOVY+P36fUpyG6CU5aWKGVcBZTOBvnallA9Q0vZ2PqncpitEonCDGqQgrqKONVEml+txwG5TRIExyUrMGIrmLk1We4aONHXB5w/oPUPDLJOTJAlzKgsAxBeiIEr7QkMjLlFDFHYfb8VB1R2IJV48Dl0MRRu82p5GZ0gs+rv7/UHR4YkktJxL9A61dI2MniFAd4Y+abBGz5B4T10Om+ZOjmHPkEZHn08rXhHXK7oyoG+IYogkB0kCqs9VbtcMIWLbPwDs+INye+FX9ftnX6d8/+hFYMAi/3A1HVK+F09W3JhICCG37bfA+v+nzB7KrQAu/Tfg7j3Ash8BudYZKmma4slKkt3nHgeyi5Xwg0/WK+EMZ10L3Po2sOJlYMolSvnepIsByMD2J8Lvr/EA4OtRQieKJqXuddhsuju09TEl0n3LWiXJsHKh4gwREoGzqwtwlprEBsSO1QYAm03Srvob45LrDGVykRhXmAWXw4Z+XwC7j7eidyAAu03CuMLwgQvxIErldscRonDakCRnpDTPow1zfX6n4ppF6xcClPfFpQ5e7Y1SqqcHKKS+Z8gY2pAsd0gLUBhBZXKhQneKWs55pLHLEuVWRrdNuJOitJNlcvrflMdpQ67a+5cJs4YohkjyGM68of3/A3TWAd5SYPqVhn0uUVLP+tqAg39LzHEOF00MRSiRE0y9FPDkK7fHzFDS4u58HzjvDsCTF/13rY4kAXOuA1ZtB879J2DR7cAdO4Av/n7wnKRzblW+73wSGOgZvC9RIlc+O7q4TAbTP6s8b3+nIli3qYLtgn9JfpADGdFIkqTFbAPA2HxzoqQwTN+QmTlFdpuECWp/0Fv7GwAAFQUeOBMwj0kTQ3GEKDREEEMAtAGsGw6cBjDYPQiH6BuK5gylc86Q3SZpIixZYkgLUPBav0yuNYIzVFGQBbfDhn5/ACda4p9dlWhC3TYAQYNXzTDgDyS1VyydGN1WEYSSCSEKFEMkeQgxVLM1/sGdYhF69leC46VtNmDWF5TbVimVizZjyIg7B7jlDeCm/1FKy+ZeH1909kgguwj4zBrg8vsjuzrTLgPyq5VY7j1/Hfx4qvuFjEgScPF3lds7/6CIorKZyjETEoOr545DYbYTNgmYUGKuXE0sypq7wzhDMUrtRLz2Wx8rImN80fD6hQQzxykXbQ6f7oo5+FQgSoxK8waLoWUzFDGkDRDNjv3vnkiUi/T8/oCMDnWRlo45Q0Dy+4ZCAxREw78Vo7XbDf1gRuw2CRNLrNM3FBqeAOhlcmbF0J3P7MLin67XkhxHE8Y+PC/FECEJoGyWUurU1wY0xDEbqPEQcOQdAJKeIGdElMod/Fvy5tzEg3CGzAziHHMGMGFJZrsMNjuw8Bbl9tZfD07XS6cYApSgDqObdcE9mf15EdNkuex45tbFeOqWRagsNCmGvIMXuHrPUHR3SYQo7K1Vgg6qh5kkJyjJccGr9lOcaAnj3oahXm0+L8sdLOCmleWgqkh/LfE4Q5HEUKdhFko65gwBeq9SsmYNhQYoiLk4rd39kJM9+DoOlPlR4Z0hwFp9Q8KBDecMdfb5YoYFBAIy3vr4NLr6/VpYymjCOMjYyzI5QhKA3QFUnaPcjidiW8RpT700/MDNsrOUq/X+fmDvS8M/zuGiOUMmxBBROPtGwOEB6j4IHswbCCj3AekTQ5IEfOo+5faY6cCZ16TnOMiI5IzyXCyZYj61USxwxSJtwB/QSs5i9R2JeG3BhASJIUmStFS6483mSpv0aO3BzpAkSZo7BJgTQ7EGr4pFm8dp0/qLUk2ynaFBAQrq9wH/4MSvdGKcHxVWDFlo1pD2nnp1MZTjdmjiO1ai3MnWHu2cfOX9U1Gj30ci7YbeL61MjmlyhAwTbfiqyb6hgR4lbQ3Q3YNwzPqi8v2DNA9g7etQepuAyDOGyGCyi4CZarmjMWa7+bBSmubwACXT0nNsgBId/rX1wI0vK04WIUlClECJkqjTHX2QZcBpl1DsjV5OJpwhQXWCyuSUfSlOTo0JMdQ74NcGoI4J4wwBwKeHKIZ6B8IHKGgN+2lyhQD9dSTDGZJlWXeG1PMgy2WHWxV+rRYqlROfRaT5UVaK1w512wBFrAsRHytE4WBDh3b7ZGsPth+zQHVKAtEGGXuc8LqVz7KTaXKEDBPj8FUztv6e54HeVqWnZMqyyNvN+gIACTj2d2UoZroQJXLeUj0cgZjjnK8r3/e+CHSogrJ2t/K9bGZiZi0Nh8oFQG5Z7O0IGQZi8KpolhcDV0tzPbDZopdninhtwXAHrhqpViO6zYghcTXd47RF7N9ZOLFIeyyuAIUIzlA6wxMEyXSGuvr96PeLeTj6a9ScRAuFKAiBkZ8Vfn7UFFEmd9oCZXJhAhQAw6yhGPHaB+qDBd1Lu08m8OjSj+4MOdgzREjCGDcfsDkV96TlSOztRdzygpuiX5HPrwQmnK/c/vC5YR/mkGk0mSRHBlMxF6hapAw0FTHqol+oYm66joqQlCKu+jerC8p6EzOGBPnZziD3qHqYM4aMxCWGOnQBF2mYqtNuw60XTsLYfA8WTy6OuU8tQCFCmpyxtyFd5GcnTwyJskmXw6YJQ2Cwk2gFtH6h7PDCVAR9NHf1p/24Q0MpBKWqoxkrROGgKobOmVAEAPjvD2u1Ia6jgXBpct0UQ4QME2cWMO5s5XasvqFTu4GTOxTxNO/G2PsWQQof/MWc65QMmtR+IZbIDQ0Rs739d8psqXSHJxCSYsRVf7H4rTUxY8iISOoqyXFrV3ITQZUqhsz0DEWL1Tay6lNTsXn1JagoiB07nqWWW/X6IoghbcbQ6HSGws3DET8bH7cC0cITAOWzHKd+5ukulQtXJgcYB6+aK5O78bzxKMlxo7V7AJsOnU7CkaYHY5pctksEKLBMjpDhU62WysXqGxLBCWdeBeSMib3fM68C7G7g9MdA3YfDO8ZQupqAjb8AGj6Ovp02Y4jhCUNixlVKiWFnHbDvZYohknEUhpQ91YkZQzFitQWibyiRJXJAsDMUK7lMuFllJo/ZDJ4Yc4baLVAmJ1wpsYBMJJHKuULPFysQSwwBxkS59IqhcAEKgEEMRQlQCARkHFKPf3p5Hj47eywA4MVdp5JxqGkh2BlS/gZZJkdIItCGr0Zxho5vA3b/Sbm9IEpwghFPPnDGZ5TbiZw5dHIH8PhSYP2PgWeXKwlnkRBJcmZitclgHC5gwc3K7fX/qvSL2ZzKUFpCMoCikKGr8TpDZ45VBjZPK8tN6HGNK8yCJAHd/X40xShtElfTx8RwhuIhVoBChwXK5PKS6AxFFEMhTqIVaOs2IYYsEqKgO0Px9wydbO1Bd78fTrsy8PiaeeMAAG/srR81giFcz1BnBqTJpblDmWQEVYsASEDzJ0BH/eCm9K5G4LkVQGAAOPNqXTyZYfZ1Srz2h/8FzL8Z6G4Euk6rX+ptX6+SXDbxwujzYmQZ2PF74LXvKLHdgOL8HHoj/NBNWQaaPlFus2do6My/WXHhRE9Z2ZmjbxgtIREQV6i7+v3oHfAbeoZil5IBwHULq5HtcuDi6aUJPS63w46xeR6cautFTXM3SnIiCx1xNT1crPZQiRWgYCznSRfJLJPT5uF4g1+fJp5HUJkcYIzXTnyIQne/D1lOe8R+NUG/L6BFkoeWyZXmxe4ZEq7QpJIcOOw2zKnMx/jibBxr6sb/7avH1XPHDedlWAJjmly36sqOFqEXDTpDJPlkFSizgQCgJsQdCviBv94CtJ9UBMVVj8Q34HLKp4GsQqXM6pH5wO8uA569AXj1buCtnyixzTufBJ68Clh3BXBkY/j99HcDL96u/J6/H5j+WX3g6+a14X+n/RQw0AXYHEDhBPPHTILJG6uUywlYIkcyiDyPA3Y1Na61eyBuZyjLZceXFlYl1JURmO0bMgYoJAotQCHGnKHcdAYoJNUZUvYZ2uivBSiMtDK5JM0aOny6E3N//Aa+9+KemNuKxEabNDiSXThD0cTQgXqlX2hqmfJaJEnC1XMqAAAv7R4dpXJh5wxRDBGSIETf0LGQvqG37wcOvw04s4EvPQV48uLbr8MFnLsSgAS4chRRUrkQOOMK4OwVwAX/oogau0uJ4f7DZ4F1nwWO/l3fR9MnwBOfBt7/MyDZgGX/D7juj8D59yg/H3kHqP9o8HOL8ITCCYA9fVcnRwUiSAGgGCIZhSRJ2lXqpq4+zRkyK4aSidY31BRDDKnOUFkSnKGIYmiUzxkSC/eiQT1DzqDHrYC5niF9iG+kz3QofHCiDf2+ADYdbIy5rVFghsbWi4sJTV39GPCHL808qDpDU0v1ktSrVDdow4HTaU/KSwTGlEatTC4DAhRYJkdSw/jzgG2/CQ5ROPA3YMPPlNtX/qdSHjUUln4LOP/u6HNpLvw2sOk/FJfo6EZg3UalbO6MK4C3fgr0tQHeMcAXfqfcDwCF44EZVypleFt+BVwd4hAxPCFxVJ8LVJ0LnNwOTLgw3UdDSEopzHahsbMfhxo6MeCXIUmxk9lSgdl47eQ4QyNnzlBHnw/+gKw5fIlAX7gHv75CrcdsZJXJjclxI8/jQHuvD8eaunFGeWJ63EQ/28nWHvj8ATjska/xiz6s0PcUUESnwybBF5DR2NkXtkz1oOoMTSvT53tNKc3BzHF52HOyHf/9YS2+cu74Yb2edBIIyFoZYV6WEznq+0VniJBEIfqA6vYAvW1AyzHgeXXo5oJbgNlfGt7+Yw3ozB8HXPEL4Ju7gAVfVZr0j2wAXv+OIoQqzwFu26ALIcG5/6R8/+A5oDMkPlPMGGKs9vCRJOCG/wLu2AGMmZbuoyEkpYgF7r5aZbE1JscNZ5RFXaqoVhPqjkURQ30+v7ZwT6SAi50mZ50ABUAPdEgUkQMUrJcm12pCDEmSpCfKJbBUTvRW+QOyVmIaidYI7ykA2GyS1hcXLlFOlmXdGQoJK7l6juIOvTzCB7B29Pm0KSW5Hg5dJSTx5JYDhRMByErfzl9uVJLDKs4GPrMmdceRXwl89kFFFM2/GXDnKYLnpv8G8ioGb1+1SDlGf58e/S0QZXIMT0gM7lz2XpGMRJQ+7attB2CNEjlAd4ai9QyJHguX3Rb2ivtQ0crkIgy01HuG0ucMOe02ZKvzkBLdN6RHQEdwhiwkhtpNiCFA7xsSg0sTgTHpMFZvW3NX+BlDAhEAEm7WkDFJLjTG/so5FZAkYNvRFpxoiT2Xy6qIz9HjtMHtsMOrzhnqyoA0OYohkjqEO/TyKqB2txJ88KU/AI40lIMUVAFXPgTcW6OIsUjpZZKku0Pbfgv4DP9IilhtlskRQoZBkZoot1eIoQTO6xkOQgzVtfdG7PMwxmrHSvOKB23oaiRnSE2Ty89Kb7V/skIURBlcaICCEEe9A4GIrlmq0crkYohhUV52QB1cmgiMEeOxyjn1Mrnw/99Hi9c+aEiSC3Vty/M9OHdiMQDg5fdHbpCCccYQAC1AoXcgAF+EPqrRAsUQSR0iRKGnBYAEXPtboKA6rYdkKrnurGuA3AqgqwHY81flPl8f0Fqj3OaMIULIMBCLM+GyjLWIM1TkdcHrskOWlSvj4UhGrDagp8mF6xmSZdkwZyi94TXJEkORAhRy3A441N4kK7hDsixrr70gK/pIBBE8IHpvEoExVe94DFdGe0+94Y9zTG7keG1xzFMM/UJGrp6rVJa8PIJT5ULj6rPVoauAEv0/mqEYIqnDOD9o6XeAqcvSdyzxYHcC56j9TZt/pcwXaj4MQAbc+UrwAiGEDJHQBW+5yRlDyUaSJC1eO9JVd3EVvSyB4QmAcejq4EVYV78fAbW3IZ0BCsbnT6QY6vP5tcVnaH+LJEmaeLaCGOrq98OvfhixyuREJPWRxq6IiW3x0hzkDIUX7IJIoRSCMbmRy+QOqKV900rDBz9cPnMsXHYbPq7rwMd17bEP3IKE9uG5HXY47YrwHu19QxRDJHUUTQKW3KlEYS/9drqPJj7m3wQ4soD6D4GjmwwlcpPjm4tECCEhFHpDxVD6k+QEsfqGkucMRU6TE70NLrsNbkd6lzHJcIZa1UW7TQo/R6lIi9dOf6KccFtcdpvm5kViXEEWvC47BvwyjjUlZvhqXGVyXZEDFABDmVyYAAU9PCG8M5Sf7cRFZygXRkfqzCHxd2Xsw8uUEAWKIZI6JAn49I+Bz/wUsNljb28lsouAudcrt7f8Sg9PYIkcIWSYFIU0yZfnWcMZAmLPGtJjtRMrhvQ5Q4MdBOPA1UT2KQ0FfdZQ4haLxt6W0Hk44n4Alphr02YY0hnrs5AkCVPUJLYDCQhRCATkIHfshMmeoYgBCtrg1eCeIVmWcShMrHYoV88VqXKnEBDW5QiiPUxcvQhR6KQYIoQAABbdrnzf/xpw8A3lNsMTCCHDJLSh2yo9Q4Aerx25TE51hhJcJhdt6Gpob0M6ET1LiXSGWmKknon7rTB4VZ8xZC7IYpoar30gAX1DbT0DMGqOpq7+qA5Ga3f4UApBqRpcElomd6qtF11akpw34v4vmVGKHLcDJ1t7sLOmxezLsAz6IGP9s8zRnCH2DBFCAGX+zZRPA5CBms3KfZwxRAgZJoN7hqwjhmL1DNWnoUyuwwIzhgTJKZOLXs4lAgCaLTB4VSygIwmMUESZWSLitUWsdq7HoQnEaCEKLTECFIQz1NjZF+TsCOE2scQbdf6Xx2nHJTNKAQDvHDgdcTurovUMGZ0hNUSBzhAhROfc24N/pjNECBkmxp6hgmynJgSsgLFnSJYHl/6c1srkkuMM+QPyoGb7cIu2dCEckfZEOkMxHAwrBSi0mZwxJBADSw8mIF7bKG6qYpRz+gOyNhw2UoCCGLo64Ne3BYBDqnCbGiE8wciSySUAgHc/aTLzEiyF5riyZ4gQEpXJnwLGTNd/LpqUvmMhhIwK8jwO2NXeEKvMGBKMK8iCJCmpYaE9KgP+gHZ1PuHOkEtfnoS6Q2LRFi5cINWI2ToJLZOL0dtipTI5UXpmVgxNU8VQIhLlxPkYJIYiOJjtPQMQWj5SBLjLYdPeW+OsIeEMRQpPMLJ4sjJv6P3jrSNOQOgXGQaXyXWP8sGrFEOExIMk6e5QwXjAlR19e0IIiYEkSdoizEr9QoBS+iMEWuhCs7GzD7IMOGzSoFK/4eKy27SgztDBq3pvgxWcoWT0DKliKEI5lyifa7ZAmly8zlBFvkdLlDvaOLxEOU0MZbs0B/NES/h4bSEwc9wOuKIkEAqH05gopyXJmXCGqoqyUVWUBV9AxrajzSZehXUI93clnKFO9gwRQoKYuxxYei9wxX+k+0gIIaMEscC1yowhI5GuuosF45hcd9jUs+EgSVLERLmOPusEKGhpcr2JL5OL1DMk7reCM2RMkzNDIhPlgpyhwujOkPaeeqMfp3A4RYiCLMs4pIqhaElyRs6bpJTKbbZAqdzatw7hpd0nTW0bPk1O+RscaS5XvFAMERIvdidw8eqRMzSWEGJ5NDFksTI5IHK8tp4kl5y5SFkRQhTCpV6li2SkybXGKpPzWq9nqCAOYZqoRDmjGKqOUSYXK5RCoA9eVcrkatt60dnng8MmYUJJ5CQ5I+dNUUrl0t03dKypC//+v/vx3ec/DNvvF0q4vyvdGaIYIoQQQkgSmagutM4oN3f1OZWMj7DQrG9XwxOSJOA8EeK19TlDFnKGegYSNlvGOGcoHEIktVggTS7eMjlA7xsSjstQMZYTVhUpjmqkoA8hnGKl3okyudOq0DebJGdk8SRFDO051Ya2NJYyNnYqr6Gr329KrIdPk2OAAiGEEEJSwHevmIE/3rIInz6zPN2HMohIs4aS7Qx5nMoSJVKAQp7J2TbJRCwcAzLQmaAmc71MLlKAgrKg7+zzod83vBCC4TIUMSSCCIbrDDUZnKGKgizYJKDPF9CEjJHWGO+pQHeGlH3oJXKx+4UEpXkeTCnNgSwDW46kzx0yiuW69t4oWyoDbIX7Y+wZ0uYMMUCBEEIIIckkP8uJ86eWaKlyVqLKEK9tJFmx2oJIs4b0OUPpd4Y8TjvcakN+olyAWPNw8rKcEKdJa096S+U0MRRDZBgxJsoNR8xp71O2C067DRUFijsUrlSuxWSZnBD2p9uDnaEppfE5tsIdSmffkDEevK4tuhjq6PNpaXu5YcvkGKBACCGEkAxF9GPUtveiz6cvihqSNHBVIHqG+gaVyVknQAFIbKKcPyDrfTgRFu52m6Q9Z7RSOVmW8cKuE9hX2z7s44rEUJyhsfke5Lgd8AVkHG0aeqKc1jOUo7xPIkQh3ODVWKEUgtKQnqGDQ3CGAOC8yaJvqDGu30skxoCNWGJI9Au5HbagOWc5bgYoEEIIISTDKfa6kO2yQ5aBk4bo4np1wViWLDHkih6gYIU5Q0BiE+WC5uFEcVsKTQxe3X6sBXc/+z7+5bn3h31c4QgEZO2ziCdAQZIkzWk5OIxEOWO0NmAM+hgcr633F8VKk1OjtTv6lCQ5MXDVZJKc4FzVGTpQ3xm2bC8VGM+NWGVykQYZs2eIEEIIIRmPJElh07o0ZyhJZXJuhyqG+vVSKlmW9YWbBcrkAH0B2R7DGTrR0o1nt9XAHyVooVldwOa6HVEb9kWiXLR47feOKHNuamO4AkOls98H8VLidemmDbNvqHfAj251/pR4LyL1tgGxQykEwhnq7vfjk9Od6BBJcsXmkuQEhV4XzhybBwDYfDg9pXKthrLN+lhiSPThhVxg8LJniBBCCCFkcN+QPyBraVVJi9Z2DU6T6x0IYMCvrMBHWpncj1/Zi+/89UP8deeJiNsIcVMQw8EQQQDNUcrkdh9v1faZqKQ7I6JHKrS0ygyi7Oxgw9DEkHCFHDZJW8BXFqqJcmHK5MwGKHjdDm22zt8PKSJmQok36qDWSIhSuXT1DRnFUCxBHMkZ0gIU2DNECCGEkEwm1Blq6uxDQAZsElCck6yeocFpciI8wSbpAyHTjVkxtOdkGwBgSxSnQPQAFcVwMApilMnJsoxdNa0AEpt0Z2Qo/UKCqcMcvNpsiNWWJCVNojpC0AdgPkAB0BPl/n5I6fcxO2w1FDFvaHOa+oZahtAzFOq2cs4QIYQQQggGiyERPVyS405aAp4nTICCccaQWASnGzNiqLPPh1PqglSIlHCYLecSSXOiFyaUk609mnMHAK1JmEk0LDGk9gwdHWKinBBDxYbEPXGO1oUEfciyrIuhCAl9RkTZpyhvm1IaX3iCYOGEIthtEo42deNk6+A+pmQTV5lchFASccGh3xfAgD+9Me7JhGKIEEIIIVHRxZCyqBNpW8lKkgP0NDmjM9RmoRlDgjwTYugTw4DRI41daOoM31RvtpxLhCu0RIjzDhVcyYjg1lPv4hdDY/M9yB1Golw4p6coQtBHV79fK62M9b4CwBj1nO5QBcJQnaFcjxOzK/MBpKdUzthP1tI9MGh4sRHdGQrfMwSM7hAFiiFCCCGERMXYMyTLMuqTHJ4AAO4wYshq4QmAIU2uJ/Ji8VBDcDnYzgjuULNJZ0iIgEgBCqJfSNCaoBlIRobjDEmShCnDCFEIjdUW+wwX9CHcM5fDpgnsaIT2wMUbq21EzBtKR8R2qFCO5g5F6hly2m1av9RoLpWjGCKEEEJIVERzemefDy3dA1qSXLJitQHdGeod0MtzxNV6K4khcTU9mjN0MEQM7TjWEna7VpO9LeLx5ghiaFdN8P6jRXAPFSGwhhpkMa106H1DobHagkpt1pDuDBndNjOllUaBP5QkOSPnTS4BoDhDspz4EItI9A74tYsIopQwWoiCniY3+LPMhBAFiiFCCCGERMXjtKNcncFyrKlLK5Mbk0RnKFyAglbOY6EyOTM9Q4fU1LSZ45S45Z014cWQFqBgMk0unOPT7wtgzyll0Or08tyYxzZUhuMMAfrsnoPDcIZCe4DChSjEE54ABDtDQ02SE8wfXwiX3Ybatl4cbRoc7JAsxGdjk6DNdDLnDA3+u/Kqg1fpDBFCCCEkozHOcREBCsmK1Qb0AIXe/vABClYh38ScIVEmd92CKgDA+8dbwzakxx2gEMbx2Vfbjn5fAAXZTsytKgBgvTI5wJgoN3QxVDxIDCkOZk3T0MXQGMM5LYIehkqWy4551QUAUlsqZzyPKgqU9yRaolykNDkA8LpG/+BViiFCCCGExMR41b1BvcpclpdEZ0jMGfIZnSHrlcnlZ0d3hnoH/FoPy6VnlaMg24k+XwB7VffGiF7SZS5au61nYNAQV9EvNLeqQHNOklEmJxbQBUMtk1OdoaNN3XEnykVyhrTetpbBPUOFMdw2gTEUZOow+oUEolTu3RSGKIjzqCDLqf2NRi2Ti5AmB+hlct2jePAqxRAhhBBCYmJsTk+lM9TTP3jOkFXL5ML1hRw+3YWArGxXmuvG2dWFAML3DekBCubS5GR5sAgT/UJzqwo0odKWTGdoCGlyAFCepyTK+QMyjjTGlygX2RlSz9Gmbu2zEEECsdw2gbFnaLjOEKDPG9qSwr6hVsN5NDZfeT1Ry+QipMkBxllD7BkihBBCSAYjFppHm7pxWoihJAYoeMIEKLRbMEBBiCFfQA7qbxIcOq2UyE0pzYEkSThbLZvaEdI3JMuytogtijEPx2m3IVdduIa6PsIZmlddqDlMSQlQUOO6h1omJ0mS1jcUb6lcpNI3EaDQ0efTxJoeSmHuOAuznVqf0HCS5ARzKguQ5bSjqat/yENm46XF4DAKZ6huCGlygDFAgc4QIYQQQjIYUYK052QbfAEZkqQMXU0Weprc4ACF3DBXsNNFltMOhzp4Nlyp3CF1oS9chrPHK87QrhBnKHgeTmwXQxM6hsGrzV39WqP+3MoCzbVptWCAAqCLjXhCFAIBWVvsF+cEv09ZLrvW83NcnYnVbLL0UCBJEu67YgZuu3DSkGcMGXE5bFg4sQhA5L6htu4BrN9XH3UWUDyIMrl8gzMUqWcoEJC1cISwPUMMUCCEEEII0Z2h7n49stdpT94ywhMuTS7KFex0IUlS1EQ5EastUr3mVBbAbpNwqq0Xp1r1CGghatwOm9YvFY3CMINX31ddoUljvMjPdia3TK57+GJIvCfxOCbtvXqfVLhywtBZQ2bjyo3cuHgCVv/DDFNR3GbQ5w0F9w3tr+vA6uc/xLlr1uOWP2zHD1/6KCHPZ3zN5aoYaujoG9RfBigumqjeC3eRIZsBCoQQQgghQEmOK2hoZTJjtYHozpCVyuQAQ99QGNFxKEQMed0OzBirOCLGiO14U8+0cASDM2TsFwraJsFlcoGAjA51cZyfZV5khKI5Qw3mnSHRL5TjdsDtGCwaQ8WQ9r6aDFBIBudNVvuGDjeh3xfA63vqcP3jW3DZQxvw5/dqNMH//K4TUXt7zKKlyWU5UZLjht0mwR+Q0dTZN2hb8Tfldti00lQjLJMjhBBCCIHigIiFJpDc8ATAEKAwYAxQEKlX1imTA3SnKtQZGvAHtHAAYzLZ/DAhCnqjv9nelsFCZ5ehXwjQk97aegYQCOMKDJWOXt1NSESZ3NGmbvT5zJWIaQNXI/RVVakDgkWinJjdZDZAIRmcVZGHXI8DHb0+nHf/enzjjzuw+XATbBJw+cxyPHPruVgwvhADfhl/ePfosJ9PS5PzumC3SdrfarhEuVhuKwMUCCGEEEJUqgxiqCyJ4QlAcICCSOHSFm5WdYZCxNCxpi74AjK8Ljsq8nUnTfQN7TSIIbPhCYKCkDK5QEDWwxNUZ0j0DAVkaE5OIhDhCVlO+7CGkpbluZHriS9RLlKstqAqZPBqvI5bMnDYbVg0UXGHGjv7UZjtxO0XTcbG73wKj94wH+dOKsbXLpgEAHh6a82wY6z1iHbl848WoqDH1Ye/wJCj9gyNZmfIWpdWCCGEEGJZgp2hJJfJGfpm+nwBSJKeLGdVMSTS7gSiRG6ymiQnEPHaH51qR++AHx6nXZ+HY3LRXhQSoHC4sQsdvT54nDacUa44Lm6HHdkuO7r7/Wjt7h+Wi2MkEeEJgOI2TivLxY5jLThQ34np5XkxfydSrLagylAm1+fzaz1uRWkUQwDwz5dOg9dtx5IpJbhqTsWgkrRPn1mG8cXZONbUjee2n8CK8yYM+bmEWC1QSxjL8yKHKJh1hro4Z4gQQgghmU51UZZ2O5mx2gDgMTgOPf1+rUQOAHIslCYHRHaGDtYH9wsJKguzUJrrhi8g44MTbQDiL5MrCOkHEv1Cs8blBwVbiFK51gSGKCRKDAF6yp7ZRLnmGE6PEOwnW3rQ1Klsa5PSn0A4Y2we/vPL8/ClBVVhe3PsNgm3nD8RAPDEpiNhww7MEnouiRCF8M5QdLdVL5OjGCKEEEJIhlNdnDpnyGG3wWlX3JReny6Gct0O2G2JSflKFKKHqT1UDKnO0NTS4Hk1kiRh/vjgvqG4AxSyg0XO7pB+IUG+ur9ExmsPd+CqkalavLa5RDnhhIXGagvK8jxw2W3wBWR8XNcOQOkXslnsnAnHF+ZXoiDbiZrmbvzto7oh7cM4r0qUEgoxVB/WGRJ9eOE/SxGg0M2eIUIIIYRkOtVFXu12sp0hwBCi0O+35IwhQSRnKDRJzsjZ1aFiSO3zMNkzJMq+hFMixJBIkhPooilxiXKtCYjVFohZPgdMJso1xSgntNskjFNDFN4/rrhuZt22dJPtcuCGReMBAL/ZeHhI++g2zKsSrqAokwsboKA5Q+H/rugMEUIIIYSoVBZmQVxgFwusZGJMlLPijCFBODHkD8j45LRwhsKIITF8taYl+Gq+2TI54fh096On34+P6xQxMa+6IGQ7a5fJiUS5YyYT5Vq0NLnIzy36ht4/0apsm+Z+oXi48bzxcNlt2FnTGpQ2aBbhMLrsNmSrfXeaMxSuTC7G35UWoMCeIUIIIYRkOh6nHfdePh23LZ2EioKs2L8wTLIMiXJ66tXIEEMnWrrR5wvA5bAFpfAJZo7Lg8tuQ1NXP441dQ9hzpCeJvfBiVb4AzLK8twYmx/8uYg5QImcNdSeQDFUmqsnyh0+HTtRTo/WjuxMit420Y+VzljteCnN9eDquRUAgN8OwR1qNfQLidCOckOanEhmFMT6u/JyzhAhhBBCiM6tF07G6stnpOS5jINXO7Qr2NYrkxNX1Y09Q6JEblKJN2yPk9thx6zKfABKqZw+Dye+OUP+gIyNBxsBDC6RU7aztjMkEuUA4ICJEIXmbhPOUKEiPrUY7hFSJicQMdv/+1EdjjWZixwXtIYJ4hDOUHe/f1DiYXuMv6tsl3L/gF82PQtqpEExRAghhBBL4nEqy5Sefr1MLneEOENaeEJZbtjfAaCHKNS0xO0MeZx2TSy++XEDgMHhCYC+KA7tZxoOYl+J6sURfUNmQhSaO804Q8FOnNk+LKtwRnkulk4bg4AM/G7Tkbh+V5xHRjfM47Rrn1VoqVzMNDlDxH3XKA1RoBgihBBCiCXRBq/6/DGHQ6YTsZAMEkP1kfuFBGer/T1bPmnS5uHEs3AXA1r31iqpaeGcIbEoTmSZXCIDFAA9bU+4aZHoHfCjy8TcoNCyxJESoGDk66o79JftJ+IKv4jUexZp1lCsNDmH3aZdlBitpXIUQ4QQQgixJGLwqtEZsmSAgrrw7PMF0DugLNYPnY6cJCcQiXKHG5VSKLtNikvsGRf5NgmYrZbdBW2TxDlDifospgpnKEainHgNdpsUNVUwVAyNpAAFwZIpxZhenoueAT+e3lpj+ve0Mrms4NdcFkkMxUiTA/R47dGaKEcxRAghhBBL4nEIZyigzRmyYoBCjsuhpey19wxAlmUcUvtfojlDpXkeVBkG2RZk6U3vZjCW1J1Rnqf1dxgRzlAyyuQS7QwdbepGvy8Qcbumrj4AyuuONjcoP8sZdGwjKUBBIEmS5g794d2jUd8XI9rA1ZCeqrERBq+aucgw2kMUKIYIIYQQYkmEM9RrmDNkxQAFm03SFpNtPQOobetFV78fDpuE8cXeqL8739DnE285l7GkLjRSW9smW6TOWTNNDgDK8tzIdSuJckejBAaIkIlo4QkCo8gcaQEKgivnVKAsz42Gjj68/P4pU7/TGqH3rCzMrKFAQNbcnmgXGbyqyBYliqMNiiFCCCGEWBItQGHA2gEKgC4M2nsHtN6X8cXZcDmiL7VEiAKg9wCZxbjID9cvBOglfG09AwgE5LDbxIPPH0CHuoAuSJAYkiQJU0yEKAhnyMz7ZAxRGGkBCgKXw4YbF08AALxiVgyJcIus8M6QMUCho88HkbQdrewwh84QIYQQQkjq8Riita08ZwgITpTTkuRKIyfJCeYFOUPxLdqN258dwRkSvSOyDK3UcDgYo5kT2b8lygmj9Q3pA1djv0/GvqGRGKAgmFNZAAA42dpjavtwaXIAUJY/uGdIOHxuh037WwuHVx28yp4hQgghhJAUIqKjjc6QFcvkgOBEuUPqgl4EA0RjenkustVywHjLuYrU7XM9DkwqCf9cLodNi0dORKmc6Bfyuuxw2hO3jBTC8WCURLnmblEmZ0IMFRqcoRHYMyQYW6CWt7X2DBqYGg4RoBAxTc7gDJkNJWHPECGEEEJIGvAEDV0dIc5Qt14mFy1JTuCw27QSt3gX7dXFyoJ/0cSiqIECwiVoTUCIQqLDEwSiTO5QlDK5ZlEmZ+J9EmVyuW5HQkVbqqnIV3qfusIMTA1HawRnSJTJNXf1a8NTzcbVs0wuhA0bNuDKK69ERUUFJEnCiy++GHX7TZs2YcmSJSguLkZWVhamT5+OBx98MGibNWvWYOHChcjNzUVpaSmuueYa7N+/P95DI4QQQsgoQjhDnX1+rUQnWm9DOtEDFHw4UG9eDAHA1XMr4LLbsGhSUVzPuXRaKX79lfn46edmRd0uX4vXTpwzlOiIc1Emd7ixEz5/+OQ0EaBgpgdodmU+ir0unDu5OHEHmQayXPrA1Nq26KVygYCsfT6hzlB+lhNutX+toV0RlWadIZFS2DlKh67G/S9KV1cX5syZg69+9au49tprY27v9XqxatUqzJ49G16vF5s2bcJtt90Gr9eLW2+9FQDwzjvvYOXKlVi4cCF8Ph+++93v4tJLL8XevXvh9UZPYSGEEELI6MSjlned7tBLe6weoHC4sRNtPQOQJGDyGHNi6LqF1bj27Mq4HQy7TcJlZ5XH3K7Qm7hZQ2Kxneg+nIr8LGS77Oju9+NYc3fY9y6eAIWCbBfeXf0puEawKyQYm5+F1u4BnGrtwfTyvIjbdfT6IDIy8kM+H0mSUJ7vwbGmbtS29aKqKNswYyj6Z5mj9gyNVmcobjF0+eWX4/LLLze9/bx58zBv3jzt5wkTJuD555/Hxo0bNTH0+uuvB/3OunXrUFpaih07duDCCy8Mu9++vj709fVpP7e3t8fzMgghhBBicTziSnaH8v99ltMeM50tXQgxtONYCwClZyVaU3ooySzlEiEKCXGG1H0kukzOZpMwpTQHH5xow8H6zrBiSI/WNldO6HaYf/+tTEW+B/tq23GqtTfqdqInLNtlD/vay/MUMST6hkTZHXuGUsyuXbvw7rvvYunSpRG3aWtrAwAUFUW2i9esWYP8/Hztq6qqKuHHSgghhJD0IeYMnVbLeqwangDo4uBEi1LKFG3Yaqop0GYNWbdnCNDLCg9FSJRriiNNbjShhSjEKJNriTBjSFAu4rXVRDndGYr+dyXEENPkhkllZSXcbjcWLFiAlStX4mtf+1rY7QKBAO666y4sWbIEM2fOjLi/1atXo62tTfs6fvx4sg6dEEIIIWnAo17d7tD6haxZIgcMFmpm+4VSQYFh1tBwSaYYipYoJ8uyttjPODGkhijUxnCGWmOUMJaHDF412zMkAhS6R+nQ1ZRdYtm4cSM6OzuxZcsW3HvvvZgyZQquv/76QdutXLkSe/bswaZNm6Luz+12w+12J+twCSGEEJJmhDMkiHUFO52EigNLiaFElsklVQxFHrza3uuDX22IGclR2UNhXIEihk7FcIb0JLkIYihk8KrZ2V2j3RlK2b8qEydOBADMmjUL9fX1+NGPfjRIDK1atQqvvvoqNmzYgMrKylQdGiGEEEIsSGjPTaITzBJJqDiYWhZ74GqqSEqZXBIEiZjL9MnpTvgDMuyGuPBmtUTO67LH1Ys1GhCx2LVtMXqGuoQzFKFMLmTWkNnZXd5RHqCQli7EQCAQFH4gyzJWrVqFF154AW+++aYmnAghhBCSuXicwcsUq84YAgaLocljrJOGm8g5QyKRLhnOUGVhNtwOG/p8AZxo6Q56TIghM7Hao40K1RmqbeuNOni1NUKstqBMFVV1g3qGzJXJjVYxFLcz1NnZiUOHDmk/HzlyBLt370ZRURGqq6uxevVqnDx5Ek8++SQAYO3ataiursb06dMBKHOKfv7zn+Ob3/ymto+VK1fiT3/6E1566SXk5uairq4OAJCfn4+srKxhvUBCCCGEjEyyQhwAq84YAoLFwdh8j6X6m7SeIYuXydltEiaPycHe2nYcrO/E+GJdUAoxVJyBYqgszwNJAvp9ATR19aMkJ3ybiFYmlxX+PRprKJMLBOS40+RYJqeyfft2XHzxxdrP99xzDwBgxYoVWLduHWpra1FTU6M9HggEsHr1ahw5cgQOhwOTJ0/GAw88gNtuu03b5tFHHwUAXHTRRUHP9fvf/x433XRTvIdICCGEkFHAoJ4hC5fJGcWPlfqFAN0pGG6Z3K6aFhxt6gKQPFEytUwVQw2dWHZmmXZ/SwY7Qy6HDSU5bpzu6ENta29EMSQ+30g9Q2Ny3LBJgC8go7Grz3yanDp0tavfD1mWIUlS1O1HGnGLoYsuuiiqRbdu3bqgn++44w7ccccdUfcZbX+EEEIIyUw8jtAABeuKIbtNQq7bgY4+n+XEUL7qFLT3DgzqxTHL+8dbceMT76F3IIDFk4px5tjIwz+Hgx6iEByvnamx2oKKfA9Od/ThVFsPZlXmh92mNUa0tsOuiKqGjj7Ut/WZTpMTPUP+gIw+X2DU9WxZc3IZIYQQQjKewc6QdcvkAH1RKSKirYIoaZNloKM3fndoz8k2fOWJrejo8+GcCUV44qYFsA1BUJlhSoR4bS1WO8OS5AR6vHbkRLnWGM6Qsh+lVO5UW49W9hYzTc6l/92NxlI5iiFCCCGEWBK3I3iZYqU+nHAIR2j++MI0H0kwLodNa4KPt1Tuo1NtWP7brWjv9WHB+EL87uaFyHYlT5SKRLlDDZ0IBPTKoUwOUAD0waunoiTKtWjR2pHfozI1Ue5QQydEYVasXjybTUK2a/Qmyln7EgshhBBCMhZJkuBx2tA7EABg7TlDAPDIP85DbVsvplkoVluQn+VEZ59PLaUyl3S3r7YdN/x2K9p6BnB2dQF+f/NCTVQli/FF2XDaJfQM+HGytQdVRdkAMjtAAQAqVGfoVBRnqK07epocoDtDB9QyRLfDZqrszet2oLvfj66+0Td4lc4QIYQQQiyLMVHOygEKgOJcWVEIAXrplNl47f11HVj+261o6R7AnKoCrPvqOSlx5hx2GyaV6O6QgM5Q9FlDA/4AOlTXJqozpIkh5b01+zelxWv3R3aGnt1Wgx++tAfvHWk2tU+rQDFECCGEEMtivGpt5QAFqyOa6ltNxGsfrO/AP/5mC5q7+jFrXD6e/Oo5KX3vp6ilcgcb9BCFjHeGCqL3DIl+IUmKHnsuBq9+ogpNs26rCFGI1jP0t4/q8YfNx7Cvtt3UPq0CxRAhhBBCLEuwM2TtMjkrky+coRg9Q4GAjK89uR1NXf04qyIPT91yTlJmCkVDT5TTnaFMjtYG9DK5+o4++AODU5jbepT3J8/jjJoWWK46Q/1+tfTU5GerxWtHEUMf1ynidXq5Nd3RSFAMEUIIIcSy0BlKDGZnDdV39OJYUzfsNgl/vGVR1JKrZCFKDUWiXJ/Pr5WAZaozNCbXDYdNgj8go6FjcKlcrBlDAuEMCcz+TWllchHEUHvvAE6qrtX08uTEricLiiFCCCGEWBaPU1mquOy2QelyxDwF6qyhthhlckcalaGqVYVZaXNhhDOkJJ7JmptlkzJXENttkpYEd6o1jBjqip0kB+jOkMC0M6SKoc4IAQoHVFdobL5HcyFHCvxXhRBCCCGWRcwaystyQJKSM9smEzAboHC0sRsAMLHEXOJcMhhf7IXDJqGzz4e69l49PCHblbT5RiMBkQRX2za4b0h8rtGS5AAg2+UI6hOKt2cokjO0b4SWyAEUQ4QQQgixMB6HKoYy1BFIFMIxiFUmd6RRKU2bkEYx5HLYtOc/WN+piaGiDC2RE4zVQhQGO0MiGKPAhNNjdIcS1TP0sRqaMH3syCqRAyiGCCGEEGJhPKozFGswJImOWCTHLpNLvzMEGEIUGjozPlZbUJEvBq+GcYa0nqHY71GZoW/I7EUGvUwuvBjaT2eIEEIIISTxiDQ5q88Ysjqmy+SalJ6hCcXWEEOHGjoyPlZboJXJhesZMhmgYNwPYD6hUQQodPcP7hmSZdmQJEdniBBCCCEkYYgABZbJDQ+tTK4rsjPkD8ioabKGMzRFJMrV0xkSiDK58M6Q3lcVi/IEO0MnWnrQ2eeD0y5h0pj0njdDgWKIEEIIIZZFd4ZYJjcchGPQ3usLO6cGAE619qDfH4DLbtOGfKaLcGVyme4MjRNiKGzPkHlnqGwoPUNRAhREidzkMTlw2keetBh5R0wIIYSQjGHmuHwAwJzKgvQeyAjHODi1PUKpnIjVri7Ojjq4MxVMLPHCJgFtPQPYX68sts24HqMZUd7W2NmHPl9wuVpLt7lobeN+APNpctHmDH1cp4QnzBiB4QkAwMsshBBCCLEsV88dh4umlY642SVWw2m3IdftQEefDy3d/WFLzqzSLwQow3bHF3txpLELu4+3AmCaXJHXBbfDhj5fAPVtfaguztYeE85QrGhtICRAIe45Q4PFkIjVPmMEhicAdIYIIYQQYnEohBJDfowQBeEMWaXvY4paKtfvCwCgGJIkSXN1QvuGWnuS2zOkO0ODAxRGcpIcQDFECCGEEJIRiIVya4R4bSGGrOAMAXrfkCDTxRAAjM1XZw0ZxFDvgB+9A4pgNHPhoMjrwgVTS3DOhCLTfVjeCGVyvQN+HD6tzKZimRwhhBBCCLEsWrx2hMGrR4UYKskO+3iqmVpGMRTK2ALVGTKEKIh+IYdNQq479tJekiQ8dcsiyLIMSTLXG+ZV53119fuCfu9QQycCsnJulea643otVoHOECGEEEJIBiBCFMKJoQF/AMdbFLch3bHagqmlwWVXFENARRhnyJgkZ1bcAIhrW+EMBWSgZ0AvlfvYUCIXz/6sBMUQIYQQQkgGEK1M7kRLD/wBGVlOO8pyPYMeTweTx+RArK+zXXZ41Jj1TEY4Q7VhnKH8JA4mznbZtc/C2Df0ca2SJDcSh60KKIYIIYQQQjKAgigBCkcalb6P8cXZsKU5VluQ5bKjslBxQjI9VlsgnKFTbboY0pPkkvceSZIEr2tw35CIPR+p4QkAxRAhhBBCSEYQrUzuSGM3AOuUyAlEqRxL5BT0nqFwZXLJfY/E4FVjvPa+WlUMjdDwBIBiiBBCCCEkIxDOQUuYMjk9PMFqYkgJUaAYUqgoUJyhtp4BdPcrokQfuJrcCPrQRLnGzj40dvZBkoBpIWEXIwmKIUIIIYSQDEAsltvClMmJgatWc4aWTCkBAMypKkjvgViEPI9Tm/kjEuVED5iZgavDQZs1pIowMV9ofFE2sl0jN6B65B45IYQQQggxTbRo7cOnrSmGLpw2Bju//+mkL/RHEmPzPTjY0Inath5MKc1JXZmcKng61QCFfaMgPAGgM0QIIYQQkhEURCiT6x3w45Qa1WyVgatGiryuERvbnAzGqqVyIlGuxRCtnUxCy+RErPYZIzg8AaAYIoQQQgjJCArUAIWOXh98/oB2//HmbsiyUgZVksPeHKtTka+GKKgCVi+TS+5nl6MGKAgxJMrkZoylGCKEEEIIIRbHOIemvVdPBDvSqJfI0YGxPmPzg50hEZWebGco2y3K5BQxfUCL1WaZHCGEEEIIsTgOuw25HmVBayyVO2LRJDkSHi1eO8QZKshKtjOknDvd/X4cbepGny+ALKcd1UXZSX3eZEMxRAghhBCSIYQLUdCS5IpH9qI2UxCDV2vbeiHLsj501ZvkniGX7gyJErlp5bmWGdI7VCiGCCGEEEIyBNFX0kpnaMQinKHa1h6lZC0gA0h+z5DX0DP0cZ2SJDdjhIcnABRDhBBCCCEZg+gbMjpDxp4hYn2EM9TV78expm4AgNthg8dpT+rz5hjS5EZLkhxAMUQIIYQQkjGIeG3RdN/d70N9ex8AiqGRQpbLrs1d2qvO+km2KwTo0dqdBmdopIcnABRDhBBCCCEZQ6HWM6SUyR1tVJyFgmxn0od2ksQhEuXE4NNkJ8kBujPU0N6H481KeMN0OkOEEEIIIWSkUBBSJifCE6w4bJVEpkLtG9p7KnViSDhDh9WyyrI8Nwq9I19AUwwRQgghhGQI+SFlcqJfaBJL5EYUwhlKbZlccE/SaCiRAyiGCCGEEEIyhtAyOSbJjUxEolyHOjw3FSWOokxOMBpK5ACKIUIIIYSQjCF0ztBRiqERiUiUE6SiTC7bFSKGxlIMEUIIIYSQEUR+liiTUwMUtIGrFEMjibH5nqCfC1MYoCBgmRwhhBBCCBlRaGVyXQNo7x1AY6ciiiaUZKfzsEicVBSEOkPJL5PzOG2wScpth03C5DE5SX/OVEAxRAghhBCSIYhFc0efD4caOgEAJTlu5HqS7yyQxFGW54Ek6T+LlMBkIkmSlig3eUwOXI7RISNGx6sghBBCCCExyTcsmt8/3goAmEhXaMThctgwJset/ZyqiGtRKjda+oUAiiFCCCGEkIzBbpOQ51EWtLtqWgFwxtBIZayhVC4VPUOAPmvojFGSJAdQDBFCCCGEZBSiVG7X8RYAwMQxFEMjkQpDiIIIxkg2IrhhblVBSp4vFThib0IIIYQQQkYLhdlO1DQDx5t7ADBJbqQy1hCvnYpobQC4//Oz8eGJNiyeVJyS50sFFEOEEEIIIRlEfkjyGGcMjUwq1MGruW4HnPbUFHuNK8jCuJAku5EOy+QIIYQQQjKI0OQx9gyNTIQzlJ8iV2i0QjFECCGEEJJBGJvtx+Z7kOWyp/FoyFA5e3wBctwOnDuKStbSAcvkCCGEEEIyCGOZHF2hkcvY/Cxsv28Z3KNk3k+6oBgihBBCCMkgjGVy7Bca2XicdPWGC6UkIYQQQkgGUejVxRAHrpJMh2KIEEIIISSDKDDMpJlYkpPGIyEk/VAMEUIIIYRkEMaZNHSGSKZDMUQIIYQQkkEUqgEKNgmoKqIYIpkNAxQIIYQQQjKI8cXZ+ML8SlQWZsHtYAM+yWwohgghhBBCMghJkvDzL85J92EQYglYJkcIIYQQQgjJSCiGCCGEEEIIIRkJxRAhhBBCCCEkI6EYIoQQQgghhGQkFEOEEEIIIYSQjIRiiBBCCCGEEJKRUAwRQgghhBBCMhKKIUIIIYQQQkhGQjFECCGEEEIIyUgohgghhBBCCCEZCcUQIYQQQgghJCOhGCKEEEIIIYRkJBRDhBBCCCGEkIyEYogQQgghhBCSkVAMEUIIIYQQQjISiiFCCCGEEEJIRhK3GNqwYQOuvPJKVFRUQJIkvPjii1G337RpE5YsWYLi4mJkZWVh+vTpePDBBwdtt3btWkyYMAEejweLFi3Ce++9F++hEUIIIYQQQohp4hZDXV1dmDNnDtauXWtqe6/Xi1WrVmHDhg3Yt28f7rvvPtx33314/PHHtW2effZZ3HPPPfjhD3+InTt3Ys6cObjsssvQ0NAQ7+ERQgghhBBCiCkkWZblIf+yJOGFF17ANddcE9fvXXvttfB6vXjqqacAAIsWLcLChQvxyCOPAAACgQCqqqpwxx134N577zW1z/b2duTn56OtrQ15eXlxHQ8hhBBCCCFk9GBWG6S8Z2jXrl149913sXTpUgBAf38/duzYgWXLlukHZbNh2bJl2Lx5c8T99PX1ob29PeiLEEIIIYQQQsySMjFUWVkJt9uNBQsWYOXKlfja174GAGhsbITf70dZWVnQ9mVlZairq4u4vzVr1iA/P1/7qqqqSurxE0IIIYQQQkYXjlQ90caNG9HZ2YktW7bg3nvvxZQpU3D99dcPeX+rV6/GPffco/3c1taG6upqOkSEEEIIIYRkOEITxOoISpkYmjhxIgBg1qxZqK+vx49+9CNcf/31KCkpgd1uR319fdD29fX1KC8vj7g/t9sNt9ut/SxeMB0iQgghhBBCCAB0dHQgPz8/4uMpE0NGAoEA+vr6AAAulwvz58/H+vXrtSCGQCCA9evXY9WqVab3WVFRgePHjyM3NxeSJCXjsE3T3t6OqqoqHD9+nGEOxDQ8b8hQ4HlDhgrPHTIUeN6QoZCO80aWZXR0dKCioiLqdnGLoc7OThw6dEj7+ciRI9i9ezeKiopQXV2N1atX4+TJk3jyyScBKPODqqurMX36dADKnKKf//zn+OY3v6nt45577sGKFSuwYMECnHPOOXjooYfQ1dWFm2++2fRx2Ww2VFZWxvtykkpeXh7/oSBxw/OGDAWeN2So8NwhQ4HnDRkKqT5vojlCgrjF0Pbt23HxxRdrP4u+nRUrVmDdunWora1FTU2N9nggEMDq1atx5MgROBwOTJ48GQ888ABuu+02bZvrrrsOp0+fxg9+8APU1dVh7ty5eP311weFKhBCCCGEEEJIohjWnCESHs48IkOB5w0ZCjxvyFDhuUOGAs8bMhSsfN6kfM5QJuB2u/HDH/4wKOCBkFjwvCFDgecNGSo8d8hQ4HlDhoKVzxs6Q4QQQgghhJCMhM4QIYQQQgghJCOhGCKEEEIIIYRkJBRDhBBCCCGEkIyEYogQQgghhBCSkVAMEUIIIYQQQjISiqEEs3btWkyYMAEejweLFi3Ce++9l+5DIhZizZo1WLhwIXJzc1FaWoprrrkG+/fvD9qmt7cXK1euRHFxMXJycvD5z38e9fX1aTpiYkXuv/9+SJKEu+66S7uP5w2JxMmTJ3HDDTeguLgYWVlZmDVrFrZv3649LssyfvCDH2Ds2LHIysrCsmXLcPDgwTQeMUk3fr8f3//+9zFx4kRkZWVh8uTJ+Nd//VcYA4h53hAA2LBhA6688kpUVFRAkiS8+OKLQY+bOU+am5uxfPly5OXloaCgALfccgs6OztT9hoohhLIs88+i3vuuQc//OEPsXPnTsyZMweXXXYZGhoa0n1oxCK88847WLlyJbZs2YI33ngDAwMDuPTSS9HV1aVtc/fdd+OVV17Bc889h3feeQenTp3Ctddem8ajJlZi27Zt+PWvf43Zs2cH3c/zhoSjpaUFS5YsgdPpxGuvvYa9e/fiF7/4BQoLC7Vtfvazn+Hhhx/GY489hq1bt8Lr9eKyyy5Db29vGo+cpJMHHngAjz76KB555BHs27cPDzzwAH72s5/hl7/8pbYNzxsCAF1dXZgzZw7Wrl0b9nEz58ny5cvx0Ucf4Y033sCrr76KDRs24NZbb03VSwBkkjDOOecceeXKldrPfr9frqiokNesWZPGoyJWpqGhQQYgv/POO7Isy3Jra6vsdDrl5557Tttm3759MgB58+bN6TpMYhE6OjrkqVOnym+88Ya8dOlS+c4775RlmecNicx3vvMd+fzzz4/4eCAQkMvLy+V///d/1+5rbW2V3W63/Oc//zkVh0gsyBVXXCF/9atfDbrv2muvlZcvXy7LMs8bEh4A8gsvvKD9bOY82bt3rwxA3rZtm7bNa6+9JkuSJJ88eTIlx01nKEH09/djx44dWLZsmXafzWbDsmXLsHnz5jQeGbEybW1tAICioiIAwI4dOzAwMBB0Hk2fPh3V1dU8jwhWrlyJK664Iuj8AHjekMi8/PLLWLBgAb74xS+itLQU8+bNw29+8xvt8SNHjqCuri7o3MnPz8eiRYt47mQw5513HtavX48DBw4AAN5//31s2rQJl19+OQCeN8QcZs6TzZs3o6CgAAsWLNC2WbZsGWw2G7Zu3ZqS43Sk5FkygMbGRvj9fpSVlQXdX1ZWho8//jhNR0WsTCAQwF133YUlS5Zg5syZAIC6ujq4XC4UFBQEbVtWVoa6uro0HCWxCs888wx27tyJbdu2DXqM5w2JxOHDh/Hoo4/innvuwXe/+11s27YN3/zmN+FyubBixQrt/Aj3fxfPnczl3nvvRXt7O6ZPnw673Q6/34+f/OQnWL58OQDwvCGmMHOe1NXVobS0NOhxh8OBoqKilJ1LFEOEpImVK1diz5492LRpU7oPhVic48eP484778Qbb7wBj8eT7sMhI4hAIIAFCxbgpz/9KQBg3rx52LNnDx577DGsWLEizUdHrMpf/vIXPP300/jTn/6Es846C7t378Zdd92FiooKnjdk1MEyuQRRUlICu90+KL2pvr4e5eXlaToqYlVWrVqFV199FW+99RYqKyu1+8vLy9Hf34/W1tag7XkeZTY7duxAQ0MDzj77bDgcDjgcDrzzzjt4+OGH4XA4UFZWxvOGhGXs2LE488wzg+6bMWMGampqAEA7P/h/FzHyrW99C/feey++/OUvY9asWfjKV76Cu+++G2vWrAHA84aYw8x5Ul5ePihozOfzobm5OWXnEsVQgnC5XJg/fz7Wr1+v3RcIBLB+/XosXrw4jUdGrIQsy1i1ahVeeOEFvPnmm5g4cWLQ4/Pnz4fT6Qw6j/bv34+amhqeRxnMJZdcgg8//BC7d+/WvhYsWIDly5drt3nekHAsWbJkUHz/gQMHMH78eADAxIkTUV5eHnTutLe3Y+vWrTx3Mpju7m7YbMFLRLvdjkAgAIDnDTGHmfNk8eLFaG1txY4dO7Rt3nzzTQQCASxatCg1B5qSmIYM4ZlnnpHdbre8bt06ee/evfKtt94qFxQUyHV1dek+NGIRbr/9djk/P19+++235draWu2ru7tb2+Yb3/iGXF1dLb/55pvy9u3b5cWLF8uLFy9O41ETK2JMk5NlnjckPO+9957scDjkn/zkJ/LBgwflp59+Ws7Ozpb/+Mc/atvcf//9ckFBgfzSSy/JH3zwgXz11VfLEydOlHt6etJ45CSdrFixQh43bpz86quvykeOHJGff/55uaSkRP72t7+tbcPzhsiyknK6a9cuedeuXTIA+T/+4z/kXbt2yceOHZNl2dx58pnPfEaeN2+evHXrVnnTpk3y1KlT5euvvz5lr4FiKMH88pe/lKurq2WXyyWfc8458pYtW9J9SMRCAAj79fvf/17bpqenR/6nf/onubCwUM7OzpY/97nPybW1tek7aGJJQsUQzxsSiVdeeUWeOXOm7Ha75enTp8uPP/540OOBQED+/ve/L5eVlclut1u+5JJL5P3796fpaIkVaG9vl++88065urpa9ng88qRJk+Tvfe97cl9fn7YNzxsiy7L81ltvhV3XrFixQpZlc+dJU1OTfP3118s5OTlyXl6efPPNN8sdHR0pew2SLBvGCRNCCCGEEEJIhsCeIUIIIYQQQkhGQjFECCGEEEIIyUgohgghhBBCCCEZCcUQIYQQQgghJCOhGCKEEEIIIYRkJBRDhBBCCCGEkIyEYogQQgghhBCSkVAMEUIIIYQQQjISiiFCCCGEEEJIRkIxRAghhBBCCMlIKIYIIYQQQgghGcn/B8DjD9BSASg6AAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 1000x700 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import confusion_matrix,classification_report\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import preprocessing\n",
    "import matplotlib.pyplot as plt\n",
    "#subjectnames\n",
    "file_list_num = np.arange(len(newsubjectname))\n",
    "file_list_numd = np.arange(len(subjectnamesd))\n",
    "\n",
    "kf = KFold(n_splits=12)\n",
    "torch.manual_seed(42)\n",
    "torch.cuda.manual_seed(42)\n",
    "modellist = []\n",
    "modelid = 1\n",
    "#file_list_num\n",
    "#for i, (train_index, test_index) in enumerate(kf.split(file_list_num)):\n",
    "#for train_index in file_list_num:\n",
    "train_index = file_list_num\n",
    "#test_index = file_list_numd\n",
    "test_index_train, test_index_test = train_test_split(file_list_numd, test_size=0.30, random_state=42)\n",
    "print(f\"Fold {i}:\")\n",
    "print(f\"  Train: index={train_index}\")\n",
    "#print(f\"  Test:  index={test_index}\")\n",
    "net = Net()\n",
    "net.to(device)\n",
    "optimizer = optim.Adam(net.parameters(), lr=0.000001)\n",
    "epochs = 100\n",
    "batch_sz = 20\n",
    "train_loss_epoch = []\n",
    "val_loss_epoch = []\n",
    "for epoch in range(epochs):\n",
    "  train_loss = []\n",
    "  for tr in train_index:\n",
    "    v = data_c1d[newsubjectname[tr]]\n",
    "    l = data_c2[newsubjectname[tr]]\n",
    "    #print(v[0].shape)\n",
    "    net.train()\n",
    "    for i in range(0,len(v),batch_sz):\n",
    "      #print(v[i].shape)\n",
    "      #for j in range(0,v[i].shape[0],batch_sz):\n",
    "      #print(newsubjectname[tr])\n",
    "      optimizer.zero_grad()\n",
    "      outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
    "      #print(\"Expout {}\",outputs.shape)\n",
    "      #print(\"Actual {}\",l[i:i+batch_sz].shape)\n",
    "      #print(l[i].shape)\n",
    "      loss = criterion(outputs, l[i:i+batch_sz].to(device, dtype=torch.float))\n",
    "      loss.backward()\n",
    "      train_loss.append(loss)\n",
    "      optimizer.step()\n",
    "  print(f'Epoch {epoch + 1}/{epochs}, Train Loss: {loss.item()}')\n",
    "  train_loss_epoch.append(torch.stack(train_loss).mean().cpu().detach().numpy())\n",
    "  #print(train_loss_epoch)\n",
    "  batch_sz = 20\n",
    "  expectedoutputdeap = []\n",
    "  actualoutputdeap = []\n",
    "\n",
    "  for tr in test_index_train:\n",
    "    v = data_de1[subjectnamesd[tr]]\n",
    "    l = data_del[subjectnamesd[tr]]\n",
    "    #print(v[0].shape)\n",
    "    net.train()\n",
    "    for i in range(0,len(v),batch_sz):\n",
    "      #print(v[i].shape)\n",
    "      #for j in range(0,v[i].shape[0],batch_sz):\n",
    "      #print(newsubjectname[tr])\n",
    "      optimizer.zero_grad()\n",
    "      outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
    "      #print(\"Expout {}\",outputs.shape)\n",
    "      #print(\"Actual {}\",l[i:i+batch_sz].shape)\n",
    "      #print(l[i].shape)\n",
    "      loss = criterion(outputs, l[i:i+batch_sz].to(device, dtype=torch.float))\n",
    "      loss.backward()\n",
    "      train_loss.append(loss)\n",
    "      optimizer.step()\n",
    "\n",
    "  for tr in test_index_test:\n",
    "      net.eval()\n",
    "      v = data_de1[subjectnamesd[tr]]\n",
    "      l = data_del[subjectnamesd[tr]]\n",
    "      net.eval()\n",
    "      val_loss = []\n",
    "      with torch.no_grad():\n",
    "          for i in range(0,len(v),batch_sz):\n",
    "            #print(v[i].shape)\n",
    "            #for j in range(0,v[i].shape[0],batch_sz):\n",
    "            optimizer.zero_grad()\n",
    "            outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
    "            #print(outputs.shape)\n",
    "            #print(l[i:i+batch_sz].shape)\n",
    "            loss = criterion(outputs, l[i:i+batch_sz].to(device, dtype=torch.float))\n",
    "            val_loss.append(loss)\n",
    "            #actualoutputdeap.append(torch.round(outputs.cpu()))\n",
    "            #expectedoutputdeap.append(l[i:i+batch_sz])\n",
    "            actualoutputdeap.append(torch.argmax(torch.softmax(outputs.cpu(),dim=1),dim=1))\n",
    "            expectedoutputdeap.append(torch.argmax(l[i:i+batch_sz],dim=1).numpy())\n",
    "  val_loss_mean = torch.stack(val_loss).mean().cpu().detach().numpy()\n",
    "  val_loss_epoch.append(val_loss_mean)\n",
    "  expectedoutputdeap = np.concatenate( expectedoutputdeap, axis=0 )\n",
    "  actualoutputdeap = np.concatenate( actualoutputdeap, axis=0 )\n",
    "  #print(expectedoutput.shape)\n",
    "  #print(actualoutput.shape)\n",
    "  print(classification_report(expectedoutputdeap,actualoutputdeap))\n",
    "  print(confusion_matrix(expectedoutputdeap,actualoutputdeap))\n",
    "  print(f'Validation Loss for {subjectnamesd[tr]} = {val_loss_mean}')\n",
    "plt.figure(figsize=(10,7))\n",
    "#print(len(train_loss_epoch))\n",
    "plt.plot(np.arange(epochs),train_loss_epoch,label='Train')\n",
    "plt.plot(np.arange(epochs),val_loss_epoch,label='Validation')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82511330-d09b-4538-a8f5-32a8c2e5d91e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-23T13:23:28.057924Z",
     "iopub.status.busy": "2024-01-23T13:23:28.057100Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 20:\n",
      "  Train: index=[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23\n",
      " 24 25 26 27 28 29 30 31]\n",
      "  Test:  index=[34  0  4 29 15 19  5 11  1 24  2 33  3 32 23 27 10 22 18 25  6 20  7 14\n",
      " 28]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_96/2974510044.py:43: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n",
      "/tmp/ipykernel_96/2974510044.py:61: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100, Train Loss: 1.3577150106430054\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.21      0.07      0.11        43\n",
      "           1       0.26      0.28      0.27        61\n",
      "           2       0.35      0.26      0.30        61\n",
      "           3       0.24      0.42      0.31        55\n",
      "\n",
      "    accuracy                           0.27       220\n",
      "   macro avg       0.27      0.26      0.25       220\n",
      "weighted avg       0.27      0.27      0.25       220\n",
      "\n",
      "[[ 3 14  5 21]\n",
      " [ 5 17  9 30]\n",
      " [ 4 21 16 20]\n",
      " [ 2 14 16 23]]\n",
      "Validation Loss for P40 = 1.4187015295028687\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_96/2974510044.py:87: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/tmp/ipykernel_96/2974510044.py:43: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n",
      "/tmp/ipykernel_96/2974510044.py:61: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/100, Train Loss: 1.376932978630066\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.34      0.49      0.40        43\n",
      "           1       0.31      0.31      0.31        61\n",
      "           2       0.33      0.28      0.30        61\n",
      "           3       0.33      0.27      0.30        55\n",
      "\n",
      "    accuracy                           0.33       220\n",
      "   macro avg       0.33      0.34      0.33       220\n",
      "weighted avg       0.33      0.33      0.32       220\n",
      "\n",
      "[[21 11  6  5]\n",
      " [16 19 10 16]\n",
      " [16 18 17 10]\n",
      " [ 9 13 18 15]]\n",
      "Validation Loss for P40 = 1.411934733390808\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_96/2974510044.py:87: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/tmp/ipykernel_96/2974510044.py:43: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n",
      "/tmp/ipykernel_96/2974510044.py:61: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/100, Train Loss: 1.4020754098892212\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.32      0.56      0.41        43\n",
      "           1       0.30      0.30      0.30        61\n",
      "           2       0.38      0.28      0.32        61\n",
      "           3       0.30      0.22      0.25        55\n",
      "\n",
      "    accuracy                           0.32       220\n",
      "   macro avg       0.32      0.34      0.32       220\n",
      "weighted avg       0.33      0.32      0.31       220\n",
      "\n",
      "[[24 10  5  4]\n",
      " [19 18 10 14]\n",
      " [18 16 17 10]\n",
      " [14 16 13 12]]\n",
      "Validation Loss for P40 = 1.408593773841858\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_96/2974510044.py:87: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/tmp/ipykernel_96/2974510044.py:43: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n",
      "/tmp/ipykernel_96/2974510044.py:61: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/100, Train Loss: 1.4329832792282104\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.29      0.58      0.39        43\n",
      "           1       0.28      0.20      0.23        61\n",
      "           2       0.38      0.33      0.35        61\n",
      "           3       0.33      0.24      0.27        55\n",
      "\n",
      "    accuracy                           0.32       220\n",
      "   macro avg       0.32      0.34      0.31       220\n",
      "weighted avg       0.32      0.32      0.31       220\n",
      "\n",
      "[[25  8  5  5]\n",
      " [23 12 12 14]\n",
      " [21 12 20  8]\n",
      " [16 11 15 13]]\n",
      "Validation Loss for P40 = 1.408947229385376\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_96/2974510044.py:87: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/tmp/ipykernel_96/2974510044.py:43: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n",
      "/tmp/ipykernel_96/2974510044.py:61: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/100, Train Loss: 1.3117915391921997\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.28      0.58      0.38        43\n",
      "           1       0.27      0.18      0.22        61\n",
      "           2       0.39      0.34      0.37        61\n",
      "           3       0.31      0.20      0.24        55\n",
      "\n",
      "    accuracy                           0.31       220\n",
      "   macro avg       0.31      0.33      0.30       220\n",
      "weighted avg       0.31      0.31      0.30       220\n",
      "\n",
      "[[25  8  5  5]\n",
      " [25 11 12 13]\n",
      " [22 11 21  7]\n",
      " [17 11 16 11]]\n",
      "Validation Loss for P40 = 1.4100793600082397\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_96/2974510044.py:87: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/tmp/ipykernel_96/2974510044.py:43: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n",
      "/tmp/ipykernel_96/2974510044.py:61: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6/100, Train Loss: 1.4328091144561768\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.27      0.56      0.37        43\n",
      "           1       0.26      0.21      0.23        61\n",
      "           2       0.46      0.26      0.33        61\n",
      "           3       0.30      0.25      0.27        55\n",
      "\n",
      "    accuracy                           0.30       220\n",
      "   macro avg       0.32      0.32      0.30       220\n",
      "weighted avg       0.33      0.30      0.30       220\n",
      "\n",
      "[[24  9  3  7]\n",
      " [25 13  7 16]\n",
      " [22 13 16 10]\n",
      " [17 15  9 14]]\n",
      "Validation Loss for P40 = 1.3974103927612305\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_96/2974510044.py:87: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/tmp/ipykernel_96/2974510044.py:43: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n",
      "/tmp/ipykernel_96/2974510044.py:61: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7/100, Train Loss: 1.3446555137634277\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.28      0.58      0.38        43\n",
      "           1       0.25      0.21      0.23        61\n",
      "           2       0.45      0.25      0.32        61\n",
      "           3       0.29      0.24      0.26        55\n",
      "\n",
      "    accuracy                           0.30       220\n",
      "   macro avg       0.32      0.32      0.30       220\n",
      "weighted avg       0.32      0.30      0.29       220\n",
      "\n",
      "[[25  8  3  7]\n",
      " [25 13  7 16]\n",
      " [22 15 15  9]\n",
      " [18 16  8 13]]\n",
      "Validation Loss for P40 = 1.3959490060806274\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_96/2974510044.py:87: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/tmp/ipykernel_96/2974510044.py:43: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n",
      "/tmp/ipykernel_96/2974510044.py:61: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8/100, Train Loss: 1.4171262979507446\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.27      0.58      0.37        43\n",
      "           1       0.27      0.23      0.25        61\n",
      "           2       0.45      0.25      0.32        61\n",
      "           3       0.32      0.25      0.28        55\n",
      "\n",
      "    accuracy                           0.31       220\n",
      "   macro avg       0.33      0.33      0.31       220\n",
      "weighted avg       0.33      0.31      0.30       220\n",
      "\n",
      "[[25  8  3  7]\n",
      " [26 14  7 14]\n",
      " [22 15 15  9]\n",
      " [18 15  8 14]]\n",
      "Validation Loss for P40 = 1.3976202011108398\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_96/2974510044.py:87: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/tmp/ipykernel_96/2974510044.py:43: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n",
      "/tmp/ipykernel_96/2974510044.py:61: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9/100, Train Loss: 1.4436120986938477\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.26      0.56      0.36        43\n",
      "           1       0.27      0.23      0.25        61\n",
      "           2       0.46      0.26      0.33        61\n",
      "           3       0.31      0.24      0.27        55\n",
      "\n",
      "    accuracy                           0.30       220\n",
      "   macro avg       0.33      0.32      0.30       220\n",
      "weighted avg       0.33      0.30      0.30       220\n",
      "\n",
      "[[24  9  3  7]\n",
      " [27 14  7 13]\n",
      " [23 13 16  9]\n",
      " [18 15  9 13]]\n",
      "Validation Loss for P40 = 1.3932468891143799\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_96/2974510044.py:87: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/tmp/ipykernel_96/2974510044.py:43: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n",
      "/tmp/ipykernel_96/2974510044.py:61: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10/100, Train Loss: 1.4726126194000244\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.26      0.56      0.36        43\n",
      "           1       0.29      0.26      0.28        61\n",
      "           2       0.48      0.23      0.31        61\n",
      "           3       0.33      0.27      0.30        55\n",
      "\n",
      "    accuracy                           0.31       220\n",
      "   macro avg       0.34      0.33      0.31       220\n",
      "weighted avg       0.35      0.31      0.31       220\n",
      "\n",
      "[[24  9  3  7]\n",
      " [26 16  5 14]\n",
      " [23 15 14  9]\n",
      " [18 15  7 15]]\n",
      "Validation Loss for P40 = 1.3901711702346802\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_96/2974510044.py:87: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/tmp/ipykernel_96/2974510044.py:43: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n",
      "/tmp/ipykernel_96/2974510044.py:61: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11/100, Train Loss: 1.4617708921432495\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.27      0.60      0.37        43\n",
      "           1       0.31      0.26      0.28        61\n",
      "           2       0.47      0.23      0.31        61\n",
      "           3       0.34      0.25      0.29        55\n",
      "\n",
      "    accuracy                           0.32       220\n",
      "   macro avg       0.35      0.34      0.31       220\n",
      "weighted avg       0.35      0.32      0.31       220\n",
      "\n",
      "[[26  7  3  7]\n",
      " [28 16  5 12]\n",
      " [25 14 14  8]\n",
      " [18 15  8 14]]\n",
      "Validation Loss for P40 = 1.3884048461914062\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_96/2974510044.py:87: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/tmp/ipykernel_96/2974510044.py:43: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n",
      "/tmp/ipykernel_96/2974510044.py:61: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12/100, Train Loss: 1.3704133033752441\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.27      0.60      0.37        43\n",
      "           1       0.30      0.25      0.27        61\n",
      "           2       0.45      0.25      0.32        61\n",
      "           3       0.33      0.24      0.27        55\n",
      "\n",
      "    accuracy                           0.31       220\n",
      "   macro avg       0.34      0.33      0.31       220\n",
      "weighted avg       0.34      0.31      0.30       220\n",
      "\n",
      "[[26  7  3  7]\n",
      " [28 15  6 12]\n",
      " [25 13 15  8]\n",
      " [18 15  9 13]]\n",
      "Validation Loss for P40 = 1.3895094394683838\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_96/2974510044.py:87: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/tmp/ipykernel_96/2974510044.py:43: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n",
      "/tmp/ipykernel_96/2974510044.py:61: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13/100, Train Loss: 1.365146517753601\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.27      0.58      0.36        43\n",
      "           1       0.31      0.26      0.29        61\n",
      "           2       0.47      0.23      0.31        61\n",
      "           3       0.36      0.29      0.32        55\n",
      "\n",
      "    accuracy                           0.32       220\n",
      "   macro avg       0.35      0.34      0.32       220\n",
      "weighted avg       0.36      0.32      0.32       220\n",
      "\n",
      "[[25  7  4  7]\n",
      " [27 16  5 13]\n",
      " [25 13 14  9]\n",
      " [17 15  7 16]]\n",
      "Validation Loss for P40 = 1.3890589475631714\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_96/2974510044.py:87: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/tmp/ipykernel_96/2974510044.py:43: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n",
      "/tmp/ipykernel_96/2974510044.py:61: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14/100, Train Loss: 1.4408514499664307\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.27      0.60      0.37        43\n",
      "           1       0.31      0.23      0.26        61\n",
      "           2       0.45      0.23      0.30        61\n",
      "           3       0.35      0.29      0.32        55\n",
      "\n",
      "    accuracy                           0.32       220\n",
      "   macro avg       0.34      0.34      0.31       220\n",
      "weighted avg       0.35      0.32      0.31       220\n",
      "\n",
      "[[26  5  5  7]\n",
      " [28 14  5 14]\n",
      " [25 13 14  9]\n",
      " [19 13  7 16]]\n",
      "Validation Loss for P40 = 1.3850816488265991\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_96/2974510044.py:87: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/tmp/ipykernel_96/2974510044.py:43: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n",
      "/tmp/ipykernel_96/2974510044.py:61: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15/100, Train Loss: 1.5525652170181274\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.27      0.58      0.37        43\n",
      "           1       0.31      0.25      0.28        61\n",
      "           2       0.38      0.25      0.30        61\n",
      "           3       0.30      0.22      0.25        55\n",
      "\n",
      "    accuracy                           0.30       220\n",
      "   macro avg       0.32      0.32      0.30       220\n",
      "weighted avg       0.32      0.30      0.29       220\n",
      "\n",
      "[[25  6  5  7]\n",
      " [26 15  7 13]\n",
      " [25 13 15  8]\n",
      " [17 14 12 12]]\n",
      "Validation Loss for P40 = 1.3872101306915283\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_96/2974510044.py:87: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/tmp/ipykernel_96/2974510044.py:43: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n",
      "/tmp/ipykernel_96/2974510044.py:61: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16/100, Train Loss: 1.491980791091919\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.26      0.58      0.36        43\n",
      "           1       0.32      0.26      0.29        61\n",
      "           2       0.43      0.20      0.27        61\n",
      "           3       0.34      0.29      0.31        55\n",
      "\n",
      "    accuracy                           0.31       220\n",
      "   macro avg       0.34      0.33      0.31       220\n",
      "weighted avg       0.34      0.31      0.30       220\n",
      "\n",
      "[[25  6  5  7]\n",
      " [26 16  5 14]\n",
      " [25 14 12 10]\n",
      " [19 14  6 16]]\n",
      "Validation Loss for P40 = 1.3854228258132935\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_96/2974510044.py:87: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/tmp/ipykernel_96/2974510044.py:43: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n",
      "/tmp/ipykernel_96/2974510044.py:61: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17/100, Train Loss: 1.5585073232650757\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.26      0.56      0.35        43\n",
      "           1       0.33      0.28      0.30        61\n",
      "           2       0.42      0.21      0.28        61\n",
      "           3       0.34      0.27      0.30        55\n",
      "\n",
      "    accuracy                           0.31       220\n",
      "   macro avg       0.34      0.33      0.31       220\n",
      "weighted avg       0.34      0.31      0.31       220\n",
      "\n",
      "[[24  7  5  7]\n",
      " [26 17  5 13]\n",
      " [25 14 13  9]\n",
      " [18 14  8 15]]\n",
      "Validation Loss for P40 = 1.3841251134872437\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_96/2974510044.py:87: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/tmp/ipykernel_96/2974510044.py:43: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n",
      "/tmp/ipykernel_96/2974510044.py:61: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 18/100, Train Loss: 1.4253458976745605\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.26      0.56      0.36        43\n",
      "           1       0.31      0.26      0.29        61\n",
      "           2       0.40      0.20      0.26        61\n",
      "           3       0.36      0.31      0.33        55\n",
      "\n",
      "    accuracy                           0.31       220\n",
      "   macro avg       0.33      0.33      0.31       220\n",
      "weighted avg       0.34      0.31      0.31       220\n",
      "\n",
      "[[24  7  5  7]\n",
      " [26 16  6 13]\n",
      " [25 14 12 10]\n",
      " [17 14  7 17]]\n",
      "Validation Loss for P40 = 1.3863104581832886\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_96/2974510044.py:87: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/tmp/ipykernel_96/2974510044.py:43: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n",
      "/tmp/ipykernel_96/2974510044.py:61: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19/100, Train Loss: 1.3247933387756348\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.26      0.56      0.35        43\n",
      "           1       0.28      0.23      0.25        61\n",
      "           2       0.35      0.20      0.25        61\n",
      "           3       0.35      0.27      0.31        55\n",
      "\n",
      "    accuracy                           0.30       220\n",
      "   macro avg       0.31      0.31      0.29       220\n",
      "weighted avg       0.31      0.30      0.29       220\n",
      "\n",
      "[[24  7  6  6]\n",
      " [27 14  7 13]\n",
      " [25 15 12  9]\n",
      " [17 14  9 15]]\n",
      "Validation Loss for P40 = 1.3816759586334229\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_96/2974510044.py:87: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/tmp/ipykernel_96/2974510044.py:43: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n",
      "/tmp/ipykernel_96/2974510044.py:61: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20/100, Train Loss: 1.3253430128097534\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.26      0.56      0.36        43\n",
      "           1       0.32      0.26      0.29        61\n",
      "           2       0.39      0.23      0.29        61\n",
      "           3       0.36      0.27      0.31        55\n",
      "\n",
      "    accuracy                           0.31       220\n",
      "   macro avg       0.33      0.33      0.31       220\n",
      "weighted avg       0.34      0.31      0.31       220\n",
      "\n",
      "[[24  7  6  6]\n",
      " [26 16  7 12]\n",
      " [25 13 14  9]\n",
      " [17 14  9 15]]\n",
      "Validation Loss for P40 = 1.3790878057479858\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_96/2974510044.py:87: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/tmp/ipykernel_96/2974510044.py:43: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n",
      "/tmp/ipykernel_96/2974510044.py:61: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 21/100, Train Loss: 1.289635181427002\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.27      0.58      0.36        43\n",
      "           1       0.32      0.25      0.28        61\n",
      "           2       0.44      0.28      0.34        61\n",
      "           3       0.38      0.27      0.32        55\n",
      "\n",
      "    accuracy                           0.33       220\n",
      "   macro avg       0.35      0.34      0.32       220\n",
      "weighted avg       0.36      0.33      0.32       220\n",
      "\n",
      "[[25  6  6  6]\n",
      " [27 15  7 12]\n",
      " [25 12 17  7]\n",
      " [17 14  9 15]]\n",
      "Validation Loss for P40 = 1.383111596107483\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_96/2974510044.py:87: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/tmp/ipykernel_96/2974510044.py:43: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n",
      "/tmp/ipykernel_96/2974510044.py:61: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 22/100, Train Loss: 1.3949357271194458\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.26      0.56      0.36        43\n",
      "           1       0.33      0.26      0.29        61\n",
      "           2       0.45      0.30      0.36        61\n",
      "           3       0.39      0.29      0.33        55\n",
      "\n",
      "    accuracy                           0.34       220\n",
      "   macro avg       0.36      0.35      0.34       220\n",
      "weighted avg       0.37      0.34      0.33       220\n",
      "\n",
      "[[24  7  6  6]\n",
      " [26 16  7 12]\n",
      " [24 12 18  7]\n",
      " [17 13  9 16]]\n",
      "Validation Loss for P40 = 1.3776201009750366\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_96/2974510044.py:87: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/tmp/ipykernel_96/2974510044.py:43: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n",
      "/tmp/ipykernel_96/2974510044.py:61: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 23/100, Train Loss: 1.3574507236480713\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.27      0.60      0.37        43\n",
      "           1       0.30      0.20      0.24        61\n",
      "           2       0.45      0.28      0.34        61\n",
      "           3       0.36      0.29      0.32        55\n",
      "\n",
      "    accuracy                           0.32       220\n",
      "   macro avg       0.34      0.34      0.32       220\n",
      "weighted avg       0.35      0.32      0.31       220\n",
      "\n",
      "[[26  5  6  6]\n",
      " [30 12  6 13]\n",
      " [25 10 17  9]\n",
      " [17 13  9 16]]\n",
      "Validation Loss for P40 = 1.3777981996536255\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_96/2974510044.py:87: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/tmp/ipykernel_96/2974510044.py:43: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n",
      "/tmp/ipykernel_96/2974510044.py:61: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 24/100, Train Loss: 1.4168967008590698\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.26      0.58      0.36        43\n",
      "           1       0.30      0.21      0.25        61\n",
      "           2       0.44      0.26      0.33        61\n",
      "           3       0.38      0.31      0.34        55\n",
      "\n",
      "    accuracy                           0.32       220\n",
      "   macro avg       0.35      0.34      0.32       220\n",
      "weighted avg       0.35      0.32      0.32       220\n",
      "\n",
      "[[25  6  6  6]\n",
      " [29 13  6 13]\n",
      " [25 11 16  9]\n",
      " [17 13  8 17]]\n",
      "Validation Loss for P40 = 1.3765473365783691\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_96/2974510044.py:87: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/tmp/ipykernel_96/2974510044.py:43: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n",
      "/tmp/ipykernel_96/2974510044.py:61: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 25/100, Train Loss: 1.450889229774475\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.26      0.56      0.36        43\n",
      "           1       0.28      0.21      0.24        61\n",
      "           2       0.41      0.26      0.32        61\n",
      "           3       0.35      0.27      0.31        55\n",
      "\n",
      "    accuracy                           0.31       220\n",
      "   macro avg       0.33      0.33      0.31       220\n",
      "weighted avg       0.33      0.31      0.30       220\n",
      "\n",
      "[[24  7  6  6]\n",
      " [28 13  7 13]\n",
      " [24 12 16  9]\n",
      " [16 14 10 15]]\n",
      "Validation Loss for P40 = 1.377549409866333\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_96/2974510044.py:87: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/tmp/ipykernel_96/2974510044.py:43: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n",
      "/tmp/ipykernel_96/2974510044.py:61: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 26/100, Train Loss: 1.364749789237976\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.26      0.56      0.36        43\n",
      "           1       0.29      0.23      0.25        61\n",
      "           2       0.41      0.26      0.32        61\n",
      "           3       0.38      0.27      0.32        55\n",
      "\n",
      "    accuracy                           0.31       220\n",
      "   macro avg       0.33      0.33      0.31       220\n",
      "weighted avg       0.34      0.31      0.31       220\n",
      "\n",
      "[[24  7  7  5]\n",
      " [28 14  7 12]\n",
      " [24 13 16  8]\n",
      " [16 15  9 15]]\n",
      "Validation Loss for P40 = 1.3759098052978516\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_96/2974510044.py:87: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/tmp/ipykernel_96/2974510044.py:43: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n",
      "/tmp/ipykernel_96/2974510044.py:61: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 27/100, Train Loss: 1.3228174448013306\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.27      0.60      0.37        43\n",
      "           1       0.28      0.18      0.22        61\n",
      "           2       0.39      0.25      0.30        61\n",
      "           3       0.33      0.27      0.30        55\n",
      "\n",
      "    accuracy                           0.30       220\n",
      "   macro avg       0.32      0.33      0.30       220\n",
      "weighted avg       0.32      0.30      0.29       220\n",
      "\n",
      "[[26  5  7  5]\n",
      " [29 11  7 14]\n",
      " [25 10 15 11]\n",
      " [17 14  9 15]]\n",
      "Validation Loss for P40 = 1.3694981336593628\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_96/2974510044.py:87: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/tmp/ipykernel_96/2974510044.py:43: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n",
      "/tmp/ipykernel_96/2974510044.py:61: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 28/100, Train Loss: 1.3317664861679077\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.27      0.58      0.37        43\n",
      "           1       0.30      0.21      0.25        61\n",
      "           2       0.41      0.28      0.33        61\n",
      "           3       0.35      0.27      0.31        55\n",
      "\n",
      "    accuracy                           0.32       220\n",
      "   macro avg       0.33      0.34      0.31       220\n",
      "weighted avg       0.34      0.32      0.31       220\n",
      "\n",
      "[[25  6  6  6]\n",
      " [26 13  8 14]\n",
      " [24 12 17  8]\n",
      " [17 13 10 15]]\n",
      "Validation Loss for P40 = 1.3712488412857056\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_96/2974510044.py:87: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/tmp/ipykernel_96/2974510044.py:43: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n",
      "/tmp/ipykernel_96/2974510044.py:61: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 29/100, Train Loss: 1.3627420663833618\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.27      0.60      0.37        43\n",
      "           1       0.27      0.18      0.22        61\n",
      "           2       0.41      0.26      0.32        61\n",
      "           3       0.35      0.27      0.31        55\n",
      "\n",
      "    accuracy                           0.31       220\n",
      "   macro avg       0.32      0.33      0.30       220\n",
      "weighted avg       0.33      0.31      0.30       220\n",
      "\n",
      "[[26  5  7  5]\n",
      " [29 11  7 14]\n",
      " [25 11 16  9]\n",
      " [17 14  9 15]]\n",
      "Validation Loss for P40 = 1.3725799322128296\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_96/2974510044.py:87: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/tmp/ipykernel_96/2974510044.py:43: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n",
      "/tmp/ipykernel_96/2974510044.py:61: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 30/100, Train Loss: 1.346318244934082\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.27      0.60      0.37        43\n",
      "           1       0.26      0.16      0.20        61\n",
      "           2       0.44      0.33      0.38        61\n",
      "           3       0.36      0.25      0.30        55\n",
      "\n",
      "    accuracy                           0.32       220\n",
      "   macro avg       0.33      0.34      0.31       220\n",
      "weighted avg       0.34      0.32      0.31       220\n",
      "\n",
      "[[26  5  7  5]\n",
      " [29 10  8 14]\n",
      " [25 10 20  6]\n",
      " [17 14 10 14]]\n",
      "Validation Loss for P40 = 1.3713691234588623\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_96/2974510044.py:87: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/tmp/ipykernel_96/2974510044.py:43: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n",
      "/tmp/ipykernel_96/2974510044.py:61: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 31/100, Train Loss: 1.4610604047775269\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.26      0.60      0.37        43\n",
      "           1       0.24      0.15      0.18        61\n",
      "           2       0.44      0.30      0.35        61\n",
      "           3       0.38      0.29      0.33        55\n",
      "\n",
      "    accuracy                           0.31       220\n",
      "   macro avg       0.33      0.33      0.31       220\n",
      "weighted avg       0.33      0.31      0.30       220\n",
      "\n",
      "[[26  5  7  5]\n",
      " [30  9  8 14]\n",
      " [26 10 18  7]\n",
      " [17 14  8 16]]\n",
      "Validation Loss for P40 = 1.3704184293746948\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_96/2974510044.py:87: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/tmp/ipykernel_96/2974510044.py:43: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n",
      "/tmp/ipykernel_96/2974510044.py:61: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 32/100, Train Loss: 1.3887933492660522\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.27      0.60      0.37        43\n",
      "           1       0.26      0.16      0.20        61\n",
      "           2       0.44      0.33      0.38        61\n",
      "           3       0.38      0.27      0.32        55\n",
      "\n",
      "    accuracy                           0.32       220\n",
      "   macro avg       0.34      0.34      0.32       220\n",
      "weighted avg       0.34      0.32      0.31       220\n",
      "\n",
      "[[26  5  7  5]\n",
      " [29 10  8 14]\n",
      " [25 11 20  5]\n",
      " [18 12 10 15]]\n",
      "Validation Loss for P40 = 1.3713206052780151\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_96/2974510044.py:87: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/tmp/ipykernel_96/2974510044.py:43: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n",
      "/tmp/ipykernel_96/2974510044.py:61: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 33/100, Train Loss: 1.343510627746582\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.26      0.58      0.36        43\n",
      "           1       0.28      0.18      0.22        61\n",
      "           2       0.43      0.33      0.37        61\n",
      "           3       0.38      0.27      0.32        55\n",
      "\n",
      "    accuracy                           0.32       220\n",
      "   macro avg       0.34      0.34      0.32       220\n",
      "weighted avg       0.34      0.32      0.31       220\n",
      "\n",
      "[[25  5  8  5]\n",
      " [27 11  9 14]\n",
      " [25 11 20  5]\n",
      " [18 12 10 15]]\n",
      "Validation Loss for P40 = 1.3723267316818237\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_96/2974510044.py:87: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/tmp/ipykernel_96/2974510044.py:43: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n",
      "/tmp/ipykernel_96/2974510044.py:61: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 34/100, Train Loss: 1.3974851369857788\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.26      0.58      0.36        43\n",
      "           1       0.24      0.15      0.18        61\n",
      "           2       0.43      0.33      0.37        61\n",
      "           3       0.38      0.27      0.32        55\n",
      "\n",
      "    accuracy                           0.31       220\n",
      "   macro avg       0.33      0.33      0.31       220\n",
      "weighted avg       0.33      0.31      0.30       220\n",
      "\n",
      "[[25  5  8  5]\n",
      " [29  9  9 14]\n",
      " [25 11 20  5]\n",
      " [18 12 10 15]]\n",
      "Validation Loss for P40 = 1.3732337951660156\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_96/2974510044.py:87: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/tmp/ipykernel_96/2974510044.py:43: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n",
      "/tmp/ipykernel_96/2974510044.py:61: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 35/100, Train Loss: 1.4157565832138062\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.25      0.58      0.35        43\n",
      "           1       0.26      0.15      0.19        61\n",
      "           2       0.43      0.31      0.36        61\n",
      "           3       0.37      0.27      0.31        55\n",
      "\n",
      "    accuracy                           0.31       220\n",
      "   macro avg       0.33      0.33      0.30       220\n",
      "weighted avg       0.33      0.31      0.30       220\n",
      "\n",
      "[[25  5  8  5]\n",
      " [30  9  8 14]\n",
      " [27  8 19  7]\n",
      " [19 12  9 15]]\n",
      "Validation Loss for P40 = 1.3723512887954712\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_96/2974510044.py:87: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/tmp/ipykernel_96/2974510044.py:43: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n",
      "/tmp/ipykernel_96/2974510044.py:61: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 36/100, Train Loss: 1.3457058668136597\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.26      0.58      0.35        43\n",
      "           1       0.26      0.15      0.19        61\n",
      "           2       0.42      0.31      0.36        61\n",
      "           3       0.36      0.27      0.31        55\n",
      "\n",
      "    accuracy                           0.31       220\n",
      "   macro avg       0.32      0.33      0.30       220\n",
      "weighted avg       0.33      0.31      0.30       220\n",
      "\n",
      "[[25  5  8  5]\n",
      " [29  9  8 15]\n",
      " [26  9 19  7]\n",
      " [18 12 10 15]]\n",
      "Validation Loss for P40 = 1.3716118335723877\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_96/2974510044.py:87: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/tmp/ipykernel_96/2974510044.py:43: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n",
      "/tmp/ipykernel_96/2974510044.py:61: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 37/100, Train Loss: 1.3547197580337524\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.25      0.58      0.35        43\n",
      "           1       0.26      0.15      0.19        61\n",
      "           2       0.42      0.31      0.36        61\n",
      "           3       0.36      0.27      0.31        55\n",
      "\n",
      "    accuracy                           0.31       220\n",
      "   macro avg       0.32      0.33      0.30       220\n",
      "weighted avg       0.33      0.31      0.30       220\n",
      "\n",
      "[[25  5  8  5]\n",
      " [29  9  8 15]\n",
      " [27  8 19  7]\n",
      " [18 12 10 15]]\n",
      "Validation Loss for P40 = 1.3688300848007202\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_96/2974510044.py:87: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/tmp/ipykernel_96/2974510044.py:43: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n",
      "/tmp/ipykernel_96/2974510044.py:61: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 38/100, Train Loss: 1.3679405450820923\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.26      0.60      0.36        43\n",
      "           1       0.27      0.13      0.18        61\n",
      "           2       0.42      0.31      0.36        61\n",
      "           3       0.33      0.27      0.30        55\n",
      "\n",
      "    accuracy                           0.31       220\n",
      "   macro avg       0.32      0.33      0.30       220\n",
      "weighted avg       0.33      0.31      0.29       220\n",
      "\n",
      "[[26  3  8  6]\n",
      " [29  8  8 16]\n",
      " [27  7 19  8]\n",
      " [18 12 10 15]]\n",
      "Validation Loss for P40 = 1.36531400680542\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_96/2974510044.py:87: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/tmp/ipykernel_96/2974510044.py:43: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n",
      "/tmp/ipykernel_96/2974510044.py:61: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 39/100, Train Loss: 1.3019379377365112\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.25      0.58      0.35        43\n",
      "           1       0.27      0.15      0.19        61\n",
      "           2       0.43      0.31      0.36        61\n",
      "           3       0.35      0.27      0.31        55\n",
      "\n",
      "    accuracy                           0.31       220\n",
      "   macro avg       0.33      0.33      0.30       220\n",
      "weighted avg       0.33      0.31      0.30       220\n",
      "\n",
      "[[25  4  8  6]\n",
      " [29  9  8 15]\n",
      " [28  7 19  7]\n",
      " [18 13  9 15]]\n",
      "Validation Loss for P40 = 1.367820143699646\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_96/2974510044.py:87: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/tmp/ipykernel_96/2974510044.py:43: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n",
      "/tmp/ipykernel_96/2974510044.py:61: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 40/100, Train Loss: 1.3155720233917236\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.27      0.63      0.38        43\n",
      "           1       0.29      0.15      0.20        61\n",
      "           2       0.43      0.31      0.36        61\n",
      "           3       0.34      0.27      0.30        55\n",
      "\n",
      "    accuracy                           0.32       220\n",
      "   macro avg       0.33      0.34      0.31       220\n",
      "weighted avg       0.34      0.32      0.30       220\n",
      "\n",
      "[[27  3  7  6]\n",
      " [29  9  8 15]\n",
      " [27  7 19  8]\n",
      " [18 12 10 15]]\n",
      "Validation Loss for P40 = 1.3656175136566162\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_96/2974510044.py:87: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/tmp/ipykernel_96/2974510044.py:43: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n",
      "/tmp/ipykernel_96/2974510044.py:61: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 41/100, Train Loss: 1.4862536191940308\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.26      0.60      0.36        43\n",
      "           1       0.28      0.15      0.19        61\n",
      "           2       0.45      0.31      0.37        61\n",
      "           3       0.37      0.31      0.34        55\n",
      "\n",
      "    accuracy                           0.32       220\n",
      "   macro avg       0.34      0.34      0.32       220\n",
      "weighted avg       0.35      0.32      0.31       220\n",
      "\n",
      "[[26  4  7  6]\n",
      " [29  9  8 15]\n",
      " [27  7 19  8]\n",
      " [18 12  8 17]]\n",
      "Validation Loss for P40 = 1.364883303642273\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_96/2974510044.py:87: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/tmp/ipykernel_96/2974510044.py:43: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n",
      "/tmp/ipykernel_96/2974510044.py:61: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 42/100, Train Loss: 1.4487804174423218\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.26      0.60      0.36        43\n",
      "           1       0.27      0.15      0.19        61\n",
      "           2       0.45      0.31      0.37        61\n",
      "           3       0.36      0.29      0.32        55\n",
      "\n",
      "    accuracy                           0.32       220\n",
      "   macro avg       0.34      0.34      0.31       220\n",
      "weighted avg       0.34      0.32      0.31       220\n",
      "\n",
      "[[26  4  7  6]\n",
      " [29  9  8 15]\n",
      " [28  7 19  7]\n",
      " [18 13  8 16]]\n",
      "Validation Loss for P40 = 1.3659846782684326\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_96/2974510044.py:87: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/tmp/ipykernel_96/2974510044.py:43: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n",
      "/tmp/ipykernel_96/2974510044.py:61: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 43/100, Train Loss: 1.3972772359848022\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.26      0.60      0.37        43\n",
      "           1       0.26      0.15      0.19        61\n",
      "           2       0.45      0.31      0.37        61\n",
      "           3       0.36      0.29      0.32        55\n",
      "\n",
      "    accuracy                           0.32       220\n",
      "   macro avg       0.33      0.34      0.31       220\n",
      "weighted avg       0.34      0.32      0.31       220\n",
      "\n",
      "[[26  4  7  6]\n",
      " [29  9  8 15]\n",
      " [26  8 19  8]\n",
      " [18 13  8 16]]\n",
      "Validation Loss for P40 = 1.365352988243103\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_96/2974510044.py:87: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/tmp/ipykernel_96/2974510044.py:43: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n",
      "/tmp/ipykernel_96/2974510044.py:61: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 44/100, Train Loss: 1.4053857326507568\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.26      0.63      0.37        43\n",
      "           1       0.29      0.15      0.20        61\n",
      "           2       0.44      0.31      0.37        61\n",
      "           3       0.36      0.29      0.32        55\n",
      "\n",
      "    accuracy                           0.32       220\n",
      "   macro avg       0.34      0.34      0.31       220\n",
      "weighted avg       0.35      0.32      0.31       220\n",
      "\n",
      "[[27  3  7  6]\n",
      " [29  9  8 15]\n",
      " [28  7 19  7]\n",
      " [18 12  9 16]]\n",
      "Validation Loss for P40 = 1.3595128059387207\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_96/2974510044.py:87: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/tmp/ipykernel_96/2974510044.py:43: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n",
      "/tmp/ipykernel_96/2974510044.py:61: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 45/100, Train Loss: 1.43271803855896\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.26      0.63      0.36        43\n",
      "           1       0.31      0.15      0.20        61\n",
      "           2       0.42      0.26      0.32        61\n",
      "           3       0.35      0.31      0.33        55\n",
      "\n",
      "    accuracy                           0.31       220\n",
      "   macro avg       0.34      0.34      0.30       220\n",
      "weighted avg       0.34      0.31      0.30       220\n",
      "\n",
      "[[27  3  6  7]\n",
      " [30  9  8 14]\n",
      " [29  6 16 10]\n",
      " [19 11  8 17]]\n",
      "Validation Loss for P40 = 1.3556184768676758\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_96/2974510044.py:87: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/tmp/ipykernel_96/2974510044.py:43: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n",
      "/tmp/ipykernel_96/2974510044.py:61: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 46/100, Train Loss: 1.3850723505020142\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.25      0.60      0.36        43\n",
      "           1       0.26      0.15      0.19        61\n",
      "           2       0.44      0.30      0.35        61\n",
      "           3       0.37      0.29      0.33        55\n",
      "\n",
      "    accuracy                           0.31       220\n",
      "   macro avg       0.33      0.33      0.31       220\n",
      "weighted avg       0.34      0.31      0.30       220\n",
      "\n",
      "[[26  4  7  6]\n",
      " [30  9  8 14]\n",
      " [28  8 18  7]\n",
      " [18 13  8 16]]\n",
      "Validation Loss for P40 = 1.3566992282867432\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_96/2974510044.py:87: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/tmp/ipykernel_96/2974510044.py:43: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n",
      "/tmp/ipykernel_96/2974510044.py:61: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 47/100, Train Loss: 1.2890299558639526\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.26      0.63      0.37        43\n",
      "           1       0.26      0.13      0.17        61\n",
      "           2       0.41      0.25      0.31        61\n",
      "           3       0.35      0.31      0.33        55\n",
      "\n",
      "    accuracy                           0.30       220\n",
      "   macro avg       0.32      0.33      0.29       220\n",
      "weighted avg       0.32      0.30      0.29       220\n",
      "\n",
      "[[27  3  7  6]\n",
      " [30  8  8 15]\n",
      " [29  7 15 10]\n",
      " [18 13  7 17]]\n",
      "Validation Loss for P40 = 1.3530594110488892\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_96/2974510044.py:87: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/tmp/ipykernel_96/2974510044.py:43: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n",
      "/tmp/ipykernel_96/2974510044.py:61: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 48/100, Train Loss: 1.3442063331604004\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.26      0.63      0.37        43\n",
      "           1       0.23      0.11      0.15        61\n",
      "           2       0.39      0.26      0.31        61\n",
      "           3       0.35      0.29      0.32        55\n",
      "\n",
      "    accuracy                           0.30       220\n",
      "   macro avg       0.31      0.32      0.29       220\n",
      "weighted avg       0.31      0.30      0.28       220\n",
      "\n",
      "[[27  3  7  6]\n",
      " [30  7  9 15]\n",
      " [28  8 16  9]\n",
      " [18 12  9 16]]\n",
      "Validation Loss for P40 = 1.353440284729004\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_96/2974510044.py:87: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/tmp/ipykernel_96/2974510044.py:43: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n",
      "/tmp/ipykernel_96/2974510044.py:61: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 49/100, Train Loss: 1.2813643217086792\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.26      0.63      0.36        43\n",
      "           1       0.24      0.11      0.16        61\n",
      "           2       0.41      0.26      0.32        61\n",
      "           3       0.36      0.31      0.33        55\n",
      "\n",
      "    accuracy                           0.30       220\n",
      "   macro avg       0.32      0.33      0.29       220\n",
      "weighted avg       0.32      0.30      0.29       220\n",
      "\n",
      "[[27  3  7  6]\n",
      " [30  7  9 15]\n",
      " [28  8 16  9]\n",
      " [20 11  7 17]]\n",
      "Validation Loss for P40 = 1.360164999961853\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_96/2974510044.py:87: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/tmp/ipykernel_96/2974510044.py:43: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n",
      "/tmp/ipykernel_96/2974510044.py:61: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 50/100, Train Loss: 1.3960257768630981\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.25      0.58      0.35        43\n",
      "           1       0.24      0.13      0.17        61\n",
      "           2       0.41      0.26      0.32        61\n",
      "           3       0.36      0.31      0.33        55\n",
      "\n",
      "    accuracy                           0.30       220\n",
      "   macro avg       0.32      0.32      0.29       220\n",
      "weighted avg       0.32      0.30      0.29       220\n",
      "\n",
      "[[25  4  8  6]\n",
      " [30  8  8 15]\n",
      " [28  8 16  9]\n",
      " [18 13  7 17]]\n",
      "Validation Loss for P40 = 1.3592885732650757\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_96/2974510044.py:87: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/tmp/ipykernel_96/2974510044.py:43: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n",
      "/tmp/ipykernel_96/2974510044.py:61: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 51/100, Train Loss: 1.3857582807540894\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.25      0.60      0.36        43\n",
      "           1       0.25      0.13      0.17        61\n",
      "           2       0.43      0.26      0.33        61\n",
      "           3       0.35      0.31      0.33        55\n",
      "\n",
      "    accuracy                           0.30       220\n",
      "   macro avg       0.32      0.33      0.30       220\n",
      "weighted avg       0.33      0.30      0.29       220\n",
      "\n",
      "[[26  4  6  7]\n",
      " [30  8  8 15]\n",
      " [28  7 16 10]\n",
      " [18 13  7 17]]\n",
      "Validation Loss for P40 = 1.356626272201538\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_96/2974510044.py:87: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/tmp/ipykernel_96/2974510044.py:43: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n",
      "/tmp/ipykernel_96/2974510044.py:61: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 52/100, Train Loss: 1.389414668083191\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.25      0.58      0.35        43\n",
      "           1       0.28      0.16      0.21        61\n",
      "           2       0.42      0.25      0.31        61\n",
      "           3       0.36      0.31      0.33        55\n",
      "\n",
      "    accuracy                           0.30       220\n",
      "   macro avg       0.33      0.33      0.30       220\n",
      "weighted avg       0.33      0.30      0.29       220\n",
      "\n",
      "[[25  5  6  7]\n",
      " [29 10  8 14]\n",
      " [29  8 15  9]\n",
      " [18 13  7 17]]\n",
      "Validation Loss for P40 = 1.3588141202926636\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_96/2974510044.py:87: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/tmp/ipykernel_96/2974510044.py:43: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n",
      "/tmp/ipykernel_96/2974510044.py:61: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 53/100, Train Loss: 1.2856858968734741\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.26      0.58      0.36        43\n",
      "           1       0.26      0.15      0.19        61\n",
      "           2       0.42      0.26      0.32        61\n",
      "           3       0.33      0.31      0.32        55\n",
      "\n",
      "    accuracy                           0.30       220\n",
      "   macro avg       0.32      0.33      0.30       220\n",
      "weighted avg       0.32      0.30      0.29       220\n",
      "\n",
      "[[25  5  7  6]\n",
      " [29  9  8 15]\n",
      " [25  7 16 13]\n",
      " [18 13  7 17]]\n",
      "Validation Loss for P40 = 1.3567389249801636\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_96/2974510044.py:87: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/tmp/ipykernel_96/2974510044.py:43: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n",
      "/tmp/ipykernel_96/2974510044.py:61: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 54/100, Train Loss: 1.3728201389312744\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.26      0.63      0.37        43\n",
      "           1       0.27      0.13      0.18        61\n",
      "           2       0.42      0.26      0.32        61\n",
      "           3       0.35      0.31      0.33        55\n",
      "\n",
      "    accuracy                           0.31       220\n",
      "   macro avg       0.32      0.33      0.30       220\n",
      "weighted avg       0.33      0.31      0.29       220\n",
      "\n",
      "[[27  3  7  6]\n",
      " [30  8  8 15]\n",
      " [28  6 16 11]\n",
      " [18 13  7 17]]\n",
      "Validation Loss for P40 = 1.3568247556686401\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_96/2974510044.py:87: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/tmp/ipykernel_96/2974510044.py:43: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n",
      "/tmp/ipykernel_96/2974510044.py:61: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 55/100, Train Loss: 1.4129823446273804\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.26      0.63      0.37        43\n",
      "           1       0.29      0.15      0.20        61\n",
      "           2       0.41      0.26      0.32        61\n",
      "           3       0.36      0.31      0.33        55\n",
      "\n",
      "    accuracy                           0.31       220\n",
      "   macro avg       0.33      0.34      0.30       220\n",
      "weighted avg       0.34      0.31      0.30       220\n",
      "\n",
      "[[27  3  7  6]\n",
      " [30  9  9 13]\n",
      " [28  6 16 11]\n",
      " [18 13  7 17]]\n",
      "Validation Loss for P40 = 1.3566771745681763\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_96/2974510044.py:87: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/tmp/ipykernel_96/2974510044.py:43: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n",
      "/tmp/ipykernel_96/2974510044.py:61: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 56/100, Train Loss: 1.374547004699707\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.26      0.60      0.36        43\n",
      "           1       0.27      0.15      0.19        61\n",
      "           2       0.42      0.28      0.34        61\n",
      "           3       0.36      0.31      0.33        55\n",
      "\n",
      "    accuracy                           0.31       220\n",
      "   macro avg       0.33      0.33      0.31       220\n",
      "weighted avg       0.33      0.31      0.30       220\n",
      "\n",
      "[[26  4  7  6]\n",
      " [30  9  9 13]\n",
      " [26  7 17 11]\n",
      " [18 13  7 17]]\n",
      "Validation Loss for P40 = 1.3584575653076172\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_96/2974510044.py:87: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/tmp/ipykernel_96/2974510044.py:43: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n",
      "/tmp/ipykernel_96/2974510044.py:61: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 57/100, Train Loss: 1.4244225025177002\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.24      0.56      0.34        43\n",
      "           1       0.26      0.15      0.19        61\n",
      "           2       0.40      0.26      0.32        61\n",
      "           3       0.35      0.31      0.33        55\n",
      "\n",
      "    accuracy                           0.30       220\n",
      "   macro avg       0.32      0.32      0.29       220\n",
      "weighted avg       0.32      0.30      0.29       220\n",
      "\n",
      "[[24  5  8  6]\n",
      " [30  9  9 13]\n",
      " [26  7 16 12]\n",
      " [18 13  7 17]]\n",
      "Validation Loss for P40 = 1.360120177268982\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_96/2974510044.py:87: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/tmp/ipykernel_96/2974510044.py:43: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n",
      "/tmp/ipykernel_96/2974510044.py:61: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 58/100, Train Loss: 1.3907297849655151\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.25      0.56      0.35        43\n",
      "           1       0.28      0.16      0.21        61\n",
      "           2       0.41      0.28      0.33        61\n",
      "           3       0.36      0.31      0.33        55\n",
      "\n",
      "    accuracy                           0.31       220\n",
      "   macro avg       0.33      0.33      0.30       220\n",
      "weighted avg       0.33      0.31      0.30       220\n",
      "\n",
      "[[24  5  8  6]\n",
      " [29 10  9 13]\n",
      " [26  7 17 11]\n",
      " [17 14  7 17]]\n",
      "Validation Loss for P40 = 1.3589497804641724\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_96/2974510044.py:87: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/tmp/ipykernel_96/2974510044.py:43: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n",
      "/tmp/ipykernel_96/2974510044.py:61: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 59/100, Train Loss: 1.4015980958938599\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.24      0.53      0.33        43\n",
      "           1       0.28      0.16      0.21        61\n",
      "           2       0.41      0.26      0.32        61\n",
      "           3       0.37      0.33      0.35        55\n",
      "\n",
      "    accuracy                           0.30       220\n",
      "   macro avg       0.32      0.32      0.30       220\n",
      "weighted avg       0.33      0.30      0.30       220\n",
      "\n",
      "[[23  6  7  7]\n",
      " [29 10  9 13]\n",
      " [27  7 16 11]\n",
      " [17 13  7 18]]\n",
      "Validation Loss for P40 = 1.3579628467559814\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_96/2974510044.py:87: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/tmp/ipykernel_96/2974510044.py:43: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n",
      "/tmp/ipykernel_96/2974510044.py:61: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 60/100, Train Loss: 1.4828804731369019\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.25      0.56      0.34        43\n",
      "           1       0.29      0.16      0.21        61\n",
      "           2       0.41      0.26      0.32        61\n",
      "           3       0.37      0.33      0.35        55\n",
      "\n",
      "    accuracy                           0.31       220\n",
      "   macro avg       0.33      0.33      0.30       220\n",
      "weighted avg       0.33      0.31      0.30       220\n",
      "\n",
      "[[24  5  7  7]\n",
      " [29 10  9 13]\n",
      " [27  7 16 11]\n",
      " [17 13  7 18]]\n",
      "Validation Loss for P40 = 1.3506550788879395\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_96/2974510044.py:87: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/tmp/ipykernel_96/2974510044.py:43: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n",
      "/tmp/ipykernel_96/2974510044.py:61: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 61/100, Train Loss: 1.4110623598098755\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.25      0.56      0.35        43\n",
      "           1       0.29      0.16      0.21        61\n",
      "           2       0.43      0.30      0.35        61\n",
      "           3       0.37      0.33      0.35        55\n",
      "\n",
      "    accuracy                           0.32       220\n",
      "   macro avg       0.34      0.34      0.31       220\n",
      "weighted avg       0.34      0.32      0.31       220\n",
      "\n",
      "[[24  5  7  7]\n",
      " [29 10  9 13]\n",
      " [25  7 18 11]\n",
      " [17 12  8 18]]\n",
      "Validation Loss for P40 = 1.3539355993270874\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_96/2974510044.py:87: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/tmp/ipykernel_96/2974510044.py:43: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n",
      "/tmp/ipykernel_96/2974510044.py:61: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 62/100, Train Loss: 1.32073175907135\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.25      0.53      0.34        43\n",
      "           1       0.26      0.16      0.20        61\n",
      "           2       0.44      0.30      0.35        61\n",
      "           3       0.37      0.33      0.35        55\n",
      "\n",
      "    accuracy                           0.31       220\n",
      "   macro avg       0.33      0.33      0.31       220\n",
      "weighted avg       0.34      0.31      0.31       220\n",
      "\n",
      "[[23  6  7  7]\n",
      " [29 10  9 13]\n",
      " [23  9 18 11]\n",
      " [17 13  7 18]]\n",
      "Validation Loss for P40 = 1.3563579320907593\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_96/2974510044.py:87: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/tmp/ipykernel_96/2974510044.py:43: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n",
      "/tmp/ipykernel_96/2974510044.py:61: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 63/100, Train Loss: 1.4461166858673096\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.24      0.51      0.32        43\n",
      "           1       0.26      0.16      0.20        61\n",
      "           2       0.41      0.26      0.32        61\n",
      "           3       0.35      0.31      0.33        55\n",
      "\n",
      "    accuracy                           0.30       220\n",
      "   macro avg       0.31      0.31      0.29       220\n",
      "weighted avg       0.32      0.30      0.29       220\n",
      "\n",
      "[[22  7  7  7]\n",
      " [29 10  8 14]\n",
      " [25  9 16 11]\n",
      " [17 13  8 17]]\n",
      "Validation Loss for P40 = 1.3578623533248901\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_96/2974510044.py:87: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/tmp/ipykernel_96/2974510044.py:43: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n",
      "/tmp/ipykernel_96/2974510044.py:61: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 64/100, Train Loss: 1.3434969186782837\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.24      0.51      0.33        43\n",
      "           1       0.25      0.16      0.20        61\n",
      "           2       0.42      0.26      0.32        61\n",
      "           3       0.36      0.33      0.34        55\n",
      "\n",
      "    accuracy                           0.30       220\n",
      "   macro avg       0.32      0.32      0.30       220\n",
      "weighted avg       0.32      0.30      0.29       220\n",
      "\n",
      "[[22  7  7  7]\n",
      " [29 10  8 14]\n",
      " [24 10 16 11]\n",
      " [17 13  7 18]]\n",
      "Validation Loss for P40 = 1.3573757410049438\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_96/2974510044.py:87: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/tmp/ipykernel_96/2974510044.py:43: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n",
      "/tmp/ipykernel_96/2974510044.py:61: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 65/100, Train Loss: 1.37890625\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.23      0.51      0.32        43\n",
      "           1       0.26      0.16      0.20        61\n",
      "           2       0.41      0.25      0.31        61\n",
      "           3       0.36      0.33      0.34        55\n",
      "\n",
      "    accuracy                           0.30       220\n",
      "   macro avg       0.31      0.31      0.29       220\n",
      "weighted avg       0.32      0.30      0.29       220\n",
      "\n",
      "[[22  7  7  7]\n",
      " [29 10  8 14]\n",
      " [26  9 15 11]\n",
      " [17 13  7 18]]\n",
      "Validation Loss for P40 = 1.3571504354476929\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_96/2974510044.py:87: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/tmp/ipykernel_96/2974510044.py:43: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n",
      "/tmp/ipykernel_96/2974510044.py:61: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 66/100, Train Loss: 1.290066123008728\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.24      0.53      0.33        43\n",
      "           1       0.26      0.16      0.20        61\n",
      "           2       0.41      0.25      0.31        61\n",
      "           3       0.36      0.33      0.34        55\n",
      "\n",
      "    accuracy                           0.30       220\n",
      "   macro avg       0.32      0.32      0.30       220\n",
      "weighted avg       0.32      0.30      0.29       220\n",
      "\n",
      "[[23  6  7  7]\n",
      " [29 10  8 14]\n",
      " [26  9 15 11]\n",
      " [17 13  7 18]]\n",
      "Validation Loss for P40 = 1.3541266918182373\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_96/2974510044.py:87: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/tmp/ipykernel_96/2974510044.py:43: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n",
      "/tmp/ipykernel_96/2974510044.py:61: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 67/100, Train Loss: 1.407059669494629\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.24      0.56      0.34        43\n",
      "           1       0.29      0.16      0.21        61\n",
      "           2       0.39      0.25      0.30        61\n",
      "           3       0.36      0.33      0.34        55\n",
      "\n",
      "    accuracy                           0.30       220\n",
      "   macro avg       0.32      0.32      0.30       220\n",
      "weighted avg       0.33      0.30      0.29       220\n",
      "\n",
      "[[24  5  7  7]\n",
      " [29 10  8 14]\n",
      " [28  7 15 11]\n",
      " [17 12  8 18]]\n",
      "Validation Loss for P40 = 1.3546279668807983\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_96/2974510044.py:87: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/tmp/ipykernel_96/2974510044.py:43: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n",
      "/tmp/ipykernel_96/2974510044.py:61: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 68/100, Train Loss: 1.3274253606796265\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.25      0.56      0.34        43\n",
      "           1       0.29      0.16      0.21        61\n",
      "           2       0.41      0.26      0.32        61\n",
      "           3       0.36      0.33      0.34        55\n",
      "\n",
      "    accuracy                           0.31       220\n",
      "   macro avg       0.33      0.33      0.30       220\n",
      "weighted avg       0.33      0.31      0.30       220\n",
      "\n",
      "[[24  5  7  7]\n",
      " [29 10  8 14]\n",
      " [27  7 16 11]\n",
      " [17 12  8 18]]\n",
      "Validation Loss for P40 = 1.3556002378463745\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_96/2974510044.py:87: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/tmp/ipykernel_96/2974510044.py:43: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n",
      "/tmp/ipykernel_96/2974510044.py:61: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 69/100, Train Loss: 1.3875612020492554\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.24      0.53      0.33        43\n",
      "           1       0.27      0.16      0.20        61\n",
      "           2       0.41      0.26      0.32        61\n",
      "           3       0.35      0.31      0.33        55\n",
      "\n",
      "    accuracy                           0.30       220\n",
      "   macro avg       0.32      0.32      0.30       220\n",
      "weighted avg       0.32      0.30      0.29       220\n",
      "\n",
      "[[23  6  7  7]\n",
      " [29 10  8 14]\n",
      " [27  8 16 10]\n",
      " [17 13  8 17]]\n",
      "Validation Loss for P40 = 1.3579564094543457\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_96/2974510044.py:87: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/tmp/ipykernel_96/2974510044.py:43: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n",
      "/tmp/ipykernel_96/2974510044.py:61: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 70/100, Train Loss: 1.3685821294784546\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.24      0.53      0.33        43\n",
      "           1       0.26      0.16      0.20        61\n",
      "           2       0.38      0.25      0.30        61\n",
      "           3       0.35      0.31      0.33        55\n",
      "\n",
      "    accuracy                           0.30       220\n",
      "   macro avg       0.31      0.31      0.29       220\n",
      "weighted avg       0.32      0.30      0.29       220\n",
      "\n",
      "[[23  6  8  6]\n",
      " [29 10  8 14]\n",
      " [26  9 15 11]\n",
      " [17 13  8 17]]\n",
      "Validation Loss for P40 = 1.3608144521713257\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_96/2974510044.py:87: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/tmp/ipykernel_96/2974510044.py:43: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n",
      "/tmp/ipykernel_96/2974510044.py:61: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 71/100, Train Loss: 1.4091876745224\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.23      0.51      0.32        43\n",
      "           1       0.26      0.16      0.20        61\n",
      "           2       0.38      0.25      0.30        61\n",
      "           3       0.36      0.31      0.33        55\n",
      "\n",
      "    accuracy                           0.29       220\n",
      "   macro avg       0.31      0.31      0.29       220\n",
      "weighted avg       0.31      0.29      0.28       220\n",
      "\n",
      "[[22  7  9  5]\n",
      " [29 10  8 14]\n",
      " [26  9 15 11]\n",
      " [17 13  8 17]]\n",
      "Validation Loss for P40 = 1.356858491897583\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_96/2974510044.py:87: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/tmp/ipykernel_96/2974510044.py:43: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n",
      "/tmp/ipykernel_96/2974510044.py:61: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 72/100, Train Loss: 1.346399188041687\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.24      0.51      0.33        43\n",
      "           1       0.30      0.20      0.24        61\n",
      "           2       0.44      0.30      0.35        61\n",
      "           3       0.37      0.33      0.35        55\n",
      "\n",
      "    accuracy                           0.32       220\n",
      "   macro avg       0.34      0.33      0.32       220\n",
      "weighted avg       0.34      0.32      0.31       220\n",
      "\n",
      "[[22  7  8  6]\n",
      " [27 12  8 14]\n",
      " [24  8 18 11]\n",
      " [17 13  7 18]]\n",
      "Validation Loss for P40 = 1.3585398197174072\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_96/2974510044.py:87: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/tmp/ipykernel_96/2974510044.py:43: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n",
      "/tmp/ipykernel_96/2974510044.py:61: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 73/100, Train Loss: 1.3190163373947144\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.23      0.51      0.32        43\n",
      "           1       0.27      0.16      0.20        61\n",
      "           2       0.40      0.26      0.32        61\n",
      "           3       0.35      0.31      0.33        55\n",
      "\n",
      "    accuracy                           0.30       220\n",
      "   macro avg       0.31      0.31      0.29       220\n",
      "weighted avg       0.32      0.30      0.29       220\n",
      "\n",
      "[[22  7  7  7]\n",
      " [29 10  8 14]\n",
      " [26  8 16 11]\n",
      " [17 12  9 17]]\n",
      "Validation Loss for P40 = 1.3614696264266968\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_96/2974510044.py:87: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/tmp/ipykernel_96/2974510044.py:43: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n",
      "/tmp/ipykernel_96/2974510044.py:61: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 74/100, Train Loss: 1.3220555782318115\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.23      0.51      0.32        43\n",
      "           1       0.27      0.16      0.20        61\n",
      "           2       0.42      0.28      0.34        61\n",
      "           3       0.35      0.31      0.33        55\n",
      "\n",
      "    accuracy                           0.30       220\n",
      "   macro avg       0.32      0.32      0.30       220\n",
      "weighted avg       0.33      0.30      0.29       220\n",
      "\n",
      "[[22  7  7  7]\n",
      " [29 10  7 15]\n",
      " [27  8 17  9]\n",
      " [17 12  9 17]]\n",
      "Validation Loss for P40 = 1.3591349124908447\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_96/2974510044.py:87: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/tmp/ipykernel_96/2974510044.py:43: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n",
      "/tmp/ipykernel_96/2974510044.py:61: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 75/100, Train Loss: 1.3183058500289917\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.24      0.51      0.32        43\n",
      "           1       0.28      0.18      0.22        61\n",
      "           2       0.43      0.26      0.33        61\n",
      "           3       0.35      0.33      0.34        55\n",
      "\n",
      "    accuracy                           0.30       220\n",
      "   macro avg       0.33      0.32      0.30       220\n",
      "weighted avg       0.33      0.30      0.30       220\n",
      "\n",
      "[[22  7  6  8]\n",
      " [28 11  8 14]\n",
      " [26  8 16 11]\n",
      " [17 13  7 18]]\n",
      "Validation Loss for P40 = 1.3567306995391846\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_96/2974510044.py:87: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/tmp/ipykernel_96/2974510044.py:43: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n",
      "/tmp/ipykernel_96/2974510044.py:61: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 76/100, Train Loss: 1.3883304595947266\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.24      0.51      0.32        43\n",
      "           1       0.28      0.18      0.22        61\n",
      "           2       0.46      0.30      0.36        61\n",
      "           3       0.37      0.33      0.35        55\n",
      "\n",
      "    accuracy                           0.31       220\n",
      "   macro avg       0.34      0.33      0.31       220\n",
      "weighted avg       0.34      0.31      0.31       220\n",
      "\n",
      "[[22  7  6  8]\n",
      " [28 11  8 14]\n",
      " [26  8 18  9]\n",
      " [17 13  7 18]]\n",
      "Validation Loss for P40 = 1.3559483289718628\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_96/2974510044.py:87: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/tmp/ipykernel_96/2974510044.py:43: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n",
      "/tmp/ipykernel_96/2974510044.py:61: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 77/100, Train Loss: 1.3230546712875366\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.23      0.49      0.31        43\n",
      "           1       0.30      0.20      0.24        61\n",
      "           2       0.39      0.25      0.30        61\n",
      "           3       0.35      0.33      0.34        55\n",
      "\n",
      "    accuracy                           0.30       220\n",
      "   macro avg       0.32      0.31      0.30       220\n",
      "weighted avg       0.33      0.30      0.30       220\n",
      "\n",
      "[[21  8  7  7]\n",
      " [27 12  8 14]\n",
      " [26  8 15 12]\n",
      " [17 12  8 18]]\n",
      "Validation Loss for P40 = 1.3582454919815063\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_96/2974510044.py:87: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/tmp/ipykernel_96/2974510044.py:43: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n",
      "/tmp/ipykernel_96/2974510044.py:61: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 78/100, Train Loss: 1.4148764610290527\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.23      0.49      0.31        43\n",
      "           1       0.30      0.20      0.24        61\n",
      "           2       0.43      0.30      0.35        61\n",
      "           3       0.36      0.31      0.33        55\n",
      "\n",
      "    accuracy                           0.31       220\n",
      "   macro avg       0.33      0.32      0.31       220\n",
      "weighted avg       0.34      0.31      0.31       220\n",
      "\n",
      "[[21  8  7  7]\n",
      " [27 12  8 14]\n",
      " [26  8 18  9]\n",
      " [17 12  9 17]]\n",
      "Validation Loss for P40 = 1.3608901500701904\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_96/2974510044.py:87: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/tmp/ipykernel_96/2974510044.py:43: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n",
      "/tmp/ipykernel_96/2974510044.py:61: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 79/100, Train Loss: 1.4231817722320557\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.24      0.51      0.32        43\n",
      "           1       0.26      0.16      0.20        61\n",
      "           2       0.44      0.28      0.34        61\n",
      "           3       0.36      0.33      0.34        55\n",
      "\n",
      "    accuracy                           0.30       220\n",
      "   macro avg       0.32      0.32      0.30       220\n",
      "weighted avg       0.33      0.30      0.30       220\n",
      "\n",
      "[[22  7  7  7]\n",
      " [29 10  8 14]\n",
      " [25  8 17 11]\n",
      " [17 13  7 18]]\n",
      "Validation Loss for P40 = 1.3572815656661987\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_96/2974510044.py:87: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/tmp/ipykernel_96/2974510044.py:43: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n",
      "/tmp/ipykernel_96/2974510044.py:61: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 80/100, Train Loss: 1.3786617517471313\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.23      0.49      0.31        43\n",
      "           1       0.29      0.20      0.24        61\n",
      "           2       0.42      0.28      0.34        61\n",
      "           3       0.38      0.33      0.35        55\n",
      "\n",
      "    accuracy                           0.31       220\n",
      "   macro avg       0.33      0.32      0.31       220\n",
      "weighted avg       0.34      0.31      0.31       220\n",
      "\n",
      "[[21  8  8  6]\n",
      " [27 12  8 14]\n",
      " [26  8 17 10]\n",
      " [17 13  7 18]]\n",
      "Validation Loss for P40 = 1.3627207279205322\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_96/2974510044.py:87: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/tmp/ipykernel_96/2974510044.py:43: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n",
      "/tmp/ipykernel_96/2974510044.py:61: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 81/100, Train Loss: 1.307488203048706\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.22      0.44      0.30        43\n",
      "           1       0.29      0.20      0.23        61\n",
      "           2       0.40      0.30      0.34        61\n",
      "           3       0.35      0.31      0.33        55\n",
      "\n",
      "    accuracy                           0.30       220\n",
      "   macro avg       0.32      0.31      0.30       220\n",
      "weighted avg       0.32      0.30      0.30       220\n",
      "\n",
      "[[19  9  9  6]\n",
      " [26 12  9 14]\n",
      " [23  9 18 11]\n",
      " [17 12  9 17]]\n",
      "Validation Loss for P40 = 1.3648300170898438\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_96/2974510044.py:87: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/tmp/ipykernel_96/2974510044.py:43: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n",
      "/tmp/ipykernel_96/2974510044.py:61: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 82/100, Train Loss: 1.2977218627929688\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.24      0.49      0.32        43\n",
      "           1       0.29      0.18      0.22        61\n",
      "           2       0.44      0.31      0.37        61\n",
      "           3       0.36      0.33      0.34        55\n",
      "\n",
      "    accuracy                           0.31       220\n",
      "   macro avg       0.33      0.33      0.31       220\n",
      "weighted avg       0.34      0.31      0.31       220\n",
      "\n",
      "[[21  7  7  8]\n",
      " [27 11  9 14]\n",
      " [24  8 19 10]\n",
      " [17 12  8 18]]\n",
      "Validation Loss for P40 = 1.359713077545166\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_96/2974510044.py:87: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/tmp/ipykernel_96/2974510044.py:43: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n",
      "/tmp/ipykernel_96/2974510044.py:61: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 83/100, Train Loss: 1.3550732135772705\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.24      0.51      0.33        43\n",
      "           1       0.30      0.18      0.22        61\n",
      "           2       0.44      0.33      0.38        61\n",
      "           3       0.34      0.29      0.31        55\n",
      "\n",
      "    accuracy                           0.31       220\n",
      "   macro avg       0.33      0.33      0.31       220\n",
      "weighted avg       0.34      0.31      0.31       220\n",
      "\n",
      "[[22  6  7  8]\n",
      " [27 11  9 14]\n",
      " [24  8 20  9]\n",
      " [18 12  9 16]]\n",
      "Validation Loss for P40 = 1.3613938093185425\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_96/2974510044.py:87: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/tmp/ipykernel_96/2974510044.py:43: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n",
      "/tmp/ipykernel_96/2974510044.py:61: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 84/100, Train Loss: 1.378252387046814\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.24      0.49      0.32        43\n",
      "           1       0.30      0.18      0.22        61\n",
      "           2       0.45      0.33      0.38        61\n",
      "           3       0.36      0.33      0.34        55\n",
      "\n",
      "    accuracy                           0.32       220\n",
      "   macro avg       0.34      0.33      0.32       220\n",
      "weighted avg       0.34      0.32      0.32       220\n",
      "\n",
      "[[21  6  8  8]\n",
      " [27 11  9 14]\n",
      " [23  8 20 10]\n",
      " [18 12  7 18]]\n",
      "Validation Loss for P40 = 1.362697720527649\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_96/2974510044.py:87: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/tmp/ipykernel_96/2974510044.py:43: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n",
      "/tmp/ipykernel_96/2974510044.py:61: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 85/100, Train Loss: 1.3371638059616089\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.24      0.51      0.33        43\n",
      "           1       0.29      0.20      0.24        61\n",
      "           2       0.41      0.26      0.32        61\n",
      "           3       0.35      0.31      0.33        55\n",
      "\n",
      "    accuracy                           0.30       220\n",
      "   macro avg       0.32      0.32      0.30       220\n",
      "weighted avg       0.33      0.30      0.30       220\n",
      "\n",
      "[[22  7  7  7]\n",
      " [27 12  8 14]\n",
      " [26  9 16 10]\n",
      " [17 13  8 17]]\n",
      "Validation Loss for P40 = 1.3680768013000488\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_96/2974510044.py:87: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/tmp/ipykernel_96/2974510044.py:43: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n",
      "/tmp/ipykernel_96/2974510044.py:61: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 86/100, Train Loss: 1.2910698652267456\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.24      0.51      0.33        43\n",
      "           1       0.30      0.20      0.24        61\n",
      "           2       0.47      0.33      0.38        61\n",
      "           3       0.34      0.29      0.31        55\n",
      "\n",
      "    accuracy                           0.32       220\n",
      "   macro avg       0.34      0.33      0.32       220\n",
      "weighted avg       0.35      0.32      0.32       220\n",
      "\n",
      "[[22  7  6  8]\n",
      " [27 12  8 14]\n",
      " [24  8 20  9]\n",
      " [17 13  9 16]]\n",
      "Validation Loss for P40 = 1.3657582998275757\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_96/2974510044.py:87: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/tmp/ipykernel_96/2974510044.py:43: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n",
      "/tmp/ipykernel_96/2974510044.py:61: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 87/100, Train Loss: 1.3282743692398071\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.24      0.49      0.32        43\n",
      "           1       0.29      0.20      0.24        61\n",
      "           2       0.50      0.33      0.40        61\n",
      "           3       0.38      0.35      0.36        55\n",
      "\n",
      "    accuracy                           0.33       220\n",
      "   macro avg       0.35      0.34      0.33       220\n",
      "weighted avg       0.36      0.33      0.33       220\n",
      "\n",
      "[[21  8  6  8]\n",
      " [27 12  8 14]\n",
      " [24  8 20  9]\n",
      " [17 13  6 19]]\n",
      "Validation Loss for P40 = 1.3639754056930542\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_96/2974510044.py:87: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/tmp/ipykernel_96/2974510044.py:43: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n",
      "/tmp/ipykernel_96/2974510044.py:61: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 88/100, Train Loss: 1.3288655281066895\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.24      0.51      0.33        43\n",
      "           1       0.32      0.20      0.24        61\n",
      "           2       0.47      0.33      0.38        61\n",
      "           3       0.39      0.35      0.37        55\n",
      "\n",
      "    accuracy                           0.33       220\n",
      "   macro avg       0.35      0.35      0.33       220\n",
      "weighted avg       0.36      0.33      0.33       220\n",
      "\n",
      "[[22  6  7  8]\n",
      " [27 12  9 13]\n",
      " [24  8 20  9]\n",
      " [17 12  7 19]]\n",
      "Validation Loss for P40 = 1.363345980644226\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_96/2974510044.py:87: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/tmp/ipykernel_96/2974510044.py:43: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n",
      "/tmp/ipykernel_96/2974510044.py:61: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 89/100, Train Loss: 1.4200085401535034\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.23      0.47      0.31        43\n",
      "           1       0.29      0.20      0.23        61\n",
      "           2       0.53      0.33      0.40        61\n",
      "           3       0.37      0.35      0.36        55\n",
      "\n",
      "    accuracy                           0.32       220\n",
      "   macro avg       0.35      0.33      0.32       220\n",
      "weighted avg       0.36      0.32      0.33       220\n",
      "\n",
      "[[20  9  6  8]\n",
      " [27 12  6 16]\n",
      " [23  9 20  9]\n",
      " [18 12  6 19]]\n",
      "Validation Loss for P40 = 1.3635610342025757\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_96/2974510044.py:87: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/tmp/ipykernel_96/2974510044.py:43: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n",
      "/tmp/ipykernel_96/2974510044.py:61: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 90/100, Train Loss: 1.4287999868392944\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.23      0.47      0.31        43\n",
      "           1       0.29      0.21      0.25        61\n",
      "           2       0.49      0.30      0.37        61\n",
      "           3       0.36      0.33      0.34        55\n",
      "\n",
      "    accuracy                           0.31       220\n",
      "   macro avg       0.34      0.33      0.32       220\n",
      "weighted avg       0.35      0.31      0.32       220\n",
      "\n",
      "[[20  9  6  8]\n",
      " [27 13  7 14]\n",
      " [23 10 18 10]\n",
      " [18 13  6 18]]\n",
      "Validation Loss for P40 = 1.3686118125915527\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_96/2974510044.py:87: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/tmp/ipykernel_96/2974510044.py:43: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n",
      "/tmp/ipykernel_96/2974510044.py:61: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 91/100, Train Loss: 1.2888693809509277\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.23      0.49      0.31        43\n",
      "           1       0.32      0.21      0.25        61\n",
      "           2       0.45      0.30      0.36        61\n",
      "           3       0.38      0.33      0.35        55\n",
      "\n",
      "    accuracy                           0.32       220\n",
      "   macro avg       0.34      0.33      0.32       220\n",
      "weighted avg       0.35      0.32      0.32       220\n",
      "\n",
      "[[21  8  7  7]\n",
      " [27 13  8 13]\n",
      " [26  8 18  9]\n",
      " [18 12  7 18]]\n",
      "Validation Loss for P40 = 1.3686819076538086\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_96/2974510044.py:87: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/tmp/ipykernel_96/2974510044.py:43: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n",
      "/tmp/ipykernel_96/2974510044.py:61: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 92/100, Train Loss: 1.2750962972640991\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.24      0.51      0.32        43\n",
      "           1       0.32      0.21      0.25        61\n",
      "           2       0.45      0.30      0.36        61\n",
      "           3       0.37      0.31      0.34        55\n",
      "\n",
      "    accuracy                           0.32       220\n",
      "   macro avg       0.34      0.33      0.32       220\n",
      "weighted avg       0.35      0.32      0.32       220\n",
      "\n",
      "[[22  7  7  7]\n",
      " [27 13  8 13]\n",
      " [26  8 18  9]\n",
      " [18 13  7 17]]\n",
      "Validation Loss for P40 = 1.3665995597839355\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_96/2974510044.py:87: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/tmp/ipykernel_96/2974510044.py:43: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n",
      "/tmp/ipykernel_96/2974510044.py:61: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 93/100, Train Loss: 1.349128007888794\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.23      0.49      0.32        43\n",
      "           1       0.28      0.20      0.23        61\n",
      "           2       0.43      0.30      0.35        61\n",
      "           3       0.36      0.29      0.32        55\n",
      "\n",
      "    accuracy                           0.30       220\n",
      "   macro avg       0.32      0.32      0.30       220\n",
      "weighted avg       0.33      0.30      0.30       220\n",
      "\n",
      "[[21  8  7  7]\n",
      " [27 12  9 13]\n",
      " [24 10 18  9]\n",
      " [18 13  8 16]]\n",
      "Validation Loss for P40 = 1.3688373565673828\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_96/2974510044.py:87: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/tmp/ipykernel_96/2974510044.py:43: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n",
      "/tmp/ipykernel_96/2974510044.py:61: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 94/100, Train Loss: 1.2098267078399658\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.22      0.44      0.29        43\n",
      "           1       0.27      0.20      0.23        61\n",
      "           2       0.42      0.30      0.35        61\n",
      "           3       0.36      0.29      0.32        55\n",
      "\n",
      "    accuracy                           0.30       220\n",
      "   macro avg       0.32      0.31      0.30       220\n",
      "weighted avg       0.32      0.30      0.30       220\n",
      "\n",
      "[[19 10  7  7]\n",
      " [27 12  9 13]\n",
      " [24 10 18  9]\n",
      " [18 12  9 16]]\n",
      "Validation Loss for P40 = 1.3708794116973877\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_96/2974510044.py:87: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/tmp/ipykernel_96/2974510044.py:43: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n",
      "/tmp/ipykernel_96/2974510044.py:61: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 95/100, Train Loss: 1.3937057256698608\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.23      0.49      0.31        43\n",
      "           1       0.30      0.20      0.24        61\n",
      "           2       0.41      0.30      0.34        61\n",
      "           3       0.34      0.27      0.30        55\n",
      "\n",
      "    accuracy                           0.30       220\n",
      "   macro avg       0.32      0.31      0.30       220\n",
      "weighted avg       0.33      0.30      0.30       220\n",
      "\n",
      "[[21  8  7  7]\n",
      " [27 12  9 13]\n",
      " [26  8 18  9]\n",
      " [18 12 10 15]]\n",
      "Validation Loss for P40 = 1.3689371347427368\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_96/2974510044.py:87: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/tmp/ipykernel_96/2974510044.py:43: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n",
      "/tmp/ipykernel_96/2974510044.py:61: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 96/100, Train Loss: 1.3537944555282593\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.24      0.51      0.32        43\n",
      "           1       0.29      0.18      0.22        61\n",
      "           2       0.40      0.30      0.34        61\n",
      "           3       0.34      0.27      0.30        55\n",
      "\n",
      "    accuracy                           0.30       220\n",
      "   macro avg       0.32      0.31      0.30       220\n",
      "weighted avg       0.32      0.30      0.29       220\n",
      "\n",
      "[[22  7  8  6]\n",
      " [27 11  9 14]\n",
      " [26  8 18  9]\n",
      " [18 12 10 15]]\n",
      "Validation Loss for P40 = 1.3719031810760498\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_96/2974510044.py:87: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/tmp/ipykernel_96/2974510044.py:43: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n",
      "/tmp/ipykernel_96/2974510044.py:61: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 97/100, Train Loss: 1.381346583366394\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.22      0.47      0.30        43\n",
      "           1       0.26      0.16      0.20        61\n",
      "           2       0.42      0.31      0.36        61\n",
      "           3       0.35      0.29      0.32        55\n",
      "\n",
      "    accuracy                           0.30       220\n",
      "   macro avg       0.31      0.31      0.29       220\n",
      "weighted avg       0.32      0.30      0.29       220\n",
      "\n",
      "[[20  9  7  7]\n",
      " [27 10 10 14]\n",
      " [25  8 19  9]\n",
      " [18 12  9 16]]\n",
      "Validation Loss for P40 = 1.3717149496078491\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_96/2974510044.py:87: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/tmp/ipykernel_96/2974510044.py:43: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n",
      "/tmp/ipykernel_96/2974510044.py:61: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 98/100, Train Loss: 1.3547544479370117\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.23      0.49      0.31        43\n",
      "           1       0.32      0.20      0.24        61\n",
      "           2       0.41      0.31      0.36        61\n",
      "           3       0.36      0.29      0.32        55\n",
      "\n",
      "    accuracy                           0.31       220\n",
      "   macro avg       0.33      0.32      0.31       220\n",
      "weighted avg       0.34      0.31      0.31       220\n",
      "\n",
      "[[21  6  9  7]\n",
      " [27 12  9 13]\n",
      " [25  8 19  9]\n",
      " [18 12  9 16]]\n",
      "Validation Loss for P40 = 1.3695673942565918\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_96/2974510044.py:87: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/tmp/ipykernel_96/2974510044.py:43: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n",
      "/tmp/ipykernel_96/2974510044.py:61: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 99/100, Train Loss: 1.3498438596725464\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.23      0.42      0.29        43\n",
      "           1       0.26      0.18      0.21        61\n",
      "           2       0.45      0.34      0.39        61\n",
      "           3       0.35      0.33      0.34        55\n",
      "\n",
      "    accuracy                           0.31       220\n",
      "   macro avg       0.32      0.32      0.31       220\n",
      "weighted avg       0.33      0.31      0.31       220\n",
      "\n",
      "[[18  9  9  7]\n",
      " [24 11  9 17]\n",
      " [21 10 21  9]\n",
      " [17 12  8 18]]\n",
      "Validation Loss for P40 = 1.3638173341751099\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_96/2974510044.py:87: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/tmp/ipykernel_96/2974510044.py:43: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n",
      "/tmp/ipykernel_96/2974510044.py:61: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 100/100, Train Loss: 1.351833462715149\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.24      0.49      0.32        43\n",
      "           1       0.30      0.18      0.22        61\n",
      "           2       0.44      0.33      0.38        61\n",
      "           3       0.35      0.33      0.34        55\n",
      "\n",
      "    accuracy                           0.32       220\n",
      "   macro avg       0.33      0.33      0.32       220\n",
      "weighted avg       0.34      0.32      0.31       220\n",
      "\n",
      "[[21  6  9  7]\n",
      " [25 11  8 17]\n",
      " [24  8 20  9]\n",
      " [17 12  8 18]]\n",
      "Validation Loss for P40 = 1.3638700246810913\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_96/2974510044.py:87: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x7fd0304e5cd0>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import confusion_matrix,classification_report\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import preprocessing\n",
    "import matplotlib.pyplot as plt\n",
    "#subjectnames\n",
    "file_list_num = np.arange(len(newsubjectname))\n",
    "file_list_numd = np.arange(len(subjectnamesd))\n",
    "\n",
    "kf = KFold(n_splits=12)\n",
    "torch.manual_seed(42)\n",
    "torch.cuda.manual_seed(42)\n",
    "modellist = []\n",
    "modelid = 1\n",
    "#file_list_num\n",
    "#for i, (train_index, test_index) in enumerate(kf.split(file_list_num)):\n",
    "#for train_index in file_list_num:\n",
    "train_index = file_list_numd\n",
    "test_index_train, test_index_test = train_test_split(file_list_num, test_size=0.30, random_state=42)\n",
    "#test_index = file_list_num\n",
    "print(f\"Fold {i}:\")\n",
    "print(f\"  Train: index={train_index}\")\n",
    "print(f\"  Test:  index={test_index_train}\")\n",
    "net = Net()\n",
    "net.to(device)\n",
    "optimizer = optim.Adam(net.parameters(), lr=0.000001)\n",
    "epochs = 100\n",
    "batch_sz = 20\n",
    "train_loss_epoch = []\n",
    "val_loss_epoch = []\n",
    "for epoch in range(epochs):\n",
    "  train_loss = []\n",
    "  for tr in train_index:\n",
    "    v = data_de1[subjectnamesd[tr]]\n",
    "    l = data_del[subjectnamesd[tr]]\n",
    "    #print(v[0].shape)\n",
    "    net.train()\n",
    "    for i in range(0,len(v),batch_sz):\n",
    "      #print(v[i].shape)\n",
    "      #for j in range(0,v[i].shape[0],batch_sz):\n",
    "      #print(newsubjectname[tr])\n",
    "      optimizer.zero_grad()\n",
    "      outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
    "      #print(\"Expout {}\",outputs.shape)\n",
    "      #print(\"Actual {}\",l[i:i+batch_sz].shape)\n",
    "      #print(l[i].shape)\n",
    "      loss = criterion(outputs, l[i:i+batch_sz].to(device, dtype=torch.float))\n",
    "      loss.backward()\n",
    "      train_loss.append(loss)\n",
    "      optimizer.step()\n",
    "  for tr in test_index_train:\n",
    "    v = data_c1d[newsubjectname[tr]]\n",
    "    l = data_c2[newsubjectname[tr]]\n",
    "    #print(v[0].shape)\n",
    "    net.train()\n",
    "    for i in range(0,len(v),batch_sz):\n",
    "      #print(v[i].shape)\n",
    "      #for j in range(0,v[i].shape[0],batch_sz):\n",
    "      #print(newsubjectname[tr])\n",
    "      optimizer.zero_grad()\n",
    "      outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
    "      #print(\"Expout {}\",outputs.shape)\n",
    "      #print(\"Actual {}\",l[i:i+batch_sz].shape)\n",
    "      #print(l[i].shape)\n",
    "      loss = criterion(outputs, l[i:i+batch_sz].to(device, dtype=torch.float))\n",
    "      loss.backward()\n",
    "      train_loss.append(loss)\n",
    "      optimizer.step()\n",
    "  print(f'Epoch {epoch + 1}/{epochs}, Train Loss: {loss.item()}')\n",
    "  train_loss_epoch.append(torch.stack(train_loss).mean().cpu().detach().numpy())\n",
    "  #print(train_loss_epoch)\n",
    "  expectedoutputamigos = []\n",
    "  actualoutputamigos = []\n",
    "\n",
    "  for tr in test_index_test:\n",
    "      net.eval()\n",
    "\n",
    "      v = data_c1d[newsubjectname[tr]]\n",
    "      l = data_c2[newsubjectname[tr]]\n",
    "      net.eval()\n",
    "      val_loss = []\n",
    "      with torch.no_grad():\n",
    "          for i in range(0,len(v),batch_sz):\n",
    "            #print(v[i].shape)\n",
    "            #for j in range(0,v[i].shape[0],batch_sz):\n",
    "            optimizer.zero_grad()\n",
    "            outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
    "            #print(outputs.shape)\n",
    "            #print(l[i:i+batch_sz].shape)\n",
    "            loss = criterion(outputs, l[i:i+batch_sz].to(device, dtype=torch.float))\n",
    "            val_loss.append(loss)\n",
    "            #actualoutputamigos.append(torch.round(outputs.cpu()))\n",
    "            #expectedoutputamigos.append(l[i:i+batch_sz])\n",
    "            actualoutputamigos.append(torch.argmax(torch.softmax(outputs.cpu(),dim=1),dim=1))\n",
    "            expectedoutputamigos.append(torch.argmax(l[i:i+batch_sz],dim=1).numpy())\n",
    "  val_loss_mean = torch.stack(val_loss).mean().cpu().detach().numpy()\n",
    "  val_loss_epoch.append(val_loss_mean)\n",
    "  expectedoutputamigos = np.concatenate( expectedoutputamigos, axis=0 )\n",
    "  actualoutputamigos = np.concatenate( actualoutputamigos, axis=0 )\n",
    "  #print(expectedoutput.shape)\n",
    "  #print(actualoutput.shape)\n",
    "  print(classification_report(expectedoutputamigos,actualoutputamigos))\n",
    "  print(confusion_matrix(expectedoutputamigos,actualoutputamigos))\n",
    "  print(f'Validation Loss for {newsubjectname[tr]} = {val_loss_mean}')\n",
    "plt.figure(figsize=(10,7))\n",
    "#print(len(train_loss_epoch))\n",
    "plt.plot(np.arange(epochs),train_loss_epoch,label='Train')\n",
    "plt.plot(np.arange(epochs),val_loss_epoch,label='Validation')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "629a6e47-a58b-496b-9740-4e35f730b5d6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-24T12:38:54.619238Z",
     "iopub.status.busy": "2024-01-24T12:38:54.618794Z",
     "iopub.status.idle": "2024-01-24T12:43:49.643164Z",
     "shell.execute_reply": "2024-01-24T12:43:49.641685Z",
     "shell.execute_reply.started": "2024-01-24T12:38:54.619198Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 0:\n",
      "  Train: index=[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23\n",
      " 24 25 26 27 28 29 30 31]\n",
      "  Test:  index=[0 8 2 4 3 6]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_32/3812056636.py:43: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([18, 1, 8064])\n",
      "torch.Size([15, 1, 8064])\n",
      "torch.Size([18, 1, 8064])\n",
      "torch.Size([15, 1, 8064])\n",
      "torch.Size([2, 1, 8064])\n",
      "Epoch 1/300, Train Loss: 1.2203803062438965\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         7\n",
      "           1       0.00      0.00      0.00         0\n",
      "           2       0.10      0.33      0.15         3\n",
      "           3       0.60      0.40      0.48        15\n",
      "\n",
      "    accuracy                           0.28        25\n",
      "   macro avg       0.17      0.18      0.16        25\n",
      "weighted avg       0.37      0.28      0.31        25\n",
      "\n",
      "[[0 1 3 3]\n",
      " [0 0 0 0]\n",
      " [0 1 1 1]\n",
      " [0 3 6 6]]\n",
      "Validation Loss for P31 = 1.4986132383346558\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.9/dist-packages/sklearn/metrics/_classification.py:1334: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.9/dist-packages/sklearn/metrics/_classification.py:1334: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.9/dist-packages/sklearn/metrics/_classification.py:1334: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.9/dist-packages/sklearn/metrics/_classification.py:1334: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.9/dist-packages/sklearn/metrics/_classification.py:1334: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.9/dist-packages/sklearn/metrics/_classification.py:1334: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/tmp/ipykernel_32/3812056636.py:43: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([18, 1, 8064])\n",
      "torch.Size([15, 1, 8064])\n",
      "torch.Size([18, 1, 8064])\n",
      "torch.Size([15, 1, 8064])\n",
      "torch.Size([2, 1, 8064])\n",
      "Epoch 2/300, Train Loss: 1.4611608982086182\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         7\n",
      "           1       0.00      0.00      0.00         0\n",
      "           2       0.27      1.00      0.43         3\n",
      "           3       0.67      0.40      0.50        15\n",
      "\n",
      "    accuracy                           0.36        25\n",
      "   macro avg       0.23      0.35      0.23        25\n",
      "weighted avg       0.43      0.36      0.35        25\n",
      "\n",
      "[[0 1 3 3]\n",
      " [0 0 0 0]\n",
      " [0 0 3 0]\n",
      " [0 4 5 6]]\n",
      "Validation Loss for P31 = 1.435397982597351\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.9/dist-packages/sklearn/metrics/_classification.py:1334: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.9/dist-packages/sklearn/metrics/_classification.py:1334: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.9/dist-packages/sklearn/metrics/_classification.py:1334: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.9/dist-packages/sklearn/metrics/_classification.py:1334: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.9/dist-packages/sklearn/metrics/_classification.py:1334: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.9/dist-packages/sklearn/metrics/_classification.py:1334: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/tmp/ipykernel_32/3812056636.py:43: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([18, 1, 8064])\n",
      "torch.Size([15, 1, 8064])\n",
      "torch.Size([18, 1, 8064])\n",
      "torch.Size([15, 1, 8064])\n",
      "torch.Size([2, 1, 8064])\n",
      "Epoch 3/300, Train Loss: 1.3904645442962646\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.50      0.14      0.22         7\n",
      "           1       0.00      0.00      0.00         0\n",
      "           2       0.27      1.00      0.43         3\n",
      "           3       0.71      0.33      0.45        15\n",
      "\n",
      "    accuracy                           0.36        25\n",
      "   macro avg       0.37      0.37      0.28        25\n",
      "weighted avg       0.60      0.36      0.39        25\n",
      "\n",
      "[[1 1 3 2]\n",
      " [0 0 0 0]\n",
      " [0 0 3 0]\n",
      " [1 4 5 5]]\n",
      "Validation Loss for P31 = 1.4266217947006226\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.9/dist-packages/sklearn/metrics/_classification.py:1334: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.9/dist-packages/sklearn/metrics/_classification.py:1334: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.9/dist-packages/sklearn/metrics/_classification.py:1334: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/tmp/ipykernel_32/3812056636.py:43: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([18, 1, 8064])\n",
      "torch.Size([15, 1, 8064])\n",
      "torch.Size([18, 1, 8064])\n",
      "torch.Size([15, 1, 8064])\n",
      "torch.Size([2, 1, 8064])\n",
      "Epoch 4/300, Train Loss: 1.4865715503692627\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.50      0.14      0.22         7\n",
      "           1       0.00      0.00      0.00         0\n",
      "           2       0.23      1.00      0.38         3\n",
      "           3       0.50      0.13      0.21        15\n",
      "\n",
      "    accuracy                           0.24        25\n",
      "   macro avg       0.31      0.32      0.20        25\n",
      "weighted avg       0.47      0.24      0.23        25\n",
      "\n",
      "[[1 2 2 2]\n",
      " [0 0 0 0]\n",
      " [0 0 3 0]\n",
      " [1 4 8 2]]\n",
      "Validation Loss for P31 = 1.4122663736343384\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.9/dist-packages/sklearn/metrics/_classification.py:1334: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.9/dist-packages/sklearn/metrics/_classification.py:1334: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.9/dist-packages/sklearn/metrics/_classification.py:1334: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/tmp/ipykernel_32/3812056636.py:43: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([18, 1, 8064])\n",
      "torch.Size([15, 1, 8064])\n",
      "torch.Size([18, 1, 8064])\n",
      "torch.Size([15, 1, 8064])\n",
      "torch.Size([2, 1, 8064])\n",
      "Epoch 5/300, Train Loss: 1.5749423503875732\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.17      0.14      0.15         7\n",
      "           1       0.00      0.00      0.00         0\n",
      "           2       0.22      0.67      0.33         3\n",
      "           3       0.60      0.20      0.30        15\n",
      "\n",
      "    accuracy                           0.24        25\n",
      "   macro avg       0.25      0.25      0.20        25\n",
      "weighted avg       0.43      0.24      0.26        25\n",
      "\n",
      "[[1 2 2 2]\n",
      " [0 0 0 0]\n",
      " [1 0 2 0]\n",
      " [4 3 5 3]]\n",
      "Validation Loss for P31 = 1.3721630573272705\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.9/dist-packages/sklearn/metrics/_classification.py:1334: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.9/dist-packages/sklearn/metrics/_classification.py:1334: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.9/dist-packages/sklearn/metrics/_classification.py:1334: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/tmp/ipykernel_32/3812056636.py:43: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([18, 1, 8064])\n",
      "torch.Size([15, 1, 8064])\n",
      "torch.Size([18, 1, 8064])\n",
      "torch.Size([15, 1, 8064])\n",
      "torch.Size([2, 1, 8064])\n",
      "Epoch 6/300, Train Loss: 1.3511496782302856\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.22      0.29      0.25         7\n",
      "           1       0.00      0.00      0.00         0\n",
      "           2       0.17      0.33      0.22         3\n",
      "           3       0.80      0.27      0.40        15\n",
      "\n",
      "    accuracy                           0.28        25\n",
      "   macro avg       0.30      0.22      0.22        25\n",
      "weighted avg       0.56      0.28      0.34        25\n",
      "\n",
      "[[2 2 2 1]\n",
      " [0 0 0 0]\n",
      " [2 0 1 0]\n",
      " [5 3 3 4]]\n",
      "Validation Loss for P31 = 1.357608437538147\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.9/dist-packages/sklearn/metrics/_classification.py:1334: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.9/dist-packages/sklearn/metrics/_classification.py:1334: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.9/dist-packages/sklearn/metrics/_classification.py:1334: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/tmp/ipykernel_32/3812056636.py:43: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([18, 1, 8064])\n",
      "torch.Size([15, 1, 8064])\n",
      "torch.Size([18, 1, 8064])\n",
      "torch.Size([15, 1, 8064])\n",
      "torch.Size([2, 1, 8064])\n",
      "Epoch 7/300, Train Loss: 1.5407390594482422\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.29      0.44         7\n",
      "           1       0.00      0.00      0.00         0\n",
      "           2       0.19      1.00      0.32         3\n",
      "           3       1.00      0.13      0.24        15\n",
      "\n",
      "    accuracy                           0.28        25\n",
      "   macro avg       0.55      0.35      0.25        25\n",
      "weighted avg       0.90      0.28      0.30        25\n",
      "\n",
      "[[ 2  2  3  0]\n",
      " [ 0  0  0  0]\n",
      " [ 0  0  3  0]\n",
      " [ 0  3 10  2]]\n",
      "Validation Loss for P31 = 1.3744570016860962\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.9/dist-packages/sklearn/metrics/_classification.py:1334: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.9/dist-packages/sklearn/metrics/_classification.py:1334: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.9/dist-packages/sklearn/metrics/_classification.py:1334: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/tmp/ipykernel_32/3812056636.py:43: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([18, 1, 8064])\n",
      "torch.Size([15, 1, 8064])\n",
      "torch.Size([18, 1, 8064])\n",
      "torch.Size([15, 1, 8064])\n",
      "torch.Size([2, 1, 8064])\n",
      "Epoch 8/300, Train Loss: 1.3540782928466797\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.25      0.29      0.27         7\n",
      "           1       0.00      0.00      0.00         0\n",
      "           2       0.11      0.33      0.17         3\n",
      "           3       1.00      0.27      0.42        15\n",
      "\n",
      "    accuracy                           0.28        25\n",
      "   macro avg       0.34      0.22      0.21        25\n",
      "weighted avg       0.68      0.28      0.35        25\n",
      "\n",
      "[[2 2 3 0]\n",
      " [0 0 0 0]\n",
      " [2 0 1 0]\n",
      " [4 2 5 4]]\n",
      "Validation Loss for P31 = 1.359777569770813\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.9/dist-packages/sklearn/metrics/_classification.py:1334: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.9/dist-packages/sklearn/metrics/_classification.py:1334: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.9/dist-packages/sklearn/metrics/_classification.py:1334: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/tmp/ipykernel_32/3812056636.py:43: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([18, 1, 8064])\n",
      "torch.Size([15, 1, 8064])\n",
      "torch.Size([18, 1, 8064])\n",
      "torch.Size([15, 1, 8064])\n",
      "torch.Size([2, 1, 8064])\n",
      "Epoch 9/300, Train Loss: 1.4579346179962158\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.33      0.29      0.31         7\n",
      "           1       0.00      0.00      0.00         0\n",
      "           2       0.27      1.00      0.43         3\n",
      "           3       1.00      0.27      0.42        15\n",
      "\n",
      "    accuracy                           0.36        25\n",
      "   macro avg       0.40      0.39      0.29        25\n",
      "weighted avg       0.73      0.36      0.39        25\n",
      "\n",
      "[[2 2 3 0]\n",
      " [0 0 0 0]\n",
      " [0 0 3 0]\n",
      " [4 2 5 4]]\n",
      "Validation Loss for P31 = 1.370864748954773\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.9/dist-packages/sklearn/metrics/_classification.py:1334: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.9/dist-packages/sklearn/metrics/_classification.py:1334: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.9/dist-packages/sklearn/metrics/_classification.py:1334: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/tmp/ipykernel_32/3812056636.py:43: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([18, 1, 8064])\n",
      "torch.Size([15, 1, 8064])\n",
      "torch.Size([18, 1, 8064])\n",
      "torch.Size([15, 1, 8064])\n",
      "torch.Size([2, 1, 8064])\n",
      "Epoch 10/300, Train Loss: 1.2304372787475586\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.67      0.29      0.40         7\n",
      "           1       0.00      0.00      0.00         0\n",
      "           2       0.20      1.00      0.33         3\n",
      "           3       1.00      0.20      0.33        15\n",
      "\n",
      "    accuracy                           0.32        25\n",
      "   macro avg       0.47      0.37      0.27        25\n",
      "weighted avg       0.81      0.32      0.35        25\n",
      "\n",
      "[[2 2 3 0]\n",
      " [0 0 0 0]\n",
      " [0 0 3 0]\n",
      " [1 2 9 3]]\n",
      "Validation Loss for P31 = 1.3696600198745728\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.9/dist-packages/sklearn/metrics/_classification.py:1334: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.9/dist-packages/sklearn/metrics/_classification.py:1334: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.9/dist-packages/sklearn/metrics/_classification.py:1334: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/tmp/ipykernel_32/3812056636.py:43: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([18, 1, 8064])\n",
      "torch.Size([15, 1, 8064])\n",
      "torch.Size([18, 1, 8064])\n",
      "torch.Size([15, 1, 8064])\n",
      "torch.Size([2, 1, 8064])\n",
      "Epoch 11/300, Train Loss: 1.27469801902771\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.40      0.29      0.33         7\n",
      "           1       0.00      0.00      0.00         0\n",
      "           2       0.23      1.00      0.38         3\n",
      "           3       1.00      0.20      0.33        15\n",
      "\n",
      "    accuracy                           0.32        25\n",
      "   macro avg       0.41      0.37      0.26        25\n",
      "weighted avg       0.74      0.32      0.34        25\n",
      "\n",
      "[[2 2 3 0]\n",
      " [0 0 0 0]\n",
      " [0 0 3 0]\n",
      " [3 2 7 3]]\n",
      "Validation Loss for P31 = 1.3758182525634766\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.9/dist-packages/sklearn/metrics/_classification.py:1334: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.9/dist-packages/sklearn/metrics/_classification.py:1334: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.9/dist-packages/sklearn/metrics/_classification.py:1334: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/tmp/ipykernel_32/3812056636.py:43: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([18, 1, 8064])\n",
      "torch.Size([15, 1, 8064])\n",
      "torch.Size([18, 1, 8064])\n",
      "torch.Size([15, 1, 8064])\n",
      "torch.Size([2, 1, 8064])\n",
      "Epoch 12/300, Train Loss: 1.3307137489318848\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.27      0.43      0.33         7\n",
      "           1       0.00      0.00      0.00         0\n",
      "           2       0.14      0.33      0.20         3\n",
      "           3       1.00      0.13      0.24        15\n",
      "\n",
      "    accuracy                           0.24        25\n",
      "   macro avg       0.35      0.22      0.19        25\n",
      "weighted avg       0.69      0.24      0.26        25\n",
      "\n",
      "[[3 2 2 0]\n",
      " [0 0 0 0]\n",
      " [2 0 1 0]\n",
      " [6 3 4 2]]\n",
      "Validation Loss for P31 = 1.3789713382720947\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.9/dist-packages/sklearn/metrics/_classification.py:1334: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.9/dist-packages/sklearn/metrics/_classification.py:1334: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.9/dist-packages/sklearn/metrics/_classification.py:1334: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/tmp/ipykernel_32/3812056636.py:43: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([18, 1, 8064])\n",
      "torch.Size([15, 1, 8064])\n",
      "torch.Size([18, 1, 8064])\n",
      "torch.Size([15, 1, 8064])\n",
      "torch.Size([2, 1, 8064])\n",
      "Epoch 13/300, Train Loss: 1.4989451169967651\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.25      0.29      0.27         7\n",
      "           1       0.00      0.00      0.00         0\n",
      "           2       0.22      0.67      0.33         3\n",
      "           3       1.00      0.27      0.42        15\n",
      "\n",
      "    accuracy                           0.32        25\n",
      "   macro avg       0.37      0.30      0.26        25\n",
      "weighted avg       0.70      0.32      0.37        25\n",
      "\n",
      "[[2 2 3 0]\n",
      " [0 0 0 0]\n",
      " [1 0 2 0]\n",
      " [5 2 4 4]]\n",
      "Validation Loss for P31 = 1.3699220418930054\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.9/dist-packages/sklearn/metrics/_classification.py:1334: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.9/dist-packages/sklearn/metrics/_classification.py:1334: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.9/dist-packages/sklearn/metrics/_classification.py:1334: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/tmp/ipykernel_32/3812056636.py:43: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([18, 1, 8064])\n",
      "torch.Size([15, 1, 8064])\n",
      "torch.Size([18, 1, 8064])\n",
      "torch.Size([15, 1, 8064])\n",
      "torch.Size([2, 1, 8064])\n",
      "Epoch 14/300, Train Loss: 1.2591955661773682\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.67      0.29      0.40         7\n",
      "           1       0.00      0.00      0.00         0\n",
      "           2       0.21      1.00      0.35         3\n",
      "           3       1.00      0.27      0.42        15\n",
      "\n",
      "    accuracy                           0.36        25\n",
      "   macro avg       0.47      0.39      0.29        25\n",
      "weighted avg       0.81      0.36      0.41        25\n",
      "\n",
      "[[2 2 3 0]\n",
      " [0 0 0 0]\n",
      " [0 0 3 0]\n",
      " [1 2 8 4]]\n",
      "Validation Loss for P31 = 1.3658015727996826\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.9/dist-packages/sklearn/metrics/_classification.py:1334: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.9/dist-packages/sklearn/metrics/_classification.py:1334: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.9/dist-packages/sklearn/metrics/_classification.py:1334: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/tmp/ipykernel_32/3812056636.py:43: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([18, 1, 8064])\n",
      "torch.Size([15, 1, 8064])\n",
      "torch.Size([18, 1, 8064])\n",
      "torch.Size([15, 1, 8064])\n",
      "torch.Size([2, 1, 8064])\n",
      "Epoch 15/300, Train Loss: 1.5839027166366577\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.50      0.14      0.22         7\n",
      "           1       0.00      0.00      0.00         0\n",
      "           2       0.21      1.00      0.35         3\n",
      "           3       1.00      0.33      0.50        15\n",
      "\n",
      "    accuracy                           0.36        25\n",
      "   macro avg       0.43      0.37      0.27        25\n",
      "weighted avg       0.77      0.36      0.40        25\n",
      "\n",
      "[[1 2 4 0]\n",
      " [0 0 0 0]\n",
      " [0 0 3 0]\n",
      " [1 2 7 5]]\n",
      "Validation Loss for P31 = 1.376909613609314\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.9/dist-packages/sklearn/metrics/_classification.py:1334: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.9/dist-packages/sklearn/metrics/_classification.py:1334: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.9/dist-packages/sklearn/metrics/_classification.py:1334: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/tmp/ipykernel_32/3812056636.py:43: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([18, 1, 8064])\n",
      "torch.Size([15, 1, 8064])\n",
      "torch.Size([18, 1, 8064])\n",
      "torch.Size([15, 1, 8064])\n",
      "torch.Size([2, 1, 8064])\n",
      "Epoch 16/300, Train Loss: 1.4829126596450806\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.50      0.14      0.22         7\n",
      "           1       0.00      0.00      0.00         0\n",
      "           2       0.20      1.00      0.33         3\n",
      "           3       1.00      0.27      0.42        15\n",
      "\n",
      "    accuracy                           0.32        25\n",
      "   macro avg       0.42      0.35      0.24        25\n",
      "weighted avg       0.76      0.32      0.35        25\n",
      "\n",
      "[[1 2 4 0]\n",
      " [0 0 0 0]\n",
      " [0 0 3 0]\n",
      " [1 2 8 4]]\n",
      "Validation Loss for P31 = 1.3751767873764038\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.9/dist-packages/sklearn/metrics/_classification.py:1334: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.9/dist-packages/sklearn/metrics/_classification.py:1334: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.9/dist-packages/sklearn/metrics/_classification.py:1334: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/tmp/ipykernel_32/3812056636.py:43: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([18, 1, 8064])\n",
      "torch.Size([15, 1, 8064])\n",
      "torch.Size([18, 1, 8064])\n",
      "torch.Size([15, 1, 8064])\n",
      "torch.Size([2, 1, 8064])\n",
      "Epoch 17/300, Train Loss: 1.5070836544036865\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.50      0.29      0.36         7\n",
      "           1       0.00      0.00      0.00         0\n",
      "           2       0.25      1.00      0.40         3\n",
      "           3       1.00      0.33      0.50        15\n",
      "\n",
      "    accuracy                           0.40        25\n",
      "   macro avg       0.44      0.40      0.32        25\n",
      "weighted avg       0.77      0.40      0.45        25\n",
      "\n",
      "[[2 3 2 0]\n",
      " [0 0 0 0]\n",
      " [0 0 3 0]\n",
      " [2 1 7 5]]\n",
      "Validation Loss for P31 = 1.3580260276794434\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.9/dist-packages/sklearn/metrics/_classification.py:1334: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.9/dist-packages/sklearn/metrics/_classification.py:1334: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.9/dist-packages/sklearn/metrics/_classification.py:1334: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/tmp/ipykernel_32/3812056636.py:43: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([18, 1, 8064])\n",
      "torch.Size([15, 1, 8064])\n",
      "torch.Size([18, 1, 8064])\n",
      "torch.Size([15, 1, 8064])\n",
      "torch.Size([2, 1, 8064])\n",
      "Epoch 18/300, Train Loss: 1.7182581424713135\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.33      0.14      0.20         7\n",
      "           1       0.00      0.00      0.00         0\n",
      "           2       0.25      1.00      0.40         3\n",
      "           3       1.00      0.47      0.64        15\n",
      "\n",
      "    accuracy                           0.44        25\n",
      "   macro avg       0.40      0.40      0.31        25\n",
      "weighted avg       0.72      0.44      0.49        25\n",
      "\n",
      "[[1 2 4 0]\n",
      " [0 0 0 0]\n",
      " [0 0 3 0]\n",
      " [2 1 5 7]]\n",
      "Validation Loss for P31 = 1.3481136560440063\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.9/dist-packages/sklearn/metrics/_classification.py:1334: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.9/dist-packages/sklearn/metrics/_classification.py:1334: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.9/dist-packages/sklearn/metrics/_classification.py:1334: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/tmp/ipykernel_32/3812056636.py:43: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([18, 1, 8064])\n",
      "torch.Size([15, 1, 8064])\n",
      "torch.Size([18, 1, 8064])\n",
      "torch.Size([15, 1, 8064])\n",
      "torch.Size([2, 1, 8064])\n",
      "Epoch 19/300, Train Loss: 1.3963611125946045\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         7\n",
      "           1       0.00      0.00      0.00         0\n",
      "           2       0.20      1.00      0.33         3\n",
      "           3       1.00      0.40      0.57        15\n",
      "\n",
      "    accuracy                           0.36        25\n",
      "   macro avg       0.30      0.35      0.23        25\n",
      "weighted avg       0.62      0.36      0.38        25\n",
      "\n",
      "[[0 2 5 0]\n",
      " [0 0 0 0]\n",
      " [0 0 3 0]\n",
      " [1 1 7 6]]\n",
      "Validation Loss for P31 = 1.3468139171600342\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.9/dist-packages/sklearn/metrics/_classification.py:1334: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.9/dist-packages/sklearn/metrics/_classification.py:1334: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.9/dist-packages/sklearn/metrics/_classification.py:1334: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/tmp/ipykernel_32/3812056636.py:43: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([18, 1, 8064])\n",
      "torch.Size([15, 1, 8064])\n",
      "torch.Size([18, 1, 8064])\n",
      "torch.Size([15, 1, 8064])\n",
      "torch.Size([2, 1, 8064])\n",
      "Epoch 20/300, Train Loss: 1.7062056064605713\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.33      0.14      0.20         7\n",
      "           1       0.00      0.00      0.00         0\n",
      "           2       0.27      1.00      0.43         3\n",
      "           3       1.00      0.47      0.64        15\n",
      "\n",
      "    accuracy                           0.44        25\n",
      "   macro avg       0.40      0.40      0.32        25\n",
      "weighted avg       0.73      0.44      0.49        25\n",
      "\n",
      "[[1 3 3 0]\n",
      " [0 0 0 0]\n",
      " [0 0 3 0]\n",
      " [2 1 5 7]]\n",
      "Validation Loss for P31 = 1.3541711568832397\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.9/dist-packages/sklearn/metrics/_classification.py:1334: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.9/dist-packages/sklearn/metrics/_classification.py:1334: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.9/dist-packages/sklearn/metrics/_classification.py:1334: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/tmp/ipykernel_32/3812056636.py:43: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([18, 1, 8064])\n",
      "torch.Size([15, 1, 8064])\n",
      "torch.Size([18, 1, 8064])\n",
      "torch.Size([15, 1, 8064])\n",
      "torch.Size([2, 1, 8064])\n",
      "Epoch 21/300, Train Loss: 1.8040707111358643\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         7\n",
      "           1       0.00      0.00      0.00         0\n",
      "           2       0.20      1.00      0.33         3\n",
      "           3       1.00      0.40      0.57        15\n",
      "\n",
      "    accuracy                           0.36        25\n",
      "   macro avg       0.30      0.35      0.23        25\n",
      "weighted avg       0.62      0.36      0.38        25\n",
      "\n",
      "[[0 2 5 0]\n",
      " [0 0 0 0]\n",
      " [0 0 3 0]\n",
      " [1 1 7 6]]\n",
      "Validation Loss for P31 = 1.3463194370269775\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.9/dist-packages/sklearn/metrics/_classification.py:1334: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.9/dist-packages/sklearn/metrics/_classification.py:1334: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.9/dist-packages/sklearn/metrics/_classification.py:1334: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/tmp/ipykernel_32/3812056636.py:43: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([18, 1, 8064])\n",
      "torch.Size([15, 1, 8064])\n",
      "torch.Size([18, 1, 8064])\n",
      "torch.Size([15, 1, 8064])\n",
      "torch.Size([2, 1, 8064])\n",
      "Epoch 22/300, Train Loss: 1.666510820388794\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.33      0.14      0.20         7\n",
      "           1       0.00      0.00      0.00         0\n",
      "           2       0.25      1.00      0.40         3\n",
      "           3       1.00      0.47      0.64        15\n",
      "\n",
      "    accuracy                           0.44        25\n",
      "   macro avg       0.40      0.40      0.31        25\n",
      "weighted avg       0.72      0.44      0.49        25\n",
      "\n",
      "[[1 2 4 0]\n",
      " [0 0 0 0]\n",
      " [0 0 3 0]\n",
      " [2 1 5 7]]\n",
      "Validation Loss for P31 = 1.3463388681411743\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.9/dist-packages/sklearn/metrics/_classification.py:1334: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.9/dist-packages/sklearn/metrics/_classification.py:1334: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.9/dist-packages/sklearn/metrics/_classification.py:1334: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/tmp/ipykernel_32/3812056636.py:43: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([18, 1, 8064])\n",
      "torch.Size([15, 1, 8064])\n",
      "torch.Size([18, 1, 8064])\n",
      "torch.Size([15, 1, 8064])\n",
      "torch.Size([2, 1, 8064])\n",
      "Epoch 23/300, Train Loss: 1.482912540435791\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.40      0.29      0.33         7\n",
      "           1       0.00      0.00      0.00         0\n",
      "           2       0.22      0.67      0.33         3\n",
      "           3       0.88      0.47      0.61        15\n",
      "\n",
      "    accuracy                           0.44        25\n",
      "   macro avg       0.37      0.35      0.32        25\n",
      "weighted avg       0.66      0.44      0.50        25\n",
      "\n",
      "[[2 2 3 0]\n",
      " [0 0 0 0]\n",
      " [0 0 2 1]\n",
      " [3 1 4 7]]\n",
      "Validation Loss for P31 = 1.3436607122421265\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.9/dist-packages/sklearn/metrics/_classification.py:1334: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.9/dist-packages/sklearn/metrics/_classification.py:1334: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.9/dist-packages/sklearn/metrics/_classification.py:1334: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/tmp/ipykernel_32/3812056636.py:43: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([18, 1, 8064])\n",
      "torch.Size([15, 1, 8064])\n",
      "torch.Size([18, 1, 8064])\n",
      "torch.Size([15, 1, 8064])\n",
      "torch.Size([2, 1, 8064])\n",
      "Epoch 24/300, Train Loss: 1.1181750297546387\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         7\n",
      "           1       0.00      0.00      0.00         0\n",
      "           2       0.15      0.67      0.25         3\n",
      "           3       0.88      0.47      0.61        15\n",
      "\n",
      "    accuracy                           0.36        25\n",
      "   macro avg       0.26      0.28      0.21        25\n",
      "weighted avg       0.54      0.36      0.40        25\n",
      "\n",
      "[[0 2 5 0]\n",
      " [0 0 0 0]\n",
      " [0 0 2 1]\n",
      " [1 1 6 7]]\n",
      "Validation Loss for P31 = 1.3324333429336548\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.9/dist-packages/sklearn/metrics/_classification.py:1334: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.9/dist-packages/sklearn/metrics/_classification.py:1334: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.9/dist-packages/sklearn/metrics/_classification.py:1334: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/tmp/ipykernel_32/3812056636.py:43: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([18, 1, 8064])\n",
      "torch.Size([15, 1, 8064])\n",
      "torch.Size([18, 1, 8064])\n",
      "torch.Size([15, 1, 8064])\n",
      "torch.Size([2, 1, 8064])\n",
      "Epoch 25/300, Train Loss: 1.7454001903533936\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         7\n",
      "           1       0.00      0.00      0.00         0\n",
      "           2       0.20      1.00      0.33         3\n",
      "           3       1.00      0.40      0.57        15\n",
      "\n",
      "    accuracy                           0.36        25\n",
      "   macro avg       0.30      0.35      0.23        25\n",
      "weighted avg       0.62      0.36      0.38        25\n",
      "\n",
      "[[0 2 5 0]\n",
      " [0 0 0 0]\n",
      " [0 0 3 0]\n",
      " [1 1 7 6]]\n",
      "Validation Loss for P31 = 1.3426796197891235\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.9/dist-packages/sklearn/metrics/_classification.py:1334: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.9/dist-packages/sklearn/metrics/_classification.py:1334: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.9/dist-packages/sklearn/metrics/_classification.py:1334: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/tmp/ipykernel_32/3812056636.py:43: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([18, 1, 8064])\n",
      "torch.Size([15, 1, 8064])\n",
      "torch.Size([18, 1, 8064])\n",
      "torch.Size([15, 1, 8064])\n",
      "torch.Size([2, 1, 8064])\n",
      "Epoch 26/300, Train Loss: 1.476640224456787\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         7\n",
      "           1       0.00      0.00      0.00         0\n",
      "           2       0.18      0.67      0.29         3\n",
      "           3       0.88      0.47      0.61        15\n",
      "\n",
      "    accuracy                           0.36        25\n",
      "   macro avg       0.26      0.28      0.22        25\n",
      "weighted avg       0.55      0.36      0.40        25\n",
      "\n",
      "[[0 2 5 0]\n",
      " [0 0 0 0]\n",
      " [0 0 2 1]\n",
      " [3 1 4 7]]\n",
      "Validation Loss for P31 = 1.3410578966140747\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.9/dist-packages/sklearn/metrics/_classification.py:1334: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.9/dist-packages/sklearn/metrics/_classification.py:1334: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.9/dist-packages/sklearn/metrics/_classification.py:1334: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/tmp/ipykernel_32/3812056636.py:43: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([18, 1, 8064])\n",
      "torch.Size([15, 1, 8064])\n",
      "torch.Size([18, 1, 8064])\n",
      "torch.Size([15, 1, 8064])\n",
      "torch.Size([2, 1, 8064])\n",
      "Epoch 27/300, Train Loss: 1.4291201829910278\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         7\n",
      "           1       0.00      0.00      0.00         0\n",
      "           2       0.17      0.67      0.27         3\n",
      "           3       0.86      0.40      0.55        15\n",
      "\n",
      "    accuracy                           0.32        25\n",
      "   macro avg       0.26      0.27      0.20        25\n",
      "weighted avg       0.53      0.32      0.36        25\n",
      "\n",
      "[[0 2 5 0]\n",
      " [0 0 0 0]\n",
      " [0 0 2 1]\n",
      " [3 1 5 6]]\n",
      "Validation Loss for P31 = 1.3419973850250244\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.9/dist-packages/sklearn/metrics/_classification.py:1334: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.9/dist-packages/sklearn/metrics/_classification.py:1334: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.9/dist-packages/sklearn/metrics/_classification.py:1334: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/tmp/ipykernel_32/3812056636.py:43: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([18, 1, 8064])\n",
      "torch.Size([15, 1, 8064])\n",
      "torch.Size([18, 1, 8064])\n",
      "torch.Size([15, 1, 8064])\n",
      "torch.Size([2, 1, 8064])\n",
      "Epoch 28/300, Train Loss: 1.2234840393066406\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         7\n",
      "           1       0.00      0.00      0.00         0\n",
      "           2       0.15      0.67      0.25         3\n",
      "           3       0.88      0.47      0.61        15\n",
      "\n",
      "    accuracy                           0.36        25\n",
      "   macro avg       0.26      0.28      0.21        25\n",
      "weighted avg       0.54      0.36      0.40        25\n",
      "\n",
      "[[0 2 5 0]\n",
      " [0 0 0 0]\n",
      " [0 0 2 1]\n",
      " [1 1 6 7]]\n",
      "Validation Loss for P31 = 1.3468643426895142\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.9/dist-packages/sklearn/metrics/_classification.py:1334: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.9/dist-packages/sklearn/metrics/_classification.py:1334: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.9/dist-packages/sklearn/metrics/_classification.py:1334: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/tmp/ipykernel_32/3812056636.py:43: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([18, 1, 8064])\n",
      "torch.Size([15, 1, 8064])\n",
      "torch.Size([18, 1, 8064])\n",
      "torch.Size([15, 1, 8064])\n",
      "torch.Size([2, 1, 8064])\n",
      "Epoch 29/300, Train Loss: 1.5107452869415283\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.20      0.14      0.17         7\n",
      "           1       0.00      0.00      0.00         0\n",
      "           2       0.20      0.67      0.31         3\n",
      "           3       0.86      0.40      0.55        15\n",
      "\n",
      "    accuracy                           0.36        25\n",
      "   macro avg       0.31      0.30      0.25        25\n",
      "weighted avg       0.59      0.36      0.41        25\n",
      "\n",
      "[[1 2 4 0]\n",
      " [0 0 0 0]\n",
      " [0 0 2 1]\n",
      " [4 1 4 6]]\n",
      "Validation Loss for P31 = 1.3419585227966309\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.9/dist-packages/sklearn/metrics/_classification.py:1334: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.9/dist-packages/sklearn/metrics/_classification.py:1334: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.9/dist-packages/sklearn/metrics/_classification.py:1334: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/tmp/ipykernel_32/3812056636.py:43: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([18, 1, 8064])\n",
      "torch.Size([15, 1, 8064])\n",
      "torch.Size([18, 1, 8064])\n",
      "torch.Size([15, 1, 8064])\n",
      "torch.Size([2, 1, 8064])\n",
      "Epoch 30/300, Train Loss: 1.3427536487579346\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         7\n",
      "           1       0.00      0.00      0.00         0\n",
      "           2       0.15      0.67      0.25         3\n",
      "           3       0.70      0.47      0.56        15\n",
      "\n",
      "    accuracy                           0.36        25\n",
      "   macro avg       0.21      0.28      0.20        25\n",
      "weighted avg       0.44      0.36      0.37        25\n",
      "\n",
      "[[0 0 5 2]\n",
      " [0 0 0 0]\n",
      " [0 0 2 1]\n",
      " [1 1 6 7]]\n",
      "Validation Loss for P31 = 1.3353248834609985\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.9/dist-packages/sklearn/metrics/_classification.py:1334: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.9/dist-packages/sklearn/metrics/_classification.py:1334: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.9/dist-packages/sklearn/metrics/_classification.py:1334: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/tmp/ipykernel_32/3812056636.py:43: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([18, 1, 8064])\n",
      "torch.Size([15, 1, 8064])\n",
      "torch.Size([18, 1, 8064])\n",
      "torch.Size([15, 1, 8064])\n",
      "torch.Size([2, 1, 8064])\n",
      "Epoch 31/300, Train Loss: 1.457668423652649\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         7\n",
      "           1       0.00      0.00      0.00         0\n",
      "           2       0.15      0.67      0.25         3\n",
      "           3       0.78      0.47      0.58        15\n",
      "\n",
      "    accuracy                           0.36        25\n",
      "   macro avg       0.23      0.28      0.21        25\n",
      "weighted avg       0.49      0.36      0.38        25\n",
      "\n",
      "[[0 1 5 1]\n",
      " [0 0 0 0]\n",
      " [0 0 2 1]\n",
      " [1 1 6 7]]\n",
      "Validation Loss for P31 = 1.3460350036621094\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.9/dist-packages/sklearn/metrics/_classification.py:1334: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.9/dist-packages/sklearn/metrics/_classification.py:1334: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.9/dist-packages/sklearn/metrics/_classification.py:1334: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/tmp/ipykernel_32/3812056636.py:43: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([18, 1, 8064])\n",
      "torch.Size([15, 1, 8064])\n",
      "torch.Size([18, 1, 8064])\n",
      "torch.Size([15, 1, 8064])\n",
      "torch.Size([2, 1, 8064])\n",
      "Epoch 32/300, Train Loss: 1.379944086074829\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         7\n",
      "           1       0.00      0.00      0.00         0\n",
      "           2       0.18      0.67      0.29         3\n",
      "           3       0.86      0.40      0.55        15\n",
      "\n",
      "    accuracy                           0.32        25\n",
      "   macro avg       0.26      0.27      0.21        25\n",
      "weighted avg       0.54      0.32      0.36        25\n",
      "\n",
      "[[0 3 4 0]\n",
      " [0 0 0 0]\n",
      " [0 0 2 1]\n",
      " [3 1 5 6]]\n",
      "Validation Loss for P31 = 1.355982780456543\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.9/dist-packages/sklearn/metrics/_classification.py:1334: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.9/dist-packages/sklearn/metrics/_classification.py:1334: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.9/dist-packages/sklearn/metrics/_classification.py:1334: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/tmp/ipykernel_32/3812056636.py:43: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([18, 1, 8064])\n",
      "torch.Size([15, 1, 8064])\n",
      "torch.Size([18, 1, 8064])\n",
      "torch.Size([15, 1, 8064])\n",
      "torch.Size([2, 1, 8064])\n",
      "Epoch 33/300, Train Loss: 1.283047080039978\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.20      0.14      0.17         7\n",
      "           1       0.00      0.00      0.00         0\n",
      "           2       0.20      0.67      0.31         3\n",
      "           3       0.86      0.40      0.55        15\n",
      "\n",
      "    accuracy                           0.36        25\n",
      "   macro avg       0.31      0.30      0.25        25\n",
      "weighted avg       0.59      0.36      0.41        25\n",
      "\n",
      "[[1 2 4 0]\n",
      " [0 0 0 0]\n",
      " [0 0 2 1]\n",
      " [4 1 4 6]]\n",
      "Validation Loss for P31 = 1.3410077095031738\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.9/dist-packages/sklearn/metrics/_classification.py:1334: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.9/dist-packages/sklearn/metrics/_classification.py:1334: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.9/dist-packages/sklearn/metrics/_classification.py:1334: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/tmp/ipykernel_32/3812056636.py:43: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([18, 1, 8064])\n",
      "torch.Size([15, 1, 8064])\n",
      "torch.Size([18, 1, 8064])\n",
      "torch.Size([15, 1, 8064])\n",
      "torch.Size([2, 1, 8064])\n",
      "Epoch 34/300, Train Loss: 1.1970188617706299\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         7\n",
      "           1       0.00      0.00      0.00         0\n",
      "           2       0.17      0.67      0.27         3\n",
      "           3       0.75      0.40      0.52        15\n",
      "\n",
      "    accuracy                           0.32        25\n",
      "   macro avg       0.23      0.27      0.20        25\n",
      "weighted avg       0.47      0.32      0.35        25\n",
      "\n",
      "[[0 1 5 1]\n",
      " [0 0 0 0]\n",
      " [0 0 2 1]\n",
      " [3 1 5 6]]\n",
      "Validation Loss for P31 = 1.3505103588104248\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.9/dist-packages/sklearn/metrics/_classification.py:1334: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.9/dist-packages/sklearn/metrics/_classification.py:1334: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.9/dist-packages/sklearn/metrics/_classification.py:1334: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/tmp/ipykernel_32/3812056636.py:43: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([18, 1, 8064])\n",
      "torch.Size([15, 1, 8064])\n",
      "torch.Size([18, 1, 8064])\n",
      "torch.Size([15, 1, 8064])\n",
      "torch.Size([2, 1, 8064])\n",
      "Epoch 35/300, Train Loss: 1.440330982208252\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         7\n",
      "           1       0.00      0.00      0.00         0\n",
      "           2       0.17      0.67      0.27         3\n",
      "           3       0.70      0.47      0.56        15\n",
      "\n",
      "    accuracy                           0.36        25\n",
      "   macro avg       0.22      0.28      0.21        25\n",
      "weighted avg       0.44      0.36      0.37        25\n",
      "\n",
      "[[0 0 5 2]\n",
      " [0 0 0 0]\n",
      " [0 0 2 1]\n",
      " [2 1 5 7]]\n",
      "Validation Loss for P31 = 1.3354007005691528\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.9/dist-packages/sklearn/metrics/_classification.py:1334: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.9/dist-packages/sklearn/metrics/_classification.py:1334: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.9/dist-packages/sklearn/metrics/_classification.py:1334: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/tmp/ipykernel_32/3812056636.py:43: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([18, 1, 8064])\n",
      "torch.Size([15, 1, 8064])\n",
      "torch.Size([18, 1, 8064])\n",
      "torch.Size([15, 1, 8064])\n",
      "torch.Size([2, 1, 8064])\n",
      "Epoch 36/300, Train Loss: 1.3856512308120728\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         7\n",
      "           1       0.00      0.00      0.00         0\n",
      "           2       0.17      0.67      0.27         3\n",
      "           3       0.75      0.40      0.52        15\n",
      "\n",
      "    accuracy                           0.32        25\n",
      "   macro avg       0.23      0.27      0.20        25\n",
      "weighted avg       0.47      0.32      0.35        25\n",
      "\n",
      "[[0 1 5 1]\n",
      " [0 0 0 0]\n",
      " [0 0 2 1]\n",
      " [3 1 5 6]]\n",
      "Validation Loss for P31 = 1.356235146522522\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.9/dist-packages/sklearn/metrics/_classification.py:1334: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.9/dist-packages/sklearn/metrics/_classification.py:1334: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.9/dist-packages/sklearn/metrics/_classification.py:1334: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/tmp/ipykernel_32/3812056636.py:43: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([18, 1, 8064])\n",
      "torch.Size([15, 1, 8064])\n",
      "torch.Size([18, 1, 8064])\n",
      "torch.Size([15, 1, 8064])\n",
      "torch.Size([2, 1, 8064])\n",
      "Epoch 37/300, Train Loss: 1.4770777225494385\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         7\n",
      "           1       0.00      0.00      0.00         0\n",
      "           2       0.17      0.67      0.27         3\n",
      "           3       0.75      0.40      0.52        15\n",
      "\n",
      "    accuracy                           0.32        25\n",
      "   macro avg       0.23      0.27      0.20        25\n",
      "weighted avg       0.47      0.32      0.35        25\n",
      "\n",
      "[[0 1 5 1]\n",
      " [0 0 0 0]\n",
      " [0 0 2 1]\n",
      " [3 1 5 6]]\n",
      "Validation Loss for P31 = 1.331009864807129\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.9/dist-packages/sklearn/metrics/_classification.py:1334: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.9/dist-packages/sklearn/metrics/_classification.py:1334: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.9/dist-packages/sklearn/metrics/_classification.py:1334: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/tmp/ipykernel_32/3812056636.py:43: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([18, 1, 8064])\n",
      "torch.Size([15, 1, 8064])\n",
      "torch.Size([18, 1, 8064])\n",
      "torch.Size([15, 1, 8064])\n",
      "torch.Size([2, 1, 8064])\n",
      "Epoch 38/300, Train Loss: 1.418088436126709\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         7\n",
      "           1       0.00      0.00      0.00         0\n",
      "           2       0.17      0.67      0.27         3\n",
      "           3       0.75      0.40      0.52        15\n",
      "\n",
      "    accuracy                           0.32        25\n",
      "   macro avg       0.23      0.27      0.20        25\n",
      "weighted avg       0.47      0.32      0.35        25\n",
      "\n",
      "[[0 1 5 1]\n",
      " [0 0 0 0]\n",
      " [0 0 2 1]\n",
      " [3 1 5 6]]\n",
      "Validation Loss for P31 = 1.3393124341964722\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.9/dist-packages/sklearn/metrics/_classification.py:1334: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.9/dist-packages/sklearn/metrics/_classification.py:1334: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.9/dist-packages/sklearn/metrics/_classification.py:1334: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/tmp/ipykernel_32/3812056636.py:43: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([18, 1, 8064])\n",
      "torch.Size([15, 1, 8064])\n",
      "torch.Size([18, 1, 8064])\n",
      "torch.Size([15, 1, 8064])\n",
      "torch.Size([2, 1, 8064])\n",
      "Epoch 39/300, Train Loss: 1.4353454113006592\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         7\n",
      "           1       0.00      0.00      0.00         0\n",
      "           2       0.17      0.67      0.27         3\n",
      "           3       0.75      0.40      0.52        15\n",
      "\n",
      "    accuracy                           0.32        25\n",
      "   macro avg       0.23      0.27      0.20        25\n",
      "weighted avg       0.47      0.32      0.35        25\n",
      "\n",
      "[[0 1 5 1]\n",
      " [0 0 0 0]\n",
      " [0 0 2 1]\n",
      " [3 1 5 6]]\n",
      "Validation Loss for P31 = 1.3509925603866577\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.9/dist-packages/sklearn/metrics/_classification.py:1334: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.9/dist-packages/sklearn/metrics/_classification.py:1334: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.9/dist-packages/sklearn/metrics/_classification.py:1334: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/tmp/ipykernel_32/3812056636.py:43: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([18, 1, 8064])\n",
      "torch.Size([15, 1, 8064])\n",
      "torch.Size([18, 1, 8064])\n",
      "torch.Size([15, 1, 8064])\n",
      "torch.Size([2, 1, 8064])\n",
      "Epoch 40/300, Train Loss: 1.5726505517959595\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         7\n",
      "           1       0.00      0.00      0.00         0\n",
      "           2       0.17      0.67      0.27         3\n",
      "           3       0.67      0.40      0.50        15\n",
      "\n",
      "    accuracy                           0.32        25\n",
      "   macro avg       0.21      0.27      0.19        25\n",
      "weighted avg       0.42      0.32      0.33        25\n",
      "\n",
      "[[0 0 5 2]\n",
      " [0 0 0 0]\n",
      " [0 0 2 1]\n",
      " [3 1 5 6]]\n",
      "Validation Loss for P31 = 1.3359270095825195\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.9/dist-packages/sklearn/metrics/_classification.py:1334: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.9/dist-packages/sklearn/metrics/_classification.py:1334: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.9/dist-packages/sklearn/metrics/_classification.py:1334: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/tmp/ipykernel_32/3812056636.py:43: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([18, 1, 8064])\n",
      "torch.Size([15, 1, 8064])\n",
      "torch.Size([18, 1, 8064])\n",
      "torch.Size([15, 1, 8064])\n",
      "torch.Size([2, 1, 8064])\n",
      "Epoch 41/300, Train Loss: 1.4784455299377441\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         7\n",
      "           1       0.00      0.00      0.00         0\n",
      "           2       0.17      0.67      0.27         3\n",
      "           3       0.75      0.40      0.52        15\n",
      "\n",
      "    accuracy                           0.32        25\n",
      "   macro avg       0.23      0.27      0.20        25\n",
      "weighted avg       0.47      0.32      0.35        25\n",
      "\n",
      "[[0 1 5 1]\n",
      " [0 0 0 0]\n",
      " [0 0 2 1]\n",
      " [3 1 5 6]]\n",
      "Validation Loss for P31 = 1.3655203580856323\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.9/dist-packages/sklearn/metrics/_classification.py:1334: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.9/dist-packages/sklearn/metrics/_classification.py:1334: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.9/dist-packages/sklearn/metrics/_classification.py:1334: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/tmp/ipykernel_32/3812056636.py:43: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([18, 1, 8064])\n",
      "torch.Size([15, 1, 8064])\n",
      "torch.Size([18, 1, 8064])\n",
      "torch.Size([15, 1, 8064])\n",
      "torch.Size([2, 1, 8064])\n",
      "Epoch 42/300, Train Loss: 1.4258525371551514\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         7\n",
      "           1       0.00      0.00      0.00         0\n",
      "           2       0.17      0.67      0.27         3\n",
      "           3       0.67      0.40      0.50        15\n",
      "\n",
      "    accuracy                           0.32        25\n",
      "   macro avg       0.21      0.27      0.19        25\n",
      "weighted avg       0.42      0.32      0.33        25\n",
      "\n",
      "[[0 0 5 2]\n",
      " [0 0 0 0]\n",
      " [0 0 2 1]\n",
      " [3 1 5 6]]\n",
      "Validation Loss for P31 = 1.341934084892273\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.9/dist-packages/sklearn/metrics/_classification.py:1334: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.9/dist-packages/sklearn/metrics/_classification.py:1334: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.9/dist-packages/sklearn/metrics/_classification.py:1334: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/tmp/ipykernel_32/3812056636.py:43: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([18, 1, 8064])\n",
      "torch.Size([15, 1, 8064])\n",
      "torch.Size([18, 1, 8064])\n",
      "torch.Size([15, 1, 8064])\n",
      "torch.Size([2, 1, 8064])\n",
      "Epoch 43/300, Train Loss: 1.3616880178451538\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         7\n",
      "           1       0.00      0.00      0.00         0\n",
      "           2       0.17      0.67      0.27         3\n",
      "           3       0.67      0.40      0.50        15\n",
      "\n",
      "    accuracy                           0.32        25\n",
      "   macro avg       0.21      0.27      0.19        25\n",
      "weighted avg       0.42      0.32      0.33        25\n",
      "\n",
      "[[0 0 5 2]\n",
      " [0 0 0 0]\n",
      " [0 0 2 1]\n",
      " [3 1 5 6]]\n",
      "Validation Loss for P31 = 1.3386144638061523\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.9/dist-packages/sklearn/metrics/_classification.py:1334: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.9/dist-packages/sklearn/metrics/_classification.py:1334: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.9/dist-packages/sklearn/metrics/_classification.py:1334: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/tmp/ipykernel_32/3812056636.py:43: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([18, 1, 8064])\n",
      "torch.Size([15, 1, 8064])\n",
      "torch.Size([18, 1, 8064])\n",
      "torch.Size([15, 1, 8064])\n",
      "torch.Size([2, 1, 8064])\n",
      "Epoch 44/300, Train Loss: 1.6015515327453613\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         7\n",
      "           1       0.00      0.00      0.00         0\n",
      "           2       0.17      0.67      0.27         3\n",
      "           3       0.67      0.40      0.50        15\n",
      "\n",
      "    accuracy                           0.32        25\n",
      "   macro avg       0.21      0.27      0.19        25\n",
      "weighted avg       0.42      0.32      0.33        25\n",
      "\n",
      "[[0 0 5 2]\n",
      " [0 0 0 0]\n",
      " [0 0 2 1]\n",
      " [3 1 5 6]]\n",
      "Validation Loss for P31 = 1.3361693620681763\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.9/dist-packages/sklearn/metrics/_classification.py:1334: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.9/dist-packages/sklearn/metrics/_classification.py:1334: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.9/dist-packages/sklearn/metrics/_classification.py:1334: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/tmp/ipykernel_32/3812056636.py:43: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([18, 1, 8064])\n",
      "torch.Size([15, 1, 8064])\n",
      "torch.Size([18, 1, 8064])\n",
      "torch.Size([15, 1, 8064])\n",
      "torch.Size([2, 1, 8064])\n",
      "Epoch 45/300, Train Loss: 1.5223270654678345\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         7\n",
      "           1       0.00      0.00      0.00         0\n",
      "           2       0.17      0.67      0.27         3\n",
      "           3       0.67      0.40      0.50        15\n",
      "\n",
      "    accuracy                           0.32        25\n",
      "   macro avg       0.21      0.27      0.19        25\n",
      "weighted avg       0.42      0.32      0.33        25\n",
      "\n",
      "[[0 0 5 2]\n",
      " [0 0 0 0]\n",
      " [0 0 2 1]\n",
      " [3 1 5 6]]\n",
      "Validation Loss for P31 = 1.3183890581130981\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.9/dist-packages/sklearn/metrics/_classification.py:1334: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.9/dist-packages/sklearn/metrics/_classification.py:1334: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.9/dist-packages/sklearn/metrics/_classification.py:1334: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/tmp/ipykernel_32/3812056636.py:43: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([18, 1, 8064])\n",
      "torch.Size([15, 1, 8064])\n",
      "torch.Size([18, 1, 8064])\n",
      "torch.Size([15, 1, 8064])\n",
      "torch.Size([2, 1, 8064])\n",
      "Epoch 46/300, Train Loss: 1.3385668992996216\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         7\n",
      "           1       0.00      0.00      0.00         0\n",
      "           2       0.17      0.67      0.27         3\n",
      "           3       0.67      0.40      0.50        15\n",
      "\n",
      "    accuracy                           0.32        25\n",
      "   macro avg       0.21      0.27      0.19        25\n",
      "weighted avg       0.42      0.32      0.33        25\n",
      "\n",
      "[[0 0 5 2]\n",
      " [0 0 0 0]\n",
      " [0 0 2 1]\n",
      " [3 1 5 6]]\n",
      "Validation Loss for P31 = 1.337148904800415\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.9/dist-packages/sklearn/metrics/_classification.py:1334: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.9/dist-packages/sklearn/metrics/_classification.py:1334: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.9/dist-packages/sklearn/metrics/_classification.py:1334: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/tmp/ipykernel_32/3812056636.py:43: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([18, 1, 8064])\n",
      "torch.Size([15, 1, 8064])\n",
      "torch.Size([18, 1, 8064])\n",
      "torch.Size([15, 1, 8064])\n",
      "torch.Size([2, 1, 8064])\n",
      "Epoch 47/300, Train Loss: 1.4931920766830444\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         7\n",
      "           1       0.00      0.00      0.00         0\n",
      "           2       0.17      0.67      0.27         3\n",
      "           3       0.67      0.40      0.50        15\n",
      "\n",
      "    accuracy                           0.32        25\n",
      "   macro avg       0.21      0.27      0.19        25\n",
      "weighted avg       0.42      0.32      0.33        25\n",
      "\n",
      "[[0 0 5 2]\n",
      " [0 0 0 0]\n",
      " [0 0 2 1]\n",
      " [3 1 5 6]]\n",
      "Validation Loss for P31 = 1.3323495388031006\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.9/dist-packages/sklearn/metrics/_classification.py:1334: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.9/dist-packages/sklearn/metrics/_classification.py:1334: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.9/dist-packages/sklearn/metrics/_classification.py:1334: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/tmp/ipykernel_32/3812056636.py:43: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([18, 1, 8064])\n",
      "torch.Size([15, 1, 8064])\n",
      "torch.Size([18, 1, 8064])\n",
      "torch.Size([15, 1, 8064])\n",
      "torch.Size([2, 1, 8064])\n",
      "Epoch 48/300, Train Loss: 1.437666416168213\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         7\n",
      "           1       0.00      0.00      0.00         0\n",
      "           2       0.17      0.67      0.27         3\n",
      "           3       0.67      0.40      0.50        15\n",
      "\n",
      "    accuracy                           0.32        25\n",
      "   macro avg       0.21      0.27      0.19        25\n",
      "weighted avg       0.42      0.32      0.33        25\n",
      "\n",
      "[[0 0 5 2]\n",
      " [0 0 0 0]\n",
      " [0 0 2 1]\n",
      " [3 1 5 6]]\n",
      "Validation Loss for P31 = 1.3327674865722656\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.9/dist-packages/sklearn/metrics/_classification.py:1334: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.9/dist-packages/sklearn/metrics/_classification.py:1334: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.9/dist-packages/sklearn/metrics/_classification.py:1334: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/tmp/ipykernel_32/3812056636.py:43: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([18, 1, 8064])\n",
      "torch.Size([15, 1, 8064])\n",
      "torch.Size([18, 1, 8064])\n",
      "torch.Size([15, 1, 8064])\n",
      "torch.Size([2, 1, 8064])\n",
      "Epoch 49/300, Train Loss: 1.2460057735443115\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         7\n",
      "           2       0.15      0.67      0.25         3\n",
      "           3       0.70      0.47      0.56        15\n",
      "\n",
      "    accuracy                           0.36        25\n",
      "   macro avg       0.28      0.38      0.27        25\n",
      "weighted avg       0.44      0.36      0.37        25\n",
      "\n",
      "[[0 5 2]\n",
      " [0 2 1]\n",
      " [2 6 7]]\n",
      "Validation Loss for P31 = 1.345481514930725\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_32/3812056636.py:43: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([18, 1, 8064])\n",
      "torch.Size([15, 1, 8064])\n",
      "torch.Size([18, 1, 8064])\n",
      "torch.Size([15, 1, 8064])\n",
      "torch.Size([2, 1, 8064])\n",
      "Epoch 50/300, Train Loss: 1.2886292934417725\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         7\n",
      "           2       0.17      0.67      0.27         3\n",
      "           3       0.70      0.47      0.56        15\n",
      "\n",
      "    accuracy                           0.36        25\n",
      "   macro avg       0.29      0.38      0.28        25\n",
      "weighted avg       0.44      0.36      0.37        25\n",
      "\n",
      "[[0 5 2]\n",
      " [0 2 1]\n",
      " [3 5 7]]\n",
      "Validation Loss for P31 = 1.3342421054840088\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_32/3812056636.py:43: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([18, 1, 8064])\n",
      "torch.Size([15, 1, 8064])\n",
      "torch.Size([18, 1, 8064])\n",
      "torch.Size([15, 1, 8064])\n",
      "torch.Size([2, 1, 8064])\n",
      "Epoch 51/300, Train Loss: 1.2949435710906982\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         7\n",
      "           1       0.00      0.00      0.00         0\n",
      "           2       0.15      0.67      0.25         3\n",
      "           3       0.62      0.33      0.43        15\n",
      "\n",
      "    accuracy                           0.28        25\n",
      "   macro avg       0.19      0.25      0.17        25\n",
      "weighted avg       0.39      0.28      0.29        25\n",
      "\n",
      "[[0 0 5 2]\n",
      " [0 0 0 0]\n",
      " [0 0 2 1]\n",
      " [3 1 6 5]]\n",
      "Validation Loss for P31 = 1.3485244512557983\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.9/dist-packages/sklearn/metrics/_classification.py:1334: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.9/dist-packages/sklearn/metrics/_classification.py:1334: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.9/dist-packages/sklearn/metrics/_classification.py:1334: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/tmp/ipykernel_32/3812056636.py:43: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([18, 1, 8064])\n",
      "torch.Size([15, 1, 8064])\n",
      "torch.Size([18, 1, 8064])\n",
      "torch.Size([15, 1, 8064])\n",
      "torch.Size([2, 1, 8064])\n",
      "Epoch 52/300, Train Loss: 1.616647481918335\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.33      0.29      0.31         7\n",
      "           2       0.22      0.67      0.33         3\n",
      "           3       0.70      0.47      0.56        15\n",
      "\n",
      "    accuracy                           0.44        25\n",
      "   macro avg       0.42      0.47      0.40        25\n",
      "weighted avg       0.54      0.44      0.46        25\n",
      "\n",
      "[[2 3 2]\n",
      " [0 2 1]\n",
      " [4 4 7]]\n",
      "Validation Loss for P31 = 1.3194602727890015\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_32/3812056636.py:43: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([18, 1, 8064])\n",
      "torch.Size([15, 1, 8064])\n",
      "torch.Size([18, 1, 8064])\n",
      "torch.Size([15, 1, 8064])\n",
      "torch.Size([2, 1, 8064])\n",
      "Epoch 53/300, Train Loss: 1.2435247898101807\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.33      0.29      0.31         7\n",
      "           1       0.00      0.00      0.00         0\n",
      "           2       0.22      0.67      0.33         3\n",
      "           3       0.67      0.40      0.50        15\n",
      "\n",
      "    accuracy                           0.40        25\n",
      "   macro avg       0.31      0.34      0.29        25\n",
      "weighted avg       0.52      0.40      0.43        25\n",
      "\n",
      "[[2 0 3 2]\n",
      " [0 0 0 0]\n",
      " [0 0 2 1]\n",
      " [4 1 4 6]]\n",
      "Validation Loss for P31 = 1.3272405862808228\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.9/dist-packages/sklearn/metrics/_classification.py:1334: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.9/dist-packages/sklearn/metrics/_classification.py:1334: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.9/dist-packages/sklearn/metrics/_classification.py:1334: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/tmp/ipykernel_32/3812056636.py:43: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([18, 1, 8064])\n",
      "torch.Size([15, 1, 8064])\n",
      "torch.Size([18, 1, 8064])\n",
      "torch.Size([15, 1, 8064])\n",
      "torch.Size([2, 1, 8064])\n",
      "Epoch 54/300, Train Loss: 1.596765398979187\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         7\n",
      "           1       0.00      0.00      0.00         0\n",
      "           2       0.15      0.67      0.25         3\n",
      "           3       0.62      0.33      0.43        15\n",
      "\n",
      "    accuracy                           0.28        25\n",
      "   macro avg       0.19      0.25      0.17        25\n",
      "weighted avg       0.39      0.28      0.29        25\n",
      "\n",
      "[[0 0 5 2]\n",
      " [0 0 0 0]\n",
      " [0 0 2 1]\n",
      " [3 1 6 5]]\n",
      "Validation Loss for P31 = 1.3465129137039185\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.9/dist-packages/sklearn/metrics/_classification.py:1334: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.9/dist-packages/sklearn/metrics/_classification.py:1334: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.9/dist-packages/sklearn/metrics/_classification.py:1334: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/tmp/ipykernel_32/3812056636.py:43: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([18, 1, 8064])\n",
      "torch.Size([15, 1, 8064])\n",
      "torch.Size([18, 1, 8064])\n",
      "torch.Size([15, 1, 8064])\n",
      "torch.Size([2, 1, 8064])\n",
      "Epoch 55/300, Train Loss: 1.8098344802856445\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         7\n",
      "           1       0.00      0.00      0.00         0\n",
      "           2       0.17      0.67      0.27         3\n",
      "           3       0.62      0.33      0.43        15\n",
      "\n",
      "    accuracy                           0.28        25\n",
      "   macro avg       0.20      0.25      0.18        25\n",
      "weighted avg       0.40      0.28      0.29        25\n",
      "\n",
      "[[0 0 5 2]\n",
      " [0 0 0 0]\n",
      " [0 0 2 1]\n",
      " [4 1 5 5]]\n",
      "Validation Loss for P31 = 1.3394170999526978\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.9/dist-packages/sklearn/metrics/_classification.py:1334: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.9/dist-packages/sklearn/metrics/_classification.py:1334: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.9/dist-packages/sklearn/metrics/_classification.py:1334: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/tmp/ipykernel_32/3812056636.py:43: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([18, 1, 8064])\n",
      "torch.Size([15, 1, 8064])\n",
      "torch.Size([18, 1, 8064])\n",
      "torch.Size([15, 1, 8064])\n",
      "torch.Size([2, 1, 8064])\n",
      "Epoch 56/300, Train Loss: 1.0841641426086426\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.33      0.29      0.31         7\n",
      "           2       0.18      0.67      0.29         3\n",
      "           3       0.75      0.40      0.52        15\n",
      "\n",
      "    accuracy                           0.40        25\n",
      "   macro avg       0.42      0.45      0.37        25\n",
      "weighted avg       0.57      0.40      0.43        25\n",
      "\n",
      "[[2 4 1]\n",
      " [0 2 1]\n",
      " [4 5 6]]\n",
      "Validation Loss for P31 = 1.3321589231491089\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_32/3812056636.py:43: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([18, 1, 8064])\n",
      "torch.Size([15, 1, 8064])\n",
      "torch.Size([18, 1, 8064])\n",
      "torch.Size([15, 1, 8064])\n",
      "torch.Size([2, 1, 8064])\n",
      "Epoch 57/300, Train Loss: 1.4096300601959229\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         7\n",
      "           2       0.15      0.67      0.25         3\n",
      "           3       0.67      0.40      0.50        15\n",
      "\n",
      "    accuracy                           0.32        25\n",
      "   macro avg       0.27      0.36      0.25        25\n",
      "weighted avg       0.42      0.32      0.33        25\n",
      "\n",
      "[[0 5 2]\n",
      " [0 2 1]\n",
      " [3 6 6]]\n",
      "Validation Loss for P31 = 1.349941372871399\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_32/3812056636.py:43: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([18, 1, 8064])\n",
      "torch.Size([15, 1, 8064])\n",
      "torch.Size([18, 1, 8064])\n",
      "torch.Size([15, 1, 8064])\n",
      "torch.Size([2, 1, 8064])\n",
      "Epoch 58/300, Train Loss: 1.610534429550171\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         7\n",
      "           2       0.15      0.67      0.25         3\n",
      "           3       0.67      0.40      0.50        15\n",
      "\n",
      "    accuracy                           0.32        25\n",
      "   macro avg       0.27      0.36      0.25        25\n",
      "weighted avg       0.42      0.32      0.33        25\n",
      "\n",
      "[[0 5 2]\n",
      " [0 2 1]\n",
      " [3 6 6]]\n",
      "Validation Loss for P31 = 1.348160743713379\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_32/3812056636.py:43: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([18, 1, 8064])\n",
      "torch.Size([15, 1, 8064])\n",
      "torch.Size([18, 1, 8064])\n",
      "torch.Size([15, 1, 8064])\n",
      "torch.Size([2, 1, 8064])\n",
      "Epoch 59/300, Train Loss: 1.5620753765106201\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         7\n",
      "           2       0.15      0.67      0.25         3\n",
      "           3       0.67      0.40      0.50        15\n",
      "\n",
      "    accuracy                           0.32        25\n",
      "   macro avg       0.27      0.36      0.25        25\n",
      "weighted avg       0.42      0.32      0.33        25\n",
      "\n",
      "[[0 5 2]\n",
      " [0 2 1]\n",
      " [3 6 6]]\n",
      "Validation Loss for P31 = 1.3372653722763062\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_32/3812056636.py:43: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([18, 1, 8064])\n",
      "torch.Size([15, 1, 8064])\n",
      "torch.Size([18, 1, 8064])\n",
      "torch.Size([15, 1, 8064])\n",
      "torch.Size([2, 1, 8064])\n",
      "Epoch 60/300, Train Loss: 1.465182900428772\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         7\n",
      "           2       0.14      0.67      0.24         3\n",
      "           3       0.75      0.40      0.52        15\n",
      "\n",
      "    accuracy                           0.32        25\n",
      "   macro avg       0.30      0.36      0.25        25\n",
      "weighted avg       0.47      0.32      0.34        25\n",
      "\n",
      "[[0 6 1]\n",
      " [0 2 1]\n",
      " [3 6 6]]\n",
      "Validation Loss for P31 = 1.338560938835144\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_32/3812056636.py:43: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([18, 1, 8064])\n",
      "torch.Size([15, 1, 8064])\n",
      "torch.Size([18, 1, 8064])\n",
      "torch.Size([15, 1, 8064])\n",
      "torch.Size([2, 1, 8064])\n",
      "Epoch 61/300, Train Loss: 1.0742772817611694\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         7\n",
      "           2       0.14      0.67      0.24         3\n",
      "           3       0.75      0.40      0.52        15\n",
      "\n",
      "    accuracy                           0.32        25\n",
      "   macro avg       0.30      0.36      0.25        25\n",
      "weighted avg       0.47      0.32      0.34        25\n",
      "\n",
      "[[0 6 1]\n",
      " [0 2 1]\n",
      " [3 6 6]]\n",
      "Validation Loss for P31 = 1.3369524478912354\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_32/3812056636.py:43: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([18, 1, 8064])\n",
      "torch.Size([15, 1, 8064])\n",
      "torch.Size([18, 1, 8064])\n",
      "torch.Size([15, 1, 8064])\n",
      "torch.Size([2, 1, 8064])\n",
      "Epoch 62/300, Train Loss: 1.503957986831665\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         7\n",
      "           2       0.14      0.67      0.24         3\n",
      "           3       0.75      0.40      0.52        15\n",
      "\n",
      "    accuracy                           0.32        25\n",
      "   macro avg       0.30      0.36      0.25        25\n",
      "weighted avg       0.47      0.32      0.34        25\n",
      "\n",
      "[[0 6 1]\n",
      " [0 2 1]\n",
      " [3 6 6]]\n",
      "Validation Loss for P31 = 1.3300814628601074\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_32/3812056636.py:43: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([18, 1, 8064])\n",
      "torch.Size([15, 1, 8064])\n",
      "torch.Size([18, 1, 8064])\n",
      "torch.Size([15, 1, 8064])\n",
      "torch.Size([2, 1, 8064])\n",
      "Epoch 63/300, Train Loss: 1.205225944519043\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         7\n",
      "           2       0.14      0.67      0.24         3\n",
      "           3       0.75      0.40      0.52        15\n",
      "\n",
      "    accuracy                           0.32        25\n",
      "   macro avg       0.30      0.36      0.25        25\n",
      "weighted avg       0.47      0.32      0.34        25\n",
      "\n",
      "[[0 6 1]\n",
      " [0 2 1]\n",
      " [3 6 6]]\n",
      "Validation Loss for P31 = 1.3295238018035889\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_32/3812056636.py:43: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([18, 1, 8064])\n",
      "torch.Size([15, 1, 8064])\n",
      "torch.Size([18, 1, 8064])\n",
      "torch.Size([15, 1, 8064])\n",
      "torch.Size([2, 1, 8064])\n",
      "Epoch 64/300, Train Loss: 1.4601157903671265\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         7\n",
      "           2       0.17      0.67      0.27         3\n",
      "           3       0.70      0.47      0.56        15\n",
      "\n",
      "    accuracy                           0.36        25\n",
      "   macro avg       0.29      0.38      0.28        25\n",
      "weighted avg       0.44      0.36      0.37        25\n",
      "\n",
      "[[0 5 2]\n",
      " [0 2 1]\n",
      " [3 5 7]]\n",
      "Validation Loss for P31 = 1.3212575912475586\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_32/3812056636.py:43: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([18, 1, 8064])\n",
      "torch.Size([15, 1, 8064])\n",
      "torch.Size([18, 1, 8064])\n",
      "torch.Size([15, 1, 8064])\n",
      "torch.Size([2, 1, 8064])\n",
      "Epoch 65/300, Train Loss: 1.3146376609802246\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.25      0.14      0.18         7\n",
      "           2       0.15      0.67      0.25         3\n",
      "           3       0.75      0.40      0.52        15\n",
      "\n",
      "    accuracy                           0.36        25\n",
      "   macro avg       0.38      0.40      0.32        25\n",
      "weighted avg       0.54      0.36      0.39        25\n",
      "\n",
      "[[1 5 1]\n",
      " [0 2 1]\n",
      " [3 6 6]]\n",
      "Validation Loss for P31 = 1.3189609050750732\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_32/3812056636.py:43: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([18, 1, 8064])\n",
      "torch.Size([15, 1, 8064])\n",
      "torch.Size([18, 1, 8064])\n",
      "torch.Size([15, 1, 8064])\n",
      "torch.Size([2, 1, 8064])\n",
      "Epoch 66/300, Train Loss: 1.6308857202529907\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.25      0.14      0.18         7\n",
      "           2       0.17      0.67      0.27         3\n",
      "           3       0.67      0.40      0.50        15\n",
      "\n",
      "    accuracy                           0.36        25\n",
      "   macro avg       0.36      0.40      0.32        25\n",
      "weighted avg       0.49      0.36      0.38        25\n",
      "\n",
      "[[1 4 2]\n",
      " [0 2 1]\n",
      " [3 6 6]]\n",
      "Validation Loss for P31 = 1.3231834173202515\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_32/3812056636.py:43: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([18, 1, 8064])\n",
      "torch.Size([15, 1, 8064])\n",
      "torch.Size([18, 1, 8064])\n",
      "torch.Size([15, 1, 8064])\n",
      "torch.Size([2, 1, 8064])\n",
      "Epoch 67/300, Train Loss: 1.449326515197754\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.25      0.14      0.18         7\n",
      "           2       0.18      0.67      0.29         3\n",
      "           3       0.70      0.47      0.56        15\n",
      "\n",
      "    accuracy                           0.40        25\n",
      "   macro avg       0.38      0.43      0.34        25\n",
      "weighted avg       0.51      0.40      0.42        25\n",
      "\n",
      "[[1 4 2]\n",
      " [0 2 1]\n",
      " [3 5 7]]\n",
      "Validation Loss for P31 = 1.3197039365768433\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_32/3812056636.py:43: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([18, 1, 8064])\n",
      "torch.Size([15, 1, 8064])\n",
      "torch.Size([18, 1, 8064])\n",
      "torch.Size([15, 1, 8064])\n",
      "torch.Size([2, 1, 8064])\n",
      "Epoch 68/300, Train Loss: 1.1658772230148315\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.20      0.14      0.17         7\n",
      "           2       0.17      0.67      0.27         3\n",
      "           3       0.75      0.40      0.52        15\n",
      "\n",
      "    accuracy                           0.36        25\n",
      "   macro avg       0.37      0.40      0.32        25\n",
      "weighted avg       0.53      0.36      0.39        25\n",
      "\n",
      "[[1 5 1]\n",
      " [0 2 1]\n",
      " [4 5 6]]\n",
      "Validation Loss for P31 = 1.3307199478149414\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_32/3812056636.py:43: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([18, 1, 8064])\n",
      "torch.Size([15, 1, 8064])\n",
      "torch.Size([18, 1, 8064])\n",
      "torch.Size([15, 1, 8064])\n",
      "torch.Size([2, 1, 8064])\n",
      "Epoch 69/300, Train Loss: 1.5968496799468994\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         7\n",
      "           2       0.14      0.67      0.24         3\n",
      "           3       0.75      0.40      0.52        15\n",
      "\n",
      "    accuracy                           0.32        25\n",
      "   macro avg       0.30      0.36      0.25        25\n",
      "weighted avg       0.47      0.32      0.34        25\n",
      "\n",
      "[[0 6 1]\n",
      " [0 2 1]\n",
      " [3 6 6]]\n",
      "Validation Loss for P31 = 1.328148603439331\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_32/3812056636.py:43: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([18, 1, 8064])\n",
      "torch.Size([15, 1, 8064])\n",
      "torch.Size([18, 1, 8064])\n",
      "torch.Size([15, 1, 8064])\n",
      "torch.Size([2, 1, 8064])\n",
      "Epoch 70/300, Train Loss: 1.5463614463806152\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         7\n",
      "           2       0.17      0.67      0.27         3\n",
      "           3       0.70      0.47      0.56        15\n",
      "\n",
      "    accuracy                           0.36        25\n",
      "   macro avg       0.29      0.38      0.28        25\n",
      "weighted avg       0.44      0.36      0.37        25\n",
      "\n",
      "[[0 5 2]\n",
      " [0 2 1]\n",
      " [3 5 7]]\n",
      "Validation Loss for P31 = 1.3188475370407104\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_32/3812056636.py:43: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([18, 1, 8064])\n",
      "torch.Size([15, 1, 8064])\n",
      "torch.Size([18, 1, 8064])\n",
      "torch.Size([15, 1, 8064])\n",
      "torch.Size([2, 1, 8064])\n",
      "Epoch 71/300, Train Loss: 1.294040560722351\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         7\n",
      "           2       0.15      0.67      0.25         3\n",
      "           3       0.78      0.47      0.58        15\n",
      "\n",
      "    accuracy                           0.36        25\n",
      "   macro avg       0.31      0.38      0.28        25\n",
      "weighted avg       0.49      0.36      0.38        25\n",
      "\n",
      "[[0 6 1]\n",
      " [0 2 1]\n",
      " [3 5 7]]\n",
      "Validation Loss for P31 = 1.3350343704223633\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_32/3812056636.py:43: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([18, 1, 8064])\n",
      "torch.Size([15, 1, 8064])\n",
      "torch.Size([18, 1, 8064])\n",
      "torch.Size([15, 1, 8064])\n",
      "torch.Size([2, 1, 8064])\n",
      "Epoch 72/300, Train Loss: 1.2375303506851196\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         7\n",
      "           2       0.15      0.67      0.25         3\n",
      "           3       0.67      0.40      0.50        15\n",
      "\n",
      "    accuracy                           0.32        25\n",
      "   macro avg       0.27      0.36      0.25        25\n",
      "weighted avg       0.42      0.32      0.33        25\n",
      "\n",
      "[[0 5 2]\n",
      " [0 2 1]\n",
      " [3 6 6]]\n",
      "Validation Loss for P31 = 1.338364839553833\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_32/3812056636.py:43: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([18, 1, 8064])\n",
      "torch.Size([15, 1, 8064])\n",
      "torch.Size([18, 1, 8064])\n",
      "torch.Size([15, 1, 8064])\n",
      "torch.Size([2, 1, 8064])\n",
      "Epoch 73/300, Train Loss: 1.4593085050582886\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         7\n",
      "           2       0.17      0.67      0.27         3\n",
      "           3       0.70      0.47      0.56        15\n",
      "\n",
      "    accuracy                           0.36        25\n",
      "   macro avg       0.29      0.38      0.28        25\n",
      "weighted avg       0.44      0.36      0.37        25\n",
      "\n",
      "[[0 5 2]\n",
      " [0 2 1]\n",
      " [3 5 7]]\n",
      "Validation Loss for P31 = 1.3251807689666748\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_32/3812056636.py:43: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([18, 1, 8064])\n",
      "torch.Size([15, 1, 8064])\n",
      "torch.Size([18, 1, 8064])\n",
      "torch.Size([15, 1, 8064])\n",
      "torch.Size([2, 1, 8064])\n",
      "Epoch 74/300, Train Loss: 1.3174185752868652\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         7\n",
      "           2       0.17      0.67      0.27         3\n",
      "           3       0.70      0.47      0.56        15\n",
      "\n",
      "    accuracy                           0.36        25\n",
      "   macro avg       0.29      0.38      0.28        25\n",
      "weighted avg       0.44      0.36      0.37        25\n",
      "\n",
      "[[0 5 2]\n",
      " [0 2 1]\n",
      " [3 5 7]]\n",
      "Validation Loss for P31 = 1.3221763372421265\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_32/3812056636.py:43: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([18, 1, 8064])\n",
      "torch.Size([15, 1, 8064])\n",
      "torch.Size([18, 1, 8064])\n",
      "torch.Size([15, 1, 8064])\n",
      "torch.Size([2, 1, 8064])\n",
      "Epoch 75/300, Train Loss: 1.2724123001098633\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.25      0.14      0.18         7\n",
      "           2       0.18      0.67      0.29         3\n",
      "           3       0.70      0.47      0.56        15\n",
      "\n",
      "    accuracy                           0.40        25\n",
      "   macro avg       0.38      0.43      0.34        25\n",
      "weighted avg       0.51      0.40      0.42        25\n",
      "\n",
      "[[1 4 2]\n",
      " [0 2 1]\n",
      " [3 5 7]]\n",
      "Validation Loss for P31 = 1.3116506338119507\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_32/3812056636.py:43: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([18, 1, 8064])\n",
      "torch.Size([15, 1, 8064])\n",
      "torch.Size([18, 1, 8064])\n",
      "torch.Size([15, 1, 8064])\n",
      "torch.Size([2, 1, 8064])\n",
      "Epoch 76/300, Train Loss: 1.4906660318374634\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.20      0.14      0.17         7\n",
      "           2       0.20      0.67      0.31         3\n",
      "           3       0.70      0.47      0.56        15\n",
      "\n",
      "    accuracy                           0.40        25\n",
      "   macro avg       0.37      0.43      0.34        25\n",
      "weighted avg       0.50      0.40      0.42        25\n",
      "\n",
      "[[1 4 2]\n",
      " [0 2 1]\n",
      " [4 4 7]]\n",
      "Validation Loss for P31 = 1.316306233406067\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_32/3812056636.py:43: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([18, 1, 8064])\n",
      "torch.Size([15, 1, 8064])\n",
      "torch.Size([18, 1, 8064])\n",
      "torch.Size([15, 1, 8064])\n",
      "torch.Size([2, 1, 8064])\n",
      "Epoch 77/300, Train Loss: 1.496506690979004\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         7\n",
      "           2       0.17      0.67      0.27         3\n",
      "           3       0.70      0.47      0.56        15\n",
      "\n",
      "    accuracy                           0.36        25\n",
      "   macro avg       0.29      0.38      0.28        25\n",
      "weighted avg       0.44      0.36      0.37        25\n",
      "\n",
      "[[0 5 2]\n",
      " [0 2 1]\n",
      " [3 5 7]]\n",
      "Validation Loss for P31 = 1.3102173805236816\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_32/3812056636.py:43: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([18, 1, 8064])\n",
      "torch.Size([15, 1, 8064])\n",
      "torch.Size([18, 1, 8064])\n",
      "torch.Size([15, 1, 8064])\n",
      "torch.Size([2, 1, 8064])\n",
      "Epoch 78/300, Train Loss: 1.521584391593933\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         7\n",
      "           2       0.17      0.67      0.27         3\n",
      "           3       0.70      0.47      0.56        15\n",
      "\n",
      "    accuracy                           0.36        25\n",
      "   macro avg       0.29      0.38      0.28        25\n",
      "weighted avg       0.44      0.36      0.37        25\n",
      "\n",
      "[[0 5 2]\n",
      " [0 2 1]\n",
      " [3 5 7]]\n",
      "Validation Loss for P31 = 1.3233437538146973\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_32/3812056636.py:43: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([18, 1, 8064])\n",
      "torch.Size([15, 1, 8064])\n",
      "torch.Size([18, 1, 8064])\n",
      "torch.Size([15, 1, 8064])\n",
      "torch.Size([2, 1, 8064])\n",
      "Epoch 79/300, Train Loss: 1.7283742427825928\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         7\n",
      "           2       0.17      0.67      0.27         3\n",
      "           3       0.70      0.47      0.56        15\n",
      "\n",
      "    accuracy                           0.36        25\n",
      "   macro avg       0.29      0.38      0.28        25\n",
      "weighted avg       0.44      0.36      0.37        25\n",
      "\n",
      "[[0 5 2]\n",
      " [0 2 1]\n",
      " [3 5 7]]\n",
      "Validation Loss for P31 = 1.3229681253433228\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_32/3812056636.py:43: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([18, 1, 8064])\n",
      "torch.Size([15, 1, 8064])\n",
      "torch.Size([18, 1, 8064])\n",
      "torch.Size([15, 1, 8064])\n",
      "torch.Size([2, 1, 8064])\n",
      "Epoch 80/300, Train Loss: 1.2195228338241577\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         7\n",
      "           2       0.17      0.67      0.27         3\n",
      "           3       0.70      0.47      0.56        15\n",
      "\n",
      "    accuracy                           0.36        25\n",
      "   macro avg       0.29      0.38      0.28        25\n",
      "weighted avg       0.44      0.36      0.37        25\n",
      "\n",
      "[[0 5 2]\n",
      " [0 2 1]\n",
      " [3 5 7]]\n",
      "Validation Loss for P31 = 1.3170641660690308\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_32/3812056636.py:43: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([18, 1, 8064])\n",
      "torch.Size([15, 1, 8064])\n",
      "torch.Size([18, 1, 8064])\n",
      "torch.Size([15, 1, 8064])\n",
      "torch.Size([2, 1, 8064])\n",
      "Epoch 81/300, Train Loss: 1.4070098400115967\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         7\n",
      "           2       0.17      0.67      0.27         3\n",
      "           3       0.70      0.47      0.56        15\n",
      "\n",
      "    accuracy                           0.36        25\n",
      "   macro avg       0.29      0.38      0.28        25\n",
      "weighted avg       0.44      0.36      0.37        25\n",
      "\n",
      "[[0 5 2]\n",
      " [0 2 1]\n",
      " [3 5 7]]\n",
      "Validation Loss for P31 = 1.3097753524780273\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_32/3812056636.py:43: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([18, 1, 8064])\n",
      "torch.Size([15, 1, 8064])\n",
      "torch.Size([18, 1, 8064])\n",
      "torch.Size([15, 1, 8064])\n",
      "torch.Size([2, 1, 8064])\n",
      "Epoch 82/300, Train Loss: 1.6121708154678345\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.25      0.14      0.18         7\n",
      "           2       0.18      0.67      0.29         3\n",
      "           3       0.70      0.47      0.56        15\n",
      "\n",
      "    accuracy                           0.40        25\n",
      "   macro avg       0.38      0.43      0.34        25\n",
      "weighted avg       0.51      0.40      0.42        25\n",
      "\n",
      "[[1 4 2]\n",
      " [0 2 1]\n",
      " [3 5 7]]\n",
      "Validation Loss for P31 = 1.305383324623108\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_32/3812056636.py:43: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([18, 1, 8064])\n",
      "torch.Size([15, 1, 8064])\n",
      "torch.Size([18, 1, 8064])\n",
      "torch.Size([15, 1, 8064])\n",
      "torch.Size([2, 1, 8064])\n",
      "Epoch 83/300, Train Loss: 1.428572177886963\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.25      0.14      0.18         7\n",
      "           2       0.18      0.67      0.29         3\n",
      "           3       0.70      0.47      0.56        15\n",
      "\n",
      "    accuracy                           0.40        25\n",
      "   macro avg       0.38      0.43      0.34        25\n",
      "weighted avg       0.51      0.40      0.42        25\n",
      "\n",
      "[[1 4 2]\n",
      " [0 2 1]\n",
      " [3 5 7]]\n",
      "Validation Loss for P31 = 1.3184572458267212\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_32/3812056636.py:43: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([18, 1, 8064])\n",
      "torch.Size([15, 1, 8064])\n",
      "torch.Size([18, 1, 8064])\n",
      "torch.Size([15, 1, 8064])\n",
      "torch.Size([2, 1, 8064])\n",
      "Epoch 84/300, Train Loss: 1.4216599464416504\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         7\n",
      "           2       0.17      0.67      0.27         3\n",
      "           3       0.70      0.47      0.56        15\n",
      "\n",
      "    accuracy                           0.36        25\n",
      "   macro avg       0.29      0.38      0.28        25\n",
      "weighted avg       0.44      0.36      0.37        25\n",
      "\n",
      "[[0 5 2]\n",
      " [0 2 1]\n",
      " [3 5 7]]\n",
      "Validation Loss for P31 = 1.326857328414917\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_32/3812056636.py:43: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([18, 1, 8064])\n",
      "torch.Size([15, 1, 8064])\n",
      "torch.Size([18, 1, 8064])\n",
      "torch.Size([15, 1, 8064])\n",
      "torch.Size([2, 1, 8064])\n",
      "Epoch 85/300, Train Loss: 1.3053114414215088\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.25      0.14      0.18         7\n",
      "           2       0.18      0.67      0.29         3\n",
      "           3       0.70      0.47      0.56        15\n",
      "\n",
      "    accuracy                           0.40        25\n",
      "   macro avg       0.38      0.43      0.34        25\n",
      "weighted avg       0.51      0.40      0.42        25\n",
      "\n",
      "[[1 4 2]\n",
      " [0 2 1]\n",
      " [3 5 7]]\n",
      "Validation Loss for P31 = 1.3112000226974487\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_32/3812056636.py:43: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([18, 1, 8064])\n",
      "torch.Size([15, 1, 8064])\n",
      "torch.Size([18, 1, 8064])\n",
      "torch.Size([15, 1, 8064])\n",
      "torch.Size([2, 1, 8064])\n",
      "Epoch 86/300, Train Loss: 1.4782817363739014\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.25      0.14      0.18         7\n",
      "           2       0.18      0.67      0.29         3\n",
      "           3       0.70      0.47      0.56        15\n",
      "\n",
      "    accuracy                           0.40        25\n",
      "   macro avg       0.38      0.43      0.34        25\n",
      "weighted avg       0.51      0.40      0.42        25\n",
      "\n",
      "[[1 4 2]\n",
      " [0 2 1]\n",
      " [3 5 7]]\n",
      "Validation Loss for P31 = 1.3311197757720947\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_32/3812056636.py:43: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([18, 1, 8064])\n",
      "torch.Size([15, 1, 8064])\n",
      "torch.Size([18, 1, 8064])\n",
      "torch.Size([15, 1, 8064])\n",
      "torch.Size([2, 1, 8064])\n",
      "Epoch 87/300, Train Loss: 1.7224962711334229\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.25      0.14      0.18         7\n",
      "           2       0.15      0.67      0.25         3\n",
      "           3       0.75      0.40      0.52        15\n",
      "\n",
      "    accuracy                           0.36        25\n",
      "   macro avg       0.38      0.40      0.32        25\n",
      "weighted avg       0.54      0.36      0.39        25\n",
      "\n",
      "[[1 5 1]\n",
      " [0 2 1]\n",
      " [3 6 6]]\n",
      "Validation Loss for P31 = 1.321182131767273\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_32/3812056636.py:43: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([18, 1, 8064])\n",
      "torch.Size([15, 1, 8064])\n",
      "torch.Size([18, 1, 8064])\n",
      "torch.Size([15, 1, 8064])\n",
      "torch.Size([2, 1, 8064])\n",
      "Epoch 88/300, Train Loss: 1.3111159801483154\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.25      0.14      0.18         7\n",
      "           2       0.17      0.67      0.27         3\n",
      "           3       0.67      0.40      0.50        15\n",
      "\n",
      "    accuracy                           0.36        25\n",
      "   macro avg       0.36      0.40      0.32        25\n",
      "weighted avg       0.49      0.36      0.38        25\n",
      "\n",
      "[[1 4 2]\n",
      " [0 2 1]\n",
      " [3 6 6]]\n",
      "Validation Loss for P31 = 1.3275381326675415\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_32/3812056636.py:43: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([18, 1, 8064])\n",
      "torch.Size([15, 1, 8064])\n",
      "torch.Size([18, 1, 8064])\n",
      "torch.Size([15, 1, 8064])\n",
      "torch.Size([2, 1, 8064])\n",
      "Epoch 89/300, Train Loss: 1.147775650024414\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.25      0.14      0.18         7\n",
      "           2       0.17      0.67      0.27         3\n",
      "           3       0.67      0.40      0.50        15\n",
      "\n",
      "    accuracy                           0.36        25\n",
      "   macro avg       0.36      0.40      0.32        25\n",
      "weighted avg       0.49      0.36      0.38        25\n",
      "\n",
      "[[1 4 2]\n",
      " [0 2 1]\n",
      " [3 6 6]]\n",
      "Validation Loss for P31 = 1.311179280281067\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_32/3812056636.py:43: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([18, 1, 8064])\n",
      "torch.Size([15, 1, 8064])\n",
      "torch.Size([18, 1, 8064])\n",
      "torch.Size([15, 1, 8064])\n",
      "torch.Size([2, 1, 8064])\n",
      "Epoch 90/300, Train Loss: 1.2648036479949951\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.25      0.14      0.18         7\n",
      "           2       0.17      0.67      0.27         3\n",
      "           3       0.67      0.40      0.50        15\n",
      "\n",
      "    accuracy                           0.36        25\n",
      "   macro avg       0.36      0.40      0.32        25\n",
      "weighted avg       0.49      0.36      0.38        25\n",
      "\n",
      "[[1 4 2]\n",
      " [0 2 1]\n",
      " [3 6 6]]\n",
      "Validation Loss for P31 = 1.3175424337387085\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_32/3812056636.py:43: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([18, 1, 8064])\n",
      "torch.Size([15, 1, 8064])\n",
      "torch.Size([18, 1, 8064])\n",
      "torch.Size([15, 1, 8064])\n",
      "torch.Size([2, 1, 8064])\n",
      "Epoch 91/300, Train Loss: 1.659102439880371\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.33      0.14      0.20         7\n",
      "           2       0.15      0.67      0.25         3\n",
      "           3       0.67      0.40      0.50        15\n",
      "\n",
      "    accuracy                           0.36        25\n",
      "   macro avg       0.38      0.40      0.32        25\n",
      "weighted avg       0.51      0.36      0.39        25\n",
      "\n",
      "[[1 4 2]\n",
      " [0 2 1]\n",
      " [2 7 6]]\n",
      "Validation Loss for P31 = 1.318269968032837\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_32/3812056636.py:43: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([18, 1, 8064])\n",
      "torch.Size([15, 1, 8064])\n",
      "torch.Size([18, 1, 8064])\n",
      "torch.Size([15, 1, 8064])\n",
      "torch.Size([2, 1, 8064])\n",
      "Epoch 92/300, Train Loss: 1.6580824851989746\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.25      0.14      0.18         7\n",
      "           2       0.17      0.67      0.27         3\n",
      "           3       0.67      0.40      0.50        15\n",
      "\n",
      "    accuracy                           0.36        25\n",
      "   macro avg       0.36      0.40      0.32        25\n",
      "weighted avg       0.49      0.36      0.38        25\n",
      "\n",
      "[[1 4 2]\n",
      " [0 2 1]\n",
      " [3 6 6]]\n",
      "Validation Loss for P31 = 1.3025126457214355\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_32/3812056636.py:43: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([18, 1, 8064])\n",
      "torch.Size([15, 1, 8064])\n",
      "torch.Size([18, 1, 8064])\n",
      "torch.Size([15, 1, 8064])\n",
      "torch.Size([2, 1, 8064])\n",
      "Epoch 93/300, Train Loss: 1.3500351905822754\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.40      0.29      0.33         7\n",
      "           2       0.20      0.67      0.31         3\n",
      "           3       0.70      0.47      0.56        15\n",
      "\n",
      "    accuracy                           0.44        25\n",
      "   macro avg       0.43      0.47      0.40        25\n",
      "weighted avg       0.56      0.44      0.47        25\n",
      "\n",
      "[[2 3 2]\n",
      " [0 2 1]\n",
      " [3 5 7]]\n",
      "Validation Loss for P31 = 1.298522710800171\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_32/3812056636.py:43: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([18, 1, 8064])\n",
      "torch.Size([15, 1, 8064])\n",
      "torch.Size([18, 1, 8064])\n",
      "torch.Size([15, 1, 8064])\n",
      "torch.Size([2, 1, 8064])\n",
      "Epoch 94/300, Train Loss: 1.3700830936431885\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.25      0.14      0.18         7\n",
      "           2       0.15      0.67      0.25         3\n",
      "           3       0.75      0.40      0.52        15\n",
      "\n",
      "    accuracy                           0.36        25\n",
      "   macro avg       0.38      0.40      0.32        25\n",
      "weighted avg       0.54      0.36      0.39        25\n",
      "\n",
      "[[1 5 1]\n",
      " [0 2 1]\n",
      " [3 6 6]]\n",
      "Validation Loss for P31 = 1.3166624307632446\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_32/3812056636.py:43: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([18, 1, 8064])\n",
      "torch.Size([15, 1, 8064])\n",
      "torch.Size([18, 1, 8064])\n",
      "torch.Size([15, 1, 8064])\n",
      "torch.Size([2, 1, 8064])\n",
      "Epoch 95/300, Train Loss: 1.6174418926239014\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.40      0.29      0.33         7\n",
      "           2       0.17      0.67      0.27         3\n",
      "           3       0.75      0.40      0.52        15\n",
      "\n",
      "    accuracy                           0.40        25\n",
      "   macro avg       0.44      0.45      0.37        25\n",
      "weighted avg       0.58      0.40      0.44        25\n",
      "\n",
      "[[2 4 1]\n",
      " [0 2 1]\n",
      " [3 6 6]]\n",
      "Validation Loss for P31 = 1.3087737560272217\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_32/3812056636.py:43: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([18, 1, 8064])\n",
      "torch.Size([15, 1, 8064])\n",
      "torch.Size([18, 1, 8064])\n",
      "torch.Size([15, 1, 8064])\n",
      "torch.Size([2, 1, 8064])\n",
      "Epoch 96/300, Train Loss: 1.3774505853652954\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.25      0.14      0.18         7\n",
      "           2       0.15      0.67      0.25         3\n",
      "           3       0.75      0.40      0.52        15\n",
      "\n",
      "    accuracy                           0.36        25\n",
      "   macro avg       0.38      0.40      0.32        25\n",
      "weighted avg       0.54      0.36      0.39        25\n",
      "\n",
      "[[1 5 1]\n",
      " [0 2 1]\n",
      " [3 6 6]]\n",
      "Validation Loss for P31 = 1.3141673803329468\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_32/3812056636.py:43: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([18, 1, 8064])\n",
      "torch.Size([15, 1, 8064])\n",
      "torch.Size([18, 1, 8064])\n",
      "torch.Size([15, 1, 8064])\n",
      "torch.Size([2, 1, 8064])\n",
      "Epoch 97/300, Train Loss: 1.4934881925582886\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.33      0.14      0.20         7\n",
      "           2       0.14      0.67      0.24         3\n",
      "           3       0.75      0.40      0.52        15\n",
      "\n",
      "    accuracy                           0.36        25\n",
      "   macro avg       0.41      0.40      0.32        25\n",
      "weighted avg       0.56      0.36      0.40        25\n",
      "\n",
      "[[1 5 1]\n",
      " [0 2 1]\n",
      " [2 7 6]]\n",
      "Validation Loss for P31 = 1.317000389099121\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_32/3812056636.py:43: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([18, 1, 8064])\n",
      "torch.Size([15, 1, 8064])\n",
      "torch.Size([18, 1, 8064])\n",
      "torch.Size([15, 1, 8064])\n",
      "torch.Size([2, 1, 8064])\n",
      "Epoch 98/300, Train Loss: 1.5126510858535767\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.33      0.14      0.20         7\n",
      "           2       0.17      0.67      0.27         3\n",
      "           3       0.70      0.47      0.56        15\n",
      "\n",
      "    accuracy                           0.40        25\n",
      "   macro avg       0.40      0.43      0.34        25\n",
      "weighted avg       0.53      0.40      0.42        25\n",
      "\n",
      "[[1 4 2]\n",
      " [0 2 1]\n",
      " [2 6 7]]\n",
      "Validation Loss for P31 = 1.3130855560302734\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_32/3812056636.py:43: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([18, 1, 8064])\n",
      "torch.Size([15, 1, 8064])\n",
      "torch.Size([18, 1, 8064])\n",
      "torch.Size([15, 1, 8064])\n",
      "torch.Size([2, 1, 8064])\n",
      "Epoch 99/300, Train Loss: 1.2828055620193481\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.33      0.14      0.20         7\n",
      "           2       0.15      0.67      0.25         3\n",
      "           3       0.78      0.47      0.58        15\n",
      "\n",
      "    accuracy                           0.40        25\n",
      "   macro avg       0.42      0.43      0.34        25\n",
      "weighted avg       0.58      0.40      0.44        25\n",
      "\n",
      "[[1 5 1]\n",
      " [0 2 1]\n",
      " [2 6 7]]\n",
      "Validation Loss for P31 = 1.3226779699325562\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_32/3812056636.py:43: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([18, 1, 8064])\n",
      "torch.Size([15, 1, 8064])\n",
      "torch.Size([18, 1, 8064])\n",
      "torch.Size([15, 1, 8064])\n",
      "torch.Size([2, 1, 8064])\n",
      "Epoch 100/300, Train Loss: 1.2292602062225342\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.25      0.14      0.18         7\n",
      "           2       0.17      0.67      0.27         3\n",
      "           3       0.78      0.47      0.58        15\n",
      "\n",
      "    accuracy                           0.40        25\n",
      "   macro avg       0.40      0.43      0.34        25\n",
      "weighted avg       0.56      0.40      0.43        25\n",
      "\n",
      "[[1 5 1]\n",
      " [0 2 1]\n",
      " [3 5 7]]\n",
      "Validation Loss for P31 = 1.3171324729919434\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_32/3812056636.py:43: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([18, 1, 8064])\n",
      "torch.Size([15, 1, 8064])\n",
      "torch.Size([18, 1, 8064])\n",
      "torch.Size([15, 1, 8064])\n",
      "torch.Size([2, 1, 8064])\n",
      "Epoch 101/300, Train Loss: 1.252178430557251\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.33      0.14      0.20         7\n",
      "           2       0.15      0.67      0.25         3\n",
      "           3       0.78      0.47      0.58        15\n",
      "\n",
      "    accuracy                           0.40        25\n",
      "   macro avg       0.42      0.43      0.34        25\n",
      "weighted avg       0.58      0.40      0.44        25\n",
      "\n",
      "[[1 5 1]\n",
      " [0 2 1]\n",
      " [2 6 7]]\n",
      "Validation Loss for P31 = 1.3178461790084839\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_32/3812056636.py:43: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([18, 1, 8064])\n",
      "torch.Size([15, 1, 8064])\n",
      "torch.Size([18, 1, 8064])\n",
      "torch.Size([15, 1, 8064])\n",
      "torch.Size([2, 1, 8064])\n",
      "Epoch 102/300, Train Loss: 1.6377123594284058\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.33      0.14      0.20         7\n",
      "           2       0.17      0.67      0.27         3\n",
      "           3       0.60      0.40      0.48        15\n",
      "\n",
      "    accuracy                           0.36        25\n",
      "   macro avg       0.37      0.40      0.32        25\n",
      "weighted avg       0.47      0.36      0.38        25\n",
      "\n",
      "[[1 3 3]\n",
      " [0 2 1]\n",
      " [2 7 6]]\n",
      "Validation Loss for P31 = 1.3180001974105835\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_32/3812056636.py:43: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([18, 1, 8064])\n",
      "torch.Size([15, 1, 8064])\n",
      "torch.Size([18, 1, 8064])\n",
      "torch.Size([15, 1, 8064])\n",
      "torch.Size([2, 1, 8064])\n",
      "Epoch 103/300, Train Loss: 1.57224702835083\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.33      0.14      0.20         7\n",
      "           2       0.17      0.67      0.27         3\n",
      "           3       0.70      0.47      0.56        15\n",
      "\n",
      "    accuracy                           0.40        25\n",
      "   macro avg       0.40      0.43      0.34        25\n",
      "weighted avg       0.53      0.40      0.42        25\n",
      "\n",
      "[[1 4 2]\n",
      " [0 2 1]\n",
      " [2 6 7]]\n",
      "Validation Loss for P31 = 1.323235273361206\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_32/3812056636.py:43: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([18, 1, 8064])\n",
      "torch.Size([15, 1, 8064])\n",
      "torch.Size([18, 1, 8064])\n",
      "torch.Size([15, 1, 8064])\n",
      "torch.Size([2, 1, 8064])\n",
      "Epoch 104/300, Train Loss: 1.6553716659545898\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.33      0.14      0.20         7\n",
      "           2       0.15      0.67      0.25         3\n",
      "           3       0.67      0.40      0.50        15\n",
      "\n",
      "    accuracy                           0.36        25\n",
      "   macro avg       0.38      0.40      0.32        25\n",
      "weighted avg       0.51      0.36      0.39        25\n",
      "\n",
      "[[1 4 2]\n",
      " [0 2 1]\n",
      " [2 7 6]]\n",
      "Validation Loss for P31 = 1.314505934715271\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_32/3812056636.py:43: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([18, 1, 8064])\n",
      "torch.Size([15, 1, 8064])\n",
      "torch.Size([18, 1, 8064])\n",
      "torch.Size([15, 1, 8064])\n",
      "torch.Size([2, 1, 8064])\n",
      "Epoch 105/300, Train Loss: 1.4646861553192139\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.25      0.14      0.18         7\n",
      "           2       0.18      0.67      0.29         3\n",
      "           3       0.70      0.47      0.56        15\n",
      "\n",
      "    accuracy                           0.40        25\n",
      "   macro avg       0.38      0.43      0.34        25\n",
      "weighted avg       0.51      0.40      0.42        25\n",
      "\n",
      "[[1 4 2]\n",
      " [0 2 1]\n",
      " [3 5 7]]\n",
      "Validation Loss for P31 = 1.3059883117675781\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_32/3812056636.py:43: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([18, 1, 8064])\n",
      "torch.Size([15, 1, 8064])\n",
      "torch.Size([18, 1, 8064])\n",
      "torch.Size([15, 1, 8064])\n",
      "torch.Size([2, 1, 8064])\n",
      "Epoch 106/300, Train Loss: 1.4648187160491943\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.25      0.14      0.18         7\n",
      "           2       0.18      0.67      0.29         3\n",
      "           3       0.70      0.47      0.56        15\n",
      "\n",
      "    accuracy                           0.40        25\n",
      "   macro avg       0.38      0.43      0.34        25\n",
      "weighted avg       0.51      0.40      0.42        25\n",
      "\n",
      "[[1 4 2]\n",
      " [0 2 1]\n",
      " [3 5 7]]\n",
      "Validation Loss for P31 = 1.313174843788147\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_32/3812056636.py:43: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([18, 1, 8064])\n",
      "torch.Size([15, 1, 8064])\n",
      "torch.Size([18, 1, 8064])\n",
      "torch.Size([15, 1, 8064])\n",
      "torch.Size([2, 1, 8064])\n",
      "Epoch 107/300, Train Loss: 1.5036115646362305\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.25      0.14      0.18         7\n",
      "           2       0.18      0.67      0.29         3\n",
      "           3       0.70      0.47      0.56        15\n",
      "\n",
      "    accuracy                           0.40        25\n",
      "   macro avg       0.38      0.43      0.34        25\n",
      "weighted avg       0.51      0.40      0.42        25\n",
      "\n",
      "[[1 4 2]\n",
      " [0 2 1]\n",
      " [3 5 7]]\n",
      "Validation Loss for P31 = 1.3062171936035156\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_32/3812056636.py:43: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([18, 1, 8064])\n",
      "torch.Size([15, 1, 8064])\n",
      "torch.Size([18, 1, 8064])\n",
      "torch.Size([15, 1, 8064])\n",
      "torch.Size([2, 1, 8064])\n",
      "Epoch 108/300, Train Loss: 1.101937174797058\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.25      0.14      0.18         7\n",
      "           2       0.15      0.67      0.25         3\n",
      "           3       0.75      0.40      0.52        15\n",
      "\n",
      "    accuracy                           0.36        25\n",
      "   macro avg       0.38      0.40      0.32        25\n",
      "weighted avg       0.54      0.36      0.39        25\n",
      "\n",
      "[[1 5 1]\n",
      " [0 2 1]\n",
      " [3 6 6]]\n",
      "Validation Loss for P31 = 1.313115119934082\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_32/3812056636.py:43: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([18, 1, 8064])\n",
      "torch.Size([15, 1, 8064])\n",
      "torch.Size([18, 1, 8064])\n",
      "torch.Size([15, 1, 8064])\n",
      "torch.Size([2, 1, 8064])\n",
      "Epoch 109/300, Train Loss: 1.3400667905807495\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.25      0.14      0.18         7\n",
      "           2       0.17      0.67      0.27         3\n",
      "           3       0.78      0.47      0.58        15\n",
      "\n",
      "    accuracy                           0.40        25\n",
      "   macro avg       0.40      0.43      0.34        25\n",
      "weighted avg       0.56      0.40      0.43        25\n",
      "\n",
      "[[1 5 1]\n",
      " [0 2 1]\n",
      " [3 5 7]]\n",
      "Validation Loss for P31 = 1.316957712173462\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_32/3812056636.py:43: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([18, 1, 8064])\n",
      "torch.Size([15, 1, 8064])\n",
      "torch.Size([18, 1, 8064])\n",
      "torch.Size([15, 1, 8064])\n",
      "torch.Size([2, 1, 8064])\n",
      "Epoch 110/300, Train Loss: 1.1484754085540771\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.25      0.14      0.18         7\n",
      "           2       0.18      0.67      0.29         3\n",
      "           3       0.70      0.47      0.56        15\n",
      "\n",
      "    accuracy                           0.40        25\n",
      "   macro avg       0.38      0.43      0.34        25\n",
      "weighted avg       0.51      0.40      0.42        25\n",
      "\n",
      "[[1 4 2]\n",
      " [0 2 1]\n",
      " [3 5 7]]\n",
      "Validation Loss for P31 = 1.3114241361618042\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_32/3812056636.py:43: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([18, 1, 8064])\n",
      "torch.Size([15, 1, 8064])\n",
      "torch.Size([18, 1, 8064])\n",
      "torch.Size([15, 1, 8064])\n",
      "torch.Size([2, 1, 8064])\n",
      "Epoch 111/300, Train Loss: 1.543461561203003\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         7\n",
      "           2       0.14      0.67      0.24         3\n",
      "           3       0.75      0.40      0.52        15\n",
      "\n",
      "    accuracy                           0.32        25\n",
      "   macro avg       0.30      0.36      0.25        25\n",
      "weighted avg       0.47      0.32      0.34        25\n",
      "\n",
      "[[0 6 1]\n",
      " [0 2 1]\n",
      " [3 6 6]]\n",
      "Validation Loss for P31 = 1.3220491409301758\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_32/3812056636.py:43: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([18, 1, 8064])\n",
      "torch.Size([15, 1, 8064])\n",
      "torch.Size([18, 1, 8064])\n",
      "torch.Size([15, 1, 8064])\n",
      "torch.Size([2, 1, 8064])\n",
      "Epoch 112/300, Train Loss: 1.4149543046951294\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.25      0.14      0.18         7\n",
      "           2       0.17      0.67      0.27         3\n",
      "           3       0.67      0.40      0.50        15\n",
      "\n",
      "    accuracy                           0.36        25\n",
      "   macro avg       0.36      0.40      0.32        25\n",
      "weighted avg       0.49      0.36      0.38        25\n",
      "\n",
      "[[1 4 2]\n",
      " [0 2 1]\n",
      " [3 6 6]]\n",
      "Validation Loss for P31 = 1.3018369674682617\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_32/3812056636.py:43: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([18, 1, 8064])\n",
      "torch.Size([15, 1, 8064])\n",
      "torch.Size([18, 1, 8064])\n",
      "torch.Size([15, 1, 8064])\n",
      "torch.Size([2, 1, 8064])\n",
      "Epoch 113/300, Train Loss: 1.5157785415649414\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         7\n",
      "           2       0.15      0.67      0.25         3\n",
      "           3       0.67      0.40      0.50        15\n",
      "\n",
      "    accuracy                           0.32        25\n",
      "   macro avg       0.27      0.36      0.25        25\n",
      "weighted avg       0.42      0.32      0.33        25\n",
      "\n",
      "[[0 5 2]\n",
      " [0 2 1]\n",
      " [3 6 6]]\n",
      "Validation Loss for P31 = 1.3230857849121094\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_32/3812056636.py:43: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([18, 1, 8064])\n",
      "torch.Size([15, 1, 8064])\n",
      "torch.Size([18, 1, 8064])\n",
      "torch.Size([15, 1, 8064])\n",
      "torch.Size([2, 1, 8064])\n",
      "Epoch 114/300, Train Loss: 1.3299555778503418\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         7\n",
      "           2       0.17      0.67      0.27         3\n",
      "           3       0.60      0.40      0.48        15\n",
      "\n",
      "    accuracy                           0.32        25\n",
      "   macro avg       0.26      0.36      0.25        25\n",
      "weighted avg       0.38      0.32      0.32        25\n",
      "\n",
      "[[0 4 3]\n",
      " [0 2 1]\n",
      " [3 6 6]]\n",
      "Validation Loss for P31 = 1.3157482147216797\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_32/3812056636.py:43: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([18, 1, 8064])\n",
      "torch.Size([15, 1, 8064])\n",
      "torch.Size([18, 1, 8064])\n",
      "torch.Size([15, 1, 8064])\n",
      "torch.Size([2, 1, 8064])\n",
      "Epoch 115/300, Train Loss: 1.4072496891021729\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         7\n",
      "           2       0.15      0.67      0.25         3\n",
      "           3       0.67      0.40      0.50        15\n",
      "\n",
      "    accuracy                           0.32        25\n",
      "   macro avg       0.27      0.36      0.25        25\n",
      "weighted avg       0.42      0.32      0.33        25\n",
      "\n",
      "[[0 5 2]\n",
      " [0 2 1]\n",
      " [3 6 6]]\n",
      "Validation Loss for P31 = 1.3203269243240356\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_32/3812056636.py:43: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([18, 1, 8064])\n",
      "torch.Size([15, 1, 8064])\n",
      "torch.Size([18, 1, 8064])\n",
      "torch.Size([15, 1, 8064])\n",
      "torch.Size([2, 1, 8064])\n",
      "Epoch 116/300, Train Loss: 1.4622329473495483\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         7\n",
      "           2       0.15      0.67      0.25         3\n",
      "           3       0.67      0.40      0.50        15\n",
      "\n",
      "    accuracy                           0.32        25\n",
      "   macro avg       0.27      0.36      0.25        25\n",
      "weighted avg       0.42      0.32      0.33        25\n",
      "\n",
      "[[0 5 2]\n",
      " [0 2 1]\n",
      " [3 6 6]]\n",
      "Validation Loss for P31 = 1.3261054754257202\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_32/3812056636.py:43: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([18, 1, 8064])\n",
      "torch.Size([15, 1, 8064])\n",
      "torch.Size([18, 1, 8064])\n",
      "torch.Size([15, 1, 8064])\n",
      "torch.Size([2, 1, 8064])\n",
      "Epoch 117/300, Train Loss: 1.2166510820388794\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         7\n",
      "           2       0.18      0.67      0.29         3\n",
      "           3       0.55      0.40      0.46        15\n",
      "\n",
      "    accuracy                           0.32        25\n",
      "   macro avg       0.24      0.36      0.25        25\n",
      "weighted avg       0.35      0.32      0.31        25\n",
      "\n",
      "[[0 3 4]\n",
      " [0 2 1]\n",
      " [3 6 6]]\n",
      "Validation Loss for P31 = 1.3271384239196777\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_32/3812056636.py:43: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([18, 1, 8064])\n",
      "torch.Size([15, 1, 8064])\n",
      "torch.Size([18, 1, 8064])\n",
      "torch.Size([15, 1, 8064])\n",
      "torch.Size([2, 1, 8064])\n",
      "Epoch 118/300, Train Loss: 1.4076929092407227\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         7\n",
      "           2       0.17      0.67      0.27         3\n",
      "           3       0.60      0.40      0.48        15\n",
      "\n",
      "    accuracy                           0.32        25\n",
      "   macro avg       0.26      0.36      0.25        25\n",
      "weighted avg       0.38      0.32      0.32        25\n",
      "\n",
      "[[0 4 3]\n",
      " [0 2 1]\n",
      " [3 6 6]]\n",
      "Validation Loss for P31 = 1.3217231035232544\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_32/3812056636.py:43: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([18, 1, 8064])\n",
      "torch.Size([15, 1, 8064])\n",
      "torch.Size([18, 1, 8064])\n",
      "torch.Size([15, 1, 8064])\n",
      "torch.Size([2, 1, 8064])\n",
      "Epoch 119/300, Train Loss: 1.1241440773010254\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         7\n",
      "           2       0.18      0.67      0.29         3\n",
      "           3       0.55      0.40      0.46        15\n",
      "\n",
      "    accuracy                           0.32        25\n",
      "   macro avg       0.24      0.36      0.25        25\n",
      "weighted avg       0.35      0.32      0.31        25\n",
      "\n",
      "[[0 3 4]\n",
      " [0 2 1]\n",
      " [3 6 6]]\n",
      "Validation Loss for P31 = 1.3213077783584595\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_32/3812056636.py:43: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([18, 1, 8064])\n",
      "torch.Size([15, 1, 8064])\n",
      "torch.Size([18, 1, 8064])\n",
      "torch.Size([15, 1, 8064])\n",
      "torch.Size([2, 1, 8064])\n",
      "Epoch 120/300, Train Loss: 1.512098789215088\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.25      0.14      0.18         7\n",
      "           2       0.17      0.67      0.27         3\n",
      "           3       0.67      0.40      0.50        15\n",
      "\n",
      "    accuracy                           0.36        25\n",
      "   macro avg       0.36      0.40      0.32        25\n",
      "weighted avg       0.49      0.36      0.38        25\n",
      "\n",
      "[[1 4 2]\n",
      " [0 2 1]\n",
      " [3 6 6]]\n",
      "Validation Loss for P31 = 1.318191647529602\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_32/3812056636.py:43: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([18, 1, 8064])\n",
      "torch.Size([15, 1, 8064])\n",
      "torch.Size([18, 1, 8064])\n",
      "torch.Size([15, 1, 8064])\n",
      "torch.Size([2, 1, 8064])\n",
      "Epoch 121/300, Train Loss: 1.615891933441162\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.25      0.14      0.18         7\n",
      "           2       0.17      0.67      0.27         3\n",
      "           3       0.67      0.40      0.50        15\n",
      "\n",
      "    accuracy                           0.36        25\n",
      "   macro avg       0.36      0.40      0.32        25\n",
      "weighted avg       0.49      0.36      0.38        25\n",
      "\n",
      "[[1 4 2]\n",
      " [0 2 1]\n",
      " [3 6 6]]\n",
      "Validation Loss for P31 = 1.321312665939331\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_32/3812056636.py:43: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([18, 1, 8064])\n",
      "torch.Size([15, 1, 8064])\n",
      "torch.Size([18, 1, 8064])\n",
      "torch.Size([15, 1, 8064])\n",
      "torch.Size([2, 1, 8064])\n",
      "Epoch 122/300, Train Loss: 1.380591630935669\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         7\n",
      "           2       0.17      0.67      0.27         3\n",
      "           3       0.60      0.40      0.48        15\n",
      "\n",
      "    accuracy                           0.32        25\n",
      "   macro avg       0.26      0.36      0.25        25\n",
      "weighted avg       0.38      0.32      0.32        25\n",
      "\n",
      "[[0 4 3]\n",
      " [0 2 1]\n",
      " [3 6 6]]\n",
      "Validation Loss for P31 = 1.3282259702682495\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_32/3812056636.py:43: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([18, 1, 8064])\n",
      "torch.Size([15, 1, 8064])\n",
      "torch.Size([18, 1, 8064])\n",
      "torch.Size([15, 1, 8064])\n",
      "torch.Size([2, 1, 8064])\n",
      "Epoch 123/300, Train Loss: 1.5269544124603271\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         7\n",
      "           2       0.17      0.67      0.27         3\n",
      "           3       0.60      0.40      0.48        15\n",
      "\n",
      "    accuracy                           0.32        25\n",
      "   macro avg       0.26      0.36      0.25        25\n",
      "weighted avg       0.38      0.32      0.32        25\n",
      "\n",
      "[[0 4 3]\n",
      " [0 2 1]\n",
      " [3 6 6]]\n",
      "Validation Loss for P31 = 1.327613353729248\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_32/3812056636.py:43: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([18, 1, 8064])\n",
      "torch.Size([15, 1, 8064])\n",
      "torch.Size([18, 1, 8064])\n",
      "torch.Size([15, 1, 8064])\n",
      "torch.Size([2, 1, 8064])\n",
      "Epoch 124/300, Train Loss: 1.51071298122406\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         7\n",
      "           2       0.18      0.67      0.29         3\n",
      "           3       0.55      0.40      0.46        15\n",
      "\n",
      "    accuracy                           0.32        25\n",
      "   macro avg       0.24      0.36      0.25        25\n",
      "weighted avg       0.35      0.32      0.31        25\n",
      "\n",
      "[[0 3 4]\n",
      " [0 2 1]\n",
      " [3 6 6]]\n",
      "Validation Loss for P31 = 1.3191230297088623\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_32/3812056636.py:43: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([18, 1, 8064])\n",
      "torch.Size([15, 1, 8064])\n",
      "torch.Size([18, 1, 8064])\n",
      "torch.Size([15, 1, 8064])\n",
      "torch.Size([2, 1, 8064])\n",
      "Epoch 125/300, Train Loss: 1.249264121055603\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.25      0.14      0.18         7\n",
      "           2       0.17      0.67      0.27         3\n",
      "           3       0.67      0.40      0.50        15\n",
      "\n",
      "    accuracy                           0.36        25\n",
      "   macro avg       0.36      0.40      0.32        25\n",
      "weighted avg       0.49      0.36      0.38        25\n",
      "\n",
      "[[1 4 2]\n",
      " [0 2 1]\n",
      " [3 6 6]]\n",
      "Validation Loss for P31 = 1.3316898345947266\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_32/3812056636.py:43: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([18, 1, 8064])\n",
      "torch.Size([15, 1, 8064])\n",
      "torch.Size([18, 1, 8064])\n",
      "torch.Size([15, 1, 8064])\n",
      "torch.Size([2, 1, 8064])\n",
      "Epoch 126/300, Train Loss: 1.623986005783081\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.25      0.14      0.18         7\n",
      "           2       0.15      0.67      0.25         3\n",
      "           3       0.75      0.40      0.52        15\n",
      "\n",
      "    accuracy                           0.36        25\n",
      "   macro avg       0.38      0.40      0.32        25\n",
      "weighted avg       0.54      0.36      0.39        25\n",
      "\n",
      "[[1 5 1]\n",
      " [0 2 1]\n",
      " [3 6 6]]\n",
      "Validation Loss for P31 = 1.3205320835113525\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_32/3812056636.py:43: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([18, 1, 8064])\n",
      "torch.Size([15, 1, 8064])\n",
      "torch.Size([18, 1, 8064])\n",
      "torch.Size([15, 1, 8064])\n",
      "torch.Size([2, 1, 8064])\n",
      "Epoch 127/300, Train Loss: 1.533492922782898\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.25      0.14      0.18         7\n",
      "           2       0.17      0.67      0.27         3\n",
      "           3       0.67      0.40      0.50        15\n",
      "\n",
      "    accuracy                           0.36        25\n",
      "   macro avg       0.36      0.40      0.32        25\n",
      "weighted avg       0.49      0.36      0.38        25\n",
      "\n",
      "[[1 4 2]\n",
      " [0 2 1]\n",
      " [3 6 6]]\n",
      "Validation Loss for P31 = 1.3167047500610352\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_32/3812056636.py:43: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([18, 1, 8064])\n",
      "torch.Size([15, 1, 8064])\n",
      "torch.Size([18, 1, 8064])\n",
      "torch.Size([15, 1, 8064])\n",
      "torch.Size([2, 1, 8064])\n",
      "Epoch 128/300, Train Loss: 1.7087280750274658\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.25      0.14      0.18         7\n",
      "           2       0.17      0.67      0.27         3\n",
      "           3       0.67      0.40      0.50        15\n",
      "\n",
      "    accuracy                           0.36        25\n",
      "   macro avg       0.36      0.40      0.32        25\n",
      "weighted avg       0.49      0.36      0.38        25\n",
      "\n",
      "[[1 4 2]\n",
      " [0 2 1]\n",
      " [3 6 6]]\n",
      "Validation Loss for P31 = 1.3194020986557007\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_32/3812056636.py:43: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([18, 1, 8064])\n",
      "torch.Size([15, 1, 8064])\n",
      "torch.Size([18, 1, 8064])\n",
      "torch.Size([15, 1, 8064])\n",
      "torch.Size([2, 1, 8064])\n",
      "Epoch 129/300, Train Loss: 1.4537217617034912\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         7\n",
      "           2       0.14      0.67      0.24         3\n",
      "           3       0.75      0.40      0.52        15\n",
      "\n",
      "    accuracy                           0.32        25\n",
      "   macro avg       0.30      0.36      0.25        25\n",
      "weighted avg       0.47      0.32      0.34        25\n",
      "\n",
      "[[0 6 1]\n",
      " [0 2 1]\n",
      " [3 6 6]]\n",
      "Validation Loss for P31 = 1.3199752569198608\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_32/3812056636.py:43: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([18, 1, 8064])\n",
      "torch.Size([15, 1, 8064])\n",
      "torch.Size([18, 1, 8064])\n",
      "torch.Size([15, 1, 8064])\n",
      "torch.Size([2, 1, 8064])\n",
      "Epoch 130/300, Train Loss: 1.501119613647461\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.25      0.14      0.18         7\n",
      "           2       0.15      0.67      0.25         3\n",
      "           3       0.75      0.40      0.52        15\n",
      "\n",
      "    accuracy                           0.36        25\n",
      "   macro avg       0.38      0.40      0.32        25\n",
      "weighted avg       0.54      0.36      0.39        25\n",
      "\n",
      "[[1 5 1]\n",
      " [0 2 1]\n",
      " [3 6 6]]\n",
      "Validation Loss for P31 = 1.3116034269332886\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_32/3812056636.py:43: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([18, 1, 8064])\n",
      "torch.Size([15, 1, 8064])\n",
      "torch.Size([18, 1, 8064])\n",
      "torch.Size([15, 1, 8064])\n",
      "torch.Size([2, 1, 8064])\n",
      "Epoch 131/300, Train Loss: 1.2739548683166504\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.33      0.14      0.20         7\n",
      "           2       0.15      0.67      0.25         3\n",
      "           3       0.67      0.40      0.50        15\n",
      "\n",
      "    accuracy                           0.36        25\n",
      "   macro avg       0.38      0.40      0.32        25\n",
      "weighted avg       0.51      0.36      0.39        25\n",
      "\n",
      "[[1 4 2]\n",
      " [0 2 1]\n",
      " [2 7 6]]\n",
      "Validation Loss for P31 = 1.307965636253357\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_32/3812056636.py:43: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([18, 1, 8064])\n",
      "torch.Size([15, 1, 8064])\n",
      "torch.Size([18, 1, 8064])\n",
      "torch.Size([15, 1, 8064])\n",
      "torch.Size([2, 1, 8064])\n",
      "Epoch 132/300, Train Loss: 1.4706649780273438\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.25      0.14      0.18         7\n",
      "           2       0.17      0.67      0.27         3\n",
      "           3       0.67      0.40      0.50        15\n",
      "\n",
      "    accuracy                           0.36        25\n",
      "   macro avg       0.36      0.40      0.32        25\n",
      "weighted avg       0.49      0.36      0.38        25\n",
      "\n",
      "[[1 4 2]\n",
      " [0 2 1]\n",
      " [3 6 6]]\n",
      "Validation Loss for P31 = 1.3038462400436401\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_32/3812056636.py:43: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([18, 1, 8064])\n",
      "torch.Size([15, 1, 8064])\n",
      "torch.Size([18, 1, 8064])\n",
      "torch.Size([15, 1, 8064])\n",
      "torch.Size([2, 1, 8064])\n",
      "Epoch 133/300, Train Loss: 1.4120852947235107\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.25      0.14      0.18         7\n",
      "           2       0.17      0.67      0.27         3\n",
      "           3       0.67      0.40      0.50        15\n",
      "\n",
      "    accuracy                           0.36        25\n",
      "   macro avg       0.36      0.40      0.32        25\n",
      "weighted avg       0.49      0.36      0.38        25\n",
      "\n",
      "[[1 4 2]\n",
      " [0 2 1]\n",
      " [3 6 6]]\n",
      "Validation Loss for P31 = 1.3044525384902954\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_32/3812056636.py:43: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([18, 1, 8064])\n",
      "torch.Size([15, 1, 8064])\n",
      "torch.Size([18, 1, 8064])\n",
      "torch.Size([15, 1, 8064])\n",
      "torch.Size([2, 1, 8064])\n",
      "Epoch 134/300, Train Loss: 1.343393325805664\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.25      0.14      0.18         7\n",
      "           2       0.17      0.67      0.27         3\n",
      "           3       0.67      0.40      0.50        15\n",
      "\n",
      "    accuracy                           0.36        25\n",
      "   macro avg       0.36      0.40      0.32        25\n",
      "weighted avg       0.49      0.36      0.38        25\n",
      "\n",
      "[[1 4 2]\n",
      " [0 2 1]\n",
      " [3 6 6]]\n",
      "Validation Loss for P31 = 1.300956130027771\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_32/3812056636.py:43: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([18, 1, 8064])\n",
      "torch.Size([15, 1, 8064])\n",
      "torch.Size([18, 1, 8064])\n",
      "torch.Size([15, 1, 8064])\n",
      "torch.Size([2, 1, 8064])\n",
      "Epoch 135/300, Train Loss: 1.3457950353622437\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.25      0.14      0.18         7\n",
      "           2       0.17      0.67      0.27         3\n",
      "           3       0.67      0.40      0.50        15\n",
      "\n",
      "    accuracy                           0.36        25\n",
      "   macro avg       0.36      0.40      0.32        25\n",
      "weighted avg       0.49      0.36      0.38        25\n",
      "\n",
      "[[1 4 2]\n",
      " [0 2 1]\n",
      " [3 6 6]]\n",
      "Validation Loss for P31 = 1.316501259803772\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_32/3812056636.py:43: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([18, 1, 8064])\n",
      "torch.Size([15, 1, 8064])\n",
      "torch.Size([18, 1, 8064])\n",
      "torch.Size([15, 1, 8064])\n",
      "torch.Size([2, 1, 8064])\n",
      "Epoch 136/300, Train Loss: 1.301889181137085\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.25      0.14      0.18         7\n",
      "           2       0.17      0.67      0.27         3\n",
      "           3       0.67      0.40      0.50        15\n",
      "\n",
      "    accuracy                           0.36        25\n",
      "   macro avg       0.36      0.40      0.32        25\n",
      "weighted avg       0.49      0.36      0.38        25\n",
      "\n",
      "[[1 4 2]\n",
      " [0 2 1]\n",
      " [3 6 6]]\n",
      "Validation Loss for P31 = 1.2944403886795044\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_32/3812056636.py:43: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([18, 1, 8064])\n",
      "torch.Size([15, 1, 8064])\n",
      "torch.Size([18, 1, 8064])\n",
      "torch.Size([15, 1, 8064])\n",
      "torch.Size([2, 1, 8064])\n",
      "Epoch 137/300, Train Loss: 1.5048072338104248\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.25      0.14      0.18         7\n",
      "           2       0.17      0.67      0.27         3\n",
      "           3       0.67      0.40      0.50        15\n",
      "\n",
      "    accuracy                           0.36        25\n",
      "   macro avg       0.36      0.40      0.32        25\n",
      "weighted avg       0.49      0.36      0.38        25\n",
      "\n",
      "[[1 4 2]\n",
      " [0 2 1]\n",
      " [3 6 6]]\n",
      "Validation Loss for P31 = 1.3045122623443604\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_32/3812056636.py:43: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([18, 1, 8064])\n",
      "torch.Size([15, 1, 8064])\n",
      "torch.Size([18, 1, 8064])\n",
      "torch.Size([15, 1, 8064])\n",
      "torch.Size([2, 1, 8064])\n",
      "Epoch 138/300, Train Loss: 1.4543094635009766\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.25      0.14      0.18         7\n",
      "           2       0.15      0.67      0.25         3\n",
      "           3       0.75      0.40      0.52        15\n",
      "\n",
      "    accuracy                           0.36        25\n",
      "   macro avg       0.38      0.40      0.32        25\n",
      "weighted avg       0.54      0.36      0.39        25\n",
      "\n",
      "[[1 5 1]\n",
      " [0 2 1]\n",
      " [3 6 6]]\n",
      "Validation Loss for P31 = 1.308799147605896\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_32/3812056636.py:43: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([18, 1, 8064])\n",
      "torch.Size([15, 1, 8064])\n",
      "torch.Size([18, 1, 8064])\n",
      "torch.Size([15, 1, 8064])\n",
      "torch.Size([2, 1, 8064])\n",
      "Epoch 139/300, Train Loss: 1.3484697341918945\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.25      0.14      0.18         7\n",
      "           2       0.15      0.67      0.25         3\n",
      "           3       0.75      0.40      0.52        15\n",
      "\n",
      "    accuracy                           0.36        25\n",
      "   macro avg       0.38      0.40      0.32        25\n",
      "weighted avg       0.54      0.36      0.39        25\n",
      "\n",
      "[[1 5 1]\n",
      " [0 2 1]\n",
      " [3 6 6]]\n",
      "Validation Loss for P31 = 1.3067562580108643\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_32/3812056636.py:43: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([18, 1, 8064])\n",
      "torch.Size([15, 1, 8064])\n",
      "torch.Size([18, 1, 8064])\n",
      "torch.Size([15, 1, 8064])\n",
      "torch.Size([2, 1, 8064])\n",
      "Epoch 140/300, Train Loss: 1.4482827186584473\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.25      0.14      0.18         7\n",
      "           2       0.17      0.67      0.27         3\n",
      "           3       0.67      0.40      0.50        15\n",
      "\n",
      "    accuracy                           0.36        25\n",
      "   macro avg       0.36      0.40      0.32        25\n",
      "weighted avg       0.49      0.36      0.38        25\n",
      "\n",
      "[[1 4 2]\n",
      " [0 2 1]\n",
      " [3 6 6]]\n",
      "Validation Loss for P31 = 1.311018705368042\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_32/3812056636.py:43: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([18, 1, 8064])\n",
      "torch.Size([15, 1, 8064])\n",
      "torch.Size([18, 1, 8064])\n",
      "torch.Size([15, 1, 8064])\n",
      "torch.Size([2, 1, 8064])\n",
      "Epoch 141/300, Train Loss: 1.5125062465667725\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.25      0.14      0.18         7\n",
      "           2       0.17      0.67      0.27         3\n",
      "           3       0.67      0.40      0.50        15\n",
      "\n",
      "    accuracy                           0.36        25\n",
      "   macro avg       0.36      0.40      0.32        25\n",
      "weighted avg       0.49      0.36      0.38        25\n",
      "\n",
      "[[1 4 2]\n",
      " [0 2 1]\n",
      " [3 6 6]]\n",
      "Validation Loss for P31 = 1.2994499206542969\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_32/3812056636.py:43: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([18, 1, 8064])\n",
      "torch.Size([15, 1, 8064])\n",
      "torch.Size([18, 1, 8064])\n",
      "torch.Size([15, 1, 8064])\n",
      "torch.Size([2, 1, 8064])\n",
      "Epoch 142/300, Train Loss: 1.4249954223632812\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.25      0.14      0.18         7\n",
      "           2       0.17      0.67      0.27         3\n",
      "           3       0.67      0.40      0.50        15\n",
      "\n",
      "    accuracy                           0.36        25\n",
      "   macro avg       0.36      0.40      0.32        25\n",
      "weighted avg       0.49      0.36      0.38        25\n",
      "\n",
      "[[1 4 2]\n",
      " [0 2 1]\n",
      " [3 6 6]]\n",
      "Validation Loss for P31 = 1.3048065900802612\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_32/3812056636.py:43: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([18, 1, 8064])\n",
      "torch.Size([15, 1, 8064])\n",
      "torch.Size([18, 1, 8064])\n",
      "torch.Size([15, 1, 8064])\n",
      "torch.Size([2, 1, 8064])\n",
      "Epoch 143/300, Train Loss: 1.145262360572815\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.25      0.14      0.18         7\n",
      "           2       0.17      0.67      0.27         3\n",
      "           3       0.67      0.40      0.50        15\n",
      "\n",
      "    accuracy                           0.36        25\n",
      "   macro avg       0.36      0.40      0.32        25\n",
      "weighted avg       0.49      0.36      0.38        25\n",
      "\n",
      "[[1 4 2]\n",
      " [0 2 1]\n",
      " [3 6 6]]\n",
      "Validation Loss for P31 = 1.2920551300048828\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_32/3812056636.py:43: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([18, 1, 8064])\n",
      "torch.Size([15, 1, 8064])\n",
      "torch.Size([18, 1, 8064])\n",
      "torch.Size([15, 1, 8064])\n",
      "torch.Size([2, 1, 8064])\n",
      "Epoch 144/300, Train Loss: 1.2325735092163086\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.25      0.14      0.18         7\n",
      "           2       0.17      0.67      0.27         3\n",
      "           3       0.67      0.40      0.50        15\n",
      "\n",
      "    accuracy                           0.36        25\n",
      "   macro avg       0.36      0.40      0.32        25\n",
      "weighted avg       0.49      0.36      0.38        25\n",
      "\n",
      "[[1 4 2]\n",
      " [0 2 1]\n",
      " [3 6 6]]\n",
      "Validation Loss for P31 = 1.304207444190979\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_32/3812056636.py:43: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([18, 1, 8064])\n",
      "torch.Size([15, 1, 8064])\n",
      "torch.Size([18, 1, 8064])\n",
      "torch.Size([15, 1, 8064])\n",
      "torch.Size([2, 1, 8064])\n",
      "Epoch 145/300, Train Loss: 1.4634804725646973\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.25      0.14      0.18         7\n",
      "           2       0.17      0.67      0.27         3\n",
      "           3       0.67      0.40      0.50        15\n",
      "\n",
      "    accuracy                           0.36        25\n",
      "   macro avg       0.36      0.40      0.32        25\n",
      "weighted avg       0.49      0.36      0.38        25\n",
      "\n",
      "[[1 4 2]\n",
      " [0 2 1]\n",
      " [3 6 6]]\n",
      "Validation Loss for P31 = 1.2965691089630127\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_32/3812056636.py:43: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([18, 1, 8064])\n",
      "torch.Size([15, 1, 8064])\n",
      "torch.Size([18, 1, 8064])\n",
      "torch.Size([15, 1, 8064])\n",
      "torch.Size([2, 1, 8064])\n",
      "Epoch 146/300, Train Loss: 1.5332921743392944\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.25      0.14      0.18         7\n",
      "           2       0.17      0.67      0.27         3\n",
      "           3       0.67      0.40      0.50        15\n",
      "\n",
      "    accuracy                           0.36        25\n",
      "   macro avg       0.36      0.40      0.32        25\n",
      "weighted avg       0.49      0.36      0.38        25\n",
      "\n",
      "[[1 4 2]\n",
      " [0 2 1]\n",
      " [3 6 6]]\n",
      "Validation Loss for P31 = 1.3001585006713867\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_32/3812056636.py:43: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([18, 1, 8064])\n",
      "torch.Size([15, 1, 8064])\n",
      "torch.Size([18, 1, 8064])\n",
      "torch.Size([15, 1, 8064])\n",
      "torch.Size([2, 1, 8064])\n",
      "Epoch 147/300, Train Loss: 1.2937610149383545\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.25      0.14      0.18         7\n",
      "           2       0.17      0.67      0.27         3\n",
      "           3       0.67      0.40      0.50        15\n",
      "\n",
      "    accuracy                           0.36        25\n",
      "   macro avg       0.36      0.40      0.32        25\n",
      "weighted avg       0.49      0.36      0.38        25\n",
      "\n",
      "[[1 4 2]\n",
      " [0 2 1]\n",
      " [3 6 6]]\n",
      "Validation Loss for P31 = 1.2928615808486938\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_32/3812056636.py:43: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([18, 1, 8064])\n",
      "torch.Size([15, 1, 8064])\n",
      "torch.Size([18, 1, 8064])\n",
      "torch.Size([15, 1, 8064])\n",
      "torch.Size([2, 1, 8064])\n",
      "Epoch 148/300, Train Loss: 1.3256279230117798\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.25      0.14      0.18         7\n",
      "           2       0.17      0.67      0.27         3\n",
      "           3       0.67      0.40      0.50        15\n",
      "\n",
      "    accuracy                           0.36        25\n",
      "   macro avg       0.36      0.40      0.32        25\n",
      "weighted avg       0.49      0.36      0.38        25\n",
      "\n",
      "[[1 4 2]\n",
      " [0 2 1]\n",
      " [3 6 6]]\n",
      "Validation Loss for P31 = 1.285316824913025\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_32/3812056636.py:43: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([18, 1, 8064])\n",
      "torch.Size([15, 1, 8064])\n",
      "torch.Size([18, 1, 8064])\n",
      "torch.Size([15, 1, 8064])\n",
      "torch.Size([2, 1, 8064])\n",
      "Epoch 149/300, Train Loss: 1.1648666858673096\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         7\n",
      "           2       0.14      0.67      0.24         3\n",
      "           3       0.75      0.40      0.52        15\n",
      "\n",
      "    accuracy                           0.32        25\n",
      "   macro avg       0.30      0.36      0.25        25\n",
      "weighted avg       0.47      0.32      0.34        25\n",
      "\n",
      "[[0 6 1]\n",
      " [0 2 1]\n",
      " [3 6 6]]\n",
      "Validation Loss for P31 = 1.2925081253051758\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_32/3812056636.py:43: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([18, 1, 8064])\n",
      "torch.Size([15, 1, 8064])\n",
      "torch.Size([18, 1, 8064])\n",
      "torch.Size([15, 1, 8064])\n",
      "torch.Size([2, 1, 8064])\n",
      "Epoch 150/300, Train Loss: 1.4348186254501343\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.25      0.14      0.18         7\n",
      "           2       0.17      0.67      0.27         3\n",
      "           3       0.67      0.40      0.50        15\n",
      "\n",
      "    accuracy                           0.36        25\n",
      "   macro avg       0.36      0.40      0.32        25\n",
      "weighted avg       0.49      0.36      0.38        25\n",
      "\n",
      "[[1 4 2]\n",
      " [0 2 1]\n",
      " [3 6 6]]\n",
      "Validation Loss for P31 = 1.2876232862472534\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_32/3812056636.py:43: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([18, 1, 8064])\n",
      "torch.Size([15, 1, 8064])\n",
      "torch.Size([18, 1, 8064])\n",
      "torch.Size([15, 1, 8064])\n",
      "torch.Size([2, 1, 8064])\n",
      "Epoch 151/300, Train Loss: 1.5105879306793213\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.25      0.14      0.18         7\n",
      "           2       0.18      0.67      0.29         3\n",
      "           3       0.60      0.40      0.48        15\n",
      "\n",
      "    accuracy                           0.36        25\n",
      "   macro avg       0.34      0.40      0.32        25\n",
      "weighted avg       0.45      0.36      0.37        25\n",
      "\n",
      "[[1 3 3]\n",
      " [0 2 1]\n",
      " [3 6 6]]\n",
      "Validation Loss for P31 = 1.288743019104004\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_32/3812056636.py:43: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([18, 1, 8064])\n",
      "torch.Size([15, 1, 8064])\n",
      "torch.Size([18, 1, 8064])\n",
      "torch.Size([15, 1, 8064])\n",
      "torch.Size([2, 1, 8064])\n",
      "Epoch 152/300, Train Loss: 1.5348824262619019\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         7\n",
      "           2       0.15      0.67      0.25         3\n",
      "           3       0.67      0.40      0.50        15\n",
      "\n",
      "    accuracy                           0.32        25\n",
      "   macro avg       0.27      0.36      0.25        25\n",
      "weighted avg       0.42      0.32      0.33        25\n",
      "\n",
      "[[0 5 2]\n",
      " [0 2 1]\n",
      " [3 6 6]]\n",
      "Validation Loss for P31 = 1.3013300895690918\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_32/3812056636.py:43: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([18, 1, 8064])\n",
      "torch.Size([15, 1, 8064])\n",
      "torch.Size([18, 1, 8064])\n",
      "torch.Size([15, 1, 8064])\n",
      "torch.Size([2, 1, 8064])\n",
      "Epoch 153/300, Train Loss: 1.3508944511413574\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         7\n",
      "           2       0.17      0.67      0.27         3\n",
      "           3       0.60      0.40      0.48        15\n",
      "\n",
      "    accuracy                           0.32        25\n",
      "   macro avg       0.26      0.36      0.25        25\n",
      "weighted avg       0.38      0.32      0.32        25\n",
      "\n",
      "[[0 4 3]\n",
      " [0 2 1]\n",
      " [3 6 6]]\n",
      "Validation Loss for P31 = 1.2921562194824219\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_32/3812056636.py:43: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([18, 1, 8064])\n",
      "torch.Size([15, 1, 8064])\n",
      "torch.Size([18, 1, 8064])\n",
      "torch.Size([15, 1, 8064])\n",
      "torch.Size([2, 1, 8064])\n",
      "Epoch 154/300, Train Loss: 1.4522581100463867\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.25      0.14      0.18         7\n",
      "           2       0.18      0.67      0.29         3\n",
      "           3       0.60      0.40      0.48        15\n",
      "\n",
      "    accuracy                           0.36        25\n",
      "   macro avg       0.34      0.40      0.32        25\n",
      "weighted avg       0.45      0.36      0.37        25\n",
      "\n",
      "[[1 3 3]\n",
      " [0 2 1]\n",
      " [3 6 6]]\n",
      "Validation Loss for P31 = 1.288220763206482\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_32/3812056636.py:43: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([18, 1, 8064])\n",
      "torch.Size([15, 1, 8064])\n",
      "torch.Size([18, 1, 8064])\n",
      "torch.Size([15, 1, 8064])\n",
      "torch.Size([2, 1, 8064])\n",
      "Epoch 155/300, Train Loss: 1.3937046527862549\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.25      0.14      0.18         7\n",
      "           2       0.18      0.67      0.29         3\n",
      "           3       0.60      0.40      0.48        15\n",
      "\n",
      "    accuracy                           0.36        25\n",
      "   macro avg       0.34      0.40      0.32        25\n",
      "weighted avg       0.45      0.36      0.37        25\n",
      "\n",
      "[[1 3 3]\n",
      " [0 2 1]\n",
      " [3 6 6]]\n",
      "Validation Loss for P31 = 1.2840347290039062\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_32/3812056636.py:43: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([18, 1, 8064])\n",
      "torch.Size([15, 1, 8064])\n",
      "torch.Size([18, 1, 8064])\n",
      "torch.Size([15, 1, 8064])\n",
      "torch.Size([2, 1, 8064])\n",
      "Epoch 156/300, Train Loss: 1.597663164138794\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         7\n",
      "           2       0.15      0.67      0.25         3\n",
      "           3       0.67      0.40      0.50        15\n",
      "\n",
      "    accuracy                           0.32        25\n",
      "   macro avg       0.27      0.36      0.25        25\n",
      "weighted avg       0.42      0.32      0.33        25\n",
      "\n",
      "[[0 5 2]\n",
      " [0 2 1]\n",
      " [3 6 6]]\n",
      "Validation Loss for P31 = 1.2901195287704468\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_32/3812056636.py:43: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([18, 1, 8064])\n",
      "torch.Size([15, 1, 8064])\n",
      "torch.Size([18, 1, 8064])\n",
      "torch.Size([15, 1, 8064])\n",
      "torch.Size([2, 1, 8064])\n",
      "Epoch 157/300, Train Loss: 1.4352725744247437\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         7\n",
      "           2       0.15      0.67      0.25         3\n",
      "           3       0.67      0.40      0.50        15\n",
      "\n",
      "    accuracy                           0.32        25\n",
      "   macro avg       0.27      0.36      0.25        25\n",
      "weighted avg       0.42      0.32      0.33        25\n",
      "\n",
      "[[0 5 2]\n",
      " [0 2 1]\n",
      " [3 6 6]]\n",
      "Validation Loss for P31 = 1.2952079772949219\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_32/3812056636.py:43: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([18, 1, 8064])\n",
      "torch.Size([15, 1, 8064])\n",
      "torch.Size([18, 1, 8064])\n",
      "torch.Size([15, 1, 8064])\n",
      "torch.Size([2, 1, 8064])\n",
      "Epoch 158/300, Train Loss: 1.573725700378418\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         7\n",
      "           2       0.17      0.67      0.27         3\n",
      "           3       0.60      0.40      0.48        15\n",
      "\n",
      "    accuracy                           0.32        25\n",
      "   macro avg       0.26      0.36      0.25        25\n",
      "weighted avg       0.38      0.32      0.32        25\n",
      "\n",
      "[[0 4 3]\n",
      " [0 2 1]\n",
      " [3 6 6]]\n",
      "Validation Loss for P31 = 1.2887731790542603\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_32/3812056636.py:43: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([18, 1, 8064])\n",
      "torch.Size([15, 1, 8064])\n",
      "torch.Size([18, 1, 8064])\n",
      "torch.Size([15, 1, 8064])\n",
      "torch.Size([2, 1, 8064])\n",
      "Epoch 159/300, Train Loss: 1.591364860534668\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.25      0.14      0.18         7\n",
      "           2       0.17      0.67      0.27         3\n",
      "           3       0.67      0.40      0.50        15\n",
      "\n",
      "    accuracy                           0.36        25\n",
      "   macro avg       0.36      0.40      0.32        25\n",
      "weighted avg       0.49      0.36      0.38        25\n",
      "\n",
      "[[1 4 2]\n",
      " [0 2 1]\n",
      " [3 6 6]]\n",
      "Validation Loss for P31 = 1.2979662418365479\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_32/3812056636.py:43: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([18, 1, 8064])\n",
      "torch.Size([15, 1, 8064])\n",
      "torch.Size([18, 1, 8064])\n",
      "torch.Size([15, 1, 8064])\n",
      "torch.Size([2, 1, 8064])\n",
      "Epoch 160/300, Train Loss: 1.4563384056091309\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.25      0.14      0.18         7\n",
      "           2       0.17      0.67      0.27         3\n",
      "           3       0.67      0.40      0.50        15\n",
      "\n",
      "    accuracy                           0.36        25\n",
      "   macro avg       0.36      0.40      0.32        25\n",
      "weighted avg       0.49      0.36      0.38        25\n",
      "\n",
      "[[1 4 2]\n",
      " [0 2 1]\n",
      " [3 6 6]]\n",
      "Validation Loss for P31 = 1.293076515197754\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_32/3812056636.py:43: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([18, 1, 8064])\n",
      "torch.Size([15, 1, 8064])\n",
      "torch.Size([18, 1, 8064])\n",
      "torch.Size([15, 1, 8064])\n",
      "torch.Size([2, 1, 8064])\n",
      "Epoch 161/300, Train Loss: 1.2623136043548584\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         7\n",
      "           2       0.18      0.67      0.29         3\n",
      "           3       0.55      0.40      0.46        15\n",
      "\n",
      "    accuracy                           0.32        25\n",
      "   macro avg       0.24      0.36      0.25        25\n",
      "weighted avg       0.35      0.32      0.31        25\n",
      "\n",
      "[[0 3 4]\n",
      " [0 2 1]\n",
      " [3 6 6]]\n",
      "Validation Loss for P31 = 1.2992074489593506\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_32/3812056636.py:43: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([18, 1, 8064])\n",
      "torch.Size([15, 1, 8064])\n",
      "torch.Size([18, 1, 8064])\n",
      "torch.Size([15, 1, 8064])\n",
      "torch.Size([2, 1, 8064])\n",
      "Epoch 162/300, Train Loss: 1.3914463520050049\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         7\n",
      "           2       0.18      0.67      0.29         3\n",
      "           3       0.55      0.40      0.46        15\n",
      "\n",
      "    accuracy                           0.32        25\n",
      "   macro avg       0.24      0.36      0.25        25\n",
      "weighted avg       0.35      0.32      0.31        25\n",
      "\n",
      "[[0 3 4]\n",
      " [0 2 1]\n",
      " [3 6 6]]\n",
      "Validation Loss for P31 = 1.2985228300094604\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_32/3812056636.py:43: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([18, 1, 8064])\n",
      "torch.Size([15, 1, 8064])\n",
      "torch.Size([18, 1, 8064])\n",
      "torch.Size([15, 1, 8064])\n",
      "torch.Size([2, 1, 8064])\n",
      "Epoch 163/300, Train Loss: 1.5869848728179932\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.25      0.14      0.18         7\n",
      "           2       0.18      0.67      0.29         3\n",
      "           3       0.60      0.40      0.48        15\n",
      "\n",
      "    accuracy                           0.36        25\n",
      "   macro avg       0.34      0.40      0.32        25\n",
      "weighted avg       0.45      0.36      0.37        25\n",
      "\n",
      "[[1 3 3]\n",
      " [0 2 1]\n",
      " [3 6 6]]\n",
      "Validation Loss for P31 = 1.2899656295776367\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_32/3812056636.py:43: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([18, 1, 8064])\n",
      "torch.Size([15, 1, 8064])\n",
      "torch.Size([18, 1, 8064])\n",
      "torch.Size([15, 1, 8064])\n",
      "torch.Size([2, 1, 8064])\n",
      "Epoch 164/300, Train Loss: 1.4160555601119995\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.25      0.14      0.18         7\n",
      "           2       0.17      0.67      0.27         3\n",
      "           3       0.67      0.40      0.50        15\n",
      "\n",
      "    accuracy                           0.36        25\n",
      "   macro avg       0.36      0.40      0.32        25\n",
      "weighted avg       0.49      0.36      0.38        25\n",
      "\n",
      "[[1 4 2]\n",
      " [0 2 1]\n",
      " [3 6 6]]\n",
      "Validation Loss for P31 = 1.295397400856018\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_32/3812056636.py:43: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([18, 1, 8064])\n",
      "torch.Size([15, 1, 8064])\n",
      "torch.Size([18, 1, 8064])\n",
      "torch.Size([15, 1, 8064])\n",
      "torch.Size([2, 1, 8064])\n",
      "Epoch 165/300, Train Loss: 1.461719274520874\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         7\n",
      "           2       0.17      0.67      0.27         3\n",
      "           3       0.60      0.40      0.48        15\n",
      "\n",
      "    accuracy                           0.32        25\n",
      "   macro avg       0.26      0.36      0.25        25\n",
      "weighted avg       0.38      0.32      0.32        25\n",
      "\n",
      "[[0 4 3]\n",
      " [0 2 1]\n",
      " [3 6 6]]\n",
      "Validation Loss for P31 = 1.295365810394287\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_32/3812056636.py:43: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([18, 1, 8064])\n",
      "torch.Size([15, 1, 8064])\n",
      "torch.Size([18, 1, 8064])\n",
      "torch.Size([15, 1, 8064])\n",
      "torch.Size([2, 1, 8064])\n",
      "Epoch 166/300, Train Loss: 1.5564022064208984\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         7\n",
      "           2       0.15      0.67      0.25         3\n",
      "           3       0.67      0.40      0.50        15\n",
      "\n",
      "    accuracy                           0.32        25\n",
      "   macro avg       0.27      0.36      0.25        25\n",
      "weighted avg       0.42      0.32      0.33        25\n",
      "\n",
      "[[0 5 2]\n",
      " [0 2 1]\n",
      " [3 6 6]]\n",
      "Validation Loss for P31 = 1.3071047067642212\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_32/3812056636.py:43: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([18, 1, 8064])\n",
      "torch.Size([15, 1, 8064])\n",
      "torch.Size([18, 1, 8064])\n",
      "torch.Size([15, 1, 8064])\n",
      "torch.Size([2, 1, 8064])\n",
      "Epoch 167/300, Train Loss: 0.9593974351882935\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.25      0.14      0.18         7\n",
      "           2       0.17      0.67      0.27         3\n",
      "           3       0.67      0.40      0.50        15\n",
      "\n",
      "    accuracy                           0.36        25\n",
      "   macro avg       0.36      0.40      0.32        25\n",
      "weighted avg       0.49      0.36      0.38        25\n",
      "\n",
      "[[1 4 2]\n",
      " [0 2 1]\n",
      " [3 6 6]]\n",
      "Validation Loss for P31 = 1.2999873161315918\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_32/3812056636.py:43: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([18, 1, 8064])\n",
      "torch.Size([15, 1, 8064])\n",
      "torch.Size([18, 1, 8064])\n",
      "torch.Size([15, 1, 8064])\n",
      "torch.Size([2, 1, 8064])\n",
      "Epoch 168/300, Train Loss: 1.1975934505462646\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.25      0.14      0.18         7\n",
      "           2       0.17      0.67      0.27         3\n",
      "           3       0.67      0.40      0.50        15\n",
      "\n",
      "    accuracy                           0.36        25\n",
      "   macro avg       0.36      0.40      0.32        25\n",
      "weighted avg       0.49      0.36      0.38        25\n",
      "\n",
      "[[1 4 2]\n",
      " [0 2 1]\n",
      " [3 6 6]]\n",
      "Validation Loss for P31 = 1.2994333505630493\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_32/3812056636.py:43: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([18, 1, 8064])\n",
      "torch.Size([15, 1, 8064])\n",
      "torch.Size([18, 1, 8064])\n",
      "torch.Size([15, 1, 8064])\n",
      "torch.Size([2, 1, 8064])\n",
      "Epoch 169/300, Train Loss: 1.3435173034667969\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.25      0.14      0.18         7\n",
      "           2       0.17      0.67      0.27         3\n",
      "           3       0.67      0.40      0.50        15\n",
      "\n",
      "    accuracy                           0.36        25\n",
      "   macro avg       0.36      0.40      0.32        25\n",
      "weighted avg       0.49      0.36      0.38        25\n",
      "\n",
      "[[1 4 2]\n",
      " [0 2 1]\n",
      " [3 6 6]]\n",
      "Validation Loss for P31 = 1.3033157587051392\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_32/3812056636.py:43: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([18, 1, 8064])\n",
      "torch.Size([15, 1, 8064])\n",
      "torch.Size([18, 1, 8064])\n",
      "torch.Size([15, 1, 8064])\n",
      "torch.Size([2, 1, 8064])\n",
      "Epoch 170/300, Train Loss: 1.4812636375427246\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.25      0.14      0.18         7\n",
      "           2       0.17      0.67      0.27         3\n",
      "           3       0.67      0.40      0.50        15\n",
      "\n",
      "    accuracy                           0.36        25\n",
      "   macro avg       0.36      0.40      0.32        25\n",
      "weighted avg       0.49      0.36      0.38        25\n",
      "\n",
      "[[1 4 2]\n",
      " [0 2 1]\n",
      " [3 6 6]]\n",
      "Validation Loss for P31 = 1.300148367881775\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_32/3812056636.py:43: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([18, 1, 8064])\n",
      "torch.Size([15, 1, 8064])\n",
      "torch.Size([18, 1, 8064])\n",
      "torch.Size([15, 1, 8064])\n",
      "torch.Size([2, 1, 8064])\n",
      "Epoch 171/300, Train Loss: 0.9724048972129822\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.33      0.14      0.20         7\n",
      "           2       0.15      0.67      0.25         3\n",
      "           3       0.67      0.40      0.50        15\n",
      "\n",
      "    accuracy                           0.36        25\n",
      "   macro avg       0.38      0.40      0.32        25\n",
      "weighted avg       0.51      0.36      0.39        25\n",
      "\n",
      "[[1 4 2]\n",
      " [0 2 1]\n",
      " [2 7 6]]\n",
      "Validation Loss for P31 = 1.2999372482299805\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_32/3812056636.py:43: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([18, 1, 8064])\n",
      "torch.Size([15, 1, 8064])\n",
      "torch.Size([18, 1, 8064])\n",
      "torch.Size([15, 1, 8064])\n",
      "torch.Size([2, 1, 8064])\n",
      "Epoch 172/300, Train Loss: 1.6076966524124146\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.33      0.14      0.20         7\n",
      "           2       0.15      0.67      0.25         3\n",
      "           3       0.67      0.40      0.50        15\n",
      "\n",
      "    accuracy                           0.36        25\n",
      "   macro avg       0.38      0.40      0.32        25\n",
      "weighted avg       0.51      0.36      0.39        25\n",
      "\n",
      "[[1 4 2]\n",
      " [0 2 1]\n",
      " [2 7 6]]\n",
      "Validation Loss for P31 = 1.2994346618652344\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_32/3812056636.py:43: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([18, 1, 8064])\n",
      "torch.Size([15, 1, 8064])\n",
      "torch.Size([18, 1, 8064])\n",
      "torch.Size([15, 1, 8064])\n",
      "torch.Size([2, 1, 8064])\n",
      "Epoch 173/300, Train Loss: 1.494552731513977\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.33      0.14      0.20         7\n",
      "           2       0.17      0.67      0.27         3\n",
      "           3       0.70      0.47      0.56        15\n",
      "\n",
      "    accuracy                           0.40        25\n",
      "   macro avg       0.40      0.43      0.34        25\n",
      "weighted avg       0.53      0.40      0.42        25\n",
      "\n",
      "[[1 4 2]\n",
      " [0 2 1]\n",
      " [2 6 7]]\n",
      "Validation Loss for P31 = 1.2902002334594727\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_32/3812056636.py:43: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([18, 1, 8064])\n",
      "torch.Size([15, 1, 8064])\n",
      "torch.Size([18, 1, 8064])\n",
      "torch.Size([15, 1, 8064])\n",
      "torch.Size([2, 1, 8064])\n",
      "Epoch 174/300, Train Loss: 1.38827645778656\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.33      0.14      0.20         7\n",
      "           2       0.17      0.67      0.27         3\n",
      "           3       0.60      0.40      0.48        15\n",
      "\n",
      "    accuracy                           0.36        25\n",
      "   macro avg       0.37      0.40      0.32        25\n",
      "weighted avg       0.47      0.36      0.38        25\n",
      "\n",
      "[[1 3 3]\n",
      " [0 2 1]\n",
      " [2 7 6]]\n",
      "Validation Loss for P31 = 1.2984024286270142\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_32/3812056636.py:43: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([18, 1, 8064])\n",
      "torch.Size([15, 1, 8064])\n",
      "torch.Size([18, 1, 8064])\n",
      "torch.Size([15, 1, 8064])\n",
      "torch.Size([2, 1, 8064])\n",
      "Epoch 175/300, Train Loss: 1.562694787979126\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.33      0.14      0.20         7\n",
      "           2       0.15      0.67      0.25         3\n",
      "           3       0.67      0.40      0.50        15\n",
      "\n",
      "    accuracy                           0.36        25\n",
      "   macro avg       0.38      0.40      0.32        25\n",
      "weighted avg       0.51      0.36      0.39        25\n",
      "\n",
      "[[1 4 2]\n",
      " [0 2 1]\n",
      " [2 7 6]]\n",
      "Validation Loss for P31 = 1.2874386310577393\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_32/3812056636.py:43: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([18, 1, 8064])\n",
      "torch.Size([15, 1, 8064])\n",
      "torch.Size([18, 1, 8064])\n",
      "torch.Size([15, 1, 8064])\n",
      "torch.Size([2, 1, 8064])\n",
      "Epoch 176/300, Train Loss: 1.1625864505767822\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.33      0.14      0.20         7\n",
      "           2       0.17      0.67      0.27         3\n",
      "           3       0.60      0.40      0.48        15\n",
      "\n",
      "    accuracy                           0.36        25\n",
      "   macro avg       0.37      0.40      0.32        25\n",
      "weighted avg       0.47      0.36      0.38        25\n",
      "\n",
      "[[1 3 3]\n",
      " [0 2 1]\n",
      " [2 7 6]]\n",
      "Validation Loss for P31 = 1.292279839515686\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_32/3812056636.py:43: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([18, 1, 8064])\n",
      "torch.Size([15, 1, 8064])\n",
      "torch.Size([18, 1, 8064])\n",
      "torch.Size([15, 1, 8064])\n",
      "torch.Size([2, 1, 8064])\n",
      "Epoch 177/300, Train Loss: 1.5626730918884277\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.33      0.14      0.20         7\n",
      "           2       0.15      0.67      0.25         3\n",
      "           3       0.67      0.40      0.50        15\n",
      "\n",
      "    accuracy                           0.36        25\n",
      "   macro avg       0.38      0.40      0.32        25\n",
      "weighted avg       0.51      0.36      0.39        25\n",
      "\n",
      "[[1 4 2]\n",
      " [0 2 1]\n",
      " [2 7 6]]\n",
      "Validation Loss for P31 = 1.298357367515564\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_32/3812056636.py:43: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([18, 1, 8064])\n",
      "torch.Size([15, 1, 8064])\n",
      "torch.Size([18, 1, 8064])\n",
      "torch.Size([15, 1, 8064])\n",
      "torch.Size([2, 1, 8064])\n",
      "Epoch 178/300, Train Loss: 1.3064308166503906\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.33      0.14      0.20         7\n",
      "           2       0.17      0.67      0.27         3\n",
      "           3       0.60      0.40      0.48        15\n",
      "\n",
      "    accuracy                           0.36        25\n",
      "   macro avg       0.37      0.40      0.32        25\n",
      "weighted avg       0.47      0.36      0.38        25\n",
      "\n",
      "[[1 3 3]\n",
      " [0 2 1]\n",
      " [2 7 6]]\n",
      "Validation Loss for P31 = 1.2937813997268677\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_32/3812056636.py:43: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([18, 1, 8064])\n",
      "torch.Size([15, 1, 8064])\n",
      "torch.Size([18, 1, 8064])\n",
      "torch.Size([15, 1, 8064])\n",
      "torch.Size([2, 1, 8064])\n",
      "Epoch 179/300, Train Loss: 1.6369390487670898\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         7\n",
      "           2       0.14      0.67      0.24         3\n",
      "           3       0.75      0.40      0.52        15\n",
      "\n",
      "    accuracy                           0.32        25\n",
      "   macro avg       0.30      0.36      0.25        25\n",
      "weighted avg       0.47      0.32      0.34        25\n",
      "\n",
      "[[0 6 1]\n",
      " [0 2 1]\n",
      " [3 6 6]]\n",
      "Validation Loss for P31 = 1.3017218112945557\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_32/3812056636.py:43: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([18, 1, 8064])\n",
      "torch.Size([15, 1, 8064])\n",
      "torch.Size([18, 1, 8064])\n",
      "torch.Size([15, 1, 8064])\n",
      "torch.Size([2, 1, 8064])\n",
      "Epoch 180/300, Train Loss: 1.2050797939300537\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         7\n",
      "           2       0.15      0.67      0.25         3\n",
      "           3       0.67      0.40      0.50        15\n",
      "\n",
      "    accuracy                           0.32        25\n",
      "   macro avg       0.27      0.36      0.25        25\n",
      "weighted avg       0.42      0.32      0.33        25\n",
      "\n",
      "[[0 5 2]\n",
      " [0 2 1]\n",
      " [3 6 6]]\n",
      "Validation Loss for P31 = 1.3133659362792969\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_32/3812056636.py:43: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([18, 1, 8064])\n",
      "torch.Size([15, 1, 8064])\n",
      "torch.Size([18, 1, 8064])\n",
      "torch.Size([15, 1, 8064])\n",
      "torch.Size([2, 1, 8064])\n",
      "Epoch 181/300, Train Loss: 1.2348380088806152\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         7\n",
      "           2       0.14      0.67      0.24         3\n",
      "           3       0.75      0.40      0.52        15\n",
      "\n",
      "    accuracy                           0.32        25\n",
      "   macro avg       0.30      0.36      0.25        25\n",
      "weighted avg       0.47      0.32      0.34        25\n",
      "\n",
      "[[0 6 1]\n",
      " [0 2 1]\n",
      " [3 6 6]]\n",
      "Validation Loss for P31 = 1.3050180673599243\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_32/3812056636.py:43: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([18, 1, 8064])\n",
      "torch.Size([15, 1, 8064])\n",
      "torch.Size([18, 1, 8064])\n",
      "torch.Size([15, 1, 8064])\n",
      "torch.Size([2, 1, 8064])\n",
      "Epoch 182/300, Train Loss: 1.6516458988189697\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         7\n",
      "           2       0.14      0.67      0.24         3\n",
      "           3       0.75      0.40      0.52        15\n",
      "\n",
      "    accuracy                           0.32        25\n",
      "   macro avg       0.30      0.36      0.25        25\n",
      "weighted avg       0.47      0.32      0.34        25\n",
      "\n",
      "[[0 6 1]\n",
      " [0 2 1]\n",
      " [3 6 6]]\n",
      "Validation Loss for P31 = 1.3082141876220703\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_32/3812056636.py:43: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([18, 1, 8064])\n",
      "torch.Size([15, 1, 8064])\n",
      "torch.Size([18, 1, 8064])\n",
      "torch.Size([15, 1, 8064])\n",
      "torch.Size([2, 1, 8064])\n",
      "Epoch 183/300, Train Loss: 1.2028669118881226\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         7\n",
      "           2       0.15      0.67      0.25         3\n",
      "           3       0.67      0.40      0.50        15\n",
      "\n",
      "    accuracy                           0.32        25\n",
      "   macro avg       0.27      0.36      0.25        25\n",
      "weighted avg       0.42      0.32      0.33        25\n",
      "\n",
      "[[0 5 2]\n",
      " [0 2 1]\n",
      " [3 6 6]]\n",
      "Validation Loss for P31 = 1.3040220737457275\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_32/3812056636.py:43: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([18, 1, 8064])\n",
      "torch.Size([15, 1, 8064])\n",
      "torch.Size([18, 1, 8064])\n",
      "torch.Size([15, 1, 8064])\n",
      "torch.Size([2, 1, 8064])\n",
      "Epoch 184/300, Train Loss: 1.459580898284912\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         7\n",
      "           2       0.15      0.67      0.25         3\n",
      "           3       0.67      0.40      0.50        15\n",
      "\n",
      "    accuracy                           0.32        25\n",
      "   macro avg       0.27      0.36      0.25        25\n",
      "weighted avg       0.42      0.32      0.33        25\n",
      "\n",
      "[[0 5 2]\n",
      " [0 2 1]\n",
      " [3 6 6]]\n",
      "Validation Loss for P31 = 1.2945390939712524\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_32/3812056636.py:43: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([18, 1, 8064])\n",
      "torch.Size([15, 1, 8064])\n",
      "torch.Size([18, 1, 8064])\n",
      "torch.Size([15, 1, 8064])\n",
      "torch.Size([2, 1, 8064])\n",
      "Epoch 185/300, Train Loss: 1.486255168914795\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         7\n",
      "           2       0.15      0.67      0.25         3\n",
      "           3       0.70      0.47      0.56        15\n",
      "\n",
      "    accuracy                           0.36        25\n",
      "   macro avg       0.28      0.38      0.27        25\n",
      "weighted avg       0.44      0.36      0.37        25\n",
      "\n",
      "[[0 5 2]\n",
      " [0 2 1]\n",
      " [2 6 7]]\n",
      "Validation Loss for P31 = 1.3014016151428223\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_32/3812056636.py:43: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([18, 1, 8064])\n",
      "torch.Size([15, 1, 8064])\n",
      "torch.Size([18, 1, 8064])\n",
      "torch.Size([15, 1, 8064])\n",
      "torch.Size([2, 1, 8064])\n",
      "Epoch 186/300, Train Loss: 1.3755974769592285\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         7\n",
      "           2       0.14      0.67      0.24         3\n",
      "           3       0.78      0.47      0.58        15\n",
      "\n",
      "    accuracy                           0.36        25\n",
      "   macro avg       0.31      0.38      0.27        25\n",
      "weighted avg       0.48      0.36      0.38        25\n",
      "\n",
      "[[0 6 1]\n",
      " [0 2 1]\n",
      " [2 6 7]]\n",
      "Validation Loss for P31 = 1.3006706237792969\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_32/3812056636.py:43: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([18, 1, 8064])\n",
      "torch.Size([15, 1, 8064])\n",
      "torch.Size([18, 1, 8064])\n",
      "torch.Size([15, 1, 8064])\n",
      "torch.Size([2, 1, 8064])\n",
      "Epoch 187/300, Train Loss: 1.2686978578567505\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         7\n",
      "           2       0.15      0.67      0.25         3\n",
      "           3       0.70      0.47      0.56        15\n",
      "\n",
      "    accuracy                           0.36        25\n",
      "   macro avg       0.28      0.38      0.27        25\n",
      "weighted avg       0.44      0.36      0.37        25\n",
      "\n",
      "[[0 5 2]\n",
      " [0 2 1]\n",
      " [2 6 7]]\n",
      "Validation Loss for P31 = 1.2917028665542603\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_32/3812056636.py:43: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([18, 1, 8064])\n",
      "torch.Size([15, 1, 8064])\n",
      "torch.Size([18, 1, 8064])\n",
      "torch.Size([15, 1, 8064])\n",
      "torch.Size([2, 1, 8064])\n",
      "Epoch 188/300, Train Loss: 1.6613529920578003\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         7\n",
      "           2       0.15      0.67      0.25         3\n",
      "           3       0.70      0.47      0.56        15\n",
      "\n",
      "    accuracy                           0.36        25\n",
      "   macro avg       0.28      0.38      0.27        25\n",
      "weighted avg       0.44      0.36      0.37        25\n",
      "\n",
      "[[0 5 2]\n",
      " [0 2 1]\n",
      " [2 6 7]]\n",
      "Validation Loss for P31 = 1.301565170288086\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_32/3812056636.py:43: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([18, 1, 8064])\n",
      "torch.Size([15, 1, 8064])\n",
      "torch.Size([18, 1, 8064])\n",
      "torch.Size([15, 1, 8064])\n",
      "torch.Size([2, 1, 8064])\n",
      "Epoch 189/300, Train Loss: 1.395964503288269\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         7\n",
      "           2       0.14      0.67      0.24         3\n",
      "           3       0.78      0.47      0.58        15\n",
      "\n",
      "    accuracy                           0.36        25\n",
      "   macro avg       0.31      0.38      0.27        25\n",
      "weighted avg       0.48      0.36      0.38        25\n",
      "\n",
      "[[0 6 1]\n",
      " [0 2 1]\n",
      " [2 6 7]]\n",
      "Validation Loss for P31 = 1.3042024374008179\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_32/3812056636.py:43: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([18, 1, 8064])\n",
      "torch.Size([15, 1, 8064])\n",
      "torch.Size([18, 1, 8064])\n",
      "torch.Size([15, 1, 8064])\n",
      "torch.Size([2, 1, 8064])\n",
      "Epoch 190/300, Train Loss: 1.3237791061401367\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         7\n",
      "           2       0.15      0.67      0.25         3\n",
      "           3       0.70      0.47      0.56        15\n",
      "\n",
      "    accuracy                           0.36        25\n",
      "   macro avg       0.28      0.38      0.27        25\n",
      "weighted avg       0.44      0.36      0.37        25\n",
      "\n",
      "[[0 5 2]\n",
      " [0 2 1]\n",
      " [2 6 7]]\n",
      "Validation Loss for P31 = 1.309670090675354\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_32/3812056636.py:43: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([18, 1, 8064])\n",
      "torch.Size([15, 1, 8064])\n",
      "torch.Size([18, 1, 8064])\n",
      "torch.Size([15, 1, 8064])\n",
      "torch.Size([2, 1, 8064])\n",
      "Epoch 191/300, Train Loss: 1.546682596206665\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         7\n",
      "           2       0.15      0.67      0.25         3\n",
      "           3       0.70      0.47      0.56        15\n",
      "\n",
      "    accuracy                           0.36        25\n",
      "   macro avg       0.28      0.38      0.27        25\n",
      "weighted avg       0.44      0.36      0.37        25\n",
      "\n",
      "[[0 5 2]\n",
      " [0 2 1]\n",
      " [2 6 7]]\n",
      "Validation Loss for P31 = 1.3019624948501587\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_32/3812056636.py:43: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([18, 1, 8064])\n",
      "torch.Size([15, 1, 8064])\n",
      "torch.Size([18, 1, 8064])\n",
      "torch.Size([15, 1, 8064])\n",
      "torch.Size([2, 1, 8064])\n",
      "Epoch 192/300, Train Loss: 1.3328053951263428\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         7\n",
      "           2       0.15      0.67      0.25         3\n",
      "           3       0.70      0.47      0.56        15\n",
      "\n",
      "    accuracy                           0.36        25\n",
      "   macro avg       0.28      0.38      0.27        25\n",
      "weighted avg       0.44      0.36      0.37        25\n",
      "\n",
      "[[0 5 2]\n",
      " [0 2 1]\n",
      " [2 6 7]]\n",
      "Validation Loss for P31 = 1.2944530248641968\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_32/3812056636.py:43: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([18, 1, 8064])\n",
      "torch.Size([15, 1, 8064])\n",
      "torch.Size([18, 1, 8064])\n",
      "torch.Size([15, 1, 8064])\n",
      "torch.Size([2, 1, 8064])\n",
      "Epoch 193/300, Train Loss: 1.4524035453796387\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         7\n",
      "           2       0.15      0.67      0.25         3\n",
      "           3       0.70      0.47      0.56        15\n",
      "\n",
      "    accuracy                           0.36        25\n",
      "   macro avg       0.28      0.38      0.27        25\n",
      "weighted avg       0.44      0.36      0.37        25\n",
      "\n",
      "[[0 5 2]\n",
      " [0 2 1]\n",
      " [2 6 7]]\n",
      "Validation Loss for P31 = 1.2974493503570557\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_32/3812056636.py:43: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([18, 1, 8064])\n",
      "torch.Size([15, 1, 8064])\n",
      "torch.Size([18, 1, 8064])\n",
      "torch.Size([15, 1, 8064])\n",
      "torch.Size([2, 1, 8064])\n",
      "Epoch 194/300, Train Loss: 1.6889859437942505\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         7\n",
      "           2       0.15      0.67      0.25         3\n",
      "           3       0.70      0.47      0.56        15\n",
      "\n",
      "    accuracy                           0.36        25\n",
      "   macro avg       0.28      0.38      0.27        25\n",
      "weighted avg       0.44      0.36      0.37        25\n",
      "\n",
      "[[0 5 2]\n",
      " [0 2 1]\n",
      " [2 6 7]]\n",
      "Validation Loss for P31 = 1.2955049276351929\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_32/3812056636.py:43: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([18, 1, 8064])\n",
      "torch.Size([15, 1, 8064])\n",
      "torch.Size([18, 1, 8064])\n",
      "torch.Size([15, 1, 8064])\n",
      "torch.Size([2, 1, 8064])\n",
      "Epoch 195/300, Train Loss: 1.4758734703063965\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         7\n",
      "           2       0.17      0.67      0.27         3\n",
      "           3       0.64      0.47      0.54        15\n",
      "\n",
      "    accuracy                           0.36        25\n",
      "   macro avg       0.27      0.38      0.27        25\n",
      "weighted avg       0.40      0.36      0.36        25\n",
      "\n",
      "[[0 4 3]\n",
      " [0 2 1]\n",
      " [2 6 7]]\n",
      "Validation Loss for P31 = 1.2975653409957886\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_32/3812056636.py:43: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([18, 1, 8064])\n",
      "torch.Size([15, 1, 8064])\n",
      "torch.Size([18, 1, 8064])\n",
      "torch.Size([15, 1, 8064])\n",
      "torch.Size([2, 1, 8064])\n",
      "Epoch 196/300, Train Loss: 1.4966918230056763\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         7\n",
      "           2       0.15      0.67      0.25         3\n",
      "           3       0.70      0.47      0.56        15\n",
      "\n",
      "    accuracy                           0.36        25\n",
      "   macro avg       0.28      0.38      0.27        25\n",
      "weighted avg       0.44      0.36      0.37        25\n",
      "\n",
      "[[0 5 2]\n",
      " [0 2 1]\n",
      " [2 6 7]]\n",
      "Validation Loss for P31 = 1.3095908164978027\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_32/3812056636.py:43: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([18, 1, 8064])\n",
      "torch.Size([15, 1, 8064])\n",
      "torch.Size([18, 1, 8064])\n",
      "torch.Size([15, 1, 8064])\n",
      "torch.Size([2, 1, 8064])\n",
      "Epoch 197/300, Train Loss: 1.6571063995361328\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         7\n",
      "           2       0.15      0.67      0.25         3\n",
      "           3       0.70      0.47      0.56        15\n",
      "\n",
      "    accuracy                           0.36        25\n",
      "   macro avg       0.28      0.38      0.27        25\n",
      "weighted avg       0.44      0.36      0.37        25\n",
      "\n",
      "[[0 5 2]\n",
      " [0 2 1]\n",
      " [2 6 7]]\n",
      "Validation Loss for P31 = 1.3046369552612305\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_32/3812056636.py:43: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([18, 1, 8064])\n",
      "torch.Size([15, 1, 8064])\n",
      "torch.Size([18, 1, 8064])\n",
      "torch.Size([15, 1, 8064])\n",
      "torch.Size([2, 1, 8064])\n",
      "Epoch 198/300, Train Loss: 1.5965399742126465\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         7\n",
      "           2       0.15      0.67      0.25         3\n",
      "           3       0.67      0.40      0.50        15\n",
      "\n",
      "    accuracy                           0.32        25\n",
      "   macro avg       0.27      0.36      0.25        25\n",
      "weighted avg       0.42      0.32      0.33        25\n",
      "\n",
      "[[0 5 2]\n",
      " [0 2 1]\n",
      " [3 6 6]]\n",
      "Validation Loss for P31 = 1.3001317977905273\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_32/3812056636.py:43: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([18, 1, 8064])\n",
      "torch.Size([15, 1, 8064])\n",
      "torch.Size([18, 1, 8064])\n",
      "torch.Size([15, 1, 8064])\n",
      "torch.Size([2, 1, 8064])\n",
      "Epoch 199/300, Train Loss: 1.3543332815170288\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         7\n",
      "           2       0.15      0.67      0.25         3\n",
      "           3       0.70      0.47      0.56        15\n",
      "\n",
      "    accuracy                           0.36        25\n",
      "   macro avg       0.28      0.38      0.27        25\n",
      "weighted avg       0.44      0.36      0.37        25\n",
      "\n",
      "[[0 5 2]\n",
      " [0 2 1]\n",
      " [2 6 7]]\n",
      "Validation Loss for P31 = 1.2969335317611694\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_32/3812056636.py:43: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([18, 1, 8064])\n",
      "torch.Size([15, 1, 8064])\n",
      "torch.Size([18, 1, 8064])\n",
      "torch.Size([15, 1, 8064])\n",
      "torch.Size([2, 1, 8064])\n",
      "Epoch 200/300, Train Loss: 1.3104021549224854\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         7\n",
      "           2       0.17      0.67      0.27         3\n",
      "           3       0.64      0.47      0.54        15\n",
      "\n",
      "    accuracy                           0.36        25\n",
      "   macro avg       0.27      0.38      0.27        25\n",
      "weighted avg       0.40      0.36      0.36        25\n",
      "\n",
      "[[0 4 3]\n",
      " [0 2 1]\n",
      " [2 6 7]]\n",
      "Validation Loss for P31 = 1.3094744682312012\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_32/3812056636.py:43: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([18, 1, 8064])\n",
      "torch.Size([15, 1, 8064])\n",
      "torch.Size([18, 1, 8064])\n",
      "torch.Size([15, 1, 8064])\n",
      "torch.Size([2, 1, 8064])\n",
      "Epoch 201/300, Train Loss: 1.5153303146362305\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         7\n",
      "           2       0.18      0.67      0.29         3\n",
      "           3       0.58      0.47      0.52        15\n",
      "\n",
      "    accuracy                           0.36        25\n",
      "   macro avg       0.26      0.38      0.27        25\n",
      "weighted avg       0.37      0.36      0.35        25\n",
      "\n",
      "[[0 3 4]\n",
      " [0 2 1]\n",
      " [2 6 7]]\n",
      "Validation Loss for P31 = 1.2987991571426392\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_32/3812056636.py:43: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([18, 1, 8064])\n",
      "torch.Size([15, 1, 8064])\n",
      "torch.Size([18, 1, 8064])\n",
      "torch.Size([15, 1, 8064])\n",
      "torch.Size([2, 1, 8064])\n",
      "Epoch 202/300, Train Loss: 1.2552822828292847\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         7\n",
      "           2       0.15      0.67      0.25         3\n",
      "           3       0.67      0.40      0.50        15\n",
      "\n",
      "    accuracy                           0.32        25\n",
      "   macro avg       0.27      0.36      0.25        25\n",
      "weighted avg       0.42      0.32      0.33        25\n",
      "\n",
      "[[0 5 2]\n",
      " [0 2 1]\n",
      " [3 6 6]]\n",
      "Validation Loss for P31 = 1.3126708269119263\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_32/3812056636.py:43: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([18, 1, 8064])\n",
      "torch.Size([15, 1, 8064])\n",
      "torch.Size([18, 1, 8064])\n",
      "torch.Size([15, 1, 8064])\n",
      "torch.Size([2, 1, 8064])\n",
      "Epoch 203/300, Train Loss: 1.2849853038787842\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         7\n",
      "           2       0.15      0.67      0.25         3\n",
      "           3       0.67      0.40      0.50        15\n",
      "\n",
      "    accuracy                           0.32        25\n",
      "   macro avg       0.27      0.36      0.25        25\n",
      "weighted avg       0.42      0.32      0.33        25\n",
      "\n",
      "[[0 5 2]\n",
      " [0 2 1]\n",
      " [3 6 6]]\n",
      "Validation Loss for P31 = 1.3084770441055298\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_32/3812056636.py:43: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([18, 1, 8064])\n",
      "torch.Size([15, 1, 8064])\n",
      "torch.Size([18, 1, 8064])\n",
      "torch.Size([15, 1, 8064])\n",
      "torch.Size([2, 1, 8064])\n",
      "Epoch 204/300, Train Loss: 1.339979887008667\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         7\n",
      "           2       0.17      0.67      0.27         3\n",
      "           3       0.60      0.40      0.48        15\n",
      "\n",
      "    accuracy                           0.32        25\n",
      "   macro avg       0.26      0.36      0.25        25\n",
      "weighted avg       0.38      0.32      0.32        25\n",
      "\n",
      "[[0 4 3]\n",
      " [0 2 1]\n",
      " [3 6 6]]\n",
      "Validation Loss for P31 = 1.3063760995864868\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_32/3812056636.py:43: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([18, 1, 8064])\n",
      "torch.Size([15, 1, 8064])\n",
      "torch.Size([18, 1, 8064])\n",
      "torch.Size([15, 1, 8064])\n",
      "torch.Size([2, 1, 8064])\n",
      "Epoch 205/300, Train Loss: 1.4098875522613525\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         7\n",
      "           2       0.15      0.67      0.25         3\n",
      "           3       0.67      0.40      0.50        15\n",
      "\n",
      "    accuracy                           0.32        25\n",
      "   macro avg       0.27      0.36      0.25        25\n",
      "weighted avg       0.42      0.32      0.33        25\n",
      "\n",
      "[[0 5 2]\n",
      " [0 2 1]\n",
      " [3 6 6]]\n",
      "Validation Loss for P31 = 1.3038755655288696\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_32/3812056636.py:43: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([18, 1, 8064])\n",
      "torch.Size([15, 1, 8064])\n",
      "torch.Size([18, 1, 8064])\n",
      "torch.Size([15, 1, 8064])\n",
      "torch.Size([2, 1, 8064])\n",
      "Epoch 206/300, Train Loss: 1.3736960887908936\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         7\n",
      "           2       0.15      0.67      0.25         3\n",
      "           3       0.70      0.47      0.56        15\n",
      "\n",
      "    accuracy                           0.36        25\n",
      "   macro avg       0.28      0.38      0.27        25\n",
      "weighted avg       0.44      0.36      0.37        25\n",
      "\n",
      "[[0 5 2]\n",
      " [0 2 1]\n",
      " [2 6 7]]\n",
      "Validation Loss for P31 = 1.2965762615203857\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_32/3812056636.py:43: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([18, 1, 8064])\n",
      "torch.Size([15, 1, 8064])\n",
      "torch.Size([18, 1, 8064])\n",
      "torch.Size([15, 1, 8064])\n",
      "torch.Size([2, 1, 8064])\n",
      "Epoch 207/300, Train Loss: 1.2933027744293213\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.33      0.14      0.20         7\n",
      "           2       0.17      0.67      0.27         3\n",
      "           3       0.70      0.47      0.56        15\n",
      "\n",
      "    accuracy                           0.40        25\n",
      "   macro avg       0.40      0.43      0.34        25\n",
      "weighted avg       0.53      0.40      0.42        25\n",
      "\n",
      "[[1 4 2]\n",
      " [0 2 1]\n",
      " [2 6 7]]\n",
      "Validation Loss for P31 = 1.2996740341186523\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_32/3812056636.py:43: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([18, 1, 8064])\n",
      "torch.Size([15, 1, 8064])\n",
      "torch.Size([18, 1, 8064])\n",
      "torch.Size([15, 1, 8064])\n",
      "torch.Size([2, 1, 8064])\n",
      "Epoch 208/300, Train Loss: 1.8054938316345215\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.33      0.14      0.20         7\n",
      "           2       0.17      0.67      0.27         3\n",
      "           3       0.70      0.47      0.56        15\n",
      "\n",
      "    accuracy                           0.40        25\n",
      "   macro avg       0.40      0.43      0.34        25\n",
      "weighted avg       0.53      0.40      0.42        25\n",
      "\n",
      "[[1 4 2]\n",
      " [0 2 1]\n",
      " [2 6 7]]\n",
      "Validation Loss for P31 = 1.3009953498840332\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_32/3812056636.py:43: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([18, 1, 8064])\n",
      "torch.Size([15, 1, 8064])\n",
      "torch.Size([18, 1, 8064])\n",
      "torch.Size([15, 1, 8064])\n",
      "torch.Size([2, 1, 8064])\n",
      "Epoch 209/300, Train Loss: 1.1485536098480225\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.33      0.14      0.20         7\n",
      "           2       0.17      0.67      0.27         3\n",
      "           3       0.70      0.47      0.56        15\n",
      "\n",
      "    accuracy                           0.40        25\n",
      "   macro avg       0.40      0.43      0.34        25\n",
      "weighted avg       0.53      0.40      0.42        25\n",
      "\n",
      "[[1 4 2]\n",
      " [0 2 1]\n",
      " [2 6 7]]\n",
      "Validation Loss for P31 = 1.2933933734893799\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_32/3812056636.py:43: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([18, 1, 8064])\n",
      "torch.Size([15, 1, 8064])\n",
      "torch.Size([18, 1, 8064])\n",
      "torch.Size([15, 1, 8064])\n",
      "torch.Size([2, 1, 8064])\n",
      "Epoch 210/300, Train Loss: 1.5278311967849731\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.33      0.14      0.20         7\n",
      "           2       0.17      0.67      0.27         3\n",
      "           3       0.70      0.47      0.56        15\n",
      "\n",
      "    accuracy                           0.40        25\n",
      "   macro avg       0.40      0.43      0.34        25\n",
      "weighted avg       0.53      0.40      0.42        25\n",
      "\n",
      "[[1 4 2]\n",
      " [0 2 1]\n",
      " [2 6 7]]\n",
      "Validation Loss for P31 = 1.311720609664917\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_32/3812056636.py:43: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([18, 1, 8064])\n",
      "torch.Size([15, 1, 8064])\n",
      "torch.Size([18, 1, 8064])\n",
      "torch.Size([15, 1, 8064])\n",
      "torch.Size([2, 1, 8064])\n",
      "Epoch 211/300, Train Loss: 1.4848425388336182\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.33      0.14      0.20         7\n",
      "           2       0.17      0.67      0.27         3\n",
      "           3       0.70      0.47      0.56        15\n",
      "\n",
      "    accuracy                           0.40        25\n",
      "   macro avg       0.40      0.43      0.34        25\n",
      "weighted avg       0.53      0.40      0.42        25\n",
      "\n",
      "[[1 4 2]\n",
      " [0 2 1]\n",
      " [2 6 7]]\n",
      "Validation Loss for P31 = 1.297753095626831\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_32/3812056636.py:43: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([18, 1, 8064])\n",
      "torch.Size([15, 1, 8064])\n",
      "torch.Size([18, 1, 8064])\n",
      "torch.Size([15, 1, 8064])\n",
      "torch.Size([2, 1, 8064])\n",
      "Epoch 212/300, Train Loss: 1.61647367477417\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.25      0.14      0.18         7\n",
      "           2       0.17      0.67      0.27         3\n",
      "           3       0.67      0.40      0.50        15\n",
      "\n",
      "    accuracy                           0.36        25\n",
      "   macro avg       0.36      0.40      0.32        25\n",
      "weighted avg       0.49      0.36      0.38        25\n",
      "\n",
      "[[1 4 2]\n",
      " [0 2 1]\n",
      " [3 6 6]]\n",
      "Validation Loss for P31 = 1.309586524963379\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_32/3812056636.py:43: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([18, 1, 8064])\n",
      "torch.Size([15, 1, 8064])\n",
      "torch.Size([18, 1, 8064])\n",
      "torch.Size([15, 1, 8064])\n",
      "torch.Size([2, 1, 8064])\n",
      "Epoch 213/300, Train Loss: 1.4348292350769043\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         7\n",
      "           2       0.17      0.67      0.27         3\n",
      "           3       0.60      0.40      0.48        15\n",
      "\n",
      "    accuracy                           0.32        25\n",
      "   macro avg       0.26      0.36      0.25        25\n",
      "weighted avg       0.38      0.32      0.32        25\n",
      "\n",
      "[[0 4 3]\n",
      " [0 2 1]\n",
      " [3 6 6]]\n",
      "Validation Loss for P31 = 1.3059123754501343\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_32/3812056636.py:43: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([18, 1, 8064])\n",
      "torch.Size([15, 1, 8064])\n",
      "torch.Size([18, 1, 8064])\n",
      "torch.Size([15, 1, 8064])\n",
      "torch.Size([2, 1, 8064])\n",
      "Epoch 214/300, Train Loss: 1.2455825805664062\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         7\n",
      "           2       0.15      0.67      0.25         3\n",
      "           3       0.67      0.40      0.50        15\n",
      "\n",
      "    accuracy                           0.32        25\n",
      "   macro avg       0.27      0.36      0.25        25\n",
      "weighted avg       0.42      0.32      0.33        25\n",
      "\n",
      "[[0 5 2]\n",
      " [0 2 1]\n",
      " [3 6 6]]\n",
      "Validation Loss for P31 = 1.3121579885482788\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_32/3812056636.py:43: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([18, 1, 8064])\n",
      "torch.Size([15, 1, 8064])\n",
      "torch.Size([18, 1, 8064])\n",
      "torch.Size([15, 1, 8064])\n",
      "torch.Size([2, 1, 8064])\n",
      "Epoch 215/300, Train Loss: 1.3702070713043213\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         7\n",
      "           2       0.15      0.67      0.25         3\n",
      "           3       0.67      0.40      0.50        15\n",
      "\n",
      "    accuracy                           0.32        25\n",
      "   macro avg       0.27      0.36      0.25        25\n",
      "weighted avg       0.42      0.32      0.33        25\n",
      "\n",
      "[[0 5 2]\n",
      " [0 2 1]\n",
      " [3 6 6]]\n",
      "Validation Loss for P31 = 1.313437581062317\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_32/3812056636.py:43: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([18, 1, 8064])\n",
      "torch.Size([15, 1, 8064])\n",
      "torch.Size([18, 1, 8064])\n",
      "torch.Size([15, 1, 8064])\n",
      "torch.Size([2, 1, 8064])\n",
      "Epoch 216/300, Train Loss: 1.3150688409805298\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         7\n",
      "           2       0.17      0.67      0.27         3\n",
      "           3       0.60      0.40      0.48        15\n",
      "\n",
      "    accuracy                           0.32        25\n",
      "   macro avg       0.26      0.36      0.25        25\n",
      "weighted avg       0.38      0.32      0.32        25\n",
      "\n",
      "[[0 4 3]\n",
      " [0 2 1]\n",
      " [3 6 6]]\n",
      "Validation Loss for P31 = 1.2975025177001953\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_32/3812056636.py:43: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([18, 1, 8064])\n",
      "torch.Size([15, 1, 8064])\n",
      "torch.Size([18, 1, 8064])\n",
      "torch.Size([15, 1, 8064])\n",
      "torch.Size([2, 1, 8064])\n",
      "Epoch 217/300, Train Loss: 1.619088053703308\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.33      0.14      0.20         7\n",
      "           2       0.17      0.67      0.27         3\n",
      "           3       0.70      0.47      0.56        15\n",
      "\n",
      "    accuracy                           0.40        25\n",
      "   macro avg       0.40      0.43      0.34        25\n",
      "weighted avg       0.53      0.40      0.42        25\n",
      "\n",
      "[[1 4 2]\n",
      " [0 2 1]\n",
      " [2 6 7]]\n",
      "Validation Loss for P31 = 1.2946885824203491\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_32/3812056636.py:43: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([18, 1, 8064])\n",
      "torch.Size([15, 1, 8064])\n",
      "torch.Size([18, 1, 8064])\n",
      "torch.Size([15, 1, 8064])\n",
      "torch.Size([2, 1, 8064])\n",
      "Epoch 218/300, Train Loss: 1.4808158874511719\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.33      0.14      0.20         7\n",
      "           2       0.17      0.67      0.27         3\n",
      "           3       0.70      0.47      0.56        15\n",
      "\n",
      "    accuracy                           0.40        25\n",
      "   macro avg       0.40      0.43      0.34        25\n",
      "weighted avg       0.53      0.40      0.42        25\n",
      "\n",
      "[[1 4 2]\n",
      " [0 2 1]\n",
      " [2 6 7]]\n",
      "Validation Loss for P31 = 1.2949416637420654\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_32/3812056636.py:43: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([18, 1, 8064])\n",
      "torch.Size([15, 1, 8064])\n",
      "torch.Size([18, 1, 8064])\n",
      "torch.Size([15, 1, 8064])\n",
      "torch.Size([2, 1, 8064])\n",
      "Epoch 219/300, Train Loss: 1.3884738683700562\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         7\n",
      "           2       0.15      0.67      0.25         3\n",
      "           3       0.70      0.47      0.56        15\n",
      "\n",
      "    accuracy                           0.36        25\n",
      "   macro avg       0.28      0.38      0.27        25\n",
      "weighted avg       0.44      0.36      0.37        25\n",
      "\n",
      "[[0 5 2]\n",
      " [0 2 1]\n",
      " [2 6 7]]\n",
      "Validation Loss for P31 = 1.3024839162826538\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_32/3812056636.py:43: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([18, 1, 8064])\n",
      "torch.Size([15, 1, 8064])\n",
      "torch.Size([18, 1, 8064])\n",
      "torch.Size([15, 1, 8064])\n",
      "torch.Size([2, 1, 8064])\n",
      "Epoch 220/300, Train Loss: 1.4382216930389404\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         7\n",
      "           2       0.17      0.67      0.27         3\n",
      "           3       0.60      0.40      0.48        15\n",
      "\n",
      "    accuracy                           0.32        25\n",
      "   macro avg       0.26      0.36      0.25        25\n",
      "weighted avg       0.38      0.32      0.32        25\n",
      "\n",
      "[[0 4 3]\n",
      " [0 2 1]\n",
      " [3 6 6]]\n",
      "Validation Loss for P31 = 1.309676170349121\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_32/3812056636.py:43: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([18, 1, 8064])\n",
      "torch.Size([15, 1, 8064])\n",
      "torch.Size([18, 1, 8064])\n",
      "torch.Size([15, 1, 8064])\n",
      "torch.Size([2, 1, 8064])\n",
      "Epoch 221/300, Train Loss: 1.4652204513549805\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.25      0.14      0.18         7\n",
      "           2       0.17      0.67      0.27         3\n",
      "           3       0.67      0.40      0.50        15\n",
      "\n",
      "    accuracy                           0.36        25\n",
      "   macro avg       0.36      0.40      0.32        25\n",
      "weighted avg       0.49      0.36      0.38        25\n",
      "\n",
      "[[1 4 2]\n",
      " [0 2 1]\n",
      " [3 6 6]]\n",
      "Validation Loss for P31 = 1.2976731061935425\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_32/3812056636.py:43: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([18, 1, 8064])\n",
      "torch.Size([15, 1, 8064])\n",
      "torch.Size([18, 1, 8064])\n",
      "torch.Size([15, 1, 8064])\n",
      "torch.Size([2, 1, 8064])\n",
      "Epoch 222/300, Train Loss: 1.4202452898025513\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.33      0.14      0.20         7\n",
      "           2       0.17      0.67      0.27         3\n",
      "           3       0.70      0.47      0.56        15\n",
      "\n",
      "    accuracy                           0.40        25\n",
      "   macro avg       0.40      0.43      0.34        25\n",
      "weighted avg       0.53      0.40      0.42        25\n",
      "\n",
      "[[1 4 2]\n",
      " [0 2 1]\n",
      " [2 6 7]]\n",
      "Validation Loss for P31 = 1.29837167263031\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_32/3812056636.py:43: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([18, 1, 8064])\n",
      "torch.Size([15, 1, 8064])\n",
      "torch.Size([18, 1, 8064])\n",
      "torch.Size([15, 1, 8064])\n",
      "torch.Size([2, 1, 8064])\n",
      "Epoch 223/300, Train Loss: 1.460073471069336\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.33      0.14      0.20         7\n",
      "           2       0.17      0.67      0.27         3\n",
      "           3       0.70      0.47      0.56        15\n",
      "\n",
      "    accuracy                           0.40        25\n",
      "   macro avg       0.40      0.43      0.34        25\n",
      "weighted avg       0.53      0.40      0.42        25\n",
      "\n",
      "[[1 4 2]\n",
      " [0 2 1]\n",
      " [2 6 7]]\n",
      "Validation Loss for P31 = 1.3016828298568726\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_32/3812056636.py:43: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([18, 1, 8064])\n",
      "torch.Size([15, 1, 8064])\n",
      "torch.Size([18, 1, 8064])\n",
      "torch.Size([15, 1, 8064])\n",
      "torch.Size([2, 1, 8064])\n",
      "Epoch 224/300, Train Loss: 1.5735177993774414\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.33      0.14      0.20         7\n",
      "           2       0.17      0.67      0.27         3\n",
      "           3       0.70      0.47      0.56        15\n",
      "\n",
      "    accuracy                           0.40        25\n",
      "   macro avg       0.40      0.43      0.34        25\n",
      "weighted avg       0.53      0.40      0.42        25\n",
      "\n",
      "[[1 4 2]\n",
      " [0 2 1]\n",
      " [2 6 7]]\n",
      "Validation Loss for P31 = 1.3039461374282837\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_32/3812056636.py:43: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([18, 1, 8064])\n",
      "torch.Size([15, 1, 8064])\n",
      "torch.Size([18, 1, 8064])\n",
      "torch.Size([15, 1, 8064])\n",
      "torch.Size([2, 1, 8064])\n",
      "Epoch 225/300, Train Loss: 1.1102882623672485\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         7\n",
      "           2       0.17      0.67      0.27         3\n",
      "           3       0.64      0.47      0.54        15\n",
      "\n",
      "    accuracy                           0.36        25\n",
      "   macro avg       0.27      0.38      0.27        25\n",
      "weighted avg       0.40      0.36      0.36        25\n",
      "\n",
      "[[0 4 3]\n",
      " [0 2 1]\n",
      " [2 6 7]]\n",
      "Validation Loss for P31 = 1.303475022315979\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_32/3812056636.py:43: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([18, 1, 8064])\n",
      "torch.Size([15, 1, 8064])\n",
      "torch.Size([18, 1, 8064])\n",
      "torch.Size([15, 1, 8064])\n",
      "torch.Size([2, 1, 8064])\n",
      "Epoch 226/300, Train Loss: 1.8268197774887085\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         7\n",
      "           2       0.17      0.67      0.27         3\n",
      "           3       0.60      0.40      0.48        15\n",
      "\n",
      "    accuracy                           0.32        25\n",
      "   macro avg       0.26      0.36      0.25        25\n",
      "weighted avg       0.38      0.32      0.32        25\n",
      "\n",
      "[[0 4 3]\n",
      " [0 2 1]\n",
      " [3 6 6]]\n",
      "Validation Loss for P31 = 1.3017092943191528\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_32/3812056636.py:43: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([18, 1, 8064])\n",
      "torch.Size([15, 1, 8064])\n",
      "torch.Size([18, 1, 8064])\n",
      "torch.Size([15, 1, 8064])\n",
      "torch.Size([2, 1, 8064])\n",
      "Epoch 227/300, Train Loss: 1.4645862579345703\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         7\n",
      "           2       0.17      0.67      0.27         3\n",
      "           3       0.60      0.40      0.48        15\n",
      "\n",
      "    accuracy                           0.32        25\n",
      "   macro avg       0.26      0.36      0.25        25\n",
      "weighted avg       0.38      0.32      0.32        25\n",
      "\n",
      "[[0 4 3]\n",
      " [0 2 1]\n",
      " [3 6 6]]\n",
      "Validation Loss for P31 = 1.3079432249069214\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_32/3812056636.py:43: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([18, 1, 8064])\n",
      "torch.Size([15, 1, 8064])\n",
      "torch.Size([18, 1, 8064])\n",
      "torch.Size([15, 1, 8064])\n",
      "torch.Size([2, 1, 8064])\n",
      "Epoch 228/300, Train Loss: 1.2578860521316528\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         7\n",
      "           2       0.15      0.67      0.25         3\n",
      "           3       0.70      0.47      0.56        15\n",
      "\n",
      "    accuracy                           0.36        25\n",
      "   macro avg       0.28      0.38      0.27        25\n",
      "weighted avg       0.44      0.36      0.37        25\n",
      "\n",
      "[[0 5 2]\n",
      " [0 2 1]\n",
      " [2 6 7]]\n",
      "Validation Loss for P31 = 1.3131017684936523\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_32/3812056636.py:43: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([18, 1, 8064])\n",
      "torch.Size([15, 1, 8064])\n",
      "torch.Size([18, 1, 8064])\n",
      "torch.Size([15, 1, 8064])\n",
      "torch.Size([2, 1, 8064])\n",
      "Epoch 229/300, Train Loss: 1.4979345798492432\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         7\n",
      "           2       0.15      0.67      0.25         3\n",
      "           3       0.67      0.40      0.50        15\n",
      "\n",
      "    accuracy                           0.32        25\n",
      "   macro avg       0.27      0.36      0.25        25\n",
      "weighted avg       0.42      0.32      0.33        25\n",
      "\n",
      "[[0 5 2]\n",
      " [0 2 1]\n",
      " [3 6 6]]\n",
      "Validation Loss for P31 = 1.316974401473999\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_32/3812056636.py:43: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([18, 1, 8064])\n",
      "torch.Size([15, 1, 8064])\n",
      "torch.Size([18, 1, 8064])\n",
      "torch.Size([15, 1, 8064])\n",
      "torch.Size([2, 1, 8064])\n",
      "Epoch 230/300, Train Loss: 1.4075205326080322\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         7\n",
      "           2       0.15      0.67      0.25         3\n",
      "           3       0.70      0.47      0.56        15\n",
      "\n",
      "    accuracy                           0.36        25\n",
      "   macro avg       0.28      0.38      0.27        25\n",
      "weighted avg       0.44      0.36      0.37        25\n",
      "\n",
      "[[0 5 2]\n",
      " [0 2 1]\n",
      " [2 6 7]]\n",
      "Validation Loss for P31 = 1.319967269897461\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_32/3812056636.py:43: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([18, 1, 8064])\n",
      "torch.Size([15, 1, 8064])\n",
      "torch.Size([18, 1, 8064])\n",
      "torch.Size([15, 1, 8064])\n",
      "torch.Size([2, 1, 8064])\n",
      "Epoch 231/300, Train Loss: 1.0989242792129517\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         7\n",
      "           2       0.17      0.67      0.27         3\n",
      "           3       0.60      0.40      0.48        15\n",
      "\n",
      "    accuracy                           0.32        25\n",
      "   macro avg       0.26      0.36      0.25        25\n",
      "weighted avg       0.38      0.32      0.32        25\n",
      "\n",
      "[[0 4 3]\n",
      " [0 2 1]\n",
      " [3 6 6]]\n",
      "Validation Loss for P31 = 1.3230634927749634\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_32/3812056636.py:43: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([18, 1, 8064])\n",
      "torch.Size([15, 1, 8064])\n",
      "torch.Size([18, 1, 8064])\n",
      "torch.Size([15, 1, 8064])\n",
      "torch.Size([2, 1, 8064])\n",
      "Epoch 232/300, Train Loss: 1.3169924020767212\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         7\n",
      "           2       0.17      0.67      0.27         3\n",
      "           3       0.60      0.40      0.48        15\n",
      "\n",
      "    accuracy                           0.32        25\n",
      "   macro avg       0.26      0.36      0.25        25\n",
      "weighted avg       0.38      0.32      0.32        25\n",
      "\n",
      "[[0 4 3]\n",
      " [0 2 1]\n",
      " [3 6 6]]\n",
      "Validation Loss for P31 = 1.3268626928329468\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_32/3812056636.py:43: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([18, 1, 8064])\n",
      "torch.Size([15, 1, 8064])\n",
      "torch.Size([18, 1, 8064])\n",
      "torch.Size([15, 1, 8064])\n",
      "torch.Size([2, 1, 8064])\n",
      "Epoch 233/300, Train Loss: 1.3899428844451904\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         7\n",
      "           2       0.17      0.67      0.27         3\n",
      "           3       0.60      0.40      0.48        15\n",
      "\n",
      "    accuracy                           0.32        25\n",
      "   macro avg       0.26      0.36      0.25        25\n",
      "weighted avg       0.38      0.32      0.32        25\n",
      "\n",
      "[[0 4 3]\n",
      " [0 2 1]\n",
      " [3 6 6]]\n",
      "Validation Loss for P31 = 1.3139500617980957\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_32/3812056636.py:43: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([18, 1, 8064])\n",
      "torch.Size([15, 1, 8064])\n",
      "torch.Size([18, 1, 8064])\n",
      "torch.Size([15, 1, 8064])\n",
      "torch.Size([2, 1, 8064])\n",
      "Epoch 234/300, Train Loss: 1.093748927116394\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         7\n",
      "           2       0.17      0.67      0.27         3\n",
      "           3       0.60      0.40      0.48        15\n",
      "\n",
      "    accuracy                           0.32        25\n",
      "   macro avg       0.26      0.36      0.25        25\n",
      "weighted avg       0.38      0.32      0.32        25\n",
      "\n",
      "[[0 4 3]\n",
      " [0 2 1]\n",
      " [3 6 6]]\n",
      "Validation Loss for P31 = 1.3232914209365845\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_32/3812056636.py:43: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([18, 1, 8064])\n",
      "torch.Size([15, 1, 8064])\n",
      "torch.Size([18, 1, 8064])\n",
      "torch.Size([15, 1, 8064])\n",
      "torch.Size([2, 1, 8064])\n",
      "Epoch 235/300, Train Loss: 1.138669490814209\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         7\n",
      "           2       0.15      0.67      0.25         3\n",
      "           3       0.70      0.47      0.56        15\n",
      "\n",
      "    accuracy                           0.36        25\n",
      "   macro avg       0.28      0.38      0.27        25\n",
      "weighted avg       0.44      0.36      0.37        25\n",
      "\n",
      "[[0 5 2]\n",
      " [0 2 1]\n",
      " [2 6 7]]\n",
      "Validation Loss for P31 = 1.3141318559646606\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_32/3812056636.py:43: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([18, 1, 8064])\n",
      "torch.Size([15, 1, 8064])\n",
      "torch.Size([18, 1, 8064])\n",
      "torch.Size([15, 1, 8064])\n",
      "torch.Size([2, 1, 8064])\n",
      "Epoch 236/300, Train Loss: 1.390237808227539\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         7\n",
      "           2       0.15      0.67      0.25         3\n",
      "           3       0.70      0.47      0.56        15\n",
      "\n",
      "    accuracy                           0.36        25\n",
      "   macro avg       0.28      0.38      0.27        25\n",
      "weighted avg       0.44      0.36      0.37        25\n",
      "\n",
      "[[0 5 2]\n",
      " [0 2 1]\n",
      " [2 6 7]]\n",
      "Validation Loss for P31 = 1.3091838359832764\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_32/3812056636.py:43: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([18, 1, 8064])\n",
      "torch.Size([15, 1, 8064])\n",
      "torch.Size([18, 1, 8064])\n",
      "torch.Size([15, 1, 8064])\n",
      "torch.Size([2, 1, 8064])\n",
      "Epoch 237/300, Train Loss: 1.2677104473114014\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.33      0.14      0.20         7\n",
      "           2       0.17      0.67      0.27         3\n",
      "           3       0.70      0.47      0.56        15\n",
      "\n",
      "    accuracy                           0.40        25\n",
      "   macro avg       0.40      0.43      0.34        25\n",
      "weighted avg       0.53      0.40      0.42        25\n",
      "\n",
      "[[1 4 2]\n",
      " [0 2 1]\n",
      " [2 6 7]]\n",
      "Validation Loss for P31 = 1.2996034622192383\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_32/3812056636.py:43: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([18, 1, 8064])\n",
      "torch.Size([15, 1, 8064])\n",
      "torch.Size([18, 1, 8064])\n",
      "torch.Size([15, 1, 8064])\n",
      "torch.Size([2, 1, 8064])\n",
      "Epoch 238/300, Train Loss: 1.5320441722869873\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         7\n",
      "           2       0.15      0.67      0.25         3\n",
      "           3       0.70      0.47      0.56        15\n",
      "\n",
      "    accuracy                           0.36        25\n",
      "   macro avg       0.28      0.38      0.27        25\n",
      "weighted avg       0.44      0.36      0.37        25\n",
      "\n",
      "[[0 5 2]\n",
      " [0 2 1]\n",
      " [2 6 7]]\n",
      "Validation Loss for P31 = 1.3136661052703857\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_32/3812056636.py:43: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([18, 1, 8064])\n",
      "torch.Size([15, 1, 8064])\n",
      "torch.Size([18, 1, 8064])\n",
      "torch.Size([15, 1, 8064])\n",
      "torch.Size([2, 1, 8064])\n",
      "Epoch 239/300, Train Loss: 1.4973621368408203\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         7\n",
      "           2       0.15      0.67      0.25         3\n",
      "           3       0.70      0.47      0.56        15\n",
      "\n",
      "    accuracy                           0.36        25\n",
      "   macro avg       0.28      0.38      0.27        25\n",
      "weighted avg       0.44      0.36      0.37        25\n",
      "\n",
      "[[0 5 2]\n",
      " [0 2 1]\n",
      " [2 6 7]]\n",
      "Validation Loss for P31 = 1.3142112493515015\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_32/3812056636.py:43: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([18, 1, 8064])\n",
      "torch.Size([15, 1, 8064])\n",
      "torch.Size([18, 1, 8064])\n",
      "torch.Size([15, 1, 8064])\n",
      "torch.Size([2, 1, 8064])\n",
      "Epoch 240/300, Train Loss: 1.5581779479980469\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.25      0.14      0.18         7\n",
      "           2       0.17      0.67      0.27         3\n",
      "           3       0.67      0.40      0.50        15\n",
      "\n",
      "    accuracy                           0.36        25\n",
      "   macro avg       0.36      0.40      0.32        25\n",
      "weighted avg       0.49      0.36      0.38        25\n",
      "\n",
      "[[1 4 2]\n",
      " [0 2 1]\n",
      " [3 6 6]]\n",
      "Validation Loss for P31 = 1.3158369064331055\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_32/3812056636.py:43: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([18, 1, 8064])\n",
      "torch.Size([15, 1, 8064])\n",
      "torch.Size([18, 1, 8064])\n",
      "torch.Size([15, 1, 8064])\n",
      "torch.Size([2, 1, 8064])\n",
      "Epoch 241/300, Train Loss: 1.5964441299438477\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.25      0.14      0.18         7\n",
      "           2       0.17      0.67      0.27         3\n",
      "           3       0.67      0.40      0.50        15\n",
      "\n",
      "    accuracy                           0.36        25\n",
      "   macro avg       0.36      0.40      0.32        25\n",
      "weighted avg       0.49      0.36      0.38        25\n",
      "\n",
      "[[1 4 2]\n",
      " [0 2 1]\n",
      " [3 6 6]]\n",
      "Validation Loss for P31 = 1.2985129356384277\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_32/3812056636.py:43: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([18, 1, 8064])\n",
      "torch.Size([15, 1, 8064])\n",
      "torch.Size([18, 1, 8064])\n",
      "torch.Size([15, 1, 8064])\n",
      "torch.Size([2, 1, 8064])\n",
      "Epoch 242/300, Train Loss: 1.7663087844848633\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.25      0.14      0.18         7\n",
      "           2       0.17      0.67      0.27         3\n",
      "           3       0.67      0.40      0.50        15\n",
      "\n",
      "    accuracy                           0.36        25\n",
      "   macro avg       0.36      0.40      0.32        25\n",
      "weighted avg       0.49      0.36      0.38        25\n",
      "\n",
      "[[1 4 2]\n",
      " [0 2 1]\n",
      " [3 6 6]]\n",
      "Validation Loss for P31 = 1.3032197952270508\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_32/3812056636.py:43: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([18, 1, 8064])\n",
      "torch.Size([15, 1, 8064])\n",
      "torch.Size([18, 1, 8064])\n",
      "torch.Size([15, 1, 8064])\n",
      "torch.Size([2, 1, 8064])\n",
      "Epoch 243/300, Train Loss: 1.5428224802017212\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.33      0.14      0.20         7\n",
      "           2       0.17      0.67      0.27         3\n",
      "           3       0.70      0.47      0.56        15\n",
      "\n",
      "    accuracy                           0.40        25\n",
      "   macro avg       0.40      0.43      0.34        25\n",
      "weighted avg       0.53      0.40      0.42        25\n",
      "\n",
      "[[1 4 2]\n",
      " [0 2 1]\n",
      " [2 6 7]]\n",
      "Validation Loss for P31 = 1.2948163747787476\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_32/3812056636.py:43: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([18, 1, 8064])\n",
      "torch.Size([15, 1, 8064])\n",
      "torch.Size([18, 1, 8064])\n",
      "torch.Size([15, 1, 8064])\n",
      "torch.Size([2, 1, 8064])\n",
      "Epoch 244/300, Train Loss: 1.431136131286621\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.33      0.14      0.20         7\n",
      "           2       0.17      0.67      0.27         3\n",
      "           3       0.70      0.47      0.56        15\n",
      "\n",
      "    accuracy                           0.40        25\n",
      "   macro avg       0.40      0.43      0.34        25\n",
      "weighted avg       0.53      0.40      0.42        25\n",
      "\n",
      "[[1 4 2]\n",
      " [0 2 1]\n",
      " [2 6 7]]\n",
      "Validation Loss for P31 = 1.2958683967590332\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_32/3812056636.py:43: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([18, 1, 8064])\n",
      "torch.Size([15, 1, 8064])\n",
      "torch.Size([18, 1, 8064])\n",
      "torch.Size([15, 1, 8064])\n",
      "torch.Size([2, 1, 8064])\n",
      "Epoch 245/300, Train Loss: 1.511720061302185\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.33      0.14      0.20         7\n",
      "           2       0.17      0.67      0.27         3\n",
      "           3       0.70      0.47      0.56        15\n",
      "\n",
      "    accuracy                           0.40        25\n",
      "   macro avg       0.40      0.43      0.34        25\n",
      "weighted avg       0.53      0.40      0.42        25\n",
      "\n",
      "[[1 4 2]\n",
      " [0 2 1]\n",
      " [2 6 7]]\n",
      "Validation Loss for P31 = 1.2904491424560547\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_32/3812056636.py:43: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([18, 1, 8064])\n",
      "torch.Size([15, 1, 8064])\n",
      "torch.Size([18, 1, 8064])\n",
      "torch.Size([15, 1, 8064])\n",
      "torch.Size([2, 1, 8064])\n",
      "Epoch 246/300, Train Loss: 1.501006007194519\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.33      0.14      0.20         7\n",
      "           2       0.17      0.67      0.27         3\n",
      "           3       0.70      0.47      0.56        15\n",
      "\n",
      "    accuracy                           0.40        25\n",
      "   macro avg       0.40      0.43      0.34        25\n",
      "weighted avg       0.53      0.40      0.42        25\n",
      "\n",
      "[[1 4 2]\n",
      " [0 2 1]\n",
      " [2 6 7]]\n",
      "Validation Loss for P31 = 1.3020795583724976\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_32/3812056636.py:43: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([18, 1, 8064])\n",
      "torch.Size([15, 1, 8064])\n",
      "torch.Size([18, 1, 8064])\n",
      "torch.Size([15, 1, 8064])\n",
      "torch.Size([2, 1, 8064])\n",
      "Epoch 247/300, Train Loss: 1.45697021484375\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.33      0.14      0.20         7\n",
      "           2       0.17      0.67      0.27         3\n",
      "           3       0.70      0.47      0.56        15\n",
      "\n",
      "    accuracy                           0.40        25\n",
      "   macro avg       0.40      0.43      0.34        25\n",
      "weighted avg       0.53      0.40      0.42        25\n",
      "\n",
      "[[1 4 2]\n",
      " [0 2 1]\n",
      " [2 6 7]]\n",
      "Validation Loss for P31 = 1.2973769903182983\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_32/3812056636.py:43: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([18, 1, 8064])\n",
      "torch.Size([15, 1, 8064])\n",
      "torch.Size([18, 1, 8064])\n",
      "torch.Size([15, 1, 8064])\n",
      "torch.Size([2, 1, 8064])\n",
      "Epoch 248/300, Train Loss: 1.3717169761657715\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.33      0.14      0.20         7\n",
      "           2       0.17      0.67      0.27         3\n",
      "           3       0.70      0.47      0.56        15\n",
      "\n",
      "    accuracy                           0.40        25\n",
      "   macro avg       0.40      0.43      0.34        25\n",
      "weighted avg       0.53      0.40      0.42        25\n",
      "\n",
      "[[1 4 2]\n",
      " [0 2 1]\n",
      " [2 6 7]]\n",
      "Validation Loss for P31 = 1.30008065700531\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_32/3812056636.py:43: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([18, 1, 8064])\n",
      "torch.Size([15, 1, 8064])\n",
      "torch.Size([18, 1, 8064])\n",
      "torch.Size([15, 1, 8064])\n",
      "torch.Size([2, 1, 8064])\n",
      "Epoch 249/300, Train Loss: 1.2790844440460205\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.33      0.14      0.20         7\n",
      "           2       0.17      0.67      0.27         3\n",
      "           3       0.70      0.47      0.56        15\n",
      "\n",
      "    accuracy                           0.40        25\n",
      "   macro avg       0.40      0.43      0.34        25\n",
      "weighted avg       0.53      0.40      0.42        25\n",
      "\n",
      "[[1 4 2]\n",
      " [0 2 1]\n",
      " [2 6 7]]\n",
      "Validation Loss for P31 = 1.2960405349731445\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_32/3812056636.py:43: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([18, 1, 8064])\n",
      "torch.Size([15, 1, 8064])\n",
      "torch.Size([18, 1, 8064])\n",
      "torch.Size([15, 1, 8064])\n",
      "torch.Size([2, 1, 8064])\n",
      "Epoch 250/300, Train Loss: 1.202538013458252\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         7\n",
      "           2       0.15      0.67      0.25         3\n",
      "           3       0.70      0.47      0.56        15\n",
      "\n",
      "    accuracy                           0.36        25\n",
      "   macro avg       0.28      0.38      0.27        25\n",
      "weighted avg       0.44      0.36      0.37        25\n",
      "\n",
      "[[0 5 2]\n",
      " [0 2 1]\n",
      " [2 6 7]]\n",
      "Validation Loss for P31 = 1.2980847358703613\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_32/3812056636.py:43: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([18, 1, 8064])\n",
      "torch.Size([15, 1, 8064])\n",
      "torch.Size([18, 1, 8064])\n",
      "torch.Size([15, 1, 8064])\n",
      "torch.Size([2, 1, 8064])\n",
      "Epoch 251/300, Train Loss: 1.6197609901428223\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.25      0.14      0.18         7\n",
      "           2       0.17      0.67      0.27         3\n",
      "           3       0.67      0.40      0.50        15\n",
      "\n",
      "    accuracy                           0.36        25\n",
      "   macro avg       0.36      0.40      0.32        25\n",
      "weighted avg       0.49      0.36      0.38        25\n",
      "\n",
      "[[1 4 2]\n",
      " [0 2 1]\n",
      " [3 6 6]]\n",
      "Validation Loss for P31 = 1.3013025522232056\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_32/3812056636.py:43: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([18, 1, 8064])\n",
      "torch.Size([15, 1, 8064])\n",
      "torch.Size([18, 1, 8064])\n",
      "torch.Size([15, 1, 8064])\n",
      "torch.Size([2, 1, 8064])\n",
      "Epoch 252/300, Train Loss: 1.3770737648010254\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.25      0.14      0.18         7\n",
      "           2       0.17      0.67      0.27         3\n",
      "           3       0.67      0.40      0.50        15\n",
      "\n",
      "    accuracy                           0.36        25\n",
      "   macro avg       0.36      0.40      0.32        25\n",
      "weighted avg       0.49      0.36      0.38        25\n",
      "\n",
      "[[1 4 2]\n",
      " [0 2 1]\n",
      " [3 6 6]]\n",
      "Validation Loss for P31 = 1.3018429279327393\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_32/3812056636.py:43: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([18, 1, 8064])\n",
      "torch.Size([15, 1, 8064])\n",
      "torch.Size([18, 1, 8064])\n",
      "torch.Size([15, 1, 8064])\n",
      "torch.Size([2, 1, 8064])\n",
      "Epoch 253/300, Train Loss: 1.391343593597412\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.33      0.14      0.20         7\n",
      "           2       0.17      0.67      0.27         3\n",
      "           3       0.70      0.47      0.56        15\n",
      "\n",
      "    accuracy                           0.40        25\n",
      "   macro avg       0.40      0.43      0.34        25\n",
      "weighted avg       0.53      0.40      0.42        25\n",
      "\n",
      "[[1 4 2]\n",
      " [0 2 1]\n",
      " [2 6 7]]\n",
      "Validation Loss for P31 = 1.300352692604065\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_32/3812056636.py:43: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([18, 1, 8064])\n",
      "torch.Size([15, 1, 8064])\n",
      "torch.Size([18, 1, 8064])\n",
      "torch.Size([15, 1, 8064])\n",
      "torch.Size([2, 1, 8064])\n",
      "Epoch 254/300, Train Loss: 1.5068024396896362\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         7\n",
      "           2       0.17      0.67      0.27         3\n",
      "           3       0.60      0.40      0.48        15\n",
      "\n",
      "    accuracy                           0.32        25\n",
      "   macro avg       0.26      0.36      0.25        25\n",
      "weighted avg       0.38      0.32      0.32        25\n",
      "\n",
      "[[0 4 3]\n",
      " [0 2 1]\n",
      " [3 6 6]]\n",
      "Validation Loss for P31 = 1.3004302978515625\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_32/3812056636.py:43: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([18, 1, 8064])\n",
      "torch.Size([15, 1, 8064])\n",
      "torch.Size([18, 1, 8064])\n",
      "torch.Size([15, 1, 8064])\n",
      "torch.Size([2, 1, 8064])\n",
      "Epoch 255/300, Train Loss: 1.4076976776123047\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         7\n",
      "           2       0.15      0.67      0.25         3\n",
      "           3       0.70      0.47      0.56        15\n",
      "\n",
      "    accuracy                           0.36        25\n",
      "   macro avg       0.28      0.38      0.27        25\n",
      "weighted avg       0.44      0.36      0.37        25\n",
      "\n",
      "[[0 5 2]\n",
      " [0 2 1]\n",
      " [2 6 7]]\n",
      "Validation Loss for P31 = 1.3031452894210815\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_32/3812056636.py:43: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([18, 1, 8064])\n",
      "torch.Size([15, 1, 8064])\n",
      "torch.Size([18, 1, 8064])\n",
      "torch.Size([15, 1, 8064])\n",
      "torch.Size([2, 1, 8064])\n",
      "Epoch 256/300, Train Loss: 1.6321690082550049\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         7\n",
      "           2       0.17      0.67      0.27         3\n",
      "           3       0.60      0.40      0.48        15\n",
      "\n",
      "    accuracy                           0.32        25\n",
      "   macro avg       0.26      0.36      0.25        25\n",
      "weighted avg       0.38      0.32      0.32        25\n",
      "\n",
      "[[0 4 3]\n",
      " [0 2 1]\n",
      " [3 6 6]]\n",
      "Validation Loss for P31 = 1.3038171529769897\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_32/3812056636.py:43: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([18, 1, 8064])\n",
      "torch.Size([15, 1, 8064])\n",
      "torch.Size([18, 1, 8064])\n",
      "torch.Size([15, 1, 8064])\n",
      "torch.Size([2, 1, 8064])\n",
      "Epoch 257/300, Train Loss: 1.249348759651184\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         7\n",
      "           2       0.15      0.67      0.25         3\n",
      "           3       0.60      0.40      0.48        15\n",
      "\n",
      "    accuracy                           0.32        25\n",
      "   macro avg       0.25      0.36      0.24        25\n",
      "weighted avg       0.38      0.32      0.32        25\n",
      "\n",
      "[[0 4 3]\n",
      " [0 2 1]\n",
      " [2 7 6]]\n",
      "Validation Loss for P31 = 1.3140424489974976\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_32/3812056636.py:43: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([18, 1, 8064])\n",
      "torch.Size([15, 1, 8064])\n",
      "torch.Size([18, 1, 8064])\n",
      "torch.Size([15, 1, 8064])\n",
      "torch.Size([2, 1, 8064])\n",
      "Epoch 258/300, Train Loss: 1.5275180339813232\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         7\n",
      "           2       0.17      0.67      0.27         3\n",
      "           3       0.60      0.40      0.48        15\n",
      "\n",
      "    accuracy                           0.32        25\n",
      "   macro avg       0.26      0.36      0.25        25\n",
      "weighted avg       0.38      0.32      0.32        25\n",
      "\n",
      "[[0 4 3]\n",
      " [0 2 1]\n",
      " [3 6 6]]\n",
      "Validation Loss for P31 = 1.3125702142715454\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_32/3812056636.py:43: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([18, 1, 8064])\n",
      "torch.Size([15, 1, 8064])\n",
      "torch.Size([18, 1, 8064])\n",
      "torch.Size([15, 1, 8064])\n",
      "torch.Size([2, 1, 8064])\n",
      "Epoch 259/300, Train Loss: 1.508857011795044\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.25      0.14      0.18         7\n",
      "           2       0.17      0.67      0.27         3\n",
      "           3       0.67      0.40      0.50        15\n",
      "\n",
      "    accuracy                           0.36        25\n",
      "   macro avg       0.36      0.40      0.32        25\n",
      "weighted avg       0.49      0.36      0.38        25\n",
      "\n",
      "[[1 4 2]\n",
      " [0 2 1]\n",
      " [3 6 6]]\n",
      "Validation Loss for P31 = 1.302316665649414\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_32/3812056636.py:43: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([18, 1, 8064])\n",
      "torch.Size([15, 1, 8064])\n",
      "torch.Size([18, 1, 8064])\n",
      "torch.Size([15, 1, 8064])\n",
      "torch.Size([2, 1, 8064])\n",
      "Epoch 260/300, Train Loss: 1.541471242904663\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         7\n",
      "           2       0.17      0.67      0.27         3\n",
      "           3       0.60      0.40      0.48        15\n",
      "\n",
      "    accuracy                           0.32        25\n",
      "   macro avg       0.26      0.36      0.25        25\n",
      "weighted avg       0.38      0.32      0.32        25\n",
      "\n",
      "[[0 4 3]\n",
      " [0 2 1]\n",
      " [3 6 6]]\n",
      "Validation Loss for P31 = 1.304901123046875\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_32/3812056636.py:43: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([18, 1, 8064])\n",
      "torch.Size([15, 1, 8064])\n",
      "torch.Size([18, 1, 8064])\n",
      "torch.Size([15, 1, 8064])\n",
      "torch.Size([2, 1, 8064])\n",
      "Epoch 261/300, Train Loss: 1.450639247894287\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.33      0.14      0.20         7\n",
      "           2       0.15      0.67      0.25         3\n",
      "           3       0.67      0.40      0.50        15\n",
      "\n",
      "    accuracy                           0.36        25\n",
      "   macro avg       0.38      0.40      0.32        25\n",
      "weighted avg       0.51      0.36      0.39        25\n",
      "\n",
      "[[1 4 2]\n",
      " [0 2 1]\n",
      " [2 7 6]]\n",
      "Validation Loss for P31 = 1.3142611980438232\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_32/3812056636.py:43: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([18, 1, 8064])\n",
      "torch.Size([15, 1, 8064])\n",
      "torch.Size([18, 1, 8064])\n",
      "torch.Size([15, 1, 8064])\n",
      "torch.Size([2, 1, 8064])\n",
      "Epoch 262/300, Train Loss: 1.668042778968811\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         7\n",
      "           2       0.18      0.67      0.29         3\n",
      "           3       0.67      0.53      0.59        15\n",
      "\n",
      "    accuracy                           0.40        25\n",
      "   macro avg       0.28      0.40      0.29        25\n",
      "weighted avg       0.42      0.40      0.39        25\n",
      "\n",
      "[[0 4 3]\n",
      " [0 2 1]\n",
      " [2 5 8]]\n",
      "Validation Loss for P31 = 1.2952443361282349\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_32/3812056636.py:43: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([18, 1, 8064])\n",
      "torch.Size([15, 1, 8064])\n",
      "torch.Size([18, 1, 8064])\n",
      "torch.Size([15, 1, 8064])\n",
      "torch.Size([2, 1, 8064])\n",
      "Epoch 263/300, Train Loss: 1.3388491868972778\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         7\n",
      "           2       0.15      0.67      0.25         3\n",
      "           3       0.60      0.40      0.48        15\n",
      "\n",
      "    accuracy                           0.32        25\n",
      "   macro avg       0.25      0.36      0.24        25\n",
      "weighted avg       0.38      0.32      0.32        25\n",
      "\n",
      "[[0 4 3]\n",
      " [0 2 1]\n",
      " [2 7 6]]\n",
      "Validation Loss for P31 = 1.3204630613327026\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_32/3812056636.py:43: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([18, 1, 8064])\n",
      "torch.Size([15, 1, 8064])\n",
      "torch.Size([18, 1, 8064])\n",
      "torch.Size([15, 1, 8064])\n",
      "torch.Size([2, 1, 8064])\n",
      "Epoch 264/300, Train Loss: 0.7657839059829712\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.33      0.14      0.20         7\n",
      "           2       0.17      0.67      0.27         3\n",
      "           3       0.70      0.47      0.56        15\n",
      "\n",
      "    accuracy                           0.40        25\n",
      "   macro avg       0.40      0.43      0.34        25\n",
      "weighted avg       0.53      0.40      0.42        25\n",
      "\n",
      "[[1 4 2]\n",
      " [0 2 1]\n",
      " [2 6 7]]\n",
      "Validation Loss for P31 = 1.3109145164489746\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_32/3812056636.py:43: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([18, 1, 8064])\n",
      "torch.Size([15, 1, 8064])\n",
      "torch.Size([18, 1, 8064])\n",
      "torch.Size([15, 1, 8064])\n",
      "torch.Size([2, 1, 8064])\n",
      "Epoch 265/300, Train Loss: 1.1334677934646606\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.33      0.14      0.20         7\n",
      "           2       0.17      0.67      0.27         3\n",
      "           3       0.70      0.47      0.56        15\n",
      "\n",
      "    accuracy                           0.40        25\n",
      "   macro avg       0.40      0.43      0.34        25\n",
      "weighted avg       0.53      0.40      0.42        25\n",
      "\n",
      "[[1 4 2]\n",
      " [0 2 1]\n",
      " [2 6 7]]\n",
      "Validation Loss for P31 = 1.3060808181762695\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_32/3812056636.py:43: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([18, 1, 8064])\n",
      "torch.Size([15, 1, 8064])\n",
      "torch.Size([18, 1, 8064])\n",
      "torch.Size([15, 1, 8064])\n",
      "torch.Size([2, 1, 8064])\n",
      "Epoch 266/300, Train Loss: 1.4254156351089478\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.33      0.14      0.20         7\n",
      "           2       0.17      0.67      0.27         3\n",
      "           3       0.70      0.47      0.56        15\n",
      "\n",
      "    accuracy                           0.40        25\n",
      "   macro avg       0.40      0.43      0.34        25\n",
      "weighted avg       0.53      0.40      0.42        25\n",
      "\n",
      "[[1 4 2]\n",
      " [0 2 1]\n",
      " [2 6 7]]\n",
      "Validation Loss for P31 = 1.303576111793518\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_32/3812056636.py:43: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([18, 1, 8064])\n",
      "torch.Size([15, 1, 8064])\n",
      "torch.Size([18, 1, 8064])\n",
      "torch.Size([15, 1, 8064])\n",
      "torch.Size([2, 1, 8064])\n",
      "Epoch 267/300, Train Loss: 1.4191139936447144\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.33      0.14      0.20         7\n",
      "           2       0.21      1.00      0.35         3\n",
      "           3       0.75      0.40      0.52        15\n",
      "\n",
      "    accuracy                           0.40        25\n",
      "   macro avg       0.43      0.51      0.36        25\n",
      "weighted avg       0.57      0.40      0.41        25\n",
      "\n",
      "[[1 4 2]\n",
      " [0 3 0]\n",
      " [2 7 6]]\n",
      "Validation Loss for P31 = 1.3173959255218506\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_32/3812056636.py:43: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([18, 1, 8064])\n",
      "torch.Size([15, 1, 8064])\n",
      "torch.Size([18, 1, 8064])\n",
      "torch.Size([15, 1, 8064])\n",
      "torch.Size([2, 1, 8064])\n",
      "Epoch 268/300, Train Loss: 1.3619904518127441\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         7\n",
      "           2       0.20      1.00      0.33         3\n",
      "           3       0.88      0.47      0.61        15\n",
      "\n",
      "    accuracy                           0.40        25\n",
      "   macro avg       0.36      0.49      0.31        25\n",
      "weighted avg       0.55      0.40      0.41        25\n",
      "\n",
      "[[0 6 1]\n",
      " [0 3 0]\n",
      " [2 6 7]]\n",
      "Validation Loss for P31 = 1.3254594802856445\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_32/3812056636.py:43: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([18, 1, 8064])\n",
      "torch.Size([15, 1, 8064])\n",
      "torch.Size([18, 1, 8064])\n",
      "torch.Size([15, 1, 8064])\n",
      "torch.Size([2, 1, 8064])\n",
      "Epoch 269/300, Train Loss: 1.543723702430725\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         7\n",
      "           2       0.17      0.67      0.27         3\n",
      "           3       0.64      0.47      0.54        15\n",
      "\n",
      "    accuracy                           0.36        25\n",
      "   macro avg       0.27      0.38      0.27        25\n",
      "weighted avg       0.40      0.36      0.36        25\n",
      "\n",
      "[[0 4 3]\n",
      " [0 2 1]\n",
      " [2 6 7]]\n",
      "Validation Loss for P31 = 1.320508360862732\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_32/3812056636.py:43: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([18, 1, 8064])\n",
      "torch.Size([15, 1, 8064])\n",
      "torch.Size([18, 1, 8064])\n",
      "torch.Size([15, 1, 8064])\n",
      "torch.Size([2, 1, 8064])\n",
      "Epoch 270/300, Train Loss: 1.4111162424087524\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         7\n",
      "           2       0.17      0.67      0.27         3\n",
      "           3       0.64      0.47      0.54        15\n",
      "\n",
      "    accuracy                           0.36        25\n",
      "   macro avg       0.27      0.38      0.27        25\n",
      "weighted avg       0.40      0.36      0.36        25\n",
      "\n",
      "[[0 4 3]\n",
      " [0 2 1]\n",
      " [2 6 7]]\n",
      "Validation Loss for P31 = 1.3145984411239624\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_32/3812056636.py:43: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([18, 1, 8064])\n",
      "torch.Size([15, 1, 8064])\n",
      "torch.Size([18, 1, 8064])\n",
      "torch.Size([15, 1, 8064])\n",
      "torch.Size([2, 1, 8064])\n",
      "Epoch 271/300, Train Loss: 1.6110001802444458\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         7\n",
      "           2       0.17      0.67      0.27         3\n",
      "           3       0.64      0.47      0.54        15\n",
      "\n",
      "    accuracy                           0.36        25\n",
      "   macro avg       0.27      0.38      0.27        25\n",
      "weighted avg       0.40      0.36      0.36        25\n",
      "\n",
      "[[0 4 3]\n",
      " [0 2 1]\n",
      " [2 6 7]]\n",
      "Validation Loss for P31 = 1.3017065525054932\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_32/3812056636.py:43: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([18, 1, 8064])\n",
      "torch.Size([15, 1, 8064])\n",
      "torch.Size([18, 1, 8064])\n",
      "torch.Size([15, 1, 8064])\n",
      "torch.Size([2, 1, 8064])\n",
      "Epoch 272/300, Train Loss: 1.6302886009216309\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         7\n",
      "           2       0.17      0.67      0.27         3\n",
      "           3       0.64      0.47      0.54        15\n",
      "\n",
      "    accuracy                           0.36        25\n",
      "   macro avg       0.27      0.38      0.27        25\n",
      "weighted avg       0.40      0.36      0.36        25\n",
      "\n",
      "[[0 4 3]\n",
      " [0 2 1]\n",
      " [2 6 7]]\n",
      "Validation Loss for P31 = 1.3055553436279297\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_32/3812056636.py:43: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([18, 1, 8064])\n",
      "torch.Size([15, 1, 8064])\n",
      "torch.Size([18, 1, 8064])\n",
      "torch.Size([15, 1, 8064])\n",
      "torch.Size([2, 1, 8064])\n",
      "Epoch 273/300, Train Loss: 1.5339057445526123\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         7\n",
      "           2       0.17      0.67      0.27         3\n",
      "           3       0.64      0.47      0.54        15\n",
      "\n",
      "    accuracy                           0.36        25\n",
      "   macro avg       0.27      0.38      0.27        25\n",
      "weighted avg       0.40      0.36      0.36        25\n",
      "\n",
      "[[0 4 3]\n",
      " [0 2 1]\n",
      " [2 6 7]]\n",
      "Validation Loss for P31 = 1.3088563680648804\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_32/3812056636.py:43: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([18, 1, 8064])\n",
      "torch.Size([15, 1, 8064])\n",
      "torch.Size([18, 1, 8064])\n",
      "torch.Size([15, 1, 8064])\n",
      "torch.Size([2, 1, 8064])\n",
      "Epoch 274/300, Train Loss: 1.4477026462554932\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         7\n",
      "           2       0.17      0.67      0.27         3\n",
      "           3       0.64      0.47      0.54        15\n",
      "\n",
      "    accuracy                           0.36        25\n",
      "   macro avg       0.27      0.38      0.27        25\n",
      "weighted avg       0.40      0.36      0.36        25\n",
      "\n",
      "[[0 4 3]\n",
      " [0 2 1]\n",
      " [2 6 7]]\n",
      "Validation Loss for P31 = 1.3101931810379028\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_32/3812056636.py:43: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([18, 1, 8064])\n",
      "torch.Size([15, 1, 8064])\n",
      "torch.Size([18, 1, 8064])\n",
      "torch.Size([15, 1, 8064])\n",
      "torch.Size([2, 1, 8064])\n",
      "Epoch 275/300, Train Loss: 1.573521375656128\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         7\n",
      "           2       0.17      0.67      0.27         3\n",
      "           3       0.64      0.47      0.54        15\n",
      "\n",
      "    accuracy                           0.36        25\n",
      "   macro avg       0.27      0.38      0.27        25\n",
      "weighted avg       0.40      0.36      0.36        25\n",
      "\n",
      "[[0 4 3]\n",
      " [0 2 1]\n",
      " [2 6 7]]\n",
      "Validation Loss for P31 = 1.300554633140564\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_32/3812056636.py:43: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([18, 1, 8064])\n",
      "torch.Size([15, 1, 8064])\n",
      "torch.Size([18, 1, 8064])\n",
      "torch.Size([15, 1, 8064])\n",
      "torch.Size([2, 1, 8064])\n",
      "Epoch 276/300, Train Loss: 0.9675279259681702\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         7\n",
      "           2       0.17      0.67      0.27         3\n",
      "           3       0.64      0.47      0.54        15\n",
      "\n",
      "    accuracy                           0.36        25\n",
      "   macro avg       0.27      0.38      0.27        25\n",
      "weighted avg       0.40      0.36      0.36        25\n",
      "\n",
      "[[0 4 3]\n",
      " [0 2 1]\n",
      " [2 6 7]]\n",
      "Validation Loss for P31 = 1.2977896928787231\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_32/3812056636.py:43: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([18, 1, 8064])\n",
      "torch.Size([15, 1, 8064])\n",
      "torch.Size([18, 1, 8064])\n",
      "torch.Size([15, 1, 8064])\n",
      "torch.Size([2, 1, 8064])\n",
      "Epoch 277/300, Train Loss: 1.2911152839660645\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         7\n",
      "           2       0.17      0.67      0.27         3\n",
      "           3       0.60      0.40      0.48        15\n",
      "\n",
      "    accuracy                           0.32        25\n",
      "   macro avg       0.26      0.36      0.25        25\n",
      "weighted avg       0.38      0.32      0.32        25\n",
      "\n",
      "[[0 4 3]\n",
      " [0 2 1]\n",
      " [3 6 6]]\n",
      "Validation Loss for P31 = 1.2948354482650757\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_32/3812056636.py:43: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([18, 1, 8064])\n",
      "torch.Size([15, 1, 8064])\n",
      "torch.Size([18, 1, 8064])\n",
      "torch.Size([15, 1, 8064])\n",
      "torch.Size([2, 1, 8064])\n",
      "Epoch 278/300, Train Loss: 1.138615369796753\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         7\n",
      "           2       0.17      0.67      0.27         3\n",
      "           3       0.64      0.47      0.54        15\n",
      "\n",
      "    accuracy                           0.36        25\n",
      "   macro avg       0.27      0.38      0.27        25\n",
      "weighted avg       0.40      0.36      0.36        25\n",
      "\n",
      "[[0 4 3]\n",
      " [0 2 1]\n",
      " [2 6 7]]\n",
      "Validation Loss for P31 = 1.2972018718719482\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_32/3812056636.py:43: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([18, 1, 8064])\n",
      "torch.Size([15, 1, 8064])\n",
      "torch.Size([18, 1, 8064])\n",
      "torch.Size([15, 1, 8064])\n",
      "torch.Size([2, 1, 8064])\n",
      "Epoch 279/300, Train Loss: 1.5294189453125\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         7\n",
      "           2       0.17      0.67      0.27         3\n",
      "           3       0.60      0.40      0.48        15\n",
      "\n",
      "    accuracy                           0.32        25\n",
      "   macro avg       0.26      0.36      0.25        25\n",
      "weighted avg       0.38      0.32      0.32        25\n",
      "\n",
      "[[0 4 3]\n",
      " [0 2 1]\n",
      " [3 6 6]]\n",
      "Validation Loss for P31 = 1.2990936040878296\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_32/3812056636.py:43: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([18, 1, 8064])\n",
      "torch.Size([15, 1, 8064])\n",
      "torch.Size([18, 1, 8064])\n",
      "torch.Size([15, 1, 8064])\n",
      "torch.Size([2, 1, 8064])\n",
      "Epoch 280/300, Train Loss: 1.5800285339355469\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         7\n",
      "           2       0.17      0.67      0.27         3\n",
      "           3       0.60      0.40      0.48        15\n",
      "\n",
      "    accuracy                           0.32        25\n",
      "   macro avg       0.26      0.36      0.25        25\n",
      "weighted avg       0.38      0.32      0.32        25\n",
      "\n",
      "[[0 4 3]\n",
      " [0 2 1]\n",
      " [3 6 6]]\n",
      "Validation Loss for P31 = 1.3060928583145142\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_32/3812056636.py:43: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([18, 1, 8064])\n",
      "torch.Size([15, 1, 8064])\n",
      "torch.Size([18, 1, 8064])\n",
      "torch.Size([15, 1, 8064])\n",
      "torch.Size([2, 1, 8064])\n",
      "Epoch 281/300, Train Loss: 1.3490718603134155\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         7\n",
      "           2       0.17      0.67      0.27         3\n",
      "           3       0.60      0.40      0.48        15\n",
      "\n",
      "    accuracy                           0.32        25\n",
      "   macro avg       0.26      0.36      0.25        25\n",
      "weighted avg       0.38      0.32      0.32        25\n",
      "\n",
      "[[0 4 3]\n",
      " [0 2 1]\n",
      " [3 6 6]]\n",
      "Validation Loss for P31 = 1.3043222427368164\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_32/3812056636.py:43: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([18, 1, 8064])\n",
      "torch.Size([15, 1, 8064])\n",
      "torch.Size([18, 1, 8064])\n",
      "torch.Size([15, 1, 8064])\n",
      "torch.Size([2, 1, 8064])\n",
      "Epoch 282/300, Train Loss: 1.5123109817504883\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         7\n",
      "           2       0.17      0.67      0.27         3\n",
      "           3       0.64      0.47      0.54        15\n",
      "\n",
      "    accuracy                           0.36        25\n",
      "   macro avg       0.27      0.38      0.27        25\n",
      "weighted avg       0.40      0.36      0.36        25\n",
      "\n",
      "[[0 4 3]\n",
      " [0 2 1]\n",
      " [2 6 7]]\n",
      "Validation Loss for P31 = 1.315847396850586\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_32/3812056636.py:43: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([18, 1, 8064])\n",
      "torch.Size([15, 1, 8064])\n",
      "torch.Size([18, 1, 8064])\n",
      "torch.Size([15, 1, 8064])\n",
      "torch.Size([2, 1, 8064])\n",
      "Epoch 283/300, Train Loss: 1.218111515045166\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         7\n",
      "           2       0.17      0.67      0.27         3\n",
      "           3       0.60      0.40      0.48        15\n",
      "\n",
      "    accuracy                           0.32        25\n",
      "   macro avg       0.26      0.36      0.25        25\n",
      "weighted avg       0.38      0.32      0.32        25\n",
      "\n",
      "[[0 4 3]\n",
      " [0 2 1]\n",
      " [3 6 6]]\n",
      "Validation Loss for P31 = 1.3092641830444336\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_32/3812056636.py:43: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([18, 1, 8064])\n",
      "torch.Size([15, 1, 8064])\n",
      "torch.Size([18, 1, 8064])\n",
      "torch.Size([15, 1, 8064])\n",
      "torch.Size([2, 1, 8064])\n",
      "Epoch 284/300, Train Loss: 1.3970921039581299\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         7\n",
      "           2       0.17      0.67      0.27         3\n",
      "           3       0.60      0.40      0.48        15\n",
      "\n",
      "    accuracy                           0.32        25\n",
      "   macro avg       0.26      0.36      0.25        25\n",
      "weighted avg       0.38      0.32      0.32        25\n",
      "\n",
      "[[0 4 3]\n",
      " [0 2 1]\n",
      " [3 6 6]]\n",
      "Validation Loss for P31 = 1.3106828927993774\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_32/3812056636.py:43: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([18, 1, 8064])\n",
      "torch.Size([15, 1, 8064])\n",
      "torch.Size([18, 1, 8064])\n",
      "torch.Size([15, 1, 8064])\n",
      "torch.Size([2, 1, 8064])\n",
      "Epoch 285/300, Train Loss: 1.2555131912231445\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         7\n",
      "           2       0.17      0.67      0.27         3\n",
      "           3       0.60      0.40      0.48        15\n",
      "\n",
      "    accuracy                           0.32        25\n",
      "   macro avg       0.26      0.36      0.25        25\n",
      "weighted avg       0.38      0.32      0.32        25\n",
      "\n",
      "[[0 4 3]\n",
      " [0 2 1]\n",
      " [3 6 6]]\n",
      "Validation Loss for P31 = 1.3120288848876953\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_32/3812056636.py:43: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([18, 1, 8064])\n",
      "torch.Size([15, 1, 8064])\n",
      "torch.Size([18, 1, 8064])\n",
      "torch.Size([15, 1, 8064])\n",
      "torch.Size([2, 1, 8064])\n",
      "Epoch 286/300, Train Loss: 1.4455618858337402\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         7\n",
      "           2       0.18      0.67      0.29         3\n",
      "           3       0.64      0.47      0.54        15\n",
      "\n",
      "    accuracy                           0.36        25\n",
      "   macro avg       0.27      0.38      0.27        25\n",
      "weighted avg       0.40      0.36      0.36        25\n",
      "\n",
      "[[0 4 3]\n",
      " [0 2 1]\n",
      " [3 5 7]]\n",
      "Validation Loss for P31 = 1.311187744140625\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_32/3812056636.py:43: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([18, 1, 8064])\n",
      "torch.Size([15, 1, 8064])\n",
      "torch.Size([18, 1, 8064])\n",
      "torch.Size([15, 1, 8064])\n",
      "torch.Size([2, 1, 8064])\n",
      "Epoch 287/300, Train Loss: 1.5124735832214355\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         7\n",
      "           2       0.17      0.67      0.27         3\n",
      "           3       0.60      0.40      0.48        15\n",
      "\n",
      "    accuracy                           0.32        25\n",
      "   macro avg       0.26      0.36      0.25        25\n",
      "weighted avg       0.38      0.32      0.32        25\n",
      "\n",
      "[[0 4 3]\n",
      " [0 2 1]\n",
      " [3 6 6]]\n",
      "Validation Loss for P31 = 1.310028314590454\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_32/3812056636.py:43: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([18, 1, 8064])\n",
      "torch.Size([15, 1, 8064])\n",
      "torch.Size([18, 1, 8064])\n",
      "torch.Size([15, 1, 8064])\n",
      "torch.Size([2, 1, 8064])\n",
      "Epoch 288/300, Train Loss: 1.2679851055145264\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         7\n",
      "           2       0.21      1.00      0.35         3\n",
      "           3       0.75      0.40      0.52        15\n",
      "\n",
      "    accuracy                           0.36        25\n",
      "   macro avg       0.32      0.47      0.29        25\n",
      "weighted avg       0.48      0.36      0.36        25\n",
      "\n",
      "[[0 5 2]\n",
      " [0 3 0]\n",
      " [3 6 6]]\n",
      "Validation Loss for P31 = 1.3090183734893799\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_32/3812056636.py:43: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([18, 1, 8064])\n",
      "torch.Size([15, 1, 8064])\n",
      "torch.Size([18, 1, 8064])\n",
      "torch.Size([15, 1, 8064])\n",
      "torch.Size([2, 1, 8064])\n",
      "Epoch 289/300, Train Loss: 1.4319424629211426\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         7\n",
      "           2       0.23      1.00      0.38         3\n",
      "           3       0.67      0.40      0.50        15\n",
      "\n",
      "    accuracy                           0.36        25\n",
      "   macro avg       0.30      0.47      0.29        25\n",
      "weighted avg       0.43      0.36      0.34        25\n",
      "\n",
      "[[0 4 3]\n",
      " [0 3 0]\n",
      " [3 6 6]]\n",
      "Validation Loss for P31 = 1.3167471885681152\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_32/3812056636.py:43: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([18, 1, 8064])\n",
      "torch.Size([15, 1, 8064])\n",
      "torch.Size([18, 1, 8064])\n",
      "torch.Size([15, 1, 8064])\n",
      "torch.Size([2, 1, 8064])\n",
      "Epoch 290/300, Train Loss: 1.4648962020874023\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         7\n",
      "           2       0.23      1.00      0.38         3\n",
      "           3       0.67      0.40      0.50        15\n",
      "\n",
      "    accuracy                           0.36        25\n",
      "   macro avg       0.30      0.47      0.29        25\n",
      "weighted avg       0.43      0.36      0.34        25\n",
      "\n",
      "[[0 4 3]\n",
      " [0 3 0]\n",
      " [3 6 6]]\n",
      "Validation Loss for P31 = 1.3251502513885498\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_32/3812056636.py:43: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([18, 1, 8064])\n",
      "torch.Size([15, 1, 8064])\n",
      "torch.Size([18, 1, 8064])\n",
      "torch.Size([15, 1, 8064])\n",
      "torch.Size([2, 1, 8064])\n",
      "Epoch 291/300, Train Loss: 1.2982378005981445\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         7\n",
      "           2       0.23      1.00      0.38         3\n",
      "           3       0.67      0.40      0.50        15\n",
      "\n",
      "    accuracy                           0.36        25\n",
      "   macro avg       0.30      0.47      0.29        25\n",
      "weighted avg       0.43      0.36      0.34        25\n",
      "\n",
      "[[0 4 3]\n",
      " [0 3 0]\n",
      " [3 6 6]]\n",
      "Validation Loss for P31 = 1.3203158378601074\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_32/3812056636.py:43: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([18, 1, 8064])\n",
      "torch.Size([15, 1, 8064])\n",
      "torch.Size([18, 1, 8064])\n",
      "torch.Size([15, 1, 8064])\n",
      "torch.Size([2, 1, 8064])\n",
      "Epoch 292/300, Train Loss: 1.3666936159133911\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         7\n",
      "           2       0.17      0.67      0.27         3\n",
      "           3       0.60      0.40      0.48        15\n",
      "\n",
      "    accuracy                           0.32        25\n",
      "   macro avg       0.26      0.36      0.25        25\n",
      "weighted avg       0.38      0.32      0.32        25\n",
      "\n",
      "[[0 4 3]\n",
      " [0 2 1]\n",
      " [3 6 6]]\n",
      "Validation Loss for P31 = 1.3142023086547852\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_32/3812056636.py:43: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([18, 1, 8064])\n",
      "torch.Size([15, 1, 8064])\n",
      "torch.Size([18, 1, 8064])\n",
      "torch.Size([15, 1, 8064])\n",
      "torch.Size([2, 1, 8064])\n",
      "Epoch 293/300, Train Loss: 1.2911547422409058\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         7\n",
      "           2       0.17      0.67      0.27         3\n",
      "           3       0.60      0.40      0.48        15\n",
      "\n",
      "    accuracy                           0.32        25\n",
      "   macro avg       0.26      0.36      0.25        25\n",
      "weighted avg       0.38      0.32      0.32        25\n",
      "\n",
      "[[0 4 3]\n",
      " [0 2 1]\n",
      " [3 6 6]]\n",
      "Validation Loss for P31 = 1.290406584739685\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_32/3812056636.py:43: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([18, 1, 8064])\n",
      "torch.Size([15, 1, 8064])\n",
      "torch.Size([18, 1, 8064])\n",
      "torch.Size([15, 1, 8064])\n",
      "torch.Size([2, 1, 8064])\n",
      "Epoch 294/300, Train Loss: 1.6862709522247314\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         7\n",
      "           2       0.18      0.67      0.29         3\n",
      "           3       0.64      0.47      0.54        15\n",
      "\n",
      "    accuracy                           0.36        25\n",
      "   macro avg       0.27      0.38      0.27        25\n",
      "weighted avg       0.40      0.36      0.36        25\n",
      "\n",
      "[[0 4 3]\n",
      " [0 2 1]\n",
      " [3 5 7]]\n",
      "Validation Loss for P31 = 1.295846700668335\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_32/3812056636.py:43: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([18, 1, 8064])\n",
      "torch.Size([15, 1, 8064])\n",
      "torch.Size([18, 1, 8064])\n",
      "torch.Size([15, 1, 8064])\n",
      "torch.Size([2, 1, 8064])\n",
      "Epoch 295/300, Train Loss: 1.4734537601470947\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         7\n",
      "           2       0.17      0.67      0.27         3\n",
      "           3       0.64      0.47      0.54        15\n",
      "\n",
      "    accuracy                           0.36        25\n",
      "   macro avg       0.27      0.38      0.27        25\n",
      "weighted avg       0.40      0.36      0.36        25\n",
      "\n",
      "[[0 4 3]\n",
      " [0 2 1]\n",
      " [2 6 7]]\n",
      "Validation Loss for P31 = 1.3004409074783325\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_32/3812056636.py:43: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([18, 1, 8064])\n",
      "torch.Size([15, 1, 8064])\n",
      "torch.Size([18, 1, 8064])\n",
      "torch.Size([15, 1, 8064])\n",
      "torch.Size([2, 1, 8064])\n",
      "Epoch 296/300, Train Loss: 1.238102674484253\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         7\n",
      "           2       0.17      0.67      0.27         3\n",
      "           3       0.64      0.47      0.54        15\n",
      "\n",
      "    accuracy                           0.36        25\n",
      "   macro avg       0.27      0.38      0.27        25\n",
      "weighted avg       0.40      0.36      0.36        25\n",
      "\n",
      "[[0 4 3]\n",
      " [0 2 1]\n",
      " [2 6 7]]\n",
      "Validation Loss for P31 = 1.3152333498001099\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_32/3812056636.py:43: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([18, 1, 8064])\n",
      "torch.Size([15, 1, 8064])\n",
      "torch.Size([18, 1, 8064])\n",
      "torch.Size([15, 1, 8064])\n",
      "torch.Size([2, 1, 8064])\n",
      "Epoch 297/300, Train Loss: 1.4212642908096313\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         7\n",
      "           2       0.17      0.67      0.27         3\n",
      "           3       0.60      0.40      0.48        15\n",
      "\n",
      "    accuracy                           0.32        25\n",
      "   macro avg       0.26      0.36      0.25        25\n",
      "weighted avg       0.38      0.32      0.32        25\n",
      "\n",
      "[[0 4 3]\n",
      " [0 2 1]\n",
      " [3 6 6]]\n",
      "Validation Loss for P31 = 1.3027163743972778\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_32/3812056636.py:43: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([18, 1, 8064])\n",
      "torch.Size([15, 1, 8064])\n",
      "torch.Size([18, 1, 8064])\n",
      "torch.Size([15, 1, 8064])\n",
      "torch.Size([2, 1, 8064])\n",
      "Epoch 298/300, Train Loss: 1.301013708114624\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         7\n",
      "           2       0.17      0.67      0.27         3\n",
      "           3       0.60      0.40      0.48        15\n",
      "\n",
      "    accuracy                           0.32        25\n",
      "   macro avg       0.26      0.36      0.25        25\n",
      "weighted avg       0.38      0.32      0.32        25\n",
      "\n",
      "[[0 4 3]\n",
      " [0 2 1]\n",
      " [3 6 6]]\n",
      "Validation Loss for P31 = 1.2977839708328247\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_32/3812056636.py:43: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([18, 1, 8064])\n",
      "torch.Size([15, 1, 8064])\n",
      "torch.Size([18, 1, 8064])\n",
      "torch.Size([15, 1, 8064])\n",
      "torch.Size([2, 1, 8064])\n",
      "Epoch 299/300, Train Loss: 1.695075273513794\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         7\n",
      "           2       0.17      0.67      0.27         3\n",
      "           3       0.60      0.40      0.48        15\n",
      "\n",
      "    accuracy                           0.32        25\n",
      "   macro avg       0.26      0.36      0.25        25\n",
      "weighted avg       0.38      0.32      0.32        25\n",
      "\n",
      "[[0 4 3]\n",
      " [0 2 1]\n",
      " [3 6 6]]\n",
      "Validation Loss for P31 = 1.3078962564468384\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_32/3812056636.py:43: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([18, 1, 8064])\n",
      "torch.Size([15, 1, 8064])\n",
      "torch.Size([18, 1, 8064])\n",
      "torch.Size([15, 1, 8064])\n",
      "torch.Size([2, 1, 8064])\n",
      "Epoch 300/300, Train Loss: 1.6311728954315186\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         7\n",
      "           2       0.18      0.67      0.29         3\n",
      "           3       0.67      0.53      0.59        15\n",
      "\n",
      "    accuracy                           0.40        25\n",
      "   macro avg       0.28      0.40      0.29        25\n",
      "weighted avg       0.42      0.40      0.39        25\n",
      "\n",
      "[[0 4 3]\n",
      " [0 2 1]\n",
      " [2 5 8]]\n",
      "Validation Loss for P31 = 1.30600106716156\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1000x700 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import confusion_matrix,classification_report\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import preprocessing\n",
    "import matplotlib.pyplot as plt\n",
    "#subjectnames\n",
    "file_list_num = np.arange(len(newsubjectname))\n",
    "file_list_numd = np.arange(len(subjectnamesd))\n",
    "file_list_numcustom = np.arange(len(subjectlistuni))\n",
    "kf = KFold(n_splits=12)\n",
    "torch.manual_seed(42)\n",
    "torch.cuda.manual_seed(42)\n",
    "modellist = []\n",
    "modelid = 1\n",
    "#file_list_num\n",
    "#for i, (train_index, test_index) in enumerate(kf.split(file_list_num)):\n",
    "#for train_index in file_list_num:\n",
    "train_index = file_list_numd\n",
    "test_index_train, test_index_test = train_test_split(file_list_numcustom, test_size=0.30, random_state=42)\n",
    "#test_index = file_list_num\n",
    "print(f\"Fold {i}:\")\n",
    "print(f\"  Train: index={train_index}\")\n",
    "print(f\"  Test:  index={test_index_train}\")\n",
    "net = Net()\n",
    "net.to(device)\n",
    "optimizer = optim.Adam(net.parameters(), lr=0.000001)\n",
    "epochs = 300\n",
    "batch_sz = 20\n",
    "train_loss_epoch = []\n",
    "val_loss_epoch = []\n",
    "for epoch in range(epochs):\n",
    "  train_loss = []\n",
    "  for tr in train_index:\n",
    "    v = data_de1[subjectnamesd[tr]]\n",
    "    l = data_del[subjectnamesd[tr]]\n",
    "    #print(v[0].shape)\n",
    "    net.train()\n",
    "    for i in range(0,len(v),batch_sz):\n",
    "      #print(v[i].shape)\n",
    "      #for j in range(0,v[i].shape[0],batch_sz):\n",
    "      #print(newsubjectname[tr])\n",
    "      optimizer.zero_grad()\n",
    "      outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
    "      #print(\"Expout {}\",outputs.shape)\n",
    "      #print(\"Actual {}\",l[i:i+batch_sz].shape)\n",
    "      #print(l[i].shape)\n",
    "      loss = criterion(outputs, l[i:i+batch_sz].to(device, dtype=torch.float))\n",
    "      loss.backward()\n",
    "      train_loss.append(loss)\n",
    "      optimizer.step()\n",
    "  for tr in test_index_train:\n",
    "    v = data_custom_preprocessed[subjectlistuni[tr]][0]\n",
    "    l = data_label_custom[subjectlistuni[tr]]\n",
    "    #print(subjectlistuni[tr])\n",
    "    #print(v[0].shape)\n",
    "    if(subjectlistuni[tr] == 'P1'):\n",
    "        continue\n",
    "    net.train()\n",
    "    for i in range(0,v.shape[0],v.shape[0]):\n",
    "      #print(v[i].shape)\n",
    "      #for j in range(0,v[i].shape[0],batch_sz):\n",
    "      #print(newsubjectname[tr])\n",
    "      optimizer.zero_grad()\n",
    "      print(v.shape)\n",
    "      outputs = net(v.to(device, dtype=torch.float))\n",
    "      #print(\"Expout {}\",outputs.shape)\n",
    "      #print(\"Actual {}\",l[i:i+batch_sz].shape)\n",
    "      #print(l[i].shape)\n",
    "      loss = criterion(outputs, l.to(device, dtype=torch.float))\n",
    "      loss.backward()\n",
    "      train_loss.append(loss)\n",
    "      optimizer.step()\n",
    "  print(f'Epoch {epoch + 1}/{epochs}, Train Loss: {loss.item()}')\n",
    "  train_loss_epoch.append(torch.stack(train_loss).mean().cpu().detach().numpy())\n",
    "  #print(train_loss_epoch)\n",
    "  expectedoutputamigos = []\n",
    "  actualoutputamigos = []\n",
    "\n",
    "  for tr in test_index_test:\n",
    "      net.eval()\n",
    "      #print(\"Test\\n\")\n",
    "      #print(subjectlistuni[tr])\n",
    "      v = data_custom_preprocessed[subjectlistuni[tr]][0]\n",
    "      l = data_label_custom[subjectlistuni[tr]]\n",
    "      net.eval()\n",
    "      val_loss = []\n",
    "      with torch.no_grad():\n",
    "          for i in range(0,v.shape[0],v.shape[0]):\n",
    "            #print(v[i].shape)\n",
    "            #for j in range(0,v[i].shape[0],batch_sz):\n",
    "            optimizer.zero_grad()\n",
    "            outputs = net(v.to(device, dtype=torch.float))\n",
    "            #print(outputs.shape)\n",
    "            #print(l[i:i+batch_sz].shape)\n",
    "            loss = criterion(outputs, l.to(device, dtype=torch.float))\n",
    "            val_loss.append(loss)\n",
    "            #actualoutputamigos.append(torch.round(outputs.cpu()))\n",
    "            #expectedoutputamigos.append(l[i:i+batch_sz])\n",
    "            actualoutputamigos.append(torch.argmax(torch.softmax(outputs.cpu(),dim=1),dim=1))\n",
    "            expectedoutputamigos.append(torch.argmax(l,dim=1).numpy())\n",
    "  val_loss_mean = torch.stack(val_loss).mean().cpu().detach().numpy()\n",
    "  val_loss_epoch.append(val_loss_mean)\n",
    "  expectedoutputamigos = np.concatenate( expectedoutputamigos, axis=0 )\n",
    "  actualoutputamigos = np.concatenate( actualoutputamigos, axis=0 )\n",
    "  #print(expectedoutput.shape)\n",
    "  #print(actualoutput.shape)\n",
    "  print(classification_report(expectedoutputamigos,actualoutputamigos))\n",
    "  print(confusion_matrix(expectedoutputamigos,actualoutputamigos)) \n",
    "  print(f'Validation Loss for {newsubjectname[tr]} = {val_loss_mean}')\n",
    "ConfusionMatrixDisplay.from_predictions(expectedoutputamigos,actualoutputamigos)\n",
    "plt.figure(figsize=(10,7))\n",
    "#print(len(train_loss_epoch))\n",
    "plt.plot(np.arange(epochs),train_loss_epoch,label='Train')\n",
    "plt.plot(np.arange(epochs),val_loss_epoch,label='Validation')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "43d6ecc9-301e-4a78-a247-6ccc156870a7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-24T12:51:13.201547Z",
     "iopub.status.busy": "2024-01-24T12:51:13.200843Z",
     "iopub.status.idle": "2024-01-24T12:51:13.399976Z",
     "shell.execute_reply": "2024-01-24T12:51:13.399040Z",
     "shell.execute_reply.started": "2024-01-24T12:51:13.201511Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<sklearn.metrics._plot.confusion_matrix.ConfusionMatrixDisplay at 0x7fb4a44aa460>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAggAAAG2CAYAAAAa1H77AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjYuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/av/WaAAAACXBIWXMAAA9hAAAPYQGoP6dpAAA6wklEQVR4nO3deXxTVf7/8XfaQlqgLW3ZLJSyCQiooM4wjKwDiKAo6FhBigUq81VRBESBn4MsCnVmXBC/ilsXUBARkAFGRRTZBPyKUlcEKVtBFBBoabELyf39wRCNFzRpcpsmvJ6Px308zEnuuZ+Y0nz6OeeeYzMMwxAAAMAvhAU6AAAAUPWQIAAAABMSBAAAYEKCAAAATEgQAACACQkCAAAwIUEAAAAmJAgAAMCEBAEAAJiQIAAAABMSBAAAQozD4dDkyZPVtGlTRUVFqXnz5nrkkUfkze4KERbGBwAAAuAf//iH5syZo7lz56pt27baunWrhg8frtjYWI0ePdqjPmxs1gQAQGi5/vrrVb9+fWVmZrrabr75ZkVFRenVV1/1qA8qCBXkdDr13XffKTo6WjabLdDhAAC8ZBiGTp48qcTERIWFWTPiXlJSorKyMr/0ZRiG6fvGbrfLbrebXvvnP/9ZL774onbu3KmWLVvqs88+08aNG/Xkk096dUFUQH5+viGJg4ODgyPIj/z8fEu+J3766SejQb1wv8VZq1YtU9uUKVPOeW2Hw2FMmDDBsNlsRkREhGGz2YyZM2d6FT8VhAqKjo6WJHVWP0WoWoCjgdV2P/aHQIeASlQzn/nbFwJHWYl2vjTd9fvc38rKyvT9YYf2fdJEMdG+/UwVnnQq+cq9ys/PV0xMjKv9XNUDSVq0aJHmz5+vBQsWqG3btsrNzdWYMWOUmJiotLQ0j65JglBBZ8s8EaqmCBsJQqgLi4wMdAioROF2EoQLidXDxLWibaoV7ds1nDpzfkxMjFuCcD4PPPCAJk6cqEGDBkmSLr30Uu3bt08ZGRkkCAAAVAUOwymH4Xsf3jh16pRpXkV4eLicTs/7IUEAAMBCThlyyrcMwdvz+/fvrxkzZqhx48Zq27attm3bpieffFIjRozwuA8SBAAAQswzzzyjyZMn6+6779bhw4eVmJio//mf/9HDDz/scR8kCAAAWMgpp7wbIDh3H96Ijo7WrFmzNGvWrApfkwQBAAALOQxDDh/XJPT1/Ipgqi4AADChggAAgIUCMUnRH0gQAACwkFOGHEGYIDDEAAAATKggAABgIYYYAACACXcxAACAkEEFAQAACzn/e/jaR2UjQQAAwEIOP9zF4Ov5FUGCAACAhRyG/LCbo39i8QZzEAAAgAkVBAAALMQcBAAAYOKUTQ7ZfO6jsjHEAAAATKggAABgIadx5vC1j8pGggAAgIUcfhhi8PX8imCIAQAAmFBBAADAQsFaQSBBAADAQk7DJqfh410MPp5fEQwxAAAAEyoIAABYiCEGAABg4lCYHD4W7B1+isUbJAgAAFjI8MMcBIM5CAAAoCqgggAAgIWYgwAAAEwcRpgcho9zEAKw1DJDDAAAwIQKAgAAFnLKJqePf487VfklBBIEAAAsFKxzEBhiAAAAJlQQAACwkH8mKTLEAABASDkzB8HHzZoYYgAAAFUBFQQAACzk9MNeDIG4i4EKAgAAFjo7B8HXwxtNmjSRzWYzHaNGjfK4DyoIAABYyKmwSl8H4eOPP5bD8fMekF9++aV69+6tW265xeM+SBAAAAgxdevWdXv82GOPqXnz5urWrZvHfZAgAABgIYdhk8PH7ZrPnl9YWOjWbrfbZbfbf/PcsrIyvfrqqxo3bpxsNs/jYA4CAAAWcvx3kqKvhyQlJSUpNjbWdWRkZPzu9ZctW6YTJ05o2LBhXsVNBQEAgCCRn5+vmJgY1+Pfqx5IUmZmpvr27avExESvrkWCAACAhZxGmJw+rqTo/O9KijExMW4Jwu/Zt2+f3nvvPS1dutTra5IgAABgIYcf1kFwVHAdhOzsbNWrV0/XXXed1+cyBwEAgBDkdDqVnZ2ttLQ0RUR4Xw+gggAAgIWcks93MTgrcM57772n/fv3a8SIERW6JgkCAAAW8s9CSd6ff80118jwYRdIhhgAAIAJFQQAACxUkb0UztVHZSNBAADAQk7Z5JSvcxB8O78iSBDgsf7Djuqvdx1WfN3T2v11lJ77e0PtyK0R6LBgodrvHVSd/+TrRNcGOjqwSaDDgZ/d0v5LpbT/SokxJyVJeT/G64VNV+rDPckBjiy0BGsFgTkI8Ei3G47rb1O+0/wnG2hUn5ba/XWkZizYrdiE8kCHBovY9xcpdvNhlSaSBIaqwydr6el1f9LgeX/Vba/8Vf+3r6GeHviOmiccC3RoqAKqZIIwbNgwDRgwwPX4iSeeUFxcnEpKSkyvPXXqlGJiYjR79mxJZ/bAnjVr1u9e47XXXlN4eLhXe2NfyG7621G9syBe774er/3fRmr2hEYq/cmmPoP5RRKKbKUO1X91lw6nNJMzKjzQ4cAi6/KaaOOeZO0/UVv7jtfW/27sqFNl1XRZ4g+BDi2k+HMvhspUJROEXxs6dKiKi4vPuVTk4sWLVVZWptTUVK/6zMzM1IMPPqjXXnvtnIkHfhZRzamLLzulTzdEu9oMw6ZtG6LV5spTAYwMVqm7eI9OXVJbP7WKDXQoqCRhNqeubf2toqqV67Pv6gc6nJDiNGx+OSpbUCQI9erVU//+/ZWVlWV6LisrSwMGDFB8fLzH/e3Zs0ebNm3SxIkT1bJlywqtUX0hiYl3KDxCOnHEfcrK8aMRiqt7OkBRwSq1Pj0q+8Fi/Xh940CHgkrQos6P2nzfS/p43It6qPd6jV12rXb/6PnvU4SuoEgQJCk9PV1r1qzRvn37XG27d+/W+vXrlZ6e7lVf2dnZuu666xQbG6vU1FRlZmb+7jmlpaUqLCx0O4BQE3G8VHXe3KcfUlvIqBY0vx7gg73HaitlbopSX71Zb+S21SP91qgZcxD8yumH4QVfF1qqiKD5DdCnTx8lJiYqOzvb1ZaTk6OkpCT17NnT436cTqdycnJcQxKDBg3Sxo0btWfPnt88LyMjw20P7qSkpIq9kSBUeCxcjtNS7V9VC+LqnNbxI9wIE0rsB4oVUVSupCe+UPP7t6j5/VsUlXdSsRu+V/P7t0jOiq/KhqrptDNc+Sditf2Hupq94U/aeSRBQ678ItBhhZSzuzn6elS2oEkQwsPDlZaWppycHBmGIafTqblz52r48OEKC/P8baxevVrFxcXq16+fJKlOnTrq3bv3OYcvfmnSpEkqKChwHfn5+T69n2ByujxM335eQx06n3S12WyG2ncu0tefMMM9lJy6OFb7H7xM+eN/PkqSaurkFXWUP/4yKazyx0FRucJkqFq4I9BhoAoIqj//RowYoYyMDK1Zs0ZOp1P5+fkaPny4V31kZmbq2LFjioqKcrU5nU59/vnnmjZt2nmTDbvdLrvd7lP8wWzpi3U0fla+dn5WQzu21dDAkUcUWcOpdxcyVhlKjMhwlV3knvQZ1cPkrBlhakfwG91lizbuaazvC2upRvVy9bvkW13V+Dvd9cb1gQ4tpDhkk8PHhY58Pb8igipBaN68ubp166asrCwZhqFevXopOdnzBT1+/PFH/fvf/9bChQvVtm1bV7vD4VDnzp317rvv6tprr7Ui9KC3bnmcYhMcuv2B7xVX97R2fxWlh4Y01Ymj1QIdGoAKiq/xkx7tt0Z1axarqLS6dh5N0F1vXK8t+y6cIdTK4I8hgkAMMVTZBKGgoEC5ublubQkJCUpPT9fIkSMlnZmDcC4HDx40nZucnKxXXnlFCQkJSklJkc3mno3169dPmZmZJAi/YXl2HS3PrhPoMFDJDt7T9vdfhKA0dVWPQIeAKqzKJghr165Vhw4d3NrS09P1zDPP6J577lF4eLjbYkq/9Pjjj+vxxx93a3vllVeUlZWlgQMHmpIDSbr55ps1dOhQHT16VHXq8CUIAPAPh3wfIgjErJAqmSDk5OSctzogSSdOnDjvc3v37j3vc7+1mFJKSopSUlI8iA4AAM8xxAAAAEzYrAkAAIQMKggAAFjIkE1OH+cgGNzmCABAaGGIAQAAhAwqCAAAWMgf2zUHYrtnEgQAACx0dkdGX/uobAwxAAAAEyoIAABYiCEGAABg4lSYnD4W7H09vyIYYgAAACZUEAAAsJDDsMnh4xCBr+dXBAkCAAAWYg4CAAAwMfywm6PBSooAAKAqoIIAAICFHLLJ4eNmS76eXxEkCAAAWMhp+D6HwGn4KRgvMMQAAABMqCAAAGAhpx8mKfp6fkVQQQAAwEJO2fxyeOvgwYNKTU1VQkKCoqKidOmll2rr1q0en08FAQCAEHP8+HFdffXV6tGjh95++23VrVtX3377reLi4jzugwQBAAALBWIlxX/84x9KSkpSdna2q61p06Ze9cEQAwAAFjo7B8HXwxvLly/XVVddpVtuuUX16tVThw4d9NJLL3nVBwkCAABBorCw0O0oLS095+t2796tOXPm6OKLL9aqVat01113afTo0Zo7d67H1yJBAADAQk7ZXPsxVPj47yTFpKQkxcbGuo6MjIxzX9Pp1BVXXKGZM2eqQ4cO+tvf/qaRI0fq+eef9zhu5iAAAGAho4J3Ify6D0nKz89XTEyMq91ut5/z9RdddJHatGnj1nbJJZdoyZIlHl+TBAEAAAv5czfHmJgYtwThfK6++mrt2LHDrW3nzp1KTk72+JoMMQAAEGLGjh2rLVu2aObMmdq1a5cWLFigF198UaNGjfK4DyoIAABYKBArKf7hD3/Qm2++qUmTJmn69Olq2rSpZs2apSFDhnjcBwkCAAAW8ucQgzeuv/56XX/99RW+JkMMAADAhAoCAAAWquheCr/uo7KRIAAAYKFADTH4iiEGAABgQgUBAAALBWsFgQQBAAALBWuCwBADAAAwoYIAAICFgrWCQIIAAICFDPl+m6Lhn1C8QoIAAICFgrWCwBwEAABgQgUBAAALBWsFgQQBAAALBWuCwBADAAAwoYIAAICFgrWCQIIAAICFDMMmw8cveF/PrwiGGAAAgAkVBAAALOSUzeeFknw9vyJIEAAAsFCwzkFgiAEAAJhQQQAAwELBOkmRBAEAAAsF6xADCQIAABYK1goCcxAAAIAJFQTAA4nrA7EbOwIleuePgQ4BleC0o1TbK+E6hh+GGJiDAABAiDEkGT7+jRGIP1EYYgAAACZUEAAAsJBTNtlYSREAAPwSdzEAAICQQQUBAAALOQ2bbCyUBAAAfskw/HAXQwBuY2CIAQAAmFBBAADAQsE6SZEEAQAAC5EgAAAAk2CdpMgcBAAAQszUqVNls9ncjtatW3vVBxUEAAAsFKi7GNq2bav33nvP9TgiwruvfBIEAAAsdCZB8HUOgvfnREREqEGDBhW+JkMMAAAEicLCQrejtLT0vK/99ttvlZiYqGbNmmnIkCHav3+/V9ciQQAAwEJn72Lw9ZCkpKQkxcbGuo6MjIxzXrNjx47KycnRO++8ozlz5mjPnj3q0qWLTp486XHcDDEAAGAh47+Hr31IUn5+vmJiYlztdrv9nK/v27ev678vu+wydezYUcnJyVq0aJHS09M9uiYJAgAAQSImJsYtQfBU7dq11bJlS+3atcvjcxhiAADAQv4cYqiooqIi5eXl6aKLLvL4HBIEAACsZPjp8ML48eO1bt067d27V5s2bdLAgQMVHh6uwYMHe9wHQwwAAFjJDxUAeXn+gQMHNHjwYP3444+qW7euOnfurC1btqhu3boe90GCAABAiFm4cKHPfZAgAABgoUCtpOgrEgQAACwUrLs5MkkRAACYUEEAAMBKhs3rSYbn7KOSkSAAAGChYJ2DwBADAAAwoYIAAICV/LkZQyXyKEFYvny5xx3ecMMNFQ4GAIBQE6x3MXiUIAwYMMCjzmw2mxwOhy/xAACAKsCjBMHpdFodBwAAoSsAQwS+8mkOQklJiSIjI/0VCwAAISdYhxi8vovB4XDokUceUcOGDVWrVi3t3r1bkjR58mRlZmb6PUAAAIJaAHZz9AevE4QZM2YoJydH//znP1W9enVXe7t27fTyyy/7NTgAABAYXicI8+bN04svvqghQ4YoPDzc1X755Zfrm2++8WtwAAAEP5ufjsrl9RyEgwcPqkWLFqZ2p9Op8vJyvwQFAEDICNJ1ELyuILRp00YbNmwwtS9evFgdOnTwS1AAACCwvK4gPPzww0pLS9PBgwfldDq1dOlS7dixQ/PmzdPKlSutiBEAgOB1oVQQbrzxRq1YsULvvfeeatasqYcffljbt2/XihUr1Lt3bytiBAAgeJ3dzdHXo5JVaB2ELl26aPXq1f6OBQAAVBEVXihp69at2r59u6Qz8xKuvPJKvwUFAECoCNbtnr1OEA4cOKDBgwfrww8/VO3atSVJJ06c0J///GctXLhQjRo18neMAAAErwtlDsIdd9yh8vJybd++XceOHdOxY8e0fft2OZ1O3XHHHVbECAAAKpnXFYR169Zp06ZNatWqlautVatWeuaZZ9SlSxe/BgcAQNDzxyTDYJikmJSUdM4FkRwOhxITE/0SFAAAocJmnDl87aOyeT3E8K9//Uv33nuvtm7d6mrbunWr7rvvPj3++ON+DQ4AgKAXpJs1eVRBiIuLk832c3mjuLhYHTt2VETEmdNPnz6tiIgIjRgxQgMGDLAkUAAAUHk8ShBmzZplcRgAAISoUJ6DkJaWZnUcAACEpiC9zbHCCyVJUklJicrKytzaYmJifAoIAAAEnteTFIuLi3XPPfeoXr16qlmzpuLi4twOAADwC0E6SdHrBOHBBx/UmjVrNGfOHNntdr388suaNm2aEhMTNW/ePCtiBAAgeAVpguD1EMOKFSs0b948de/eXcOHD1eXLl3UokULJScna/78+RoyZIgVcQIAgErkdQXh2LFjatasmaQz8w2OHTsmSercubPWr1/v3+gAAAh2F8p2z82aNdOePXvUuHFjtW7dWosWLdIf//hHrVixwrV5E0JT/2FH9de7Diu+7mnt/jpKz/29oXbk1gh0WPCj1Gu2qWv7vUquf0Kl5eH6cnd9zVnWUfmHawc6NFig3aVHdPMt36hFy+NKSCjRI1Ou1uZNDQMdVsi5YFZSHD58uD777DNJ0sSJE/Xss88qMjJSY8eO1QMPPOD3AFE1dLvhuP425TvNf7KBRvVpqd1fR2rGgt2KTTAvu43g1f7iQ3pzfRv9z+M3auwz1yki3Kkn731LkdX5nENRZORp7dldW889c0WgQ0EV5HWCMHbsWI0ePVqS1KtXL33zzTdasGCBtm3bpvvuu8+nYIYNG+a2EuMTTzyhuLg4lZSUmF576tQpxcTEaPbs2ZKkJk2anHNBp6lTp6p9+/am9gMHDqh69epq166dTzFfKG7621G9syBe774er/3fRmr2hEYq/cmmPoOPBTo0+NH4Z/vp7S2ttPdQvPIOJmjmK93VIL5IrRofDXRosMDWjy/SvJxLtfnDRoEOJbQFeJLiY489JpvNpjFjxnh1ntcJwq8lJyfrpptu0mWXXeZrVyZDhw5VcXGxli5danpu8eLFKisrU2pqaoX6zsnJUUpKigoLC/XRRx/5GmpIi6jm1MWXndKnG6JdbYZh07YN0Wpz5akARgar1Yw6s85JYbE9wJEAqIiPP/5YL7zwQoW+oz2ag3D2r3RPnK0u+EO9evXUv39/ZWVl6bbbbnN7LisrSwMGDFB8fLzX/RqGoezsbD333HNq1KiRMjMz1bFjR3+FHXJi4h0Kj5BOHHH/cTl+NEJJLUoDFBWsZrMZGn3zZn2eV197Dnn/7wzAGTb5YQ5CBc4pKirSkCFD9NJLL+nRRx/1+nyPEoSnnnrKo85sNptfEwRJSk9P1/XXX699+/YpOTlZkrR7926tX79eq1atqlCfH3zwgU6dOqVevXqpYcOG+vOf/6ynnnpKNWvWPO85paWlKi39+cuwsLCwQtcGgsW4WzeqaeIxjXryhkCHAuC/fv3dY7fbZbefu8I3atQoXXfdderVq5d1CcKePXu87thf+vTpo8TERGVnZ2vq1KmSzgwPJCUlqWfPnm6vnTBhgv7+97+7tZWVlalNmzZubZmZmRo0aJDCw8PVrl07NWvWTG+88YaGDRt23jgyMjI0bdo0v7ynYFN4LFyO01Ltuqfd2uPqnNbxIz6t1o0qakzKRnVqt1/3PtVfR07UCnQ4QHDz42ZNSUlJbs1TpkxxfTf+0sKFC/Xpp5/q448/rvAlfZ6DYLXw8HClpaUpJydHhmHI6XRq7ty5Gj58uMLC3MN/4IEHlJub63bceeedbq85ceKEli5d6jZ3ITU1VZmZmb8Zx6RJk1RQUOA68vPz/fcmq7jT5WH69vMa6tD5pKvNZjPUvnORvv6E2xxDi6ExKRvV9fK9GvP09Tr0I3urAD7z4yTF/Px8t++iSZMmmS6Xn5+v++67T/Pnz1dkZGSFww6KP/9GjBihjIwMrVmzRk6nU/n5+Ro+fLjpdXXq1FGLFi3c2n49R2HBggUqKSlxm3NwNvHYuXOnWrZsec4YfquMcyFY+mIdjZ+Vr52f1dCObTU0cOQRRdZw6t2FjE2HknG3fqheV+3S/3vhGp0qrab4mDOTUIt+qq6y8qD4dQEvREaWK7Fhketx/QZFatb8uE4WVteRI+cfckXgxMTE/O6miJ988okOHz6sK674+fZVh8Oh9evX63//939VWlqq8PDw371WUPyLb968ubp166asrCwZhqFevXq55iN4KzMzU/fff79pOOHuu+9WVlaWHnvsMT9EHHrWLY9TbIJDtz/wveLqntbur6L00JCmOnG0WqBDgx8N7Pq1JOmZsSvd2me+0k1vb2kViJBgoYtbHtc/nljrevy3u86scbP63SZ66l9/DFBUIaiSt3vu2bOnvvjiC7e24cOHq3Xr1powYYJHyYFUBROEgoIC5ebmurUlJCQoPT1dI0eOlHRmDkJF5Obm6tNPP9X8+fPVunVrt+cGDx6s6dOn69FHH1VERJX731IlLM+uo+XZdQIdBizUZdTfAh0CKtEXn9dTv94pgQ4j5FX2SorR0dGmNX5q1qyphIQEr9b+qXJzENauXasOHTq4HdOmTdPNN98su92uGjVquC2m5I3MzEy1adPGlBxI0sCBA3X48GG99dZbPr4DAACCn80wDK/zmg0bNuiFF15QXl6eFi9erIYNG+qVV15R06ZN1blzZyvirHIKCwsVGxur7rpRETbK7KHu1EDWybiQRO88EegQUAlOO0r1/vbHVVBQ8Lvj+hVx9nuiyaMzFObDZEFJcpaUaO/fH7Is1nPxuoKwZMkS9enTR1FRUdq2bZtrbYCCggLNnDnT7wECABDUArzUckV5nSA8+uijev755/XSSy+pWrWf/3K++uqr9emnn/o1OAAAEBhez8bbsWOHunbtamqPjY3ViRMn/BETAAAh44LZ7rlBgwbatWuXqX3jxo1q1qyZX4ICACBknF1J0dejknmdIIwcOVL33XefPvroI9lsNn333XeaP3++xo8fr7vuusuKGAEACF5BOgfB6yGGiRMnyul0qmfPnjp16pS6du0qu92u8ePH695777UiRgAAUMm8ThBsNpseeughPfDAA9q1a5eKiorUpk0b1arFhi4AAPxasM5BqPCSgdWrVzftkggAAH6lkpda9hevE4QePXrIZjv/ZIk1a9b4FBAAAAg8rxOE9u3buz0uLy9Xbm6uvvzyS6WlpfkrLgAAQoMfhhiCooLw1FNPnbN96tSpKioqOudzAABcsIJ0iMFvmzWlpqYqKyvLX90BAIAA8tu+xps3b1akj5tRAAAQcoK0guB1gnDTTTe5PTYMQ4cOHdLWrVs1efJkvwUGAEAouGBuc4yNjXV7HBYWplatWmn69Om65ppr/BYYAAAIHK8SBIfDoeHDh+vSSy9VXFycVTEBAIAA82qSYnh4uK655hp2bQQAwFNBuheD13cxtGvXTrt377YiFgAAQs7ZOQi+HpXN6wTh0Ucf1fjx47Vy5UodOnRIhYWFbgcAAAh+Hs9BmD59uu6//37169dPknTDDTe4LblsGIZsNpscDof/owQAIJgFoALgK48ThGnTpunOO+/UBx98YGU8AACEllBfB8EwzkTXrVs3y4IBAABVg1e3Of7WLo4AAMDsglgoqWXLlr+bJBw7dsyngAAACCmhPsQgnZmH8OuVFAEAQOjxKkEYNGiQ6tWrZ1UsAACEnJAfYmD+AQAAFRCkQwweL5R09i4GAAAQ+jyuIDidTivjAAAgNAVpBcHr7Z4BAIDnQn4OAgAAqIAgrSB4vVkTAAAIfVQQAACwUpBWEEgQAACwULDOQWCIAQAAmJAgAABgJcNPhxfmzJmjyy67TDExMYqJiVGnTp309ttve9UHCQIAABY6O8Tg6+GNRo0a6bHHHtMnn3yirVu36i9/+YtuvPFGffXVVx73wRwEAABCTP/+/d0ez5gxQ3PmzNGWLVvUtm1bj/ogQQAAwEp+vIuhsLDQrdlut8tut//mqQ6HQ2+88YaKi4vVqVMnjy/JEAMAAFby4xyEpKQkxcbGuo6MjIzzXvaLL75QrVq1ZLfbdeedd+rNN99UmzZtPA6bCgIAAEEiPz9fMTExrse/VT1o1aqVcnNzVVBQoMWLFystLU3r1q3zOEkgQQAAwEK2/x6+9iHJdVeCJ6pXr64WLVpIkq688kp9/PHHevrpp/XCCy94dD4JAgAAVqoiKyk6nU6VlpZ6/HoSBAAALBSIlRQnTZqkvn37qnHjxjp58qQWLFigtWvXatWqVR73QYIAAECIOXz4sG6//XYdOnRIsbGxuuyyy7Rq1Sr17t3b4z5IEAAAsFIAhhgyMzN9vCAJAgAA1gvAZku+Yh0EAABgQgUBAAALBet2zyQIAABYqYrc5ugthhgAAIAJFQQAACzEEAMAADBjiAEAAIQKKgg+OtX/KkVUiwx0GLDYsdSiQIeASrSh0+uBDgGVoPCkU3Etrb8OQwwAAMAsSIcYSBAAALBSkCYIzEEAAAAmVBAAALAQcxAAAIAZQwwAACBUUEEAAMBCNsOQzfCtBODr+RVBggAAgJUYYgAAAKGCCgIAABbiLgYAAGDGEAMAAAgVVBAAALAQQwwAAMAsSIcYSBAAALBQsFYQmIMAAABMqCAAAGAlhhgAAMC5BGKIwFcMMQAAABMqCAAAWMkwzhy+9lHJSBAAALAQdzEAAICQQQUBAAArcRcDAAD4NZvzzOFrH5WNIQYAAGBCBQEAACsF6RADFQQAACx09i4GXw9vZGRk6A9/+IOio6NVr149DRgwQDt27PCqDxIEAACsdHYdBF8PL6xbt06jRo3Sli1btHr1apWXl+uaa65RcXGxx30wxAAAQIh555133B7n5OSoXr16+uSTT9S1a1eP+iBBAADAQv5cKKmwsNCt3W63y263/+75BQUFkqT4+HiPr8kQAwAAVjL8dEhKSkpSbGys68jIyPjdyzudTo0ZM0ZXX3212rVr53HYVBAAAAgS+fn5iomJcT32pHowatQoffnll9q4caNX1yJBAADAQv4cYoiJiXFLEH7PPffco5UrV2r9+vVq1KiRV9ckQQAAwEoB2M3RMAzde++9evPNN7V27Vo1bdrU60uSIAAAEGJGjRqlBQsW6N///reio6P1/fffS5JiY2MVFRXlUR9MUgQAwEKBWChpzpw5KigoUPfu3XXRRRe5jtdff93jPqggAABgpQAstWz4OqQhKggAAOAcqCAAAGAhf97FUJlIEAAAsJLTOHP42kclI0EAAMBKbPcMAABCBRUEAAAsZJMf5iD4JRLvkCAAAGClAKyk6A8MMQAAABMqCAAAWIjbHAEAgBl3MQAAgFBBBQEAAAvZDEM2HycZ+np+RZAgAABgJed/D1/7qGQMMQAAABMqCAAAWIghBgAAYBakdzGQIAAAYCVWUgQAAKGCCgIAABZiJUWErNRrtqlr+71Krn9CpeXh+nJ3fc1Z1lH5h2sHOjRYIOb1w4pZdMStrTyxun545uIARQSrOBzSq0800PtL4nT8SDUl1C9X75Rjum3MD7IFYvvAUMUQg/eGDRumAQMGmNrXrl0rm82mJUuWKDw8XAcPHjzn+RdffLHGjRsnSerevbvGjBljek1OTo5q165tav/pp58UHx+vOnXqqLS01Je3EfLaX3xIb65vo/95/EaNfeY6RYQ79eS9bymyenmgQ4NFypPs+u7llq7jyIymgQ4JFlj0bD2tnFtHo2Yc1EvrvlH6Q9/pjefq6d+ZdQIdGqqAKj0HoWvXrkpISNDcuXNNz61fv167du1Senp6hfpesmSJ2rZtq9atW2vZsmU+Rhraxj/bT29vaaW9h+KVdzBBM1/prgbxRWrV+GigQ4NFjHCbnHHVfj5iKDaGoq+31lSnPgXq2KtQDZLK1OX6Al3R7aR25NYIdGghxeb0z1HZqnSCUK1aNQ0dOlQ5OTmm57KystSxY0e1bdu2Qn1nZmYqNTVVqampyszM9DHSC0vNqDJJUmGxPcCRwCoRh0p10R071OCunYqfdUDhR8oCHRIs0OaqYuVujNaBvDP/lvO+itRX/1dTf/jLyQBHFmLODjH4elSyKv9nQXp6up588kmtX79eXbt2lSQVFRVp8eLFeuqppyrUZ15enjZv3qylS5fKMAyNHTtW+/btU3Jy8nnPKS0tdRuKKCwsrNC1g53NZmj0zZv1eV597TkUH+hwYIGyi6N0/J6GOp1oV9jx04p547Dq/n2vfpjVXEZUeKDDgx/des9hnToZrju6tlZYuOR0SMMmHtJfbjoe6NBQBQQ8QVi5cqVq1arl1uZwOFz/3aZNG/3pT39SVlaWK0FYtGiRDMPQoEGD3M577rnn9PLLL7u1nT59WpGRkW5tWVlZ6tu3r+Li4iRJffr0UXZ2tqZOnXreODMyMjRt2jSv31+oGXfrRjVNPKZRT94Q6FBgkZIron9+0EQ62jJKF925U1EfFupUr7iAxQX/W7+8ttYsjdPEZ/cpuVWJ8r6K0vNTGv53siJJgt8E6UJJAR9i6NGjh3Jzc92OX3/JjxgxQosXL9bJk2fKXllZWbrlllsUHR3t9rohQ4aY+po+fbrbaxwOh+bOnavU1FRXW2pqqnJycuR0nn+QZ9KkSSooKHAd+fn5vr71oDMmZaM6tduv+56+XkdO1Pr9ExASjJrhOn1RdUV8zzBDqHnpkUTdes9hdR9wQk0vKVGvvx7XTSOPaOEz9QMdWkg5u9Syr0dlC3gFoWbNmmrRooVb24EDB9weDxo0SGPHjtWiRYvUtWtXffjhh8rIyDD1FRsba+qrXr16bo9XrVqlgwcP6tZbb3Vrdzgcev/999W7d+9zxmm322W3X6hj7obGpHyorpfv1ehZ/XXox5hAB4RKZPvJoYgfyuWMC/ivC/hZaUmYbGHuXzxh4UYghrtRBQXFv/jo6GjdcsstysrKUl5enlq2bKkuXbpUqK/MzEwNGjRIDz30kFv7jBkzlJmZed4E4UI27tYP1euqXfp/L1yjU6XVFB9zSpJU9FN1lZUHxY8QvBA793v9dFW0HHWrKfzYacW8flhGmHSqc2ygQ4Of/al3oRbOrq96DcvPDDF8GaWlL9TTNYN+DHRooSVI10EImt/u6enp6tKli7Zv364JEyZUqI8jR45oxYoVWr58udq1a+f23O23366BAwfq2LFjio9n8t0vDez6tSTpmbEr3dpnvtJNb29pFYiQYKHwH8uV8NQBhZ10yBETrrJLauhwRjM5Y4Pm1wU8dPejBzT3nxfpfyc10okfI5RQv1z9hh7VkLE/BDq00GJI8vU2RVZSPL/OnTurVatW2rVrl26//fYK9TFv3jzVrFlTPXv2ND3Xs2dPRUVF6dVXX9Xo0aN9DTekdBn1t0CHgEp0bFxSoENAJalRy6m7ph/UXdPPvRgd/CNYt3u2GQajTRVRWFio2NhY/bH/I4qoFvn7JyCoHUstCnQIqERfdZof6BBQCQpPOhXXcrcKCgoUE+P/uVVnvyf+0mGiIsJ9+5447SjRmm2PWRbruQRNBQEAgKBkyA9zEPwSiVdIEAAAsFKQTlIM+DoIAACg6qGCAACAlZySfN0+m82aAAAILYFYSXH9+vXq37+/EhMTZbPZKrRrMQkCAAAhpri4WJdffrmeffbZCvfBEAMAAFYKwCTFvn37qm/fvj5dkgQBAAArBeldDCQIAAAEicLCQrfHVm4kyBwEAACsdLaC4OshKSkpSbGxsa7jXDsb+wsVBAAArOTH2xzz8/Pdllq2qnogkSAAAGApf27WFBMTw14MAACgYoqKirRr1y7X4z179ig3N1fx8fFq3LixR32QIAAAYKUA3MWwdetW9ejRw/V43LhxkqS0tDTl5OR41AcJAgAAVnIaks3HBMHp3fndu3eX4WNSwl0MAADAhAoCAABWYqEkAABg5ocEQZWfIDDEAAAATKggAABgJYYYAACAidOQz0MEXt7F4A8MMQAAABMqCAAAWMlwnjl87aOSkSAAAGAl5iAAAAAT5iAAAIBQQQUBAAArMcQAAABMDPkhQfBLJF5hiAEAAJhQQQAAwEoMMQAAABOnU5KP6xg4K38dBIYYAACACRUEAACsxBADAAAwCdIEgSEGAABgQgUBAAArBelSyyQIAABYyDCcMnzcjdHX8yuCBAEAACsZhu8VAOYgAACAqoAKAgAAVjL8MAeB2xwBAAgxTqdk83EOQQDmIDDEAAAATKggAABgJYYYAADArxlOpwwfhxgCcZsjQwwAAMCECgIAAFZiiAEAAJg4DckWfAkCQwwAAMCECgIAAFYyDEm+roPAEAMAACHFcBoyfBxiMEgQAAAIMYZTvlcQuM0RAAD4ybPPPqsmTZooMjJSHTt21P/93/95fC4JAgAAFjKchl8Ob73++usaN26cpkyZok8//VSXX365+vTpo8OHD3t0PgkCAABWMpz+Obz05JNPauTIkRo+fLjatGmj559/XjVq1FBWVpZH5zMHoYLOThhxlJcEOBJUBsep0kCHgEpUeLLyx3tR+QqLznzOVk8APK1yn9dJOq1ySVJhYaFbu91ul91uN72+rKxMn3zyiSZNmuRqCwsLU69evbR582aPrkmCUEEnT56UJH3yzowAR4JKsSLQAaAyxQU6AFSqkydPKjY21u/9Vq9eXQ0aNNDG79/yS3+1atVSUlKSW9uUKVM0depU02uPHj0qh8Oh+vXru7XXr19f33zzjUfXI0GooMTEROXn5ys6Olo2my3Q4VSawsJCJSUlKT8/XzExMYEOBxbis75wXKiftWEYOnnypBITEy3pPzIyUnv27FFZWZlf+jMMw/R9c67qgb+QIFRQWFiYGjVqFOgwAiYmJuaC+kVyIeOzvnBciJ+1FZWDX4qMjFRkZKSl1ziXOnXqKDw8XD/88INb+w8//KAGDRp41AeTFAEACDHVq1fXlVdeqffff9/V5nQ69f7776tTp04e9UEFAQCAEDRu3DilpaXpqquu0h//+EfNmjVLxcXFGj58uEfnkyDAK3a7XVOmTLF03AtVA5/1hYPPOjTdeuutOnLkiB5++GF9//33at++vd555x3TxMXzsRmBWOAZAABUacxBAAAAJiQIAADAhAQBAACYkCAAAAATEoQL0LBhwzRgwADX4yeeeEJxcXEqKTHvK3Hq1CnFxMRo9uzZkqQmTZpo1qxZv3uN1157TeHh4Ro1apS/woaXrPicp06dqvbt25vaDxw4oOrVq6tdu3b+Ch8e+vXnfNbatWtls9m0ZMkShYeH6+DBg+c8/+KLL9a4ceMkSd27d9eYMWNMr8nJyVHt2rVN7T/99JPi4+NVp04dlZayX0moIUGAhg4dquLiYi1dutT03OLFi1VWVqbU1FSv+szMzNSDDz6o11577ZxfSKh8VnzOZ+Xk5CglJUWFhYX66KOPfA0VftS1a1clJCRo7ty5pufWr1+vXbt2KT09vUJ9L1myRG3btlXr1q21bNkyHyNFVUOCANWrV0/9+/c/5xagWVlZGjBggOLj4z3ub8+ePdq0aZMmTpyoli1bnvMLCZXP35/zWYZhKDs7W0OHDtVtt92mzMxMf4QLP6lWrZqGDh2qnJwc03NZWVnq2LGj2rZtW6G+MzMzlZqaqtTUVD73EESCAElSenq61qxZo3379rnadu/erfXr13v910V2drauu+46xcbG8oujivHn53zWBx98oFOnTqlXr15KTU3VwoULVVxc7K+Q4Qfp6en69ttvtX79eldbUVGRFi9eXOHPPS8vT5s3b1ZKSopSUlK0YcMGt58rBD8SBEiS+vTpo8TERGVnZ7vacnJylJSUpJ49e3rcj9PpVE5OjqtUPWjQIG3cuFF79uzxe8zwnjef84QJE1SrVi23Y+bMmaY+MzMzNWjQIIWHh6tdu3Zq1qyZ3njjDcvfC362cuVK02fVt29f1/Nt2rTRn/70J7fq0aJFi2QYhgYNGuTW13PPPWfq68477zRdMysrS3379lVcXJzi4+PVp08ft58rBD8SBEiSwsPDlZaWppycHBmGIafTqblz52r48OEKC/P8x2T16tUqLi5Wv379JJ3ZUax3797nLGuj8nnzOT/wwAPKzc11O379RXHixAktXbrUbe4CVaPK16NHD9Nn9fLLL7u9ZsSIEVq8eLFOnjwp6cwX/C233KLo6Gi31w0ZMsTU1/Tp091e43A4NHfuXNPnnpOTI6fTadG7RGVjLwa4jBgxQhkZGVqzZo2cTqfy8/M93tTjrMzMTB07dkxRUVGuNqfTqc8//1zTpk3zKtmANTz9nOvUqaMWLVq4tf16jsKCBQtUUlKijh07utrOJh47d+5Uy5YtrXkTcFOzZk3TZ3XgwAG3x4MGDdLYsWO1aNEide3aVR9++KEyMjJMfcXGxpr6qlevntvjVatW6eDBg7r11lvd2h0Oh95//3317t3bl7eDKoIEAS7NmzdXt27dlJWVJcMw1KtXLyUnJ3t8/o8//qh///vfWrhwodukJ4fDoc6dO+vdd9/Vtddea0Xo8IKvn/MvZWZm6v7779ewYcPc2u+++25lZWXpscce80PE8Ifo6GjdcsstysrKUl5enlq2bKkuXbpUqK+zw0oPPfSQW/uMGTOUmZlJghAiSBAuUAUFBcrNzXVrS0hIUHp6ukaOHClJ55z1LEkHDx40nZucnKxXXnlFCQkJSklJkc1mc3u+X79+yszMJEGoZL58zr8nNzdXn376qebPn6/WrVu7PTd48GBNnz5djz76qCIi+DVTVaSnp6tLly7avn27JkyYUKE+jhw5ohUrVmj58uWmdS9uv/12DRw4UMeOHavQHTGoWqj3XqDWrl2rDh06uB3Tpk3TzTffLLvdrho1apxz8RVJevzxx03n/uc//1FWVpYGDhxoSg4k6eabb9by5ct19OhRi98ZfsmXz/n3ZGZmqk2bNqbkQJIGDhyow4cP66233vLxHcCfOnfurFatWqmwsFC33357hfqYN2+eatasec7Jyz179lRUVJReffVVX0NFFcB2zwAAwIQKAgAAMCFBAAAAJiQIAADAhAQBAACYkCAAAAATEgQAAGBCggAAAExIEIAgNmzYMLeFjrp3764xY8ZUehxr166VzWbTiRMnzvsam82mZcuWedzn1KlT1b59e5/i2rt3r2w2m2k1SQC/jwQB8LNhw4bJZrPJZrOpevXqatGihaZPn67Tp09bfu2lS5fqkUce8ei1nnypA7hwsUg6YIFrr71W2dnZKi0t1VtvvaVRo0apWrVqmjRpkum1ZWVlql69ul+uy/r3APyFCgJgAbvdrgYNGig5OVl33XWXevXqpeXLl0v6eVhgxowZSkxMVKtWrSRJ+fn5SklJUe3atRUfH68bb7xRe/fudfXpcDg0btw41a5dWwkJCXrwwQf165XSfz3EUFpaqgkTJigpKUl2u10tWrRQZmam9u7dqx49ekiS4uLiZLPZXDsyOp1OZWRkqGnTpoqKitLll1+uxYsXu13nrbfeUsuWLRUVFaUePXq4xempCRMmqGXLlqpRo4aaNWumyZMnq7y83PS6F154QUlJSapRo4ZSUlJUUFDg9vzLL7+sSy65RJGRkWrdurWee+45r2MBYEaCAFSCqKgolZWVuR6///772rFjh1avXq2VK1eqvLxcffr0UXR0tDZs2KAPP/xQtWrV0rXXXus674knnlBOTo6ysrK0ceNGHTt2TG+++eZvXvf222/Xa6+9ptmzZ2v79u164YUXVKtWLSUlJWnJkiWSpB07dujQoUN6+umnJUkZGRmaN2+enn/+eX311VcaO3asUlNTtW7dOklnEpmbbrpJ/fv3V25uru644w5NnDjR6/8n0dHRysnJ0ddff62nn35aL730kp566im31+zatUuLFi3SihUr9M4772jbtm26++67Xc/Pnz9fDz/8sGbMmKHt27dr5syZmjx5subOnet1PAB+xQDgV2lpacaNN95oGIZhOJ1OY/Xq1YbdbjfGjx/ver5+/fpGaWmp65xXXnnFaNWqleF0Ol1tpaWlRlRUlLFq1SrDMAzjoosuMv75z3+6ni8vLzcaNWrkupZhGEa3bt2M++67zzAMw9ixY4chyVi9evU54/zggw8MScbx48ddbSUlJUaNGjWMTZs2ub02PT3dGDx4sGEYhjFp0iSjTZs2bs9PmDDB1NevSTLefPPN8z7/r3/9y7jyyitdj6dMmWKEh4cbBw4ccLW9/fbbRlhYmHHo0CHDMAyjefPmxoIFC9z6eeSRR4xOnToZhmEYe/bsMSQZ27ZtO+91AZwbcxAAC6xcuVK1atVSeXm5nE6nbrvtNk2dOtX1/KWXXuo27+Czzz7Trl27FB0d7dZPSUmJ8vLyVFBQoEOHDqljx46u5yIiInTVVVeZhhnOys3NVXh4uLp16+Zx3Lt27dKpU6fUu3dvt/aysjJ16NBBkrR9+3a3OCSpU6dOHl/jrNdff12zZ89WXl6eioqKdPr0acXExLi9pnHjxmrYsKHbdZxOp3bs2KHo6Gjl5eUpPT1dI0eOdL3m9OnTio2N9ToeAO5IEAAL9OjRQ3PmzFH16tWVmJioiAj3f2o1a9Z0e1xUVKQrr7xS8+fPN/VVt27dCsUQFRXl9TlFRUWSpP/85z9uX8zSmXkV/rJ582YNGTJE06ZNU58+fRQbG6uFCxfqiSee8DrWl156yZSwhIeH+y1W4EJFggBYoGbNmmrRooXHr7/iiiv0+uuvq169eqa/os+66KKL9NFHH6lr166Szvyl/Mknn+iKK6445+svvfRSOZ1OrVu3Tr169TI9f7aC4XA4XG1t2rSR3W7X/v37z1t5uOSSS1wTLs/asmXL77/JX9i0aZOSk5P10EMPudr27dtnet3+/fv13XffKTEx0XWdsLAwtWrVSvXr11diYqJ2796tIUOGeHV9AL+PSYpAFTBkyBDVqVNHN954ozZs2KA9e/Zo7dq1Gj16tA4cOCBJuu+++/TYY49p2bJl+uabb3T33Xf/5hoGTZo0UVpamkaMGKFly5a5+ly0aJEkKTk5WTabTStXrtSRI0dUVFSk6OhojR8/XmPHjtXcuXOVl5enTz/9VM8884xr4t+dd96pb7/9Vg888IB27NihBQsWKCcnx6v3e/HFF2v//v1auHCh8vLyNHv27HNOuIyMjFRaWpo+++wzbdiwQaNHj1ZKSooaNGggSZo2bZoyMjI0e/Zs7dy5U1988YWys7P15JNPehUPADMSBKAKqFGjhtavX6/GjRvrpptu0iWXXKL09HSVlJS4Kgr333+/hg4dqrS0NHXq1EnR0dEaOHDgb/Y7Z84c/fWvf9Xdd9+t1q1ba+TIkSouLpYkNWzYUNOmTdPEiRNVv3593XPPPZKkRx55RJMnT1ZGRoYuueQSXXvttfrPf/6jpk2bSjozL2DJkiVatmyZLr/8cj3//POaOXOmV+/3hhtu0NixY3XPPfeoffv22rRpkyZPnmx6XYsWLXTTTTepX79+uuaaa3TZZZe53cZ4xx136OWXX1Z2drYuvfRSdevWTTk5Oa5YAVSczTjfDCcAAHDBooIAAABMSBAAAIAJCQIAADAhQQAAACYkCAAAwIQEAQAAmJAgAAAAExIEAABgQoIAAABMSBAAAIAJCQIAADAhQQAAACb/H8Fk/FO0DkcBAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.metrics import ConfusionMatrixDisplay\n",
    "ConfusionMatrixDisplay.from_predictions(expectedoutputamigos,actualoutputamigos,display_labels=['LVLA','LVHA','HVHA'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "585bf627-e03e-4cec-b0ea-fe679bd9a7cd",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-24T13:17:40.676807Z",
     "iopub.status.busy": "2024-01-24T13:17:40.675469Z",
     "iopub.status.idle": "2024-01-24T13:17:40.852135Z",
     "shell.execute_reply": "2024-01-24T13:17:40.851240Z",
     "shell.execute_reply.started": "2024-01-24T13:17:40.676750Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[19, 0, 16, 59]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[Text(0, 0, '19'), Text(0, 0, '0'), Text(0, 0, '16'), Text(0, 0, '59')]"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "counter = [0,0,0,0]\n",
    "labels = ['LVLA(0)', 'HVLA(1)', 'LVHA(2)', 'HVHA(3)']\n",
    "for k,v in data_custom_preprocessed.items():\n",
    "    y = v[1]\n",
    "    \n",
    "    for i in range(y.shape[0]):\n",
    "        if (y[i][0] >= 1 and y[i][1] >= 1):\n",
    "            counter[3] = counter[3]+1\n",
    "        elif (y[i][0] < 1 and y[i][1] >= 1):\n",
    "            counter[2] = counter[2]+1\n",
    "        elif (y[i][0] >= 1 and y[i][1] < 1):\n",
    "            counter[1] = counter[1]+1\n",
    "        elif (y[i][0] < 1 and y[i][1] < 1):\n",
    "            counter[0] = counter[0]+1\n",
    "print(counter)\n",
    "\n",
    "width = 0.30  # the width of the bars\n",
    "x = np.arange(len(labels))\n",
    "#fig, ax = plt.subplots()\n",
    "#rects1 = ax.bar(x - width/2, counter, width, label='Positive')\n",
    "#plt.bar(labels,counter, width = 0.5)\n",
    "fig, ax = plt.subplots()\n",
    "#ax.bar_label(hbars, fmt='%.2f')\n",
    "#fig = plt.figure(figsize = (10, 5))\n",
    "bar_container = ax.bar(labels, counter)\n",
    "ax.set(ylabel='No of Signals', title='Class Distribution-CustomDataset',ylim=(0, 60))\n",
    "ax.bar_label(bar_container, label_type='center')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "93fe08f6-8914-48b6-8dd5-17eaa7fdc244",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-24T13:17:35.627220Z",
     "iopub.status.busy": "2024-01-24T13:17:35.626860Z",
     "iopub.status.idle": "2024-01-24T13:17:35.818639Z",
     "shell.execute_reply": "2024-01-24T13:17:35.817744Z",
     "shell.execute_reply.started": "2024-01-24T13:17:35.627192Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[274, 269, 298, 439]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[Text(0, 0, '274'), Text(0, 0, '269'), Text(0, 0, '298'), Text(0, 0, '439')]"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "counter = [0,0,0,0]\n",
    "labels = ['LVLA(0)', 'HVLA(1)', 'LVHA(2)', 'HVHA(3)']\n",
    "for k,v in data_de.items():\n",
    "    y = data_de[k][1]\n",
    "    for i in range(y.shape[0]):\n",
    "        if (y[i][0] > 5 and y[i][1] > 5):\n",
    "            counter[3] = counter[3]+1\n",
    "        elif (y[i][0] <= 5 and y[i][1] > 5):\n",
    "            counter[2] = counter[2]+1\n",
    "        elif (y[i][0] > 5 and y[i][1] <= 5):\n",
    "            counter[1] = counter[1]+1\n",
    "        elif (y[i][0] <= 5 and y[i][1] <= 5):\n",
    "            counter[0] = counter[0]+1\n",
    "\n",
    "print(counter)\n",
    "\n",
    "width = 0.30  # the width of the bars\n",
    "x = np.arange(len(labels))\n",
    "#fig, ax = plt.subplots()\n",
    "#rects1 = ax.bar(x - width/2, counter, width, label='Positive')\n",
    "#plt.bar(labels,counter, width = 0.5)\n",
    "fig, ax = plt.subplots()\n",
    "#ax.bar_label(hbars, fmt='%.2f')\n",
    "#fig = plt.figure(figsize = (10, 5))\n",
    "bar_container = ax.bar(labels, counter)\n",
    "ax.set(ylabel='No of Signals', title='Class Distribution-DEAP',ylim=(0, 450))\n",
    "ax.bar_label(bar_container, label_type='center')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "13ae83fb-4d41-48f7-ba3a-b140e76c476a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-24T13:17:29.517314Z",
     "iopub.status.busy": "2024-01-24T13:17:29.516304Z",
     "iopub.status.idle": "2024-01-24T13:17:29.689333Z",
     "shell.execute_reply": "2024-01-24T13:17:29.688336Z",
     "shell.execute_reply.started": "2024-01-24T13:17:29.517256Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[150, 183, 206, 181]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[Text(0, 0, '150'), Text(0, 0, '183'), Text(0, 0, '206'), Text(0, 0, '181')]"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "counter = [0,0,0,0]\n",
    "labels = ['LVLA(0)', 'HVLA(1)', 'LVHA(2)', 'HVHA(3)']\n",
    "for k,v in data_cam.items():\n",
    "    y = v[1]\n",
    "    for i in range(y.shape[0]):\n",
    "        if (y[i][1] > 5 and y[i][0] > 5):\n",
    "            counter[3] = counter[3]+1\n",
    "        elif (y[i][1] <= 5 and y[i][0] > 5):\n",
    "            counter[2] = counter[2]+1\n",
    "        elif (y[i][1] > 5 and y[i][0] <= 5):\n",
    "            counter[1] = counter[1]+1\n",
    "        elif (y[i][1] <= 5 and y[i][0] <= 5):\n",
    "            counter[0] = counter[0]+1\n",
    "\n",
    "print(counter)\n",
    "\n",
    "width = 0.30  # the width of the bars\n",
    "x = np.arange(len(labels))\n",
    "#fig, ax = plt.subplots()\n",
    "#rects1 = ax.bar(x - width/2, counter, width, label='Positive')\n",
    "#plt.bar(labels,counter, width = 0.5)\n",
    "fig, ax = plt.subplots()\n",
    "#ax.bar_label(hbars, fmt='%.2f')\n",
    "#fig = plt.figure(figsize = (10, 5))\n",
    "bar_container = ax.bar(labels, counter)\n",
    "ax.set(ylabel='No of Signals', title='Class Distribution-AMIGOS',ylim=(0, 250))\n",
    "ax.bar_label(bar_container, label_type='center')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f72c759-3447-4f8a-9c67-30a7b688f117",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
