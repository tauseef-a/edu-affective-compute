{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "lV6AUpSouNYI",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "lV6AUpSouNYI",
    "outputId": "e479380e-fbed-427b-87fd-cc146892b6da"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mounted at /content/drive\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "njT3xEyzuOSC",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2024-01-21T19:55:18.294674Z",
     "iopub.status.busy": "2024-01-21T19:55:18.294070Z",
     "iopub.status.idle": "2024-01-21T19:55:40.973243Z",
     "shell.execute_reply": "2024-01-21T19:55:40.972658Z",
     "shell.execute_reply.started": "2024-01-21T19:55:18.294651Z"
    },
    "id": "njT3xEyzuOSC",
    "outputId": "d85411f6-4f18-49ad-87f7-ea614f2e47f8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Archive:  AMIGOS.zip\n",
      "  inflating: AMIGOS/Data_Preprocessed_P01.mat  \n",
      "  inflating: AMIGOS/Data_Preprocessed_P02.mat  \n",
      "  inflating: AMIGOS/Data_Preprocessed_P03.mat  \n",
      "  inflating: AMIGOS/Data_Preprocessed_P04.mat  \n",
      "  inflating: AMIGOS/Data_Preprocessed_P05.mat  \n",
      "  inflating: AMIGOS/Data_Preprocessed_P06.mat  \n",
      "  inflating: AMIGOS/Data_Preprocessed_P07.mat  \n",
      "  inflating: AMIGOS/Data_Preprocessed_P08.mat  \n",
      "  inflating: AMIGOS/Data_Preprocessed_P09.mat  \n",
      "  inflating: AMIGOS/Data_Preprocessed_P10.mat  \n",
      "  inflating: AMIGOS/Data_Preprocessed_P11.mat  \n",
      "  inflating: AMIGOS/Data_Preprocessed_P12.mat  \n",
      "  inflating: AMIGOS/Data_Preprocessed_P13.mat  \n",
      "  inflating: AMIGOS/Data_Preprocessed_P14.mat  \n",
      "  inflating: AMIGOS/Data_Preprocessed_P15.mat  \n",
      "  inflating: AMIGOS/Data_Preprocessed_P16.mat  \n",
      "  inflating: AMIGOS/Data_Preprocessed_P17.mat  \n",
      "  inflating: AMIGOS/Data_Preprocessed_P18.mat  \n",
      "  inflating: AMIGOS/Data_Preprocessed_P19.mat  \n",
      "  inflating: AMIGOS/Data_Preprocessed_P20.mat  \n",
      "  inflating: AMIGOS/Data_Preprocessed_P21.mat  \n",
      "  inflating: AMIGOS/Data_Preprocessed_P22.mat  \n",
      "  inflating: AMIGOS/Data_Preprocessed_P23.mat  \n",
      "  inflating: AMIGOS/Data_Preprocessed_P24.mat  \n",
      "  inflating: AMIGOS/Data_Preprocessed_P25.mat  \n",
      "  inflating: AMIGOS/Data_Preprocessed_P26.mat  \n",
      "  inflating: AMIGOS/Data_Preprocessed_P27.mat  \n",
      "  inflating: AMIGOS/Data_Preprocessed_P28.mat  \n",
      "  inflating: AMIGOS/Data_Preprocessed_P29.mat  \n",
      "  inflating: AMIGOS/Data_Preprocessed_P30.mat  \n",
      "  inflating: AMIGOS/Data_Preprocessed_P31.mat  \n",
      "  inflating: AMIGOS/Data_Preprocessed_P32.mat  \n",
      "  inflating: AMIGOS/Data_Preprocessed_P33.mat  \n",
      "  inflating: AMIGOS/Data_Preprocessed_P34.mat  \n",
      "  inflating: AMIGOS/Data_Preprocessed_P35.mat  \n",
      "  inflating: AMIGOS/Data_Preprocessed_P36.mat  \n",
      "  inflating: AMIGOS/Data_Preprocessed_P37.mat  \n",
      "  inflating: AMIGOS/Data_Preprocessed_P38.mat  \n",
      "  inflating: AMIGOS/Data_Preprocessed_P39.mat  \n",
      "  inflating: AMIGOS/Data_Preprocessed_P40.mat  \n"
     ]
    }
   ],
   "source": [
    "!unzip \"AMIGOS.zip\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "GPftEcnHuJrY",
   "metadata": {
    "id": "GPftEcnHuJrY"
   },
   "outputs": [],
   "source": [
    "import scipy.io\n",
    "data = scipy.io.loadmat(\"AMIGOS/Data_Preprocessed_P32.mat\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "Hz_c9Dnoua7T",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Hz_c9Dnoua7T",
    "outputId": "09a9a543-7156-4279-eda3-45021ff3edf9"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 12)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#data['joined_data'][0][19].shape\n",
    "#data['labels_selfassessment'][0][15].shape\n",
    "#data['joined_data'].shape[1]\n",
    "#data['labels_selfassessment'][0][1][0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "SI3v-4-DTC60",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 463
    },
    "id": "SI3v-4-DTC60",
    "outputId": "390a5f34-c7ad-4e73-8513-95e2c0f068e7"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10191,)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.plot(data['joined_data'][0][16][384:,16])\n",
    "data['joined_data'][0][3][384:,16].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "WFGqncuxTz4s",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 463
    },
    "id": "WFGqncuxTz4s",
    "outputId": "2877bf49-f2b1-4a12-9a31-b245c833c2f6"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7bb4a0d7ec80>]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import scipy.io\n",
    "y1 = scipy.signal.resample(data['joined_data'][0][16][:,16], 8000)\n",
    "plt.plot(y1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "81e9e46f-88cc-4ba9-a64f-347034bea365",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2024-01-22T10:02:38.714973Z",
     "iopub.status.busy": "2024-01-22T10:02:38.714697Z",
     "iopub.status.idle": "2024-01-22T10:02:38.723311Z",
     "shell.execute_reply": "2024-01-22T10:02:38.722603Z",
     "shell.execute_reply.started": "2024-01-22T10:02:38.714946Z"
    },
    "id": "81e9e46f-88cc-4ba9-a64f-347034bea365",
    "outputId": "bcb347b1-3a4c-4281-e78d-5555e64d6a27"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['AMIGOS/Data_Preprocessed_P33.mat', 'AMIGOS/Data_Preprocessed_P30.mat', 'AMIGOS/Data_Preprocessed_P13.mat', 'AMIGOS/Data_Preprocessed_P26.mat', 'AMIGOS/Data_Preprocessed_P37.mat', 'AMIGOS/Data_Preprocessed_P31.mat', 'AMIGOS/Data_Preprocessed_P10.mat', 'AMIGOS/Data_Preprocessed_P09.mat', 'AMIGOS/Data_Preprocessed_P05.mat', 'AMIGOS/Data_Preprocessed_P40.mat', 'AMIGOS/Data_Preprocessed_P35.mat', 'AMIGOS/Data_Preprocessed_P32.mat', 'AMIGOS/Data_Preprocessed_P22.mat', 'AMIGOS/Data_Preprocessed_P23.mat', 'AMIGOS/Data_Preprocessed_P17.mat', 'AMIGOS/Data_Preprocessed_P04.mat', 'AMIGOS/Data_Preprocessed_P12.mat', 'AMIGOS/Data_Preprocessed_P34.mat', 'AMIGOS/Data_Preprocessed_P29.mat', 'AMIGOS/Data_Preprocessed_P15.mat', 'AMIGOS/Data_Preprocessed_P02.mat', 'AMIGOS/Data_Preprocessed_P25.mat', 'AMIGOS/Data_Preprocessed_P18.mat', 'AMIGOS/Data_Preprocessed_P36.mat', 'AMIGOS/Data_Preprocessed_P16.mat', 'AMIGOS/Data_Preprocessed_P28.mat', 'AMIGOS/Data_Preprocessed_P03.mat', 'AMIGOS/Data_Preprocessed_P38.mat', 'AMIGOS/Data_Preprocessed_P39.mat', 'AMIGOS/Data_Preprocessed_P27.mat', 'AMIGOS/Data_Preprocessed_P01.mat', 'AMIGOS/Data_Preprocessed_P19.mat', 'AMIGOS/Data_Preprocessed_P06.mat', 'AMIGOS/Data_Preprocessed_P24.mat', 'AMIGOS/Data_Preprocessed_P11.mat', 'AMIGOS/Data_Preprocessed_P08.mat', 'AMIGOS/Data_Preprocessed_P21.mat', 'AMIGOS/Data_Preprocessed_P07.mat', 'AMIGOS/Data_Preprocessed_P14.mat', 'AMIGOS/Data_Preprocessed_P20.mat']\n",
      "['P33', 'P30', 'P13', 'P26', 'P37', 'P31', 'P10', 'P09', 'P05', 'P40', 'P35', 'P32', 'P22', 'P23', 'P17', 'P04', 'P12', 'P34', 'P29', 'P15', 'P02', 'P25', 'P18', 'P36', 'P16', 'P28', 'P03', 'P38', 'P39', 'P27', 'P01', 'P19', 'P06', 'P24', 'P11', 'P08', 'P21', 'P07', 'P14', 'P20']\n"
     ]
    }
   ],
   "source": [
    "import glob\n",
    "import os\n",
    "filelist = glob.glob('AMIGOS/*.mat')\n",
    "print(filelist)\n",
    "subjectnames = [fr[25:28] for fr in filelist]\n",
    "print(subjectnames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "74fe1cd7-c31d-44dd-8537-27f357d17096",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2024-01-22T10:02:41.299246Z",
     "iopub.status.busy": "2024-01-22T10:02:41.298968Z",
     "iopub.status.idle": "2024-01-22T10:03:05.063502Z",
     "shell.execute_reply": "2024-01-22T10:03:05.062790Z",
     "shell.execute_reply.started": "2024-01-22T10:02:41.299224Z"
    },
    "id": "74fe1cd7-c31d-44dd-8537-27f357d17096",
    "outputId": "b02ad912-56e9-45b3-dd39-d9d46bc0a2d4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "P33\n",
      "P30\n",
      "P13\n",
      "P26\n",
      "P37\n",
      "P31\n",
      "P10\n",
      "P09\n",
      "P05\n",
      "P40\n",
      "P35\n",
      "P22\n",
      "P23\n",
      "P17\n",
      "P04\n",
      "P12\n",
      "P34\n",
      "P29\n",
      "P15\n",
      "P02\n",
      "P25\n",
      "P18\n",
      "P36\n",
      "P16\n",
      "P03\n",
      "P38\n",
      "P39\n",
      "P27\n",
      "P01\n",
      "P19\n",
      "P06\n",
      "P11\n",
      "P21\n",
      "P07\n",
      "P14\n",
      "P20\n",
      "dict_keys(['P33', 'P30', 'P13', 'P26', 'P37', 'P31', 'P10', 'P09', 'P05', 'P40', 'P35', 'P22', 'P23', 'P17', 'P04', 'P12', 'P34', 'P29', 'P15', 'P02', 'P25', 'P18', 'P36', 'P16', 'P03', 'P38', 'P39', 'P27', 'P01', 'P19', 'P06', 'P11', 'P21', 'P07', 'P14', 'P20'])\n"
     ]
    }
   ],
   "source": [
    "import scipy.io\n",
    "import numpy as np\n",
    "data_am = {}\n",
    "skiplist = ['P28','P08','P24','P32']\n",
    "newsubjectname = []\n",
    "for sname in subjectnames:\n",
    "    if sname in skiplist:\n",
    "      continue\n",
    "    newsubjectname.append(sname)\n",
    "    dname = \"AMIGOS/Data_Preprocessed_\"+sname+\".mat\"\n",
    "    x = scipy.io.loadmat(dname)\n",
    "    print(sname)\n",
    "    samples = []\n",
    "    samples_labels = []\n",
    "    for i in range(x['joined_data'].shape[1]):\n",
    "        x1 = x['joined_data'][0][i]\n",
    "        x2 = scipy.signal.resample(x1[384:,16], 8064)\n",
    "        y1 = x['labels_selfassessment'][0][i][0][0:2]\n",
    "        samples.append(x2)\n",
    "        samples_labels.append(y1)\n",
    "    samples_stack = np.vstack(samples)\n",
    "    samples_labels_stack = np.vstack(samples_labels)\n",
    "    data_am[sname] = [samples_stack,samples_labels_stack]\n",
    "\n",
    "print(data_am.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "qnHCy6Wra5Fu",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "qnHCy6Wra5Fu",
    "outputId": "9d1b17db-cde0-45d9-96ac-fdac666f660f"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([3237180.31474926, 3110649.65303398, 3179062.7496687 , ...,\n",
       "       3514282.08715568, 3478618.13315719, 3540966.49534216])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_am['P01'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8976cde3-bc3f-4fcb-a8af-d624fcde1675",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2024-01-22T10:03:32.358382Z",
     "iopub.status.busy": "2024-01-22T10:03:32.357742Z",
     "iopub.status.idle": "2024-01-22T10:03:32.657956Z",
     "shell.execute_reply": "2024-01-22T10:03:32.657146Z",
     "shell.execute_reply.started": "2024-01-22T10:03:32.358357Z"
    },
    "id": "8976cde3-bc3f-4fcb-a8af-d624fcde1675",
    "outputId": "35ec17fd-7d92-4bb3-a961-3339979bfbc7"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "data_cam = {}\n",
    "for k,v in data_am.items():\n",
    "    y = v[0]\n",
    "    ym = np.mean(y,axis=-1).reshape(20,1)\n",
    "    ystd = np.std(y,axis=-1).reshape(20,1)\n",
    "    z = (y-ym)/ystd\n",
    "    #print(z.shape)\n",
    "    data_cam[k] = [z,v[1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "kgzh85M-Zyyx",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 448
    },
    "execution": {
     "iopub.execute_input": "2024-01-22T09:46:41.740505Z",
     "iopub.status.busy": "2024-01-22T09:46:41.739848Z",
     "iopub.status.idle": "2024-01-22T09:46:41.864825Z",
     "shell.execute_reply": "2024-01-22T09:46:41.864185Z",
     "shell.execute_reply.started": "2024-01-22T09:46:41.740481Z"
    },
    "id": "kgzh85M-Zyyx",
    "outputId": "10010e12-e6d0-4189-ccc0-b9350a6cf1af"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f4326733d90>]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(data_cam['P01'][0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "56JG3ogz-LUE",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2024-01-22T10:03:58.138279Z",
     "iopub.status.busy": "2024-01-22T10:03:58.137611Z",
     "iopub.status.idle": "2024-01-22T10:03:58.916859Z",
     "shell.execute_reply": "2024-01-22T10:03:58.915994Z",
     "shell.execute_reply.started": "2024-01-22T10:03:58.138253Z"
    },
    "id": "56JG3ogz-LUE",
    "outputId": "d239a446-2b69-4f9c-f45e-c880f8c64511"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 8064])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "data_c1d = {}\n",
    "BLOCK_SIZE=640\n",
    "BLOCK_STRIDE=60\n",
    "for k,v in data_cam.items():\n",
    "    datablocki = []\n",
    "    v1 = v[0]\n",
    "    v1 = v1[:,np.newaxis,:]\n",
    "    #print(v1.shape)\n",
    "    data_c1d[k] = torch.tensor(v1)\n",
    "print(data_c1d['P01'][0].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ce1ed7be-a882-45ec-810d-6b1c43af0af3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-22T10:04:28.619802Z",
     "iopub.status.busy": "2024-01-22T10:04:28.618700Z",
     "iopub.status.idle": "2024-01-22T10:04:28.688356Z",
     "shell.execute_reply": "2024-01-22T10:04:28.687618Z",
     "shell.execute_reply.started": "2024-01-22T10:04:28.619762Z"
    },
    "id": "ce1ed7be-a882-45ec-810d-6b1c43af0af3"
   },
   "outputs": [],
   "source": [
    "data_c2 = {}\n",
    "for k,v in data_cam.items():\n",
    "    y = v[1]\n",
    "    x_label = np.zeros((y.shape[0]),dtype='float64')\n",
    "    for i in range(y.shape[0]):\n",
    "        if (y[i][0] > 5):\n",
    "            x_label[i] = 1\n",
    "        else:\n",
    "            x_label[i] = 0\n",
    "\n",
    "    x_l = x_label\n",
    "    x_l = x_l.reshape(-1,1)\n",
    "    x_l = torch.tensor(x_l)\n",
    "    data_c2[k] = x_l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "fa943a48-8252-4c85-ab48-4e6cb0c101a4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-21T20:26:35.503245Z",
     "iopub.status.busy": "2024-01-21T20:26:35.502318Z",
     "iopub.status.idle": "2024-01-21T20:26:35.509003Z",
     "shell.execute_reply": "2024-01-21T20:26:35.508226Z",
     "shell.execute_reply.started": "2024-01-21T20:26:35.503218Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1.],\n",
       "        [1.],\n",
       "        [0.],\n",
       "        [1.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [0.],\n",
       "        [1.],\n",
       "        [0.],\n",
       "        [1.]], dtype=torch.float64)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_c2['P02']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "Pm5zhOqDgK79",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-22T10:05:08.579581Z",
     "iopub.status.busy": "2024-01-22T10:05:08.578795Z",
     "iopub.status.idle": "2024-01-22T10:05:08.586738Z",
     "shell.execute_reply": "2024-01-22T10:05:08.585969Z",
     "shell.execute_reply.started": "2024-01-22T10:05:08.579556Z"
    },
    "id": "Pm5zhOqDgK79"
   },
   "outputs": [],
   "source": [
    "data_c2 = {}\n",
    "maxnum = 3\n",
    "for k,v in data_cam.items():\n",
    "    y = v[1]\n",
    "    x_label = np.zeros((y.shape[0]),dtype='int32')\n",
    "    for i in range(y.shape[0]):\n",
    "        if (y[i][1] > 5 and y[i][0] > 5):\n",
    "            x_label[i] = 3\n",
    "        elif (y[i][1] <= 5 and y[i][0] > 5):\n",
    "            x_label[i] = 2\n",
    "        elif (y[i][1] > 5 and y[i][0] <= 5):\n",
    "            x_label[i] = 1\n",
    "        elif (y[i][1] <= 5 and y[i][0] <= 5):\n",
    "            x_label[i] = 0\n",
    "\n",
    "    x_l = np.zeros((x_label.size, maxnum+1))\n",
    "    x_l[np.arange(x_label.size), x_label] = 1\n",
    "\n",
    "    x_l = torch.tensor(x_l)\n",
    "    data_c2[k] = x_l\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "6d8e2d1b-cc85-483f-843a-8d7c4b9c5ec8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-22T10:14:03.574101Z",
     "iopub.status.busy": "2024-01-22T10:14:03.573139Z",
     "iopub.status.idle": "2024-01-22T10:14:03.578258Z",
     "shell.execute_reply": "2024-01-22T10:14:03.577561Z",
     "shell.execute_reply.started": "2024-01-22T10:14:03.574074Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([20, 4])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_c2['P01'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "48a74ab5-e71d-441a-b786-630c4abc3685",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-22T10:05:47.338460Z",
     "iopub.status.busy": "2024-01-22T10:05:47.337827Z",
     "iopub.status.idle": "2024-01-22T10:05:47.362656Z",
     "shell.execute_reply": "2024-01-22T10:05:47.361870Z",
     "shell.execute_reply.started": "2024-01-22T10:05:47.338432Z"
    },
    "id": "48a74ab5-e71d-441a-b786-630c4abc3685"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "#from torchinfo import Summary\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.c1=nn.Conv1d(1, 34, 10,stride=1)\n",
    "        self.mp1=nn.MaxPool1d(2)\n",
    "        self.norm1 = nn.BatchNorm1d(34)\n",
    "        self.d = nn.Dropout(p=0.63)\n",
    "        self.c2=nn.Conv1d(34, 30, 10,stride=1)\n",
    "        self.mp2=nn.MaxPool1d(2)\n",
    "        self.c3=nn.Conv1d(30, 10, 10,stride=1)\n",
    "        self.norm3 = nn.BatchNorm1d(10)\n",
    "        self.mp3=nn.MaxPool1d(2)\n",
    "        self.ft = nn.Flatten()\n",
    "\n",
    "        self.n1 = nn.Linear(20070,110)\n",
    "        #self.n1 = nn.Linear(19590,110)\n",
    "        self.normfc1=nn.BatchNorm1d(110)\n",
    "        self.d = nn.Dropout(p=0.63)\n",
    "        #self.d = nn.Dropout()\n",
    "        self.n2 = nn.Linear(110,100)\n",
    "        self.n3 = nn.Linear(100,4)\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.d(self.norm1(F.tanh(self.c1(x))))\n",
    "        #x=F.tanh(self.c1(x))\n",
    "        x = self.mp2(F.tanh(self.c2(x)))\n",
    "        #print(x.shape)\n",
    "        x = self.mp3(F.tanh(self.c3(x)))\n",
    "\n",
    "        #print(x.shape)\n",
    "        x = self.ft(x)\n",
    "        #print(x.shape)\n",
    "        x = F.tanh(self.n1(x))\n",
    "        x=self.normfc1(x)\n",
    "        #x=self.norm3(x)\n",
    "        x=self.d(x)\n",
    "\n",
    "        #x = F.softmax(self.n2(x),dim=-1)\n",
    "        x = F.tanh(self.n2(x))\n",
    "        #x = F.sigmoid(self.n3(x))\n",
    "\n",
    "        x = (self.n3(x))\n",
    "        #print(x.shape)\n",
    "        return x\n",
    "\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "#criterion = nn.BCELoss()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "624818a4-e9ca-4f32-9930-8ade33ca95df",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "execution": {
     "iopub.execute_input": "2024-01-21T20:39:25.503661Z",
     "iopub.status.busy": "2024-01-21T20:39:25.503127Z",
     "iopub.status.idle": "2024-01-21T20:39:41.152046Z",
     "shell.execute_reply": "2024-01-21T20:39:41.151535Z",
     "shell.execute_reply.started": "2024-01-21T20:39:25.503640Z"
    },
    "id": "624818a4-e9ca-4f32-9930-8ade33ca95df",
    "outputId": "7b50a269-a030-4ad0-b013-e506e2fb1233"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 0:\n",
      "  Train: index=[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23\n",
      " 24 25 26 27 28 29 30 31 32 33 34 35]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_203/3472248682.py:38: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1960: UserWarning: nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\n",
      "  warnings.warn(\"nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/60, Train Loss: 0.6609741449356079\n",
      "Epoch 2/60, Train Loss: 0.6968510746955872\n",
      "Epoch 3/60, Train Loss: 0.7063091397285461\n",
      "Epoch 4/60, Train Loss: 0.7129724025726318\n",
      "Epoch 5/60, Train Loss: 0.6755002737045288\n",
      "Epoch 6/60, Train Loss: 0.677463948726654\n",
      "Epoch 7/60, Train Loss: 0.7001715302467346\n",
      "Epoch 8/60, Train Loss: 0.641160249710083\n",
      "Epoch 9/60, Train Loss: 0.6524507403373718\n",
      "Epoch 10/60, Train Loss: 0.6981868147850037\n",
      "Epoch 11/60, Train Loss: 0.7125951051712036\n",
      "Epoch 12/60, Train Loss: 0.6761418581008911\n",
      "Epoch 13/60, Train Loss: 0.6650707125663757\n",
      "Epoch 14/60, Train Loss: 0.6498364806175232\n",
      "Epoch 15/60, Train Loss: 0.6750850081443787\n",
      "Epoch 16/60, Train Loss: 0.7362504005432129\n",
      "Epoch 17/60, Train Loss: 0.6782377362251282\n",
      "Epoch 18/60, Train Loss: 0.6005708575248718\n",
      "Epoch 19/60, Train Loss: 0.6484631896018982\n",
      "Epoch 20/60, Train Loss: 0.6615355610847473\n",
      "Epoch 21/60, Train Loss: 0.7476146817207336\n",
      "Epoch 22/60, Train Loss: 0.6450007557868958\n",
      "Epoch 23/60, Train Loss: 0.6990272998809814\n",
      "Epoch 24/60, Train Loss: 0.6960132718086243\n",
      "Epoch 25/60, Train Loss: 0.6487043499946594\n",
      "Epoch 26/60, Train Loss: 0.6940182447433472\n",
      "Epoch 27/60, Train Loss: 0.7425288558006287\n",
      "Epoch 28/60, Train Loss: 0.7695755958557129\n",
      "Epoch 29/60, Train Loss: 0.6488133072853088\n",
      "Epoch 30/60, Train Loss: 0.6783266067504883\n",
      "Epoch 31/60, Train Loss: 0.6386670470237732\n",
      "Epoch 32/60, Train Loss: 0.6566615700721741\n",
      "Epoch 33/60, Train Loss: 0.6245983242988586\n",
      "Epoch 34/60, Train Loss: 0.6381314396858215\n",
      "Epoch 35/60, Train Loss: 0.6594816446304321\n",
      "Epoch 36/60, Train Loss: 0.6990213394165039\n",
      "Epoch 37/60, Train Loss: 0.7033595442771912\n",
      "Epoch 38/60, Train Loss: 0.72736656665802\n",
      "Epoch 39/60, Train Loss: 0.6317784190177917\n",
      "Epoch 40/60, Train Loss: 0.695755660533905\n",
      "Epoch 41/60, Train Loss: 0.5978154540061951\n",
      "Epoch 42/60, Train Loss: 0.7467979788780212\n",
      "Epoch 43/60, Train Loss: 0.6905636191368103\n",
      "Epoch 44/60, Train Loss: 0.6623584628105164\n",
      "Epoch 45/60, Train Loss: 0.6861650347709656\n",
      "Epoch 46/60, Train Loss: 0.6978986859321594\n",
      "Epoch 47/60, Train Loss: 0.69769287109375\n",
      "Epoch 48/60, Train Loss: 0.6886689066886902\n",
      "Epoch 49/60, Train Loss: 0.6211285591125488\n",
      "Epoch 50/60, Train Loss: 0.7211494445800781\n",
      "Epoch 51/60, Train Loss: 0.645512580871582\n",
      "Epoch 52/60, Train Loss: 0.6711452603340149\n",
      "Epoch 53/60, Train Loss: 0.6328474283218384\n",
      "Epoch 54/60, Train Loss: 0.6318807005882263\n",
      "Epoch 55/60, Train Loss: 0.6630229353904724\n",
      "Epoch 56/60, Train Loss: 0.7082170844078064\n",
      "Epoch 57/60, Train Loss: 0.6603700518608093\n",
      "Epoch 58/60, Train Loss: 0.6021323204040527\n",
      "Epoch 59/60, Train Loss: 0.6721572875976562\n",
      "Epoch 60/60, Train Loss: 0.6605284214019775\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import confusion_matrix,classification_report\n",
    "from sklearn import preprocessing\n",
    "import matplotlib.pyplot as plt\n",
    "#subjectnames\n",
    "file_list_num = np.arange(len(newsubjectname))\n",
    "kf = KFold(n_splits=12)\n",
    "torch.manual_seed(42)\n",
    "torch.cuda.manual_seed(42)\n",
    "modellist = []\n",
    "modelid = 1\n",
    "#file_list_num\n",
    "#for i, (train_index, test_index) in enumerate(kf.split(file_list_num)):\n",
    "#for train_index in file_list_num:\n",
    "train_index = file_list_num\n",
    "print(f\"Fold {i}:\")\n",
    "print(f\"  Train: index={train_index}\")\n",
    "#print(f\"  Test:  index={test_index}\")\n",
    "net = Net()\n",
    "net.to(device)\n",
    "optimizer = optim.Adam(net.parameters(), lr=0.000001)\n",
    "epochs = 60\n",
    "batch_sz = 20\n",
    "train_loss_epoch = []\n",
    "val_loss_epoch = []\n",
    "for epoch in range(epochs):\n",
    "  train_loss = []\n",
    "  for tr in train_index:\n",
    "    v = data_c1d[newsubjectname[tr]]\n",
    "    l = data_c2[newsubjectname[tr]]\n",
    "    #print(v[0].shape)\n",
    "    net.train()\n",
    "    for i in range(0,len(v),batch_sz):\n",
    "      #print(v[i].shape)\n",
    "      #for j in range(0,v[i].shape[0],batch_sz):\n",
    "      #print(newsubjectname[tr])\n",
    "      optimizer.zero_grad()\n",
    "      outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
    "      #print(\"Expout {}\",outputs.shape)\n",
    "      #print(\"Actual {}\",l[i:i+batch_sz].shape)\n",
    "      #print(l[i].shape)\n",
    "      loss = criterion(outputs, l[i:i+batch_sz].to(device, dtype=torch.float))\n",
    "      loss.backward()\n",
    "      train_loss.append(loss)\n",
    "      optimizer.step()\n",
    "  print(f'Epoch {epoch + 1}/{epochs}, Train Loss: {loss.item()}')\n",
    "  train_loss_epoch.append(torch.stack(train_loss).mean().cpu().detach().numpy())\n",
    "\n",
    "  '''\n",
    "  for tr in test_index:\n",
    "      net.eval()\n",
    "      v = data_c1d[newsubjectname[tr]]\n",
    "      l = data_c2[newsubjectname[tr]]\n",
    "      net.eval()\n",
    "      with torch.no_grad():\n",
    "          for i in range(0,len(v),batch_sz):\n",
    "            #print(v[i].shape)\n",
    "            #for j in range(0,v[i].shape[0],batch_sz):\n",
    "            optimizer.zero_grad()\n",
    "            outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
    "            #print(outputs.shape)\n",
    "            #print(l[i].shape)\n",
    "            #outputs1 = torch.softmax(outputs,dim=-1)\n",
    "            loss = criterion(outputs, l[i:i+batch_sz].to(device, dtype=torch.float))\n",
    "            val_loss.append(loss)\n",
    "            #loss.backward()\n",
    "            actualoutput.append(torch.round(outputs.cpu()))\n",
    "            expectedoutput.append(l[i:i+batch_sz])\n",
    "            #actualoutput.append(torch.argmax(torch.softmax(outputs.cpu(),dim=1),dim=1))\n",
    "            #expectedoutput.append(torch.argmax(l[i:i+batch_sz],dim=1).numpy())\n",
    "  val_loss_mean = torch.stack(val_loss).mean().cpu().detach().numpy()\n",
    "  val_loss_epoch.append(val_loss_mean)\n",
    "  expectedoutput = np.concatenate( expectedoutput, axis=0 )\n",
    "  actualoutput = np.concatenate( actualoutput, axis=0 )\n",
    "  print(expectedoutput.shape)\n",
    "  print(actualoutput.shape)\n",
    "  print(classification_report(expectedoutput,actualoutput))\n",
    "  print(confusion_matrix(expectedoutput,actualoutput))\n",
    "  print(f'Validation Loss for {subjectnames[tr]} = {val_loss_mean}')\n",
    "  #break\n",
    "  '''\n",
    "#plt.figure(figsize=(10,7))\n",
    "#print(len(train_loss_epoch))\n",
    "#plt.plot(np.arange(epochs),train_loss_epoch,label='Train')\n",
    "#plt.plot(np.arange(epochs),val_loss_epoch,label='Validation')\n",
    "#plt.legend()\n",
    "#path = \"Model\"+str(modelid) +\".pt\"\n",
    "#path = \"ModelAMIGOS_Aro.pt\"\n",
    "#modelid = modelid+1\n",
    "#print(path)\n",
    "#torch.save(net.state_dict(), path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "5P36UViqRcul",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5P36UViqRcul",
    "outputId": "e071c001-0c26-4c44-ee20-9a315b022829"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-27-7929d1561c85>:33: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs_val = netValence(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "<ipython-input-27-7929d1561c85>:35: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs_aro = netArousal(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.39      0.22      0.28        41\n",
      "           2       0.56      0.12      0.20        42\n",
      "           3       0.24      0.52      0.33        27\n",
      "           4       0.36      0.50      0.42        50\n",
      "\n",
      "    accuracy                           0.33       160\n",
      "   macro avg       0.39      0.34      0.31       160\n",
      "weighted avg       0.40      0.33      0.31       160\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-27-7929d1561c85>:33: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs_val = netValence(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "<ipython-input-27-7929d1561c85>:35: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs_aro = netArousal(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.50      0.17      0.25        42\n",
      "           2       1.00      0.10      0.18        30\n",
      "           3       0.34      0.83      0.48        41\n",
      "           4       0.40      0.36      0.38        47\n",
      "\n",
      "    accuracy                           0.38       160\n",
      "   macro avg       0.56      0.36      0.32       160\n",
      "weighted avg       0.52      0.38      0.33       160\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-27-7929d1561c85>:33: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs_val = netValence(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "<ipython-input-27-7929d1561c85>:35: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs_aro = netArousal(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.21      0.19      0.20        31\n",
      "           2       0.57      0.12      0.20        34\n",
      "           3       0.29      0.53      0.37        43\n",
      "           4       0.48      0.40      0.44        52\n",
      "\n",
      "    accuracy                           0.34       160\n",
      "   macro avg       0.39      0.31      0.30       160\n",
      "weighted avg       0.39      0.34      0.32       160\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-27-7929d1561c85>:33: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs_val = netValence(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "<ipython-input-27-7929d1561c85>:35: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs_aro = netArousal(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.36      0.12      0.19        32\n",
      "           2       0.67      0.05      0.10        39\n",
      "           3       0.30      0.67      0.42        39\n",
      "           4       0.52      0.62      0.56        50\n",
      "\n",
      "    accuracy                           0.39       160\n",
      "   macro avg       0.46      0.37      0.32       160\n",
      "weighted avg       0.47      0.39      0.34       160\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-27-7929d1561c85>:33: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs_val = netValence(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "<ipython-input-27-7929d1561c85>:35: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs_aro = netArousal(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.44      0.10      0.16        42\n",
      "           2       0.33      0.07      0.12        28\n",
      "           3       0.21      0.77      0.33        26\n",
      "           4       0.48      0.36      0.41        64\n",
      "\n",
      "    accuracy                           0.31       160\n",
      "   macro avg       0.37      0.32      0.25       160\n",
      "weighted avg       0.40      0.31      0.28       160\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-27-7929d1561c85>:33: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs_val = netValence(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "<ipython-input-27-7929d1561c85>:35: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs_aro = netArousal(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.56      0.18      0.27        28\n",
      "           2       0.00      0.00      0.00        22\n",
      "           3       0.31      0.71      0.43        48\n",
      "           4       0.55      0.35      0.43        62\n",
      "\n",
      "    accuracy                           0.38       160\n",
      "   macro avg       0.35      0.31      0.28       160\n",
      "weighted avg       0.40      0.38      0.34       160\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-27-7929d1561c85>:33: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs_val = netValence(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "<ipython-input-27-7929d1561c85>:35: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs_aro = netArousal(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "<ipython-input-27-7929d1561c85>:33: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs_val = netValence(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "<ipython-input-27-7929d1561c85>:35: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs_aro = netArousal(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.17      0.03      0.05        33\n",
      "           2       0.00      0.00      0.00        37\n",
      "           3       0.27      0.76      0.39        41\n",
      "           4       0.37      0.29      0.32        49\n",
      "\n",
      "    accuracy                           0.29       160\n",
      "   macro avg       0.20      0.27      0.19       160\n",
      "weighted avg       0.22      0.29      0.21       160\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.26      0.20      0.23        25\n",
      "           2       1.00      0.14      0.24        37\n",
      "           3       0.20      0.55      0.29        33\n",
      "           4       0.50      0.34      0.40        65\n",
      "\n",
      "    accuracy                           0.31       160\n",
      "   macro avg       0.49      0.30      0.29       160\n",
      "weighted avg       0.52      0.31      0.31       160\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import confusion_matrix,classification_report\n",
    "from sklearn import preprocessing\n",
    "import matplotlib.pyplot as plt\n",
    "#subjectnames\n",
    "batch_sz = 20\n",
    "file_list_num = np.arange(len(subjectnames))\n",
    "modelid = 1\n",
    "netValence = Net()\n",
    "valmodelname = \"Valence_Model4\"+\".pt\"\n",
    "netValence.load_state_dict(torch.load(valmodelname))\n",
    "netValence.to(device)\n",
    "netArousal = Net()\n",
    "aromodelname = \"Model5\"+\".pt\"\n",
    "netArousal.load_state_dict(torch.load(aromodelname))\n",
    "netArousal.to(device)\n",
    "for i in range(0,32,4):\n",
    "\n",
    "    #optimizer = optim.Adam(net.parameters(), lr=0.000001)\n",
    "    expectedoutput = []\n",
    "    actualoutput = []\n",
    "    for tr in file_list_num[i:i+4]:\n",
    "        #net.eval()\n",
    "        v = data_c1d[subjectnames[tr]]\n",
    "        l = data_c3[subjectnames[tr]]\n",
    "        netValence.eval()\n",
    "        netArousal.eval()\n",
    "        with torch.no_grad():\n",
    "            for i in range(0,len(v),batch_sz):\n",
    "              #print(v[i].shape)\n",
    "              #for j in range(0,v[i].shape[0],batch_sz):\n",
    "              #optimizer.zero_grad()\n",
    "              outputs_val = netValence(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
    "              outputs_val1 = torch.round(outputs_val)\n",
    "              outputs_aro = netArousal(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
    "              outputs_aro1 = torch.round(outputs_aro)\n",
    "\n",
    "              #print(outputs_val1)\n",
    "              for j in range(0,outputs_aro1.shape[0]):\n",
    "                res = 0\n",
    "                if (outputs_val1[j][0] >= 1 and outputs_aro1[j][0] >= 1):\n",
    "                    res = 4\n",
    "                elif (outputs_val1[j][0] < 1 and outputs_aro1[j][0] >= 1):\n",
    "                    res = 3\n",
    "                elif (outputs_val1[j][0] >= 1 and outputs_aro1[j][0] < 1):\n",
    "                    res = 2\n",
    "                elif (outputs_val1[j][0] < 1 and outputs_aro1[j][0] < 1):\n",
    "                    res = 1\n",
    "                actualoutput.append(res)\n",
    "              #loss = criterion(outputs, l[i:i+batch_sz].to(device, dtype=torch.float))\n",
    "              #val_loss.append(loss)\n",
    "              #loss.backward()\n",
    "              #print(outputs.shape)\n",
    "              #print(l[i:i+batch_sz])\n",
    "              expectedoutput.append(l[i:i+batch_sz])\n",
    "              #actualoutput.append(actualoutput)\n",
    "      #val_loss_mean = torch.stack(val_loss).mean().cpu().detach().numpy()\n",
    "      #val_loss_epoch.append(val_loss_mean)\n",
    "    expectedoutput = np.concatenate( expectedoutput, axis=0 )\n",
    "      #actualoutput = np.concatenate( actualoutput, axis=0 )\n",
    "      #print(actualoutput)\n",
    "    #print(expectedoutput)\n",
    "    #print(actualoutput)\n",
    "    print(classification_report(expectedoutput,actualoutput))\n",
    "      #print(f'Validation Loss for {subjectnames[tr]} = {val_loss_mean}')\n",
    "      #break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9XuinMzzRq3R",
   "metadata": {
    "id": "9XuinMzzRq3R"
   },
   "outputs": [],
   "source": [
    "rm -rf Model*.pt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "8-a4aWI1C7If",
   "metadata": {
    "id": "8-a4aWI1C7If"
   },
   "outputs": [],
   "source": [
    "data_c3 = {}\n",
    "for k,v in data_c.items():\n",
    "    y = data_c[k][1]\n",
    "    x_label = np.zeros((y.shape[0]),dtype='int8')\n",
    "    for i in range(y.shape[0]):\n",
    "        if (y[i][0] > 5 and y[i][1] > 5):\n",
    "            x_label[i] = 4\n",
    "        elif (y[i][0] <= 5 and y[i][1] > 5):\n",
    "            x_label[i] = 3\n",
    "        elif (y[i][0] > 5 and y[i][1] <= 5):\n",
    "            x_label[i] = 2\n",
    "        elif (y[i][0] <= 5 and y[i][1] <= 5):\n",
    "            x_label[i] = 1\n",
    "    #x_l = np.zeros((x_label.size, x_label.max()+1))\n",
    "    #x_l[np.arange(x_label.size), x_label] = 1\n",
    "    #\n",
    "    #print(x_l.shape)\n",
    "    #x_l = x_l.reshape(-1,1,4)\n",
    "    #x_l = np.repeat(x_l, 117, axis=1)\n",
    "    #print(x_l.shape)\n",
    "    x_l = torch.tensor(x_label)\n",
    "    data_c3[k] = x_l\n",
    "    #print(data_c3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "538f2018-fa74-4426-9c36-d56fbeea2f5d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-22T10:06:18.421804Z",
     "iopub.status.busy": "2024-01-22T10:06:18.421138Z",
     "iopub.status.idle": "2024-01-22T10:06:18.426097Z",
     "shell.execute_reply": "2024-01-22T10:06:18.425468Z",
     "shell.execute_reply.started": "2024-01-22T10:06:18.421777Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['DEAP/s21.dat', 'DEAP/s25.dat', 'DEAP/s07.dat', 'DEAP/s22.dat', 'DEAP/s32.dat', 'DEAP/s10.dat', 'DEAP/s04.dat', 'DEAP/s23.dat', 'DEAP/s30.dat', 'DEAP/s06.dat', 'DEAP/s31.dat', 'DEAP/s16.dat', 'DEAP/s15.dat', 'DEAP/s08.dat', 'DEAP/s28.dat', 'DEAP/s17.dat', 'DEAP/s26.dat', 'DEAP/s02.dat', 'DEAP/s19.dat', 'DEAP/s18.dat', 'DEAP/s03.dat', 'DEAP/s29.dat', 'DEAP/s24.dat', 'DEAP/s05.dat', 'DEAP/s14.dat', 'DEAP/s12.dat', 'DEAP/s11.dat', 'DEAP/s27.dat', 'DEAP/s20.dat', 'DEAP/s09.dat', 'DEAP/s13.dat', 'DEAP/s01.dat']\n",
      "['s21', 's25', 's07', 's22', 's32', 's10', 's04', 's23', 's30', 's06', 's31', 's16', 's15', 's08', 's28', 's17', 's26', 's02', 's19', 's18', 's03', 's29', 's24', 's05', 's14', 's12', 's11', 's27', 's20', 's09', 's13', 's01']\n"
     ]
    }
   ],
   "source": [
    "import glob\n",
    "import os\n",
    "filelistd = glob.glob('DEAP/*.dat')\n",
    "print(filelistd)\n",
    "subjectnamesd = [fr[5:8] for fr in filelistd]\n",
    "print(subjectnamesd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "dcb43263-e6f0-4f6f-97fd-ffd8fe6efb21",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-22T10:06:21.310577Z",
     "iopub.status.busy": "2024-01-22T10:06:21.309835Z",
     "iopub.status.idle": "2024-01-22T10:06:28.004305Z",
     "shell.execute_reply": "2024-01-22T10:06:28.003539Z",
     "shell.execute_reply.started": "2024-01-22T10:06:21.310553Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['s21', 's25', 's07', 's22', 's32', 's10', 's04', 's23', 's30', 's06', 's31', 's16', 's15', 's08', 's28', 's17', 's26', 's02', 's19', 's18', 's03', 's29', 's24', 's05', 's14', 's12', 's11', 's27', 's20', 's09', 's13', 's01'])\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "datad = {}\n",
    "for sname in subjectnamesd:\n",
    "    dname = \"DEAP/\"+sname+\".dat\"\n",
    "    f = open(dname, 'rb')\n",
    "    x = pickle.load(f, encoding='latin1')\n",
    "    datad[sname] = x\n",
    "print(datad.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9e192455-a6bc-45f1-b641-9fde46b3586c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-22T10:06:35.955194Z",
     "iopub.status.busy": "2024-01-22T10:06:35.954631Z",
     "iopub.status.idle": "2024-01-22T10:06:36.015017Z",
     "shell.execute_reply": "2024-01-22T10:06:36.014310Z",
     "shell.execute_reply.started": "2024-01-22T10:06:35.955170Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "data_de = {}\n",
    "for k,v in datad.items():\n",
    "    y = datad[k]['data'][:,36,:]\n",
    "    ym = np.mean(y,axis=-1).reshape(40,1)\n",
    "    ystd = np.std(y,axis=-1).reshape(40,1)\n",
    "    z = (y-ym)/ystd\n",
    "    data_de[k] = [z,datad[k]['labels']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b1f12cea-e417-4f5d-b827-53bc3a41b517",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-22T10:06:41.148554Z",
     "iopub.status.busy": "2024-01-22T10:06:41.148009Z",
     "iopub.status.idle": "2024-01-22T10:06:41.184420Z",
     "shell.execute_reply": "2024-01-22T10:06:41.183618Z",
     "shell.execute_reply.started": "2024-01-22T10:06:41.148531Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 8064])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "data_de1 = {}\n",
    "for k,v in data_de.items():\n",
    "    datablocki = []\n",
    "    v1=np.vstack(v[0])\n",
    "    v1 = v1[:,np.newaxis,:]\n",
    "    data_de1[k] = torch.tensor(v1)\n",
    "print(data_de1['s01'][0].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "79b2bfa1-9d78-4f7d-b0f0-17c05654fbaa",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-22T10:13:02.116653Z",
     "iopub.status.busy": "2024-01-22T10:13:02.116089Z",
     "iopub.status.idle": "2024-01-22T10:13:02.124024Z",
     "shell.execute_reply": "2024-01-22T10:13:02.123440Z",
     "shell.execute_reply.started": "2024-01-22T10:13:02.116629Z"
    }
   },
   "outputs": [],
   "source": [
    "data_del = {}\n",
    "ximax = 3\n",
    "for k,v in data_de.items():\n",
    "    y = data_de[k][1]\n",
    "    x_label = np.zeros((y.shape[0]),dtype='int64')\n",
    "    for i in range(y.shape[0]):\n",
    "        if (y[i][0] > 5 and y[i][1] > 5):\n",
    "            x_label[i] = 3\n",
    "        elif (y[i][0] <= 5 and y[i][1] > 5):\n",
    "            x_label[i] = 2\n",
    "        elif (y[i][0] > 5 and y[i][1] <= 5):\n",
    "            x_label[i] = 1\n",
    "        elif (y[i][0] <= 5 and y[i][1] <= 5):\n",
    "            x_label[i] = 0\n",
    "    x_l = np.zeros((x_label.size, ximax+1))\n",
    "    x_l[np.arange(x_label.size), x_label] = 1\n",
    "    #x_l = x_label\n",
    "    #\n",
    "    #print(x_l.shape)\n",
    "    x_l = x_l.reshape(-1,4)\n",
    "\n",
    "    x_l = torch.tensor(x_l)\n",
    "    data_del[k] = x_l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3510574e-92c7-4f83-8ea3-b1c842ec8792",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-22T10:13:04.717606Z",
     "iopub.status.busy": "2024-01-22T10:13:04.717046Z",
     "iopub.status.idle": "2024-01-22T10:13:04.721949Z",
     "shell.execute_reply": "2024-01-22T10:13:04.721218Z",
     "shell.execute_reply.started": "2024-01-22T10:13:04.717580Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([40, 4])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_del['s01'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "00a549ca-dc77-4ef8-a2ce-948a31cb944d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-21T21:26:54.344614Z",
     "iopub.status.busy": "2024-01-21T21:26:54.343936Z",
     "iopub.status.idle": "2024-01-21T21:26:55.114174Z",
     "shell.execute_reply": "2024-01-21T21:26:55.113433Z",
     "shell.execute_reply.started": "2024-01-21T21:26:54.344580Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 20:\n",
      "  Train: index=[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23\n",
      " 24 25 26 27 28 29 30 31]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_410/3061022090.py:39: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1960: UserWarning: nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\n",
      "  warnings.warn(\"nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.45      1.00      0.62       572\n",
      "         1.0       0.00      0.00      0.00       708\n",
      "\n",
      "    accuracy                           0.45      1280\n",
      "   macro avg       0.22      0.50      0.31      1280\n",
      "weighted avg       0.20      0.45      0.28      1280\n",
      "\n",
      "[[572   0]\n",
      " [708   0]]\n",
      "Validation Loss for s01 = 0.6970333456993103\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.9/dist-packages/sklearn/metrics/_classification.py:1334: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.9/dist-packages/sklearn/metrics/_classification.py:1334: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.9/dist-packages/sklearn/metrics/_classification.py:1334: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import confusion_matrix,classification_report\n",
    "from sklearn import preprocessing\n",
    "import matplotlib.pyplot as plt\n",
    "#subjectnames\n",
    "file_list_numd = np.arange(len(subjectnamesd))\n",
    "net = Net()\n",
    "net.to(device)\n",
    "optimizer = optim.Adam(net.parameters(), lr=0.000001)\n",
    "torch.manual_seed(42)\n",
    "torch.cuda.manual_seed(42)\n",
    "expectedoutputdeap = []\n",
    "actualoutputdeap = []\n",
    "val_loss = []\n",
    "expectedoutput = []\n",
    "actualoutput = []\n",
    "test_index = file_list_numd\n",
    "print(f\"Fold {i}:\")\n",
    "print(f\"  Train: index={test_index}\")\n",
    "#print(f\"  Test:  index={test_index}\")\n",
    "#net = Net()\n",
    "#net.to(device)\n",
    "#optimizer = optim.Adam(net.parameters(), lr=0.000001)\n",
    "#epochs = 60\n",
    "batch_sz = 20\n",
    "train_loss_epoch = []\n",
    "val_loss_epoch = []\n",
    "\n",
    "for tr in test_index:\n",
    "    net.eval()\n",
    "    v = data_de1[subjectnamesd[tr]]\n",
    "    l = data_del[subjectnamesd[tr]]\n",
    "    net.eval()\n",
    "    with torch.no_grad():\n",
    "        for i in range(0,len(v),batch_sz):\n",
    "          #print(v[i].shape)\n",
    "          #for j in range(0,v[i].shape[0],batch_sz):\n",
    "          optimizer.zero_grad()\n",
    "          outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
    "          #print(outputs.shape)\n",
    "          #print(l[i:i+batch_sz].shape)\n",
    "          loss = criterion(outputs, l[i:i+batch_sz].to(device, dtype=torch.float))\n",
    "          val_loss.append(loss)\n",
    "          actualoutputdeap.append(torch.round(outputs.cpu()))\n",
    "          expectedoutputdeap.append(l[i:i+batch_sz])\n",
    "          #actualoutput.append(torch.argmax(torch.softmax(outputs.cpu(),dim=1),dim=1))\n",
    "          #expectedoutput.append(torch.argmax(l[i:i+batch_sz],dim=1).numpy())\n",
    "val_loss_mean = torch.stack(val_loss).mean().cpu().detach().numpy()\n",
    "val_loss_epoch.append(val_loss_mean)\n",
    "expectedoutputdeap = np.concatenate( expectedoutputdeap, axis=0 )\n",
    "actualoutputdeap = np.concatenate( actualoutputdeap, axis=0 )\n",
    "#print(expectedoutput.shape)\n",
    "#print(actualoutput.shape)\n",
    "print(classification_report(expectedoutputdeap,actualoutputdeap))\n",
    "print(confusion_matrix(expectedoutputdeap,actualoutputdeap))\n",
    "print(f'Validation Loss for {subjectnamesd[tr]} = {val_loss_mean}')\n",
    "#break\n",
    "\n",
    "#plt.figure(figsize=(10,7))\n",
    "#print(len(train_loss_epoch))\n",
    "#plt.plot(np.arange(epochs),train_loss_epoch,label='Train')\n",
    "#plt.plot(np.arange(epochs),val_loss_epoch,label='Validation')\n",
    "#plt.legend()\n",
    "#path = \"Model\"+str(modelid) +\".pt\"\n",
    "#path = \"ModelAMIGOS_Aro.pt\"\n",
    "#modelid = modelid+1\n",
    "#print(path)\n",
    "#torch.save(net.state_dict(), path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "44278dac-15a4-400c-8676-184267c3942e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-22T10:27:32.978940Z",
     "iopub.status.busy": "2024-01-22T10:27:32.978656Z",
     "iopub.status.idle": "2024-01-22T10:29:06.071354Z",
     "shell.execute_reply": "2024-01-22T10:29:06.068721Z",
     "shell.execute_reply.started": "2024-01-22T10:27:32.978917Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 20:\n",
      "  Train: index=[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23\n",
      " 24 25 26 27 28 29 30 31 32 33 34 35]\n",
      "  Test:  index=[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23\n",
      " 24 25 26 27 28 29 30 31]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_173/503690333.py:40: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100, Train Loss: 1.4774000644683838\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.17      0.01      0.03       274\n",
      "           1       0.22      0.51      0.31       269\n",
      "           2       0.21      0.24      0.22       298\n",
      "           3       0.36      0.23      0.28       439\n",
      "\n",
      "    accuracy                           0.25      1280\n",
      "   macro avg       0.24      0.25      0.21      1280\n",
      "weighted avg       0.25      0.25      0.22      1280\n",
      "\n",
      "[[  4 136  68  66]\n",
      " [  1 138  83  47]\n",
      " [  4 151  71  72]\n",
      " [ 15 198 123 103]]\n",
      "Validation Loss for s01 = 1.4376871585845947\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_173/503690333.py:66: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/tmp/ipykernel_173/503690333.py:40: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/100, Train Loss: 1.4647613763809204\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.24      0.14      0.17       274\n",
      "           1       0.22      0.50      0.30       269\n",
      "           2       0.20      0.23      0.22       298\n",
      "           3       0.40      0.16      0.23       439\n",
      "\n",
      "    accuracy                           0.24      1280\n",
      "   macro avg       0.26      0.26      0.23      1280\n",
      "weighted avg       0.28      0.24      0.23      1280\n",
      "\n",
      "[[ 37 139  66  32]\n",
      " [ 21 134  83  31]\n",
      " [ 39 149  69  41]\n",
      " [ 60 188 122  69]]\n",
      "Validation Loss for s01 = 1.446808099746704\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_173/503690333.py:66: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/tmp/ipykernel_173/503690333.py:40: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/100, Train Loss: 1.4199023246765137\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_173/503690333.py:66: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.23      0.14      0.18       274\n",
      "           1       0.22      0.55      0.32       269\n",
      "           2       0.20      0.22      0.21       298\n",
      "           3       0.42      0.12      0.19       439\n",
      "\n",
      "    accuracy                           0.24      1280\n",
      "   macro avg       0.27      0.26      0.22      1280\n",
      "weighted avg       0.29      0.24      0.22      1280\n",
      "\n",
      "[[ 39 149  66  20]\n",
      " [ 19 147  77  26]\n",
      " [ 45 160  65  28]\n",
      " [ 63 208 115  53]]\n",
      "Validation Loss for s01 = 1.4444996118545532\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_173/503690333.py:40: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/100, Train Loss: 1.4120477437973022\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.23      0.18      0.20       274\n",
      "           1       0.22      0.52      0.31       269\n",
      "           2       0.21      0.21      0.21       298\n",
      "           3       0.42      0.11      0.17       439\n",
      "\n",
      "    accuracy                           0.24      1280\n",
      "   macro avg       0.27      0.26      0.22      1280\n",
      "weighted avg       0.29      0.24      0.22      1280\n",
      "\n",
      "[[ 49 144  61  20]\n",
      " [ 33 141  70  25]\n",
      " [ 56 156  64  22]\n",
      " [ 78 199 114  48]]\n",
      "Validation Loss for s01 = 1.442763328552246\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_173/503690333.py:66: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/tmp/ipykernel_173/503690333.py:40: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/100, Train Loss: 1.5109905004501343\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_173/503690333.py:66: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.25      0.39      0.30       274\n",
      "           1       0.24      0.37      0.29       269\n",
      "           2       0.21      0.21      0.21       298\n",
      "           3       0.39      0.10      0.16       439\n",
      "\n",
      "    accuracy                           0.25      1280\n",
      "   macro avg       0.27      0.27      0.24      1280\n",
      "weighted avg       0.28      0.25      0.23      1280\n",
      "\n",
      "[[108  83  61  22]\n",
      " [ 75 100  69  25]\n",
      " [104 110  63  21]\n",
      " [150 132 114  43]]\n",
      "Validation Loss for s01 = 1.442159652709961\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_173/503690333.py:40: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6/100, Train Loss: 1.3759068250656128\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_173/503690333.py:66: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.23      0.50      0.32       274\n",
      "           1       0.24      0.26      0.25       269\n",
      "           2       0.21      0.21      0.21       298\n",
      "           3       0.40      0.10      0.16       439\n",
      "\n",
      "    accuracy                           0.25      1280\n",
      "   macro avg       0.27      0.27      0.24      1280\n",
      "weighted avg       0.29      0.25      0.23      1280\n",
      "\n",
      "[[136  62  54  22]\n",
      " [106  71  67  25]\n",
      " [153  62  62  21]\n",
      " [185 101 108  45]]\n",
      "Validation Loss for s01 = 1.4387538433074951\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_173/503690333.py:40: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7/100, Train Loss: 1.402468204498291\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_173/503690333.py:66: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.25      0.43      0.31       274\n",
      "           1       0.25      0.38      0.30       269\n",
      "           2       0.21      0.20      0.21       298\n",
      "           3       0.39      0.09      0.15       439\n",
      "\n",
      "    accuracy                           0.25      1280\n",
      "   macro avg       0.27      0.28      0.24      1280\n",
      "weighted avg       0.29      0.25      0.23      1280\n",
      "\n",
      "[[118  87  50  19]\n",
      " [ 79 103  62  25]\n",
      " [120  99  60  19]\n",
      " [160 130 109  40]]\n",
      "Validation Loss for s01 = 1.4405407905578613\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_173/503690333.py:40: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8/100, Train Loss: 1.4878965616226196\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_173/503690333.py:66: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.24      0.49      0.32       274\n",
      "           1       0.25      0.31      0.28       269\n",
      "           2       0.21      0.19      0.20       298\n",
      "           3       0.38      0.10      0.16       439\n",
      "\n",
      "    accuracy                           0.25      1280\n",
      "   macro avg       0.27      0.27      0.24      1280\n",
      "weighted avg       0.29      0.25      0.23      1280\n",
      "\n",
      "[[135  69  48  22]\n",
      " [ 97  83  61  28]\n",
      " [146  73  58  21]\n",
      " [184 108 103  44]]\n",
      "Validation Loss for s01 = 1.4388427734375\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_173/503690333.py:40: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9/100, Train Loss: 1.4712499380111694\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_173/503690333.py:66: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.24      0.53      0.33       274\n",
      "           1       0.25      0.29      0.27       269\n",
      "           2       0.22      0.19      0.21       298\n",
      "           3       0.36      0.08      0.14       439\n",
      "\n",
      "    accuracy                           0.25      1280\n",
      "   macro avg       0.27      0.27      0.23      1280\n",
      "weighted avg       0.28      0.25      0.22      1280\n",
      "\n",
      "[[145  62  46  21]\n",
      " [108  77  57  27]\n",
      " [155  68  58  17]\n",
      " [195 104 103  37]]\n",
      "Validation Loss for s01 = 1.4473025798797607\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_173/503690333.py:40: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10/100, Train Loss: 1.3282685279846191\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_173/503690333.py:66: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.23      0.55      0.33       274\n",
      "           1       0.22      0.21      0.22       269\n",
      "           2       0.21      0.19      0.20       298\n",
      "           3       0.36      0.09      0.14       439\n",
      "\n",
      "    accuracy                           0.24      1280\n",
      "   macro avg       0.26      0.26      0.22      1280\n",
      "weighted avg       0.27      0.24      0.21      1280\n",
      "\n",
      "[[151  55  46  22]\n",
      " [125  57  60  27]\n",
      " [164  58  57  19]\n",
      " [207  89 104  39]]\n",
      "Validation Loss for s01 = 1.4455190896987915\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_173/503690333.py:40: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11/100, Train Loss: 1.2842960357666016\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_173/503690333.py:66: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.24      0.54      0.33       274\n",
      "           1       0.24      0.25      0.24       269\n",
      "           2       0.21      0.18      0.20       298\n",
      "           3       0.37      0.09      0.15       439\n",
      "\n",
      "    accuracy                           0.24      1280\n",
      "   macro avg       0.26      0.27      0.23      1280\n",
      "weighted avg       0.28      0.24      0.22      1280\n",
      "\n",
      "[[149  57  46  22]\n",
      " [115  68  59  27]\n",
      " [157  68  55  18]\n",
      " [204  94 101  40]]\n",
      "Validation Loss for s01 = 1.4464690685272217\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_173/503690333.py:40: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12/100, Train Loss: 1.422817587852478\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_173/503690333.py:66: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.24      0.54      0.33       274\n",
      "           1       0.24      0.26      0.25       269\n",
      "           2       0.21      0.17      0.19       298\n",
      "           3       0.37      0.10      0.16       439\n",
      "\n",
      "    accuracy                           0.25      1280\n",
      "   macro avg       0.26      0.27      0.23      1280\n",
      "weighted avg       0.28      0.25      0.22      1280\n",
      "\n",
      "[[148  59  44  23]\n",
      " [113  71  54  31]\n",
      " [156  69  52  21]\n",
      " [199 102  94  44]]\n",
      "Validation Loss for s01 = 1.4437942504882812\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_173/503690333.py:40: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13/100, Train Loss: 1.4975078105926514\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_173/503690333.py:66: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.24      0.53      0.33       274\n",
      "           1       0.24      0.27      0.25       269\n",
      "           2       0.21      0.17      0.19       298\n",
      "           3       0.37      0.10      0.16       439\n",
      "\n",
      "    accuracy                           0.24      1280\n",
      "   macro avg       0.26      0.27      0.23      1280\n",
      "weighted avg       0.28      0.24      0.22      1280\n",
      "\n",
      "[[144  63  44  23]\n",
      " [111  73  53  32]\n",
      " [159  68  50  21]\n",
      " [196 104  94  45]]\n",
      "Validation Loss for s01 = 1.4406757354736328\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_173/503690333.py:40: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14/100, Train Loss: 1.3804224729537964\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_173/503690333.py:66: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.23      0.54      0.33       274\n",
      "           1       0.23      0.26      0.24       269\n",
      "           2       0.21      0.17      0.19       298\n",
      "           3       0.36      0.10      0.15       439\n",
      "\n",
      "    accuracy                           0.24      1280\n",
      "   macro avg       0.26      0.27      0.23      1280\n",
      "weighted avg       0.27      0.24      0.22      1280\n",
      "\n",
      "[[147  60  44  23]\n",
      " [115  69  53  32]\n",
      " [162  65  51  20]\n",
      " [202 103  91  43]]\n",
      "Validation Loss for s01 = 1.444824457168579\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_173/503690333.py:40: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15/100, Train Loss: 1.4407507181167603\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_173/503690333.py:66: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.24      0.53      0.33       274\n",
      "           1       0.23      0.29      0.26       269\n",
      "           2       0.21      0.15      0.18       298\n",
      "           3       0.36      0.10      0.15       439\n",
      "\n",
      "    accuracy                           0.24      1280\n",
      "   macro avg       0.26      0.27      0.23      1280\n",
      "weighted avg       0.27      0.24      0.22      1280\n",
      "\n",
      "[[146  64  41  23]\n",
      " [111  77  48  33]\n",
      " [161  72  45  20]\n",
      " [197 118  81  43]]\n",
      "Validation Loss for s01 = 1.444901704788208\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_173/503690333.py:40: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16/100, Train Loss: 1.342295527458191\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_173/503690333.py:66: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.24      0.53      0.33       274\n",
      "           1       0.24      0.32      0.28       269\n",
      "           2       0.21      0.15      0.18       298\n",
      "           3       0.38      0.11      0.17       439\n",
      "\n",
      "    accuracy                           0.25      1280\n",
      "   macro avg       0.27      0.28      0.24      1280\n",
      "weighted avg       0.28      0.25      0.23      1280\n",
      "\n",
      "[[144  67  39  24]\n",
      " [101  85  50  33]\n",
      " [152  80  46  20]\n",
      " [193 116  83  47]]\n",
      "Validation Loss for s01 = 1.4521396160125732\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_173/503690333.py:40: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17/100, Train Loss: 1.4612079858779907\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_173/503690333.py:66: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.24      0.52      0.33       274\n",
      "           1       0.24      0.32      0.27       269\n",
      "           2       0.22      0.15      0.18       298\n",
      "           3       0.39      0.12      0.18       439\n",
      "\n",
      "    accuracy                           0.25      1280\n",
      "   macro avg       0.27      0.28      0.24      1280\n",
      "weighted avg       0.29      0.25      0.23      1280\n",
      "\n",
      "[[143  67  38  26]\n",
      " [102  85  46  36]\n",
      " [150  83  45  20]\n",
      " [192 122  73  52]]\n",
      "Validation Loss for s01 = 1.4484121799468994\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_173/503690333.py:40: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 18/100, Train Loss: 1.3985904455184937\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_173/503690333.py:66: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.25      0.50      0.33       274\n",
      "           1       0.23      0.34      0.28       269\n",
      "           2       0.22      0.15      0.18       298\n",
      "           3       0.37      0.11      0.17       439\n",
      "\n",
      "    accuracy                           0.25      1280\n",
      "   macro avg       0.27      0.27      0.24      1280\n",
      "weighted avg       0.28      0.25      0.23      1280\n",
      "\n",
      "[[136  73  39  26]\n",
      " [ 95  92  47  35]\n",
      " [142  93  45  18]\n",
      " [178 140  74  47]]\n",
      "Validation Loss for s01 = 1.4564499855041504\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_173/503690333.py:40: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19/100, Train Loss: 1.457750678062439\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_173/503690333.py:66: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.24      0.43      0.31       274\n",
      "           1       0.23      0.39      0.29       269\n",
      "           2       0.21      0.15      0.18       298\n",
      "           3       0.38      0.11      0.18       439\n",
      "\n",
      "    accuracy                           0.25      1280\n",
      "   macro avg       0.27      0.27      0.24      1280\n",
      "weighted avg       0.28      0.25      0.23      1280\n",
      "\n",
      "[[117  91  39  27]\n",
      " [ 84 105  47  33]\n",
      " [122 111  45  20]\n",
      " [160 150  79  50]]\n",
      "Validation Loss for s01 = 1.4552674293518066\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_173/503690333.py:40: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20/100, Train Loss: 1.4630085229873657\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_173/503690333.py:66: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.24      0.46      0.32       274\n",
      "           1       0.23      0.38      0.29       269\n",
      "           2       0.23      0.15      0.18       298\n",
      "           3       0.39      0.12      0.18       439\n",
      "\n",
      "    accuracy                           0.25      1280\n",
      "   macro avg       0.27      0.28      0.24      1280\n",
      "weighted avg       0.29      0.25      0.23      1280\n",
      "\n",
      "[[126  84  37  27]\n",
      " [ 89 102  43  35]\n",
      " [133 103  44  18]\n",
      " [168 152  67  52]]\n",
      "Validation Loss for s01 = 1.453776478767395\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_173/503690333.py:40: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 21/100, Train Loss: 1.2972480058670044\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_173/503690333.py:66: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.25      0.51      0.33       274\n",
      "           1       0.23      0.33      0.27       269\n",
      "           2       0.22      0.15      0.18       298\n",
      "           3       0.40      0.12      0.18       439\n",
      "\n",
      "    accuracy                           0.25      1280\n",
      "   macro avg       0.27      0.28      0.24      1280\n",
      "weighted avg       0.29      0.25      0.23      1280\n",
      "\n",
      "[[140  68  39  27]\n",
      " [ 99  88  47  35]\n",
      " [149  86  44  19]\n",
      " [182 136  68  53]]\n",
      "Validation Loss for s01 = 1.4472476243972778\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_173/503690333.py:40: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 22/100, Train Loss: 1.396145224571228\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_173/503690333.py:66: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.24      0.49      0.33       274\n",
      "           1       0.23      0.35      0.28       269\n",
      "           2       0.23      0.14      0.17       298\n",
      "           3       0.39      0.13      0.19       439\n",
      "\n",
      "    accuracy                           0.25      1280\n",
      "   macro avg       0.27      0.28      0.24      1280\n",
      "weighted avg       0.29      0.25      0.23      1280\n",
      "\n",
      "[[133  76  37  28]\n",
      " [ 94  95  42  38]\n",
      " [144  93  42  19]\n",
      " [173 148  63  55]]\n",
      "Validation Loss for s01 = 1.4445704221725464\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_173/503690333.py:40: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 23/100, Train Loss: 1.425146222114563\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_173/503690333.py:66: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.25      0.54      0.34       274\n",
      "           1       0.23      0.31      0.26       269\n",
      "           2       0.22      0.14      0.17       298\n",
      "           3       0.39      0.12      0.18       439\n",
      "\n",
      "    accuracy                           0.25      1280\n",
      "   macro avg       0.27      0.28      0.24      1280\n",
      "weighted avg       0.29      0.25      0.23      1280\n",
      "\n",
      "[[148  62  39  25]\n",
      " [104  83  43  39]\n",
      " [156  81  42  19]\n",
      " [189 132  66  52]]\n",
      "Validation Loss for s01 = 1.4424551725387573\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_173/503690333.py:40: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 24/100, Train Loss: 1.3915777206420898\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_173/503690333.py:66: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.24      0.57      0.34       274\n",
      "           1       0.22      0.25      0.24       269\n",
      "           2       0.21      0.14      0.17       298\n",
      "           3       0.39      0.12      0.18       439\n",
      "\n",
      "    accuracy                           0.25      1280\n",
      "   macro avg       0.27      0.27      0.23      1280\n",
      "weighted avg       0.28      0.25      0.22      1280\n",
      "\n",
      "[[156  54  37  27]\n",
      " [119  68  46  36]\n",
      " [174  64  41  19]\n",
      " [200 119  67  53]]\n",
      "Validation Loss for s01 = 1.4460400342941284\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_173/503690333.py:40: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 25/100, Train Loss: 1.390722393989563\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_173/503690333.py:66: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.24      0.58      0.34       274\n",
      "           1       0.21      0.23      0.22       269\n",
      "           2       0.21      0.13      0.16       298\n",
      "           3       0.40      0.13      0.19       439\n",
      "\n",
      "    accuracy                           0.25      1280\n",
      "   macro avg       0.27      0.27      0.23      1280\n",
      "weighted avg       0.28      0.25      0.22      1280\n",
      "\n",
      "[[159  53  37  25]\n",
      " [124  63  45  37]\n",
      " [175  64  40  19]\n",
      " [204 115  65  55]]\n",
      "Validation Loss for s01 = 1.4439913034439087\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_173/503690333.py:40: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 26/100, Train Loss: 1.442102074623108\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_173/503690333.py:66: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.25      0.56      0.34       274\n",
      "           1       0.23      0.28      0.25       269\n",
      "           2       0.21      0.13      0.16       298\n",
      "           3       0.40      0.13      0.20       439\n",
      "\n",
      "    accuracy                           0.25      1280\n",
      "   macro avg       0.27      0.27      0.24      1280\n",
      "weighted avg       0.29      0.25      0.23      1280\n",
      "\n",
      "[[154  56  39  25]\n",
      " [113  74  43  39]\n",
      " [163  75  39  21]\n",
      " [196 123  63  57]]\n",
      "Validation Loss for s01 = 1.4349769353866577\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_173/503690333.py:40: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 27/100, Train Loss: 1.3607255220413208\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_173/503690333.py:66: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.25      0.55      0.34       274\n",
      "           1       0.23      0.30      0.26       269\n",
      "           2       0.21      0.13      0.16       298\n",
      "           3       0.40      0.13      0.20       439\n",
      "\n",
      "    accuracy                           0.26      1280\n",
      "   macro avg       0.27      0.28      0.24      1280\n",
      "weighted avg       0.29      0.26      0.23      1280\n",
      "\n",
      "[[151  59  37  27]\n",
      " [106  81  43  39]\n",
      " [159  80  38  21]\n",
      " [191 127  63  58]]\n",
      "Validation Loss for s01 = 1.4369165897369385\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_173/503690333.py:40: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 28/100, Train Loss: 1.339952826499939\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_173/503690333.py:66: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.25      0.54      0.34       274\n",
      "           1       0.24      0.32      0.27       269\n",
      "           2       0.22      0.13      0.16       298\n",
      "           3       0.40      0.13      0.20       439\n",
      "\n",
      "    accuracy                           0.26      1280\n",
      "   macro avg       0.27      0.28      0.24      1280\n",
      "weighted avg       0.29      0.26      0.24      1280\n",
      "\n",
      "[[148  61  37  28]\n",
      " [102  86  40  41]\n",
      " [156  83  38  21]\n",
      " [187 133  60  59]]\n",
      "Validation Loss for s01 = 1.435209035873413\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_173/503690333.py:40: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 29/100, Train Loss: 1.486368179321289\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_173/503690333.py:66: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.25      0.50      0.33       274\n",
      "           1       0.23      0.34      0.27       269\n",
      "           2       0.22      0.13      0.16       298\n",
      "           3       0.39      0.13      0.20       439\n",
      "\n",
      "    accuracy                           0.25      1280\n",
      "   macro avg       0.27      0.28      0.24      1280\n",
      "weighted avg       0.29      0.25      0.23      1280\n",
      "\n",
      "[[138  71  36  29]\n",
      " [ 97  91  40  41]\n",
      " [145  94  38  21]\n",
      " [176 143  61  59]]\n",
      "Validation Loss for s01 = 1.431317925453186\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_173/503690333.py:40: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 30/100, Train Loss: 1.3619089126586914\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.25      0.47      0.32       274\n",
      "           1       0.22      0.36      0.28       269\n",
      "           2       0.22      0.12      0.16       298\n",
      "           3       0.39      0.13      0.20       439\n",
      "\n",
      "    accuracy                           0.25      1280\n",
      "   macro avg       0.27      0.27      0.24      1280\n",
      "weighted avg       0.28      0.25      0.23      1280\n",
      "\n",
      "[[128  83  33  30]\n",
      " [ 92  98  37  42]\n",
      " [133 107  36  22]\n",
      " [167 154  59  59]]\n",
      "Validation Loss for s01 = 1.4323978424072266\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_173/503690333.py:66: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/tmp/ipykernel_173/503690333.py:40: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 31/100, Train Loss: 1.497385859489441\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_173/503690333.py:66: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.24      0.48      0.32       274\n",
      "           1       0.23      0.35      0.27       269\n",
      "           2       0.23      0.13      0.17       298\n",
      "           3       0.40      0.13      0.20       439\n",
      "\n",
      "    accuracy                           0.25      1280\n",
      "   macro avg       0.27      0.27      0.24      1280\n",
      "weighted avg       0.29      0.25      0.23      1280\n",
      "\n",
      "[[131  79  35  29]\n",
      " [ 95  95  40  39]\n",
      " [141  98  39  20]\n",
      " [172 150  59  58]]\n",
      "Validation Loss for s01 = 1.4305775165557861\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_173/503690333.py:40: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 32/100, Train Loss: 1.4459789991378784\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_173/503690333.py:66: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.25      0.54      0.34       274\n",
      "           1       0.23      0.31      0.26       269\n",
      "           2       0.22      0.12      0.16       298\n",
      "           3       0.39      0.13      0.20       439\n",
      "\n",
      "    accuracy                           0.26      1280\n",
      "   macro avg       0.27      0.28      0.24      1280\n",
      "weighted avg       0.29      0.26      0.23      1280\n",
      "\n",
      "[[148  63  34  29]\n",
      " [107  83  39  40]\n",
      " [158  81  37  22]\n",
      " [187 134  59  59]]\n",
      "Validation Loss for s01 = 1.4305458068847656\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_173/503690333.py:40: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 33/100, Train Loss: 1.4938093423843384\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_173/503690333.py:66: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.24      0.55      0.34       274\n",
      "           1       0.23      0.30      0.26       269\n",
      "           2       0.21      0.12      0.15       298\n",
      "           3       0.41      0.13      0.20       439\n",
      "\n",
      "    accuracy                           0.25      1280\n",
      "   macro avg       0.27      0.28      0.24      1280\n",
      "weighted avg       0.29      0.25      0.23      1280\n",
      "\n",
      "[[150  62  34  28]\n",
      " [111  82  40  36]\n",
      " [161  80  35  22]\n",
      " [193 128  59  59]]\n",
      "Validation Loss for s01 = 1.4369267225265503\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_173/503690333.py:40: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 34/100, Train Loss: 1.3867642879486084\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.24      0.53      0.34       274\n",
      "           1       0.24      0.33      0.28       269\n",
      "           2       0.20      0.12      0.15       298\n",
      "           3       0.40      0.13      0.19       439\n",
      "\n",
      "    accuracy                           0.25      1280\n",
      "   macro avg       0.27      0.28      0.24      1280\n",
      "weighted avg       0.29      0.25      0.23      1280\n",
      "\n",
      "[[146  65  35  28]\n",
      " [105  89  43  32]\n",
      " [160  82  35  21]\n",
      " [186 139  59  55]]\n",
      "Validation Loss for s01 = 1.4434452056884766\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_173/503690333.py:66: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/tmp/ipykernel_173/503690333.py:40: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 35/100, Train Loss: 1.3797661066055298\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.24      0.56      0.34       274\n",
      "           1       0.23      0.30      0.26       269\n",
      "           2       0.21      0.12      0.15       298\n",
      "           3       0.42      0.13      0.20       439\n",
      "\n",
      "    accuracy                           0.25      1280\n",
      "   macro avg       0.28      0.28      0.24      1280\n",
      "weighted avg       0.29      0.25      0.23      1280\n",
      "\n",
      "[[153  61  35  25]\n",
      " [115  80  42  32]\n",
      " [161  80  36  21]\n",
      " [198 126  59  56]]\n",
      "Validation Loss for s01 = 1.4383742809295654\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_173/503690333.py:66: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/tmp/ipykernel_173/503690333.py:40: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 36/100, Train Loss: 1.3346285820007324\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_173/503690333.py:66: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.25      0.55      0.35       274\n",
      "           1       0.24      0.34      0.28       269\n",
      "           2       0.20      0.11      0.15       298\n",
      "           3       0.41      0.13      0.19       439\n",
      "\n",
      "    accuracy                           0.26      1280\n",
      "   macro avg       0.28      0.28      0.24      1280\n",
      "weighted avg       0.29      0.26      0.23      1280\n",
      "\n",
      "[[150  64  35  25]\n",
      " [104  91  42  32]\n",
      " [157  86  34  21]\n",
      " [182 143  59  55]]\n",
      "Validation Loss for s01 = 1.4427063465118408\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_173/503690333.py:40: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 37/100, Train Loss: 1.3911925554275513\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_173/503690333.py:66: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.25      0.51      0.34       274\n",
      "           1       0.23      0.35      0.28       269\n",
      "           2       0.20      0.11      0.14       298\n",
      "           3       0.42      0.13      0.20       439\n",
      "\n",
      "    accuracy                           0.25      1280\n",
      "   macro avg       0.27      0.28      0.24      1280\n",
      "weighted avg       0.29      0.25      0.23      1280\n",
      "\n",
      "[[141  74  33  26]\n",
      " [100  95  39  35]\n",
      " [146 100  32  20]\n",
      " [175 152  54  58]]\n",
      "Validation Loss for s01 = 1.4375253915786743\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_173/503690333.py:40: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 38/100, Train Loss: 1.3027889728546143\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_173/503690333.py:66: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.25      0.55      0.34       274\n",
      "           1       0.22      0.30      0.26       269\n",
      "           2       0.20      0.11      0.14       298\n",
      "           3       0.41      0.13      0.20       439\n",
      "\n",
      "    accuracy                           0.25      1280\n",
      "   macro avg       0.27      0.27      0.23      1280\n",
      "weighted avg       0.29      0.25      0.23      1280\n",
      "\n",
      "[[152  63  33  26]\n",
      " [114  81  39  35]\n",
      " [162  84  32  20]\n",
      " [191 137  54  57]]\n",
      "Validation Loss for s01 = 1.4389803409576416\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_173/503690333.py:40: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 39/100, Train Loss: 1.4661582708358765\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_173/503690333.py:66: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.25      0.55      0.34       274\n",
      "           1       0.22      0.30      0.26       269\n",
      "           2       0.20      0.11      0.14       298\n",
      "           3       0.42      0.12      0.19       439\n",
      "\n",
      "    accuracy                           0.25      1280\n",
      "   macro avg       0.27      0.27      0.23      1280\n",
      "weighted avg       0.29      0.25      0.22      1280\n",
      "\n",
      "[[152  63  35  24]\n",
      " [112  81  44  32]\n",
      " [162  83  33  20]\n",
      " [192 136  57  54]]\n",
      "Validation Loss for s01 = 1.4390778541564941\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_173/503690333.py:40: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 40/100, Train Loss: 1.322748064994812\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_173/503690333.py:66: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.25      0.52      0.34       274\n",
      "           1       0.23      0.35      0.28       269\n",
      "           2       0.21      0.11      0.14       298\n",
      "           3       0.41      0.13      0.20       439\n",
      "\n",
      "    accuracy                           0.25      1280\n",
      "   macro avg       0.27      0.28      0.24      1280\n",
      "weighted avg       0.29      0.25      0.23      1280\n",
      "\n",
      "[[143  73  31  27]\n",
      " [101  94  39  35]\n",
      " [149  97  32  20]\n",
      " [180 150  52  57]]\n",
      "Validation Loss for s01 = 1.4379385709762573\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_173/503690333.py:40: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 41/100, Train Loss: 1.4850116968154907\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.25      0.55      0.34       274\n",
      "           1       0.23      0.32      0.27       269\n",
      "           2       0.21      0.11      0.14       298\n",
      "           3       0.41      0.13      0.20       439\n",
      "\n",
      "    accuracy                           0.25      1280\n",
      "   macro avg       0.27      0.28      0.24      1280\n",
      "weighted avg       0.29      0.25      0.23      1280\n",
      "\n",
      "[[151  65  31  27]\n",
      " [108  85  40  36]\n",
      " [162  83  33  20]\n",
      " [189 138  55  57]]\n",
      "Validation Loss for s01 = 1.4329006671905518\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_173/503690333.py:66: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/tmp/ipykernel_173/503690333.py:40: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 42/100, Train Loss: 1.3058209419250488\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.24      0.56      0.33       274\n",
      "           1       0.22      0.28      0.25       269\n",
      "           2       0.20      0.11      0.14       298\n",
      "           3       0.41      0.13      0.19       439\n",
      "\n",
      "    accuracy                           0.25      1280\n",
      "   macro avg       0.27      0.27      0.23      1280\n",
      "weighted avg       0.28      0.25      0.22      1280\n",
      "\n",
      "[[153  61  33  27]\n",
      " [119  74  42  34]\n",
      " [169  76  33  20]\n",
      " [200 124  59  56]]\n",
      "Validation Loss for s01 = 1.4330083131790161\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_173/503690333.py:66: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/tmp/ipykernel_173/503690333.py:40: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 43/100, Train Loss: 1.2896959781646729\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.25      0.53      0.34       274\n",
      "           1       0.22      0.34      0.27       269\n",
      "           2       0.20      0.10      0.14       298\n",
      "           3       0.41      0.13      0.20       439\n",
      "\n",
      "    accuracy                           0.25      1280\n",
      "   macro avg       0.27      0.27      0.24      1280\n",
      "weighted avg       0.29      0.25      0.23      1280\n",
      "\n",
      "[[144  72  32  26]\n",
      " [102  91  41  35]\n",
      " [152  95  31  20]\n",
      " [182 148  52  57]]\n",
      "Validation Loss for s01 = 1.4386402368545532\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_173/503690333.py:66: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/tmp/ipykernel_173/503690333.py:40: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 44/100, Train Loss: 1.3950961828231812\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.25      0.55      0.34       274\n",
      "           1       0.22      0.31      0.26       269\n",
      "           2       0.20      0.11      0.14       298\n",
      "           3       0.39      0.12      0.18       439\n",
      "\n",
      "    accuracy                           0.25      1280\n",
      "   macro avg       0.26      0.27      0.23      1280\n",
      "weighted avg       0.28      0.25      0.22      1280\n",
      "\n",
      "[[151  65  32  26]\n",
      " [109  84  43  33]\n",
      " [159  87  32  20]\n",
      " [190 141  57  51]]\n",
      "Validation Loss for s01 = 1.435865879058838\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_173/503690333.py:66: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/tmp/ipykernel_173/503690333.py:40: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 45/100, Train Loss: 1.35756516456604\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_173/503690333.py:66: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.25      0.55      0.34       274\n",
      "           1       0.22      0.30      0.26       269\n",
      "           2       0.19      0.11      0.14       298\n",
      "           3       0.41      0.12      0.19       439\n",
      "\n",
      "    accuracy                           0.25      1280\n",
      "   macro avg       0.27      0.27      0.23      1280\n",
      "weighted avg       0.28      0.25      0.22      1280\n",
      "\n",
      "[[151  64  33  26]\n",
      " [110  82  45  32]\n",
      " [160  87  32  19]\n",
      " [187 140  59  53]]\n",
      "Validation Loss for s01 = 1.4281362295150757\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_173/503690333.py:40: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 46/100, Train Loss: 1.4477081298828125\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.25      0.52      0.33       274\n",
      "           1       0.23      0.35      0.27       269\n",
      "           2       0.20      0.11      0.14       298\n",
      "           3       0.41      0.13      0.19       439\n",
      "\n",
      "    accuracy                           0.25      1280\n",
      "   macro avg       0.27      0.27      0.24      1280\n",
      "weighted avg       0.29      0.25      0.23      1280\n",
      "\n",
      "[[142  74  31  27]\n",
      " [100  93  42  34]\n",
      " [151  95  32  20]\n",
      " [182 149  52  56]]\n",
      "Validation Loss for s01 = 1.4323656558990479\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_173/503690333.py:66: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/tmp/ipykernel_173/503690333.py:40: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 47/100, Train Loss: 1.3763898611068726\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.25      0.48      0.33       274\n",
      "           1       0.21      0.36      0.27       269\n",
      "           2       0.21      0.11      0.14       298\n",
      "           3       0.39      0.13      0.19       439\n",
      "\n",
      "    accuracy                           0.25      1280\n",
      "   macro avg       0.27      0.27      0.23      1280\n",
      "weighted avg       0.28      0.25      0.23      1280\n",
      "\n",
      "[[131  85  30  28]\n",
      " [ 94  98  39  38]\n",
      " [134 112  32  20]\n",
      " [167 163  53  56]]\n",
      "Validation Loss for s01 = 1.4267871379852295\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_173/503690333.py:66: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/tmp/ipykernel_173/503690333.py:40: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 48/100, Train Loss: 1.3494738340377808\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_173/503690333.py:66: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.25      0.48      0.33       274\n",
      "           1       0.22      0.36      0.27       269\n",
      "           2       0.20      0.11      0.14       298\n",
      "           3       0.39      0.12      0.19       439\n",
      "\n",
      "    accuracy                           0.25      1280\n",
      "   macro avg       0.26      0.27      0.23      1280\n",
      "weighted avg       0.28      0.25      0.22      1280\n",
      "\n",
      "[[131  83  32  28]\n",
      " [ 94  98  42  35]\n",
      " [137 109  32  20]\n",
      " [168 162  55  54]]\n",
      "Validation Loss for s01 = 1.4280195236206055\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_173/503690333.py:40: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 49/100, Train Loss: 1.3872774839401245\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_173/503690333.py:66: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.25      0.41      0.31       274\n",
      "           1       0.20      0.39      0.26       269\n",
      "           2       0.20      0.11      0.14       298\n",
      "           3       0.39      0.12      0.19       439\n",
      "\n",
      "    accuracy                           0.24      1280\n",
      "   macro avg       0.26      0.26      0.23      1280\n",
      "weighted avg       0.28      0.24      0.22      1280\n",
      "\n",
      "[[113 102  31  28]\n",
      " [ 87 105  41  36]\n",
      " [110 136  32  20]\n",
      " [148 182  55  54]]\n",
      "Validation Loss for s01 = 1.4287450313568115\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_173/503690333.py:40: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 50/100, Train Loss: 1.3683903217315674\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_173/503690333.py:66: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.25      0.47      0.33       274\n",
      "           1       0.22      0.38      0.28       269\n",
      "           2       0.19      0.11      0.14       298\n",
      "           3       0.39      0.12      0.18       439\n",
      "\n",
      "    accuracy                           0.25      1280\n",
      "   macro avg       0.26      0.27      0.23      1280\n",
      "weighted avg       0.28      0.25      0.22      1280\n",
      "\n",
      "[[128  87  32  27]\n",
      " [ 89 103  42  35]\n",
      " [129 118  32  19]\n",
      " [164 165  59  51]]\n",
      "Validation Loss for s01 = 1.4299161434173584\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_173/503690333.py:40: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 51/100, Train Loss: 1.3536738157272339\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_173/503690333.py:66: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.25      0.47      0.33       274\n",
      "           1       0.22      0.38      0.28       269\n",
      "           2       0.20      0.11      0.14       298\n",
      "           3       0.40      0.13      0.19       439\n",
      "\n",
      "    accuracy                           0.25      1280\n",
      "   macro avg       0.27      0.27      0.23      1280\n",
      "weighted avg       0.28      0.25      0.23      1280\n",
      "\n",
      "[[129  86  31  28]\n",
      " [ 91 102  40  36]\n",
      " [131 115  32  20]\n",
      " [167 163  54  55]]\n",
      "Validation Loss for s01 = 1.4288082122802734\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_173/503690333.py:40: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 52/100, Train Loss: 1.3633649349212646\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_173/503690333.py:66: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.25      0.40      0.31       274\n",
      "           1       0.20      0.40      0.27       269\n",
      "           2       0.20      0.11      0.14       298\n",
      "           3       0.40      0.12      0.19       439\n",
      "\n",
      "    accuracy                           0.24      1280\n",
      "   macro avg       0.26      0.26      0.22      1280\n",
      "weighted avg       0.28      0.24      0.22      1280\n",
      "\n",
      "[[110 104  32  28]\n",
      " [ 87 107  41  34]\n",
      " [107 139  32  20]\n",
      " [143 188  54  54]]\n",
      "Validation Loss for s01 = 1.429817795753479\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_173/503690333.py:40: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 53/100, Train Loss: 1.3937677145004272\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_173/503690333.py:66: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.25      0.43      0.32       274\n",
      "           1       0.20      0.39      0.26       269\n",
      "           2       0.20      0.11      0.14       298\n",
      "           3       0.39      0.11      0.18       439\n",
      "\n",
      "    accuracy                           0.24      1280\n",
      "   macro avg       0.26      0.26      0.22      1280\n",
      "weighted avg       0.28      0.24      0.22      1280\n",
      "\n",
      "[[119  97  32  26]\n",
      " [ 89 104  42  34]\n",
      " [112 135  32  19]\n",
      " [151 183  55  50]]\n",
      "Validation Loss for s01 = 1.4409575462341309\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_173/503690333.py:40: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 54/100, Train Loss: 1.3728779554367065\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_173/503690333.py:66: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.25      0.42      0.31       274\n",
      "           1       0.20      0.39      0.27       269\n",
      "           2       0.20      0.11      0.14       298\n",
      "           3       0.40      0.13      0.19       439\n",
      "\n",
      "    accuracy                           0.24      1280\n",
      "   macro avg       0.26      0.26      0.23      1280\n",
      "weighted avg       0.28      0.24      0.22      1280\n",
      "\n",
      "[[116  98  33  27]\n",
      " [ 89 104  41  35]\n",
      " [112 134  32  20]\n",
      " [152 178  54  55]]\n",
      "Validation Loss for s01 = 1.4335758686065674\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_173/503690333.py:40: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 55/100, Train Loss: 1.4225934743881226\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_173/503690333.py:66: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.25      0.45      0.32       274\n",
      "           1       0.21      0.38      0.27       269\n",
      "           2       0.19      0.11      0.14       298\n",
      "           3       0.41      0.12      0.19       439\n",
      "\n",
      "    accuracy                           0.24      1280\n",
      "   macro avg       0.27      0.26      0.23      1280\n",
      "weighted avg       0.28      0.24      0.22      1280\n",
      "\n",
      "[[123  92  34  25]\n",
      " [ 90 102  45  32]\n",
      " [120 126  32  20]\n",
      " [160 168  57  54]]\n",
      "Validation Loss for s01 = 1.4354075193405151\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_173/503690333.py:40: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 56/100, Train Loss: 1.303465485572815\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_173/503690333.py:66: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.25      0.40      0.31       274\n",
      "           1       0.20      0.41      0.27       269\n",
      "           2       0.19      0.11      0.14       298\n",
      "           3       0.42      0.13      0.19       439\n",
      "\n",
      "    accuracy                           0.24      1280\n",
      "   macro avg       0.27      0.26      0.23      1280\n",
      "weighted avg       0.28      0.24      0.22      1280\n",
      "\n",
      "[[109 105  35  25]\n",
      " [ 85 109  44  31]\n",
      " [107 139  32  20]\n",
      " [138 192  54  55]]\n",
      "Validation Loss for s01 = 1.436279296875\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_173/503690333.py:40: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 57/100, Train Loss: 1.3349117040634155\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_173/503690333.py:66: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.24      0.37      0.29       274\n",
      "           1       0.20      0.43      0.28       269\n",
      "           2       0.20      0.11      0.14       298\n",
      "           3       0.41      0.13      0.20       439\n",
      "\n",
      "    accuracy                           0.24      1280\n",
      "   macro avg       0.26      0.26      0.23      1280\n",
      "weighted avg       0.28      0.24      0.22      1280\n",
      "\n",
      "[[101 113  34  26]\n",
      " [ 77 115  42  35]\n",
      " [102 143  32  21]\n",
      " [135 194  53  57]]\n",
      "Validation Loss for s01 = 1.4348448514938354\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_173/503690333.py:40: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 58/100, Train Loss: 1.3248080015182495\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_173/503690333.py:66: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.25      0.40      0.31       274\n",
      "           1       0.20      0.41      0.27       269\n",
      "           2       0.20      0.11      0.15       298\n",
      "           3       0.41      0.13      0.20       439\n",
      "\n",
      "    accuracy                           0.24      1280\n",
      "   macro avg       0.27      0.26      0.23      1280\n",
      "weighted avg       0.29      0.24      0.22      1280\n",
      "\n",
      "[[109 106  34  25]\n",
      " [ 83 110  43  33]\n",
      " [103 140  34  21]\n",
      " [137 189  57  56]]\n",
      "Validation Loss for s01 = 1.4368088245391846\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_173/503690333.py:40: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 59/100, Train Loss: 1.3090579509735107\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_173/503690333.py:66: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.25      0.41      0.31       274\n",
      "           1       0.20      0.39      0.26       269\n",
      "           2       0.20      0.11      0.14       298\n",
      "           3       0.42      0.13      0.20       439\n",
      "\n",
      "    accuracy                           0.24      1280\n",
      "   macro avg       0.27      0.26      0.23      1280\n",
      "weighted avg       0.28      0.24      0.22      1280\n",
      "\n",
      "[[112 103  32  27]\n",
      " [ 87 105  42  35]\n",
      " [107 138  32  21]\n",
      " [143 186  51  59]]\n",
      "Validation Loss for s01 = 1.4413535594940186\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_173/503690333.py:40: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 60/100, Train Loss: 1.4248344898223877\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_173/503690333.py:66: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.25      0.40      0.31       274\n",
      "           1       0.20      0.41      0.27       269\n",
      "           2       0.21      0.11      0.14       298\n",
      "           3       0.40      0.13      0.20       439\n",
      "\n",
      "    accuracy                           0.24      1280\n",
      "   macro avg       0.27      0.26      0.23      1280\n",
      "weighted avg       0.28      0.24      0.22      1280\n",
      "\n",
      "[[110 105  30  29]\n",
      " [ 84 109  39  37]\n",
      " [106 140  32  20]\n",
      " [141 189  51  58]]\n",
      "Validation Loss for s01 = 1.4358912706375122\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_173/503690333.py:40: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 61/100, Train Loss: 1.402112603187561\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_173/503690333.py:66: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.25      0.40      0.31       274\n",
      "           1       0.20      0.41      0.27       269\n",
      "           2       0.21      0.11      0.14       298\n",
      "           3       0.41      0.14      0.21       439\n",
      "\n",
      "    accuracy                           0.24      1280\n",
      "   macro avg       0.27      0.26      0.23      1280\n",
      "weighted avg       0.29      0.24      0.23      1280\n",
      "\n",
      "[[110 105  31  28]\n",
      " [ 85 109  38  37]\n",
      " [108 137  32  21]\n",
      " [143 183  53  60]]\n",
      "Validation Loss for s01 = 1.4334924221038818\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_173/503690333.py:40: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 62/100, Train Loss: 1.4177359342575073\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_173/503690333.py:66: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.25      0.40      0.30       274\n",
      "           1       0.20      0.39      0.27       269\n",
      "           2       0.21      0.11      0.14       298\n",
      "           3       0.41      0.14      0.21       439\n",
      "\n",
      "    accuracy                           0.24      1280\n",
      "   macro avg       0.27      0.26      0.23      1280\n",
      "weighted avg       0.28      0.24      0.23      1280\n",
      "\n",
      "[[110 104  33  27]\n",
      " [ 88 106  38  37]\n",
      " [106 137  33  22]\n",
      " [144 179  56  60]]\n",
      "Validation Loss for s01 = 1.42483651638031\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_173/503690333.py:40: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 63/100, Train Loss: 1.3953580856323242\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_173/503690333.py:66: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.24      0.37      0.29       274\n",
      "           1       0.21      0.42      0.28       269\n",
      "           2       0.22      0.11      0.15       298\n",
      "           3       0.41      0.14      0.21       439\n",
      "\n",
      "    accuracy                           0.24      1280\n",
      "   macro avg       0.27      0.26      0.23      1280\n",
      "weighted avg       0.29      0.24      0.23      1280\n",
      "\n",
      "[[102 113  31  28]\n",
      " [ 80 114  34  41]\n",
      " [104 139  33  22]\n",
      " [133 190  53  63]]\n",
      "Validation Loss for s01 = 1.4205495119094849\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_173/503690333.py:40: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 64/100, Train Loss: 1.3409037590026855\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_173/503690333.py:66: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.25      0.36      0.29       274\n",
      "           1       0.20      0.43      0.28       269\n",
      "           2       0.20      0.11      0.14       298\n",
      "           3       0.42      0.14      0.21       439\n",
      "\n",
      "    accuracy                           0.24      1280\n",
      "   macro avg       0.27      0.26      0.23      1280\n",
      "weighted avg       0.29      0.24      0.23      1280\n",
      "\n",
      "[[ 99 116  32  27]\n",
      " [ 77 116  39  37]\n",
      " [ 99 145  32  22]\n",
      " [128 195  54  62]]\n",
      "Validation Loss for s01 = 1.436578392982483\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_173/503690333.py:40: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 65/100, Train Loss: 1.4320982694625854\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_173/503690333.py:66: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.24      0.32      0.27       274\n",
      "           1       0.20      0.46      0.28       269\n",
      "           2       0.20      0.11      0.14       298\n",
      "           3       0.40      0.13      0.20       439\n",
      "\n",
      "    accuracy                           0.24      1280\n",
      "   macro avg       0.26      0.26      0.22      1280\n",
      "weighted avg       0.28      0.24      0.22      1280\n",
      "\n",
      "[[ 87 127  32  28]\n",
      " [ 68 125  39  37]\n",
      " [ 90 154  32  22]\n",
      " [118 207  55  59]]\n",
      "Validation Loss for s01 = 1.4364209175109863\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_173/503690333.py:40: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 66/100, Train Loss: 1.3033839464187622\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_173/503690333.py:66: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.24      0.35      0.29       274\n",
      "           1       0.20      0.45      0.28       269\n",
      "           2       0.20      0.11      0.14       298\n",
      "           3       0.43      0.14      0.21       439\n",
      "\n",
      "    accuracy                           0.24      1280\n",
      "   macro avg       0.27      0.26      0.23      1280\n",
      "weighted avg       0.29      0.24      0.22      1280\n",
      "\n",
      "[[ 96 119  34  25]\n",
      " [ 74 120  41  34]\n",
      " [ 98 147  32  21]\n",
      " [124 200  55  60]]\n",
      "Validation Loss for s01 = 1.4400681257247925\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_173/503690333.py:40: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 67/100, Train Loss: 1.424011468887329\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_173/503690333.py:66: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.24      0.42      0.31       274\n",
      "           1       0.21      0.39      0.27       269\n",
      "           2       0.20      0.11      0.14       298\n",
      "           3       0.42      0.14      0.21       439\n",
      "\n",
      "    accuracy                           0.24      1280\n",
      "   macro avg       0.27      0.26      0.23      1280\n",
      "weighted avg       0.29      0.24      0.23      1280\n",
      "\n",
      "[[116 100  31  27]\n",
      " [ 90 104  40  35]\n",
      " [119 125  33  21]\n",
      " [154 167  58  60]]\n",
      "Validation Loss for s01 = 1.424570918083191\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_173/503690333.py:40: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 68/100, Train Loss: 1.2728855609893799\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.25      0.44      0.32       274\n",
      "           1       0.21      0.38      0.27       269\n",
      "           2       0.20      0.11      0.14       298\n",
      "           3       0.42      0.14      0.21       439\n",
      "\n",
      "    accuracy                           0.25      1280\n",
      "   macro avg       0.27      0.27      0.23      1280\n",
      "weighted avg       0.29      0.25      0.23      1280\n",
      "\n",
      "[[120  95  33  26]\n",
      " [ 92 102  37  38]\n",
      " [121 124  32  21]\n",
      " [154 167  56  62]]\n",
      "Validation Loss for s01 = 1.425063967704773\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_173/503690333.py:66: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/tmp/ipykernel_173/503690333.py:40: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 69/100, Train Loss: 1.4136680364608765\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_173/503690333.py:66: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.24      0.40      0.30       274\n",
      "           1       0.20      0.39      0.26       269\n",
      "           2       0.20      0.11      0.14       298\n",
      "           3       0.41      0.13      0.19       439\n",
      "\n",
      "    accuracy                           0.23      1280\n",
      "   macro avg       0.26      0.25      0.22      1280\n",
      "weighted avg       0.28      0.23      0.22      1280\n",
      "\n",
      "[[109 107  33  25]\n",
      " [ 90 104  41  34]\n",
      " [111 134  32  21]\n",
      " [147 179  58  55]]\n",
      "Validation Loss for s01 = 1.4300789833068848\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_173/503690333.py:40: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 70/100, Train Loss: 1.3241719007492065\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_173/503690333.py:66: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.23      0.37      0.29       274\n",
      "           1       0.20      0.42      0.27       269\n",
      "           2       0.19      0.10      0.14       298\n",
      "           3       0.40      0.13      0.19       439\n",
      "\n",
      "    accuracy                           0.23      1280\n",
      "   macro avg       0.26      0.25      0.22      1280\n",
      "weighted avg       0.28      0.23      0.22      1280\n",
      "\n",
      "[[101 115  32  26]\n",
      " [ 83 112  39  35]\n",
      " [107 139  31  21]\n",
      " [141 186  57  55]]\n",
      "Validation Loss for s01 = 1.4367170333862305\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_173/503690333.py:40: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 71/100, Train Loss: 1.4425201416015625\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_173/503690333.py:66: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.24      0.36      0.29       274\n",
      "           1       0.20      0.42      0.27       269\n",
      "           2       0.20      0.11      0.14       298\n",
      "           3       0.39      0.12      0.18       439\n",
      "\n",
      "    accuracy                           0.23      1280\n",
      "   macro avg       0.26      0.25      0.22      1280\n",
      "weighted avg       0.27      0.23      0.21      1280\n",
      "\n",
      "[[100 117  32  25]\n",
      " [ 82 113  39  35]\n",
      " [104 142  32  20]\n",
      " [135 192  60  52]]\n",
      "Validation Loss for s01 = 1.4291021823883057\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_173/503690333.py:40: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 72/100, Train Loss: 1.3351598978042603\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_173/503690333.py:66: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.23      0.35      0.28       274\n",
      "           1       0.20      0.42      0.27       269\n",
      "           2       0.20      0.12      0.15       298\n",
      "           3       0.42      0.13      0.19       439\n",
      "\n",
      "    accuracy                           0.23      1280\n",
      "   macro avg       0.26      0.25      0.22      1280\n",
      "weighted avg       0.28      0.23      0.22      1280\n",
      "\n",
      "[[ 97 119  34  24]\n",
      " [ 82 113  42  32]\n",
      " [105 138  35  20]\n",
      " [132 192  60  55]]\n",
      "Validation Loss for s01 = 1.4252408742904663\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_173/503690333.py:40: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 73/100, Train Loss: 1.3219252824783325\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_173/503690333.py:66: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.23      0.34      0.28       274\n",
      "           1       0.20      0.43      0.28       269\n",
      "           2       0.20      0.11      0.15       298\n",
      "           3       0.42      0.13      0.20       439\n",
      "\n",
      "    accuracy                           0.24      1280\n",
      "   macro avg       0.26      0.26      0.23      1280\n",
      "weighted avg       0.28      0.24      0.22      1280\n",
      "\n",
      "[[ 94 120  34  26]\n",
      " [ 78 116  40  35]\n",
      " [103 141  34  20]\n",
      " [128 191  62  58]]\n",
      "Validation Loss for s01 = 1.4295787811279297\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_173/503690333.py:40: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 74/100, Train Loss: 1.3740081787109375\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.24      0.34      0.28       274\n",
      "           1       0.20      0.44      0.28       269\n",
      "           2       0.20      0.11      0.14       298\n",
      "           3       0.41      0.14      0.21       439\n",
      "\n",
      "    accuracy                           0.24      1280\n",
      "   macro avg       0.26      0.26      0.23      1280\n",
      "weighted avg       0.28      0.24      0.22      1280\n",
      "\n",
      "[[ 93 122  34  25]\n",
      " [ 75 118  37  39]\n",
      " [ 99 145  33  21]\n",
      " [124 196  59  60]]\n",
      "Validation Loss for s01 = 1.4253380298614502\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_173/503690333.py:66: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/tmp/ipykernel_173/503690333.py:40: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 75/100, Train Loss: 1.2573860883712769\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_173/503690333.py:66: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.24      0.33      0.28       274\n",
      "           1       0.20      0.46      0.28       269\n",
      "           2       0.20      0.11      0.14       298\n",
      "           3       0.42      0.13      0.20       439\n",
      "\n",
      "    accuracy                           0.24      1280\n",
      "   macro avg       0.27      0.26      0.22      1280\n",
      "weighted avg       0.29      0.24      0.22      1280\n",
      "\n",
      "[[ 91 125  34  24]\n",
      " [ 70 123  42  34]\n",
      " [ 94 152  33  19]\n",
      " [118 206  59  56]]\n",
      "Validation Loss for s01 = 1.4322137832641602\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_173/503690333.py:40: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 76/100, Train Loss: 1.3452119827270508\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.24      0.33      0.28       274\n",
      "           1       0.21      0.47      0.29       269\n",
      "           2       0.20      0.12      0.15       298\n",
      "           3       0.43      0.13      0.20       439\n",
      "\n",
      "    accuracy                           0.24      1280\n",
      "   macro avg       0.27      0.26      0.23      1280\n",
      "weighted avg       0.29      0.24      0.22      1280\n",
      "\n",
      "[[ 90 126  35  23]\n",
      " [ 68 126  43  32]\n",
      " [ 92 153  35  18]\n",
      " [118 202  63  56]]\n",
      "Validation Loss for s01 = 1.433479905128479\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_173/503690333.py:66: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/tmp/ipykernel_173/503690333.py:40: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 77/100, Train Loss: 1.3957672119140625\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.24      0.28      0.26       274\n",
      "           1       0.20      0.49      0.28       269\n",
      "           2       0.18      0.11      0.14       298\n",
      "           3       0.43      0.12      0.19       439\n",
      "\n",
      "    accuracy                           0.23      1280\n",
      "   macro avg       0.26      0.25      0.22      1280\n",
      "weighted avg       0.28      0.23      0.21      1280\n",
      "\n",
      "[[ 77 138  36  23]\n",
      " [ 63 131  44  31]\n",
      " [ 80 167  32  19]\n",
      " [ 99 223  63  54]]\n",
      "Validation Loss for s01 = 1.4379165172576904\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_173/503690333.py:66: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/tmp/ipykernel_173/503690333.py:40: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 78/100, Train Loss: 1.3278919458389282\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_173/503690333.py:66: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.24      0.33      0.28       274\n",
      "           1       0.20      0.45      0.28       269\n",
      "           2       0.20      0.12      0.15       298\n",
      "           3       0.42      0.13      0.20       439\n",
      "\n",
      "    accuracy                           0.24      1280\n",
      "   macro avg       0.27      0.26      0.23      1280\n",
      "weighted avg       0.28      0.24      0.22      1280\n",
      "\n",
      "[[ 91 125  33  25]\n",
      " [ 71 121  42  35]\n",
      " [ 95 147  35  21]\n",
      " [118 199  64  58]]\n",
      "Validation Loss for s01 = 1.4248838424682617\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_173/503690333.py:40: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 79/100, Train Loss: 1.402574896812439\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_173/503690333.py:66: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.24      0.34      0.28       274\n",
      "           1       0.20      0.43      0.28       269\n",
      "           2       0.20      0.11      0.14       298\n",
      "           3       0.41      0.13      0.20       439\n",
      "\n",
      "    accuracy                           0.24      1280\n",
      "   macro avg       0.26      0.25      0.22      1280\n",
      "weighted avg       0.28      0.24      0.22      1280\n",
      "\n",
      "[[ 93 123  33  25]\n",
      " [ 76 117  38  38]\n",
      " [100 144  33  21]\n",
      " [125 197  59  58]]\n",
      "Validation Loss for s01 = 1.4284725189208984\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_173/503690333.py:40: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 80/100, Train Loss: 1.3696659803390503\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_173/503690333.py:66: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.24      0.33      0.28       274\n",
      "           1       0.21      0.46      0.29       269\n",
      "           2       0.20      0.11      0.14       298\n",
      "           3       0.40      0.13      0.20       439\n",
      "\n",
      "    accuracy                           0.24      1280\n",
      "   macro avg       0.26      0.26      0.23      1280\n",
      "weighted avg       0.28      0.24      0.22      1280\n",
      "\n",
      "[[ 90 126  33  25]\n",
      " [ 69 124  37  39]\n",
      " [ 95 149  33  21]\n",
      " [119 202  61  57]]\n",
      "Validation Loss for s01 = 1.4278916120529175\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_173/503690333.py:40: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 81/100, Train Loss: 1.2816826105117798\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_173/503690333.py:66: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.24      0.33      0.28       274\n",
      "           1       0.20      0.45      0.28       269\n",
      "           2       0.20      0.11      0.14       298\n",
      "           3       0.42      0.14      0.21       439\n",
      "\n",
      "    accuracy                           0.24      1280\n",
      "   macro avg       0.27      0.26      0.23      1280\n",
      "weighted avg       0.29      0.24      0.23      1280\n",
      "\n",
      "[[ 91 125  32  26]\n",
      " [ 73 120  36  40]\n",
      " [ 97 147  33  21]\n",
      " [118 198  60  63]]\n",
      "Validation Loss for s01 = 1.4230730533599854\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_173/503690333.py:40: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 82/100, Train Loss: 1.424437165260315\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.24      0.37      0.29       274\n",
      "           1       0.20      0.42      0.27       269\n",
      "           2       0.20      0.11      0.14       298\n",
      "           3       0.41      0.14      0.21       439\n",
      "\n",
      "    accuracy                           0.24      1280\n",
      "   macro avg       0.26      0.26      0.23      1280\n",
      "weighted avg       0.28      0.24      0.22      1280\n",
      "\n",
      "[[102 114  32  26]\n",
      " [ 82 112  35  40]\n",
      " [104 141  32  21]\n",
      " [136 182  60  61]]\n",
      "Validation Loss for s01 = 1.4221937656402588\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_173/503690333.py:66: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/tmp/ipykernel_173/503690333.py:40: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 83/100, Train Loss: 1.4560739994049072\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_173/503690333.py:66: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.24      0.39      0.30       274\n",
      "           1       0.20      0.38      0.26       269\n",
      "           2       0.21      0.12      0.15       298\n",
      "           3       0.42      0.14      0.21       439\n",
      "\n",
      "    accuracy                           0.24      1280\n",
      "   macro avg       0.27      0.26      0.23      1280\n",
      "weighted avg       0.29      0.24      0.23      1280\n",
      "\n",
      "[[108 108  32  26]\n",
      " [ 88 103  41  37]\n",
      " [109 134  35  20]\n",
      " [144 175  59  61]]\n",
      "Validation Loss for s01 = 1.4229562282562256\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_173/503690333.py:40: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 84/100, Train Loss: 1.3778033256530762\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_173/503690333.py:66: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.24      0.31      0.27       274\n",
      "           1       0.20      0.47      0.28       269\n",
      "           2       0.21      0.11      0.14       298\n",
      "           3       0.42      0.14      0.21       439\n",
      "\n",
      "    accuracy                           0.24      1280\n",
      "   macro avg       0.27      0.26      0.23      1280\n",
      "weighted avg       0.29      0.24      0.22      1280\n",
      "\n",
      "[[ 86 131  31  26]\n",
      " [ 68 126  38  37]\n",
      " [ 91 154  33  20]\n",
      " [114 206  58  61]]\n",
      "Validation Loss for s01 = 1.4276363849639893\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_173/503690333.py:40: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 85/100, Train Loss: 1.3614463806152344\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.24      0.28      0.26       274\n",
      "           1       0.20      0.48      0.28       269\n",
      "           2       0.22      0.12      0.16       298\n",
      "           3       0.42      0.14      0.21       439\n",
      "\n",
      "    accuracy                           0.24      1280\n",
      "   macro avg       0.27      0.26      0.23      1280\n",
      "weighted avg       0.29      0.24      0.22      1280\n",
      "\n",
      "[[ 78 137  33  26]\n",
      " [ 63 129  38  39]\n",
      " [ 83 158  37  20]\n",
      " [100 217  60  62]]\n",
      "Validation Loss for s01 = 1.4194772243499756\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_173/503690333.py:66: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/tmp/ipykernel_173/503690333.py:40: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 86/100, Train Loss: 1.3745657205581665\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_173/503690333.py:66: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.24      0.28      0.26       274\n",
      "           1       0.20      0.48      0.28       269\n",
      "           2       0.20      0.11      0.14       298\n",
      "           3       0.41      0.13      0.20       439\n",
      "\n",
      "    accuracy                           0.23      1280\n",
      "   macro avg       0.26      0.25      0.22      1280\n",
      "weighted avg       0.28      0.23      0.22      1280\n",
      "\n",
      "[[ 77 138  32  27]\n",
      " [ 64 130  38  37]\n",
      " [ 81 164  33  20]\n",
      " [ 99 222  59  59]]\n",
      "Validation Loss for s01 = 1.4286390542984009\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_173/503690333.py:40: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 87/100, Train Loss: 1.3165310621261597\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_173/503690333.py:66: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.24      0.30      0.26       274\n",
      "           1       0.20      0.47      0.28       269\n",
      "           2       0.20      0.11      0.14       298\n",
      "           3       0.41      0.13      0.20       439\n",
      "\n",
      "    accuracy                           0.23      1280\n",
      "   macro avg       0.26      0.25      0.22      1280\n",
      "weighted avg       0.28      0.23      0.22      1280\n",
      "\n",
      "[[ 81 134  32  27]\n",
      " [ 66 127  38  38]\n",
      " [ 86 159  32  21]\n",
      " [110 214  56  59]]\n",
      "Validation Loss for s01 = 1.425307035446167\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_173/503690333.py:40: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 88/100, Train Loss: 1.3659840822219849\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_173/503690333.py:66: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.24      0.30      0.26       274\n",
      "           1       0.20      0.47      0.28       269\n",
      "           2       0.21      0.11      0.15       298\n",
      "           3       0.40      0.13      0.20       439\n",
      "\n",
      "    accuracy                           0.23      1280\n",
      "   macro avg       0.26      0.25      0.22      1280\n",
      "weighted avg       0.28      0.23      0.22      1280\n",
      "\n",
      "[[ 81 134  32  27]\n",
      " [ 65 127  39  38]\n",
      " [ 83 160  34  21]\n",
      " [111 211  59  58]]\n",
      "Validation Loss for s01 = 1.4277706146240234\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_173/503690333.py:40: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 89/100, Train Loss: 1.3792293071746826\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.24      0.28      0.26       274\n",
      "           1       0.20      0.48      0.28       269\n",
      "           2       0.20      0.11      0.14       298\n",
      "           3       0.42      0.14      0.21       439\n",
      "\n",
      "    accuracy                           0.23      1280\n",
      "   macro avg       0.26      0.25      0.22      1280\n",
      "weighted avg       0.28      0.23      0.22      1280\n",
      "\n",
      "[[ 77 136  33  28]\n",
      " [ 64 128  39  38]\n",
      " [ 82 162  33  21]\n",
      " [102 219  56  62]]\n",
      "Validation Loss for s01 = 1.429552674293518\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_173/503690333.py:66: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/tmp/ipykernel_173/503690333.py:40: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 90/100, Train Loss: 1.3674439191818237\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_173/503690333.py:66: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.23      0.27      0.25       274\n",
      "           1       0.20      0.48      0.28       269\n",
      "           2       0.22      0.11      0.15       298\n",
      "           3       0.41      0.14      0.21       439\n",
      "\n",
      "    accuracy                           0.24      1280\n",
      "   macro avg       0.26      0.25      0.22      1280\n",
      "weighted avg       0.28      0.24      0.22      1280\n",
      "\n",
      "[[ 75 139  32  28]\n",
      " [ 63 129  37  40]\n",
      " [ 84 158  34  22]\n",
      " [103 218  55  63]]\n",
      "Validation Loss for s01 = 1.4206593036651611\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_173/503690333.py:40: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 91/100, Train Loss: 1.418440818786621\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_173/503690333.py:66: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.24      0.27      0.25       274\n",
      "           1       0.20      0.51      0.29       269\n",
      "           2       0.22      0.11      0.15       298\n",
      "           3       0.40      0.14      0.21       439\n",
      "\n",
      "    accuracy                           0.24      1280\n",
      "   macro avg       0.27      0.26      0.22      1280\n",
      "weighted avg       0.28      0.24      0.22      1280\n",
      "\n",
      "[[ 73 143  28  30]\n",
      " [ 59 136  32  42]\n",
      " [ 79 164  33  22]\n",
      " [ 93 227  57  62]]\n",
      "Validation Loss for s01 = 1.4222863912582397\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_173/503690333.py:40: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 92/100, Train Loss: 1.3648381233215332\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_173/503690333.py:66: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.24      0.29      0.26       274\n",
      "           1       0.20      0.48      0.29       269\n",
      "           2       0.21      0.11      0.14       298\n",
      "           3       0.41      0.15      0.21       439\n",
      "\n",
      "    accuracy                           0.24      1280\n",
      "   macro avg       0.27      0.26      0.23      1280\n",
      "weighted avg       0.28      0.24      0.22      1280\n",
      "\n",
      "[[ 80 135  30  29]\n",
      " [ 63 130  35  41]\n",
      " [ 84 159  32  23]\n",
      " [107 212  56  64]]\n",
      "Validation Loss for s01 = 1.4259675741195679\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_173/503690333.py:40: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 93/100, Train Loss: 1.4035311937332153\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_173/503690333.py:66: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.24      0.26      0.25       274\n",
      "           1       0.20      0.50      0.29       269\n",
      "           2       0.23      0.12      0.15       298\n",
      "           3       0.40      0.14      0.20       439\n",
      "\n",
      "    accuracy                           0.24      1280\n",
      "   macro avg       0.27      0.25      0.22      1280\n",
      "weighted avg       0.28      0.24      0.22      1280\n",
      "\n",
      "[[ 71 146  28  29]\n",
      " [ 58 135  36  40]\n",
      " [ 79 163  35  21]\n",
      " [ 92 231  56  60]]\n",
      "Validation Loss for s01 = 1.426020860671997\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_173/503690333.py:40: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 94/100, Train Loss: 1.3852171897888184\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.24      0.26      0.25       274\n",
      "           1       0.21      0.52      0.29       269\n",
      "           2       0.21      0.12      0.15       298\n",
      "           3       0.39      0.13      0.19       439\n",
      "\n",
      "    accuracy                           0.23      1280\n",
      "   macro avg       0.26      0.25      0.22      1280\n",
      "weighted avg       0.28      0.23      0.22      1280\n",
      "\n",
      "[[ 71 145  31  27]\n",
      " [ 54 139  39  37]\n",
      " [ 78 164  35  21]\n",
      " [ 94 230  60  55]]\n",
      "Validation Loss for s01 = 1.4245147705078125\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_173/503690333.py:66: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/tmp/ipykernel_173/503690333.py:40: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 95/100, Train Loss: 1.3320192098617554\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_173/503690333.py:66: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.23      0.27      0.25       274\n",
      "           1       0.20      0.48      0.28       269\n",
      "           2       0.22      0.12      0.15       298\n",
      "           3       0.40      0.13      0.20       439\n",
      "\n",
      "    accuracy                           0.23      1280\n",
      "   macro avg       0.26      0.25      0.22      1280\n",
      "weighted avg       0.28      0.23      0.22      1280\n",
      "\n",
      "[[ 75 141  31  27]\n",
      " [ 62 128  38  41]\n",
      " [ 83 158  35  22]\n",
      " [100 222  58  59]]\n",
      "Validation Loss for s01 = 1.4254546165466309\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_173/503690333.py:40: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 96/100, Train Loss: 1.3481488227844238\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.24      0.28      0.26       274\n",
      "           1       0.20      0.48      0.28       269\n",
      "           2       0.21      0.12      0.16       298\n",
      "           3       0.40      0.12      0.19       439\n",
      "\n",
      "    accuracy                           0.23      1280\n",
      "   macro avg       0.26      0.25      0.22      1280\n",
      "weighted avg       0.28      0.23      0.21      1280\n",
      "\n",
      "[[ 76 140  33  25]\n",
      " [ 63 128  43  35]\n",
      " [ 83 158  37  20]\n",
      " [100 222  63  54]]\n",
      "Validation Loss for s01 = 1.435488224029541\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_173/503690333.py:66: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/tmp/ipykernel_173/503690333.py:40: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 97/100, Train Loss: 1.3976755142211914\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_173/503690333.py:66: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.23      0.22      0.22       274\n",
      "           1       0.20      0.54      0.29       269\n",
      "           2       0.22      0.12      0.15       298\n",
      "           3       0.41      0.13      0.20       439\n",
      "\n",
      "    accuracy                           0.23      1280\n",
      "   macro avg       0.26      0.25      0.22      1280\n",
      "weighted avg       0.28      0.23      0.21      1280\n",
      "\n",
      "[[ 59 156  33  26]\n",
      " [ 48 144  40  37]\n",
      " [ 69 172  36  21]\n",
      " [ 82 240  58  59]]\n",
      "Validation Loss for s01 = 1.432715892791748\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_173/503690333.py:40: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 98/100, Train Loss: 1.3304704427719116\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_173/503690333.py:66: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.24      0.27      0.25       274\n",
      "           1       0.20      0.48      0.28       269\n",
      "           2       0.21      0.12      0.16       298\n",
      "           3       0.40      0.13      0.19       439\n",
      "\n",
      "    accuracy                           0.23      1280\n",
      "   macro avg       0.26      0.25      0.22      1280\n",
      "weighted avg       0.28      0.23      0.22      1280\n",
      "\n",
      "[[ 75 141  32  26]\n",
      " [ 59 129  44  37]\n",
      " [ 85 155  37  21]\n",
      " [100 220  64  55]]\n",
      "Validation Loss for s01 = 1.4280173778533936\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_173/503690333.py:40: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 99/100, Train Loss: 1.3314118385314941\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_173/503690333.py:66: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.24      0.33      0.28       274\n",
      "           1       0.20      0.45      0.28       269\n",
      "           2       0.22      0.13      0.16       298\n",
      "           3       0.41      0.13      0.19       439\n",
      "\n",
      "    accuracy                           0.24      1280\n",
      "   macro avg       0.27      0.26      0.23      1280\n",
      "weighted avg       0.29      0.24      0.22      1280\n",
      "\n",
      "[[ 90 125  33  26]\n",
      " [ 72 121  41  35]\n",
      " [ 92 147  39  20]\n",
      " [117 203  63  56]]\n",
      "Validation Loss for s01 = 1.4349567890167236\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_173/503690333.py:40: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 100/100, Train Loss: 1.3440812826156616\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_173/503690333.py:66: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.23      0.24      0.23       274\n",
      "           1       0.20      0.51      0.29       269\n",
      "           2       0.20      0.12      0.15       298\n",
      "           3       0.40      0.12      0.19       439\n",
      "\n",
      "    accuracy                           0.23      1280\n",
      "   macro avg       0.26      0.25      0.21      1280\n",
      "weighted avg       0.28      0.23      0.21      1280\n",
      "\n",
      "[[ 65 150  33  26]\n",
      " [ 55 136  44  34]\n",
      " [ 75 166  36  21]\n",
      " [ 91 231  63  54]]\n",
      "Validation Loss for s01 = 1.4384188652038574\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x7f46d02cf400>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1000x700 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import confusion_matrix,classification_report\n",
    "from sklearn import preprocessing\n",
    "import matplotlib.pyplot as plt\n",
    "#subjectnames\n",
    "file_list_num = np.arange(len(newsubjectname))\n",
    "file_list_numd = np.arange(len(subjectnamesd))\n",
    "test_index = file_list_numd\n",
    "kf = KFold(n_splits=12)\n",
    "torch.manual_seed(42)\n",
    "torch.cuda.manual_seed(42)\n",
    "modellist = []\n",
    "modelid = 1\n",
    "#file_list_num\n",
    "#for i, (train_index, test_index) in enumerate(kf.split(file_list_num)):\n",
    "#for train_index in file_list_num:\n",
    "train_index = file_list_num\n",
    "print(f\"Fold {i}:\")\n",
    "print(f\"  Train: index={train_index}\")\n",
    "print(f\"  Test:  index={test_index}\")\n",
    "net = Net()\n",
    "net.to(device)\n",
    "optimizer = optim.Adam(net.parameters(), lr=0.000001)\n",
    "epochs = 100\n",
    "batch_sz = 20\n",
    "train_loss_epoch = []\n",
    "val_loss_epoch = []\n",
    "for epoch in range(epochs):\n",
    "  train_loss = []\n",
    "  for tr in train_index:\n",
    "    v = data_c1d[newsubjectname[tr]]\n",
    "    l = data_c2[newsubjectname[tr]]\n",
    "    #print(v[0].shape)\n",
    "    net.train()\n",
    "    for i in range(0,len(v),batch_sz):\n",
    "      #print(v[i].shape)\n",
    "      #for j in range(0,v[i].shape[0],batch_sz):\n",
    "      #print(newsubjectname[tr])\n",
    "      optimizer.zero_grad()\n",
    "      outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
    "      #print(\"Expout {}\",outputs.shape)\n",
    "      #print(\"Actual {}\",l[i:i+batch_sz].shape)\n",
    "      #print(l[i].shape)\n",
    "      loss = criterion(outputs, l[i:i+batch_sz].to(device, dtype=torch.float))\n",
    "      loss.backward()\n",
    "      train_loss.append(loss)\n",
    "      optimizer.step()\n",
    "  print(f'Epoch {epoch + 1}/{epochs}, Train Loss: {loss.item()}')\n",
    "  train_loss_epoch.append(torch.stack(train_loss).mean().cpu().detach().numpy())\n",
    "  #print(train_loss_epoch)\n",
    "  batch_sz = 20\n",
    "  expectedoutputdeap = []\n",
    "  actualoutputdeap = []\n",
    "\n",
    "  for tr in test_index:\n",
    "      net.eval()\n",
    "      v = data_de1[subjectnamesd[tr]]\n",
    "      l = data_del[subjectnamesd[tr]]\n",
    "      net.eval()\n",
    "      val_loss = []\n",
    "      with torch.no_grad():\n",
    "          for i in range(0,len(v),batch_sz):\n",
    "            #print(v[i].shape)\n",
    "            #for j in range(0,v[i].shape[0],batch_sz):\n",
    "            optimizer.zero_grad()\n",
    "            outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
    "            #print(outputs.shape)\n",
    "            #print(l[i:i+batch_sz].shape)\n",
    "            loss = criterion(outputs, l[i:i+batch_sz].to(device, dtype=torch.float))\n",
    "            val_loss.append(loss)\n",
    "            #actualoutputdeap.append(torch.round(outputs.cpu()))\n",
    "            #expectedoutputdeap.append(l[i:i+batch_sz])\n",
    "            actualoutputdeap.append(torch.argmax(torch.softmax(outputs.cpu(),dim=1),dim=1))\n",
    "            expectedoutputdeap.append(torch.argmax(l[i:i+batch_sz],dim=1).numpy())\n",
    "  val_loss_mean = torch.stack(val_loss).mean().cpu().detach().numpy()\n",
    "  val_loss_epoch.append(val_loss_mean)\n",
    "  expectedoutputdeap = np.concatenate( expectedoutputdeap, axis=0 )\n",
    "  actualoutputdeap = np.concatenate( actualoutputdeap, axis=0 )\n",
    "  #print(expectedoutput.shape)\n",
    "  #print(actualoutput.shape)\n",
    "  print(classification_report(expectedoutputdeap,actualoutputdeap))\n",
    "  print(confusion_matrix(expectedoutputdeap,actualoutputdeap))\n",
    "  print(f'Validation Loss for {subjectnamesd[tr]} = {val_loss_mean}')\n",
    "plt.figure(figsize=(10,7))\n",
    "#print(len(train_loss_epoch))\n",
    "plt.plot(np.arange(epochs),train_loss_epoch,label='Train')\n",
    "plt.plot(np.arange(epochs),val_loss_epoch,label='Validation')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "82511330-d09b-4538-a8f5-32a8c2e5d91e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-22T10:15:22.357675Z",
     "iopub.status.busy": "2024-01-22T10:15:22.356928Z",
     "iopub.status.idle": "2024-01-22T10:17:21.115049Z",
     "shell.execute_reply": "2024-01-22T10:17:21.114237Z",
     "shell.execute_reply.started": "2024-01-22T10:15:22.357640Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 0:\n",
      "  Train: index=[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23\n",
      " 24 25 26 27 28 29 30 31]\n",
      "  Test:  index=[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23\n",
      " 24 25 26 27 28 29 30 31 32 33 34 35]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_173/4145799004.py:41: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100, Train Loss: 1.3786548376083374\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_173/4145799004.py:68: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.19      0.05      0.07       150\n",
      "           1       0.24      0.26      0.25       183\n",
      "           2       0.35      0.34      0.34       206\n",
      "           3       0.20      0.31      0.24       181\n",
      "\n",
      "    accuracy                           0.25       720\n",
      "   macro avg       0.24      0.24      0.23       720\n",
      "weighted avg       0.25      0.25      0.24       720\n",
      "\n",
      "[[ 7 35 33 75]\n",
      " [11 48 41 83]\n",
      " [10 59 70 67]\n",
      " [ 9 60 56 56]]\n",
      "Validation Loss for P20 = 1.395013689994812\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_173/4145799004.py:41: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/100, Train Loss: 1.4325833320617676\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_173/4145799004.py:68: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.19      0.04      0.07       150\n",
      "           1       0.22      0.27      0.24       183\n",
      "           2       0.33      0.27      0.30       206\n",
      "           3       0.19      0.31      0.24       181\n",
      "\n",
      "    accuracy                           0.23       720\n",
      "   macro avg       0.23      0.22      0.21       720\n",
      "weighted avg       0.24      0.23      0.22       720\n",
      "\n",
      "[[ 6 37 27 80]\n",
      " [ 9 50 37 87]\n",
      " [ 7 72 55 72]\n",
      " [ 9 68 47 57]]\n",
      "Validation Loss for P20 = 1.3950257301330566\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_173/4145799004.py:41: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/100, Train Loss: 1.6141945123672485\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_173/4145799004.py:68: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.27      0.08      0.12       150\n",
      "           1       0.23      0.34      0.28       183\n",
      "           2       0.31      0.19      0.23       206\n",
      "           3       0.20      0.31      0.25       181\n",
      "\n",
      "    accuracy                           0.24       720\n",
      "   macro avg       0.25      0.23      0.22       720\n",
      "weighted avg       0.26      0.24      0.23       720\n",
      "\n",
      "[[12 41 26 71]\n",
      " [12 63 26 82]\n",
      " [10 87 39 70]\n",
      " [10 78 36 57]]\n",
      "Validation Loss for P20 = 1.3857492208480835\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_173/4145799004.py:41: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/100, Train Loss: 1.3762849569320679\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.30      0.14      0.19       150\n",
      "           1       0.24      0.33      0.28       183\n",
      "           2       0.32      0.20      0.24       206\n",
      "           3       0.21      0.30      0.25       181\n",
      "\n",
      "    accuracy                           0.25       720\n",
      "   macro avg       0.27      0.24      0.24       720\n",
      "weighted avg       0.27      0.25      0.24       720\n",
      "\n",
      "[[21 38 26 65]\n",
      " [19 61 27 76]\n",
      " [15 84 41 66]\n",
      " [15 76 35 55]]\n",
      "Validation Loss for P20 = 1.3916927576065063\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_173/4145799004.py:68: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/tmp/ipykernel_173/4145799004.py:41: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/100, Train Loss: 1.432396411895752\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.29      0.20      0.24       150\n",
      "           1       0.23      0.34      0.27       183\n",
      "           2       0.31      0.17      0.22       206\n",
      "           3       0.22      0.28      0.25       181\n",
      "\n",
      "    accuracy                           0.25       720\n",
      "   macro avg       0.26      0.25      0.24       720\n",
      "weighted avg       0.26      0.25      0.24       720\n",
      "\n",
      "[[30 41 22 57]\n",
      " [33 63 25 62]\n",
      " [21 93 35 57]\n",
      " [21 79 30 51]]\n",
      "Validation Loss for P20 = 1.3851889371871948\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_173/4145799004.py:68: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/tmp/ipykernel_173/4145799004.py:41: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6/100, Train Loss: 1.3732414245605469\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.30      0.25      0.27       150\n",
      "           1       0.23      0.37      0.29       183\n",
      "           2       0.34      0.18      0.24       206\n",
      "           3       0.21      0.23      0.22       181\n",
      "\n",
      "    accuracy                           0.26       720\n",
      "   macro avg       0.27      0.26      0.26       720\n",
      "weighted avg       0.27      0.26      0.25       720\n",
      "\n",
      "[[38 41 22 49]\n",
      " [41 68 23 51]\n",
      " [25 93 38 50]\n",
      " [23 89 28 41]]\n",
      "Validation Loss for P20 = 1.3846018314361572\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_173/4145799004.py:68: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/tmp/ipykernel_173/4145799004.py:41: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7/100, Train Loss: 1.4354918003082275\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.32      0.27      0.29       150\n",
      "           1       0.24      0.38      0.29       183\n",
      "           2       0.33      0.17      0.22       206\n",
      "           3       0.23      0.26      0.24       181\n",
      "\n",
      "    accuracy                           0.26       720\n",
      "   macro avg       0.28      0.27      0.26       720\n",
      "weighted avg       0.28      0.26      0.26       720\n",
      "\n",
      "[[40 40 21 49]\n",
      " [39 69 20 55]\n",
      " [24 92 34 56]\n",
      " [22 85 27 47]]\n",
      "Validation Loss for P20 = 1.3860467672348022\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_173/4145799004.py:68: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/tmp/ipykernel_173/4145799004.py:41: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8/100, Train Loss: 1.2681573629379272\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.33      0.29      0.31       150\n",
      "           1       0.22      0.32      0.26       183\n",
      "           2       0.31      0.18      0.23       206\n",
      "           3       0.23      0.27      0.25       181\n",
      "\n",
      "    accuracy                           0.26       720\n",
      "   macro avg       0.27      0.26      0.26       720\n",
      "weighted avg       0.27      0.26      0.26       720\n",
      "\n",
      "[[44 37 22 47]\n",
      " [43 58 27 55]\n",
      " [26 86 37 57]\n",
      " [22 78 33 48]]\n",
      "Validation Loss for P20 = 1.3916314840316772\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_173/4145799004.py:68: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/tmp/ipykernel_173/4145799004.py:41: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9/100, Train Loss: 1.4096972942352295\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.32      0.28      0.30       150\n",
      "           1       0.23      0.32      0.27       183\n",
      "           2       0.31      0.17      0.22       206\n",
      "           3       0.23      0.28      0.25       181\n",
      "\n",
      "    accuracy                           0.26       720\n",
      "   macro avg       0.27      0.26      0.26       720\n",
      "weighted avg       0.27      0.26      0.26       720\n",
      "\n",
      "[[42 38 22 48]\n",
      " [41 59 27 56]\n",
      " [26 85 36 59]\n",
      " [21 77 33 50]]\n",
      "Validation Loss for P20 = 1.3918544054031372\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_173/4145799004.py:68: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/tmp/ipykernel_173/4145799004.py:41: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10/100, Train Loss: 1.3800230026245117\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.32      0.29      0.31       150\n",
      "           1       0.24      0.34      0.28       183\n",
      "           2       0.34      0.16      0.21       206\n",
      "           3       0.26      0.33      0.29       181\n",
      "\n",
      "    accuracy                           0.27       720\n",
      "   macro avg       0.29      0.28      0.27       720\n",
      "weighted avg       0.29      0.27      0.27       720\n",
      "\n",
      "[[44 36 20 50]\n",
      " [45 62 17 59]\n",
      " [26 87 32 61]\n",
      " [22 75 25 59]]\n",
      "Validation Loss for P20 = 1.3857316970825195\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_173/4145799004.py:68: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/tmp/ipykernel_173/4145799004.py:41: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11/100, Train Loss: 1.4674116373062134\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.32      0.29      0.31       150\n",
      "           1       0.22      0.28      0.25       183\n",
      "           2       0.34      0.20      0.25       206\n",
      "           3       0.25      0.31      0.28       181\n",
      "\n",
      "    accuracy                           0.27       720\n",
      "   macro avg       0.28      0.27      0.27       720\n",
      "weighted avg       0.28      0.27      0.27       720\n",
      "\n",
      "[[44 35 20 51]\n",
      " [45 52 28 58]\n",
      " [26 78 42 60]\n",
      " [23 68 34 56]]\n",
      "Validation Loss for P20 = 1.3976337909698486\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_173/4145799004.py:68: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/tmp/ipykernel_173/4145799004.py:41: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12/100, Train Loss: 1.4608349800109863\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.33      0.32      0.32       150\n",
      "           1       0.23      0.32      0.27       183\n",
      "           2       0.33      0.17      0.22       206\n",
      "           3       0.25      0.31      0.28       181\n",
      "\n",
      "    accuracy                           0.27       720\n",
      "   macro avg       0.29      0.28      0.27       720\n",
      "weighted avg       0.28      0.27      0.27       720\n",
      "\n",
      "[[48 36 19 47]\n",
      " [47 58 20 58]\n",
      " [28 84 34 60]\n",
      " [24 70 31 56]]\n",
      "Validation Loss for P20 = 1.3865185976028442\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_173/4145799004.py:68: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/tmp/ipykernel_173/4145799004.py:41: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13/100, Train Loss: 1.416643500328064\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.33      0.33      0.33       150\n",
      "           1       0.23      0.30      0.26       183\n",
      "           2       0.34      0.19      0.24       206\n",
      "           3       0.25      0.30      0.27       181\n",
      "\n",
      "    accuracy                           0.28       720\n",
      "   macro avg       0.29      0.28      0.28       720\n",
      "weighted avg       0.29      0.28      0.27       720\n",
      "\n",
      "[[50 35 20 45]\n",
      " [48 55 23 57]\n",
      " [30 79 39 58]\n",
      " [25 69 33 54]]\n",
      "Validation Loss for P20 = 1.3845261335372925\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_173/4145799004.py:68: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/tmp/ipykernel_173/4145799004.py:41: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14/100, Train Loss: 1.4785704612731934\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.34      0.31      0.33       150\n",
      "           1       0.24      0.30      0.26       183\n",
      "           2       0.34      0.17      0.23       206\n",
      "           3       0.26      0.35      0.30       181\n",
      "\n",
      "    accuracy                           0.28       720\n",
      "   macro avg       0.29      0.28      0.28       720\n",
      "weighted avg       0.29      0.28      0.27       720\n",
      "\n",
      "[[47 34 20 49]\n",
      " [44 54 19 66]\n",
      " [25 77 36 68]\n",
      " [23 64 31 63]]\n",
      "Validation Loss for P20 = 1.3882896900177002\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_173/4145799004.py:68: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/tmp/ipykernel_173/4145799004.py:41: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15/100, Train Loss: 1.4287358522415161\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.33      0.33      0.33       150\n",
      "           1       0.23      0.28      0.25       183\n",
      "           2       0.32      0.18      0.23       206\n",
      "           3       0.26      0.33      0.29       181\n",
      "\n",
      "    accuracy                           0.27       720\n",
      "   macro avg       0.28      0.28      0.28       720\n",
      "weighted avg       0.28      0.27      0.27       720\n",
      "\n",
      "[[49 33 21 47]\n",
      " [48 52 25 58]\n",
      " [26 79 37 64]\n",
      " [25 63 34 59]]\n",
      "Validation Loss for P20 = 1.3895868062973022\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_173/4145799004.py:68: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/tmp/ipykernel_173/4145799004.py:41: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16/100, Train Loss: 1.4118965864181519\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.34      0.33      0.33       150\n",
      "           1       0.22      0.26      0.24       183\n",
      "           2       0.30      0.17      0.22       206\n",
      "           3       0.26      0.33      0.29       181\n",
      "\n",
      "    accuracy                           0.27       720\n",
      "   macro avg       0.28      0.27      0.27       720\n",
      "weighted avg       0.28      0.27      0.27       720\n",
      "\n",
      "[[49 33 23 45]\n",
      " [47 48 28 60]\n",
      " [24 76 36 70]\n",
      " [25 62 34 60]]\n",
      "Validation Loss for P20 = 1.3900340795516968\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_173/4145799004.py:68: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/tmp/ipykernel_173/4145799004.py:41: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17/100, Train Loss: 1.43242347240448\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_173/4145799004.py:68: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.32      0.29      0.31       150\n",
      "           1       0.21      0.23      0.22       183\n",
      "           2       0.33      0.16      0.22       206\n",
      "           3       0.24      0.37      0.29       181\n",
      "\n",
      "    accuracy                           0.26       720\n",
      "   macro avg       0.27      0.26      0.26       720\n",
      "weighted avg       0.27      0.26      0.25       720\n",
      "\n",
      "[[44 30 18 58]\n",
      " [45 42 21 75]\n",
      " [24 70 33 79]\n",
      " [25 62 27 67]]\n",
      "Validation Loss for P20 = 1.3893141746520996\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_173/4145799004.py:41: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 18/100, Train Loss: 1.4957069158554077\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_173/4145799004.py:68: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.33      0.34      0.34       150\n",
      "           1       0.20      0.22      0.21       183\n",
      "           2       0.31      0.17      0.22       206\n",
      "           3       0.26      0.36      0.30       181\n",
      "\n",
      "    accuracy                           0.27       720\n",
      "   macro avg       0.28      0.27      0.27       720\n",
      "weighted avg       0.27      0.27      0.26       720\n",
      "\n",
      "[[51 31 19 49]\n",
      " [48 40 28 67]\n",
      " [27 69 34 76]\n",
      " [27 60 28 66]]\n",
      "Validation Loss for P20 = 1.386501431465149\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_173/4145799004.py:41: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19/100, Train Loss: 1.4662309885025024\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_173/4145799004.py:68: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.33      0.33      0.33       150\n",
      "           1       0.20      0.22      0.21       183\n",
      "           2       0.33      0.15      0.21       206\n",
      "           3       0.26      0.39      0.31       181\n",
      "\n",
      "    accuracy                           0.27       720\n",
      "   macro avg       0.28      0.27      0.27       720\n",
      "weighted avg       0.28      0.27      0.26       720\n",
      "\n",
      "[[50 31 16 53]\n",
      " [50 41 26 66]\n",
      " [24 70 31 81]\n",
      " [27 63 21 70]]\n",
      "Validation Loss for P20 = 1.382900595664978\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_173/4145799004.py:41: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20/100, Train Loss: 1.44952392578125\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_173/4145799004.py:68: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.32      0.30      0.31       150\n",
      "           1       0.20      0.23      0.21       183\n",
      "           2       0.30      0.16      0.21       206\n",
      "           3       0.24      0.34      0.28       181\n",
      "\n",
      "    accuracy                           0.25       720\n",
      "   macro avg       0.26      0.26      0.25       720\n",
      "weighted avg       0.26      0.25      0.25       720\n",
      "\n",
      "[[45 32 23 50]\n",
      " [46 42 27 68]\n",
      " [25 73 33 75]\n",
      " [25 66 28 62]]\n",
      "Validation Loss for P20 = 1.3914732933044434\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_173/4145799004.py:41: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 21/100, Train Loss: 1.4871339797973633\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_173/4145799004.py:68: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.31      0.30      0.31       150\n",
      "           1       0.21      0.26      0.23       183\n",
      "           2       0.31      0.15      0.20       206\n",
      "           3       0.24      0.33      0.27       181\n",
      "\n",
      "    accuracy                           0.25       720\n",
      "   macro avg       0.27      0.26      0.25       720\n",
      "weighted avg       0.27      0.25      0.25       720\n",
      "\n",
      "[[45 33 19 53]\n",
      " [46 48 25 64]\n",
      " [26 75 31 74]\n",
      " [26 71 25 59]]\n",
      "Validation Loss for P20 = 1.384176254272461\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_173/4145799004.py:41: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 22/100, Train Loss: 1.4616886377334595\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_173/4145799004.py:68: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.33      0.34      0.33       150\n",
      "           1       0.22      0.25      0.23       183\n",
      "           2       0.30      0.17      0.21       206\n",
      "           3       0.24      0.31      0.27       181\n",
      "\n",
      "    accuracy                           0.26       720\n",
      "   macro avg       0.27      0.27      0.26       720\n",
      "weighted avg       0.27      0.26      0.26       720\n",
      "\n",
      "[[51 32 21 46]\n",
      " [51 46 28 58]\n",
      " [25 72 34 75]\n",
      " [29 63 32 57]]\n",
      "Validation Loss for P20 = 1.3861039876937866\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_173/4145799004.py:41: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 23/100, Train Loss: 1.3167163133621216\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_173/4145799004.py:68: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.31      0.33      0.32       150\n",
      "           1       0.21      0.22      0.21       183\n",
      "           2       0.31      0.17      0.22       206\n",
      "           3       0.24      0.34      0.28       181\n",
      "\n",
      "    accuracy                           0.26       720\n",
      "   macro avg       0.27      0.26      0.26       720\n",
      "weighted avg       0.27      0.26      0.25       720\n",
      "\n",
      "[[49 28 21 52]\n",
      " [54 40 24 65]\n",
      " [26 65 35 80]\n",
      " [27 60 32 62]]\n",
      "Validation Loss for P20 = 1.3856840133666992\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_173/4145799004.py:41: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 24/100, Train Loss: 1.4529529809951782\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.30      0.28      0.29       150\n",
      "           1       0.21      0.20      0.20       183\n",
      "           2       0.29      0.17      0.22       206\n",
      "           3       0.23      0.36      0.28       181\n",
      "\n",
      "    accuracy                           0.25       720\n",
      "   macro avg       0.26      0.25      0.25       720\n",
      "weighted avg       0.26      0.25      0.24       720\n",
      "\n",
      "[[42 26 24 58]\n",
      " [47 36 27 73]\n",
      " [25 54 36 91]\n",
      " [26 53 37 65]]\n",
      "Validation Loss for P20 = 1.397050142288208\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_173/4145799004.py:68: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/tmp/ipykernel_173/4145799004.py:41: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 25/100, Train Loss: 1.361546516418457\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.30      0.29      0.30       150\n",
      "           1       0.22      0.17      0.19       183\n",
      "           2       0.31      0.19      0.24       206\n",
      "           3       0.24      0.39      0.29       181\n",
      "\n",
      "    accuracy                           0.26       720\n",
      "   macro avg       0.27      0.26      0.25       720\n",
      "weighted avg       0.27      0.26      0.25       720\n",
      "\n",
      "[[44 24 24 58]\n",
      " [49 31 29 74]\n",
      " [25 43 40 98]\n",
      " [29 44 37 71]]\n",
      "Validation Loss for P20 = 1.3939355611801147\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_173/4145799004.py:68: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/tmp/ipykernel_173/4145799004.py:41: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 26/100, Train Loss: 1.4121289253234863\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.30      0.28      0.29       150\n",
      "           1       0.23      0.21      0.22       183\n",
      "           2       0.31      0.18      0.23       206\n",
      "           3       0.24      0.38      0.29       181\n",
      "\n",
      "    accuracy                           0.26       720\n",
      "   macro avg       0.27      0.26      0.26       720\n",
      "weighted avg       0.27      0.26      0.26       720\n",
      "\n",
      "[[42 27 23 58]\n",
      " [48 39 26 70]\n",
      " [24 51 38 93]\n",
      " [28 51 34 68]]\n",
      "Validation Loss for P20 = 1.3923150300979614\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_173/4145799004.py:68: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/tmp/ipykernel_173/4145799004.py:41: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 27/100, Train Loss: 1.2760270833969116\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.30      0.31      0.31       150\n",
      "           1       0.24      0.22      0.23       183\n",
      "           2       0.31      0.17      0.22       206\n",
      "           3       0.25      0.38      0.30       181\n",
      "\n",
      "    accuracy                           0.27       720\n",
      "   macro avg       0.27      0.27      0.26       720\n",
      "weighted avg       0.27      0.27      0.26       720\n",
      "\n",
      "[[47 26 23 54]\n",
      " [52 41 27 63]\n",
      " [27 51 36 92]\n",
      " [29 53 31 68]]\n",
      "Validation Loss for P20 = 1.384725570678711\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_173/4145799004.py:68: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/tmp/ipykernel_173/4145799004.py:41: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 28/100, Train Loss: 1.4550875425338745\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.30      0.33      0.31       150\n",
      "           1       0.21      0.15      0.17       183\n",
      "           2       0.29      0.20      0.24       206\n",
      "           3       0.25      0.40      0.31       181\n",
      "\n",
      "    accuracy                           0.26       720\n",
      "   macro avg       0.26      0.27      0.26       720\n",
      "weighted avg       0.26      0.26      0.25       720\n",
      "\n",
      "[[49 20 26 55]\n",
      " [54 27 34 68]\n",
      " [30 42 41 93]\n",
      " [30 41 38 72]]\n",
      "Validation Loss for P20 = 1.3871922492980957\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_173/4145799004.py:68: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/tmp/ipykernel_173/4145799004.py:41: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 29/100, Train Loss: 1.4281527996063232\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.28      0.28      0.28       150\n",
      "           1       0.24      0.19      0.21       183\n",
      "           2       0.31      0.20      0.24       206\n",
      "           3       0.23      0.38      0.29       181\n",
      "\n",
      "    accuracy                           0.26       720\n",
      "   macro avg       0.27      0.26      0.26       720\n",
      "weighted avg       0.27      0.26      0.25       720\n",
      "\n",
      "[[42 22 26 60]\n",
      " [52 34 27 70]\n",
      " [28 42 42 94]\n",
      " [28 43 42 68]]\n",
      "Validation Loss for P20 = 1.3929675817489624\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_173/4145799004.py:68: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/tmp/ipykernel_173/4145799004.py:41: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 30/100, Train Loss: 1.3592039346694946\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.28      0.25      0.26       150\n",
      "           1       0.22      0.16      0.18       183\n",
      "           2       0.31      0.24      0.27       206\n",
      "           3       0.24      0.39      0.29       181\n",
      "\n",
      "    accuracy                           0.26       720\n",
      "   macro avg       0.26      0.26      0.25       720\n",
      "weighted avg       0.26      0.26      0.25       720\n",
      "\n",
      "[[37 21 31 61]\n",
      " [47 29 34 73]\n",
      " [22 42 49 93]\n",
      " [26 40 45 70]]\n",
      "Validation Loss for P20 = 1.399171233177185\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_173/4145799004.py:68: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/tmp/ipykernel_173/4145799004.py:41: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 31/100, Train Loss: 1.5632905960083008\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_173/4145799004.py:68: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.30      0.29      0.29       150\n",
      "           1       0.22      0.17      0.19       183\n",
      "           2       0.30      0.19      0.23       206\n",
      "           3       0.23      0.39      0.29       181\n",
      "\n",
      "    accuracy                           0.26       720\n",
      "   macro avg       0.26      0.26      0.25       720\n",
      "weighted avg       0.26      0.26      0.25       720\n",
      "\n",
      "[[44 19 24 63]\n",
      " [50 31 28 74]\n",
      " [25 47 39 95]\n",
      " [30 43 38 70]]\n",
      "Validation Loss for P20 = 1.3915079832077026\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_173/4145799004.py:41: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 32/100, Train Loss: 1.3904696702957153\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_173/4145799004.py:68: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.29      0.29      0.29       150\n",
      "           1       0.22      0.16      0.19       183\n",
      "           2       0.32      0.20      0.25       206\n",
      "           3       0.24      0.39      0.30       181\n",
      "\n",
      "    accuracy                           0.26       720\n",
      "   macro avg       0.27      0.26      0.26       720\n",
      "weighted avg       0.27      0.26      0.25       720\n",
      "\n",
      "[[44 20 25 61]\n",
      " [54 30 27 72]\n",
      " [26 45 42 93]\n",
      " [30 41 39 71]]\n",
      "Validation Loss for P20 = 1.395860195159912\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_173/4145799004.py:41: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 33/100, Train Loss: 1.4428266286849976\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.29      0.29      0.29       150\n",
      "           1       0.23      0.17      0.19       183\n",
      "           2       0.33      0.20      0.25       206\n",
      "           3       0.23      0.39      0.29       181\n",
      "\n",
      "    accuracy                           0.26       720\n",
      "   macro avg       0.27      0.26      0.26       720\n",
      "weighted avg       0.27      0.26      0.25       720\n",
      "\n",
      "[[43 20 23 64]\n",
      " [52 31 24 76]\n",
      " [24 44 42 96]\n",
      " [30 42 38 71]]\n",
      "Validation Loss for P20 = 1.3919873237609863\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_173/4145799004.py:68: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/tmp/ipykernel_173/4145799004.py:41: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 34/100, Train Loss: 1.3773384094238281\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_173/4145799004.py:68: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.29      0.29      0.29       150\n",
      "           1       0.23      0.16      0.19       183\n",
      "           2       0.34      0.23      0.28       206\n",
      "           3       0.23      0.39      0.29       181\n",
      "\n",
      "    accuracy                           0.27       720\n",
      "   macro avg       0.27      0.27      0.26       720\n",
      "weighted avg       0.27      0.27      0.26       720\n",
      "\n",
      "[[43 19 25 63]\n",
      " [51 29 27 76]\n",
      " [25 39 48 94]\n",
      " [30 38 42 71]]\n",
      "Validation Loss for P20 = 1.3940423727035522\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_173/4145799004.py:41: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 35/100, Train Loss: 1.514923334121704\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.27      0.25      0.26       150\n",
      "           1       0.25      0.17      0.21       183\n",
      "           2       0.34      0.24      0.28       206\n",
      "           3       0.24      0.41      0.30       181\n",
      "\n",
      "    accuracy                           0.27       720\n",
      "   macro avg       0.28      0.27      0.26       720\n",
      "weighted avg       0.28      0.27      0.26       720\n",
      "\n",
      "[[38 20 25 67]\n",
      " [49 32 27 75]\n",
      " [25 39 50 92]\n",
      " [28 35 44 74]]\n",
      "Validation Loss for P20 = 1.3955671787261963\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_173/4145799004.py:68: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/tmp/ipykernel_173/4145799004.py:41: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 36/100, Train Loss: 1.4910941123962402\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.26      0.24      0.25       150\n",
      "           1       0.22      0.15      0.18       183\n",
      "           2       0.35      0.23      0.28       206\n",
      "           3       0.24      0.41      0.30       181\n",
      "\n",
      "    accuracy                           0.26       720\n",
      "   macro avg       0.27      0.26      0.25       720\n",
      "weighted avg       0.27      0.26      0.25       720\n",
      "\n",
      "[[36 18 26 70]\n",
      " [50 28 25 80]\n",
      " [25 40 47 94]\n",
      " [28 41 37 75]]\n",
      "Validation Loss for P20 = 1.3939642906188965\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_173/4145799004.py:68: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/tmp/ipykernel_173/4145799004.py:41: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 37/100, Train Loss: 1.4706894159317017\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.29      0.29      0.29       150\n",
      "           1       0.24      0.17      0.20       183\n",
      "           2       0.34      0.21      0.26       206\n",
      "           3       0.24      0.41      0.31       181\n",
      "\n",
      "    accuracy                           0.27       720\n",
      "   macro avg       0.28      0.27      0.26       720\n",
      "weighted avg       0.28      0.27      0.26       720\n",
      "\n",
      "[[44 19 24 63]\n",
      " [53 31 24 75]\n",
      " [27 41 44 94]\n",
      " [29 39 38 75]]\n",
      "Validation Loss for P20 = 1.3943313360214233\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_173/4145799004.py:68: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/tmp/ipykernel_173/4145799004.py:41: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 38/100, Train Loss: 1.3668988943099976\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.27      0.27      0.27       150\n",
      "           1       0.24      0.14      0.18       183\n",
      "           2       0.35      0.28      0.31       206\n",
      "           3       0.24      0.40      0.30       181\n",
      "\n",
      "    accuracy                           0.27       720\n",
      "   macro avg       0.28      0.27      0.26       720\n",
      "weighted avg       0.28      0.27      0.26       720\n",
      "\n",
      "[[40 17 27 66]\n",
      " [50 26 31 76]\n",
      " [26 35 57 88]\n",
      " [30 32 47 72]]\n",
      "Validation Loss for P20 = 1.3951696157455444\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_173/4145799004.py:68: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/tmp/ipykernel_173/4145799004.py:41: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 39/100, Train Loss: 1.365642786026001\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.29      0.31      0.30       150\n",
      "           1       0.24      0.13      0.17       183\n",
      "           2       0.34      0.29      0.31       206\n",
      "           3       0.24      0.39      0.29       181\n",
      "\n",
      "    accuracy                           0.28       720\n",
      "   macro avg       0.28      0.28      0.27       720\n",
      "weighted avg       0.28      0.28      0.27       720\n",
      "\n",
      "[[46 12 31 61]\n",
      " [54 23 32 74]\n",
      " [27 29 59 91]\n",
      " [31 30 50 70]]\n",
      "Validation Loss for P20 = 1.3986937999725342\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_173/4145799004.py:68: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/tmp/ipykernel_173/4145799004.py:41: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 40/100, Train Loss: 1.4001562595367432\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.28      0.29      0.28       150\n",
      "           1       0.27      0.19      0.22       183\n",
      "           2       0.36      0.23      0.28       206\n",
      "           3       0.25      0.42      0.31       181\n",
      "\n",
      "    accuracy                           0.28       720\n",
      "   macro avg       0.29      0.28      0.27       720\n",
      "weighted avg       0.29      0.28      0.27       720\n",
      "\n",
      "[[43 17 25 65]\n",
      " [54 34 22 73]\n",
      " [29 37 47 93]\n",
      " [30 38 37 76]]\n",
      "Validation Loss for P20 = 1.396028757095337\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_173/4145799004.py:68: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/tmp/ipykernel_173/4145799004.py:41: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 41/100, Train Loss: 1.3252089023590088\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.27      0.27      0.27       150\n",
      "           1       0.25      0.14      0.18       183\n",
      "           2       0.34      0.25      0.29       206\n",
      "           3       0.24      0.43      0.31       181\n",
      "\n",
      "    accuracy                           0.27       720\n",
      "   macro avg       0.28      0.27      0.26       720\n",
      "weighted avg       0.28      0.27      0.26       720\n",
      "\n",
      "[[40 15 28 67]\n",
      " [52 25 28 78]\n",
      " [27 28 52 99]\n",
      " [30 31 43 77]]\n",
      "Validation Loss for P20 = 1.4004350900650024\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_173/4145799004.py:68: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/tmp/ipykernel_173/4145799004.py:41: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 42/100, Train Loss: 1.42940092086792\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.26      0.25      0.26       150\n",
      "           1       0.24      0.14      0.17       183\n",
      "           2       0.32      0.21      0.26       206\n",
      "           3       0.23      0.43      0.30       181\n",
      "\n",
      "    accuracy                           0.26       720\n",
      "   macro avg       0.26      0.26      0.25       720\n",
      "weighted avg       0.26      0.26      0.25       720\n",
      "\n",
      "[[ 38  16  29  67]\n",
      " [ 52  25  25  81]\n",
      " [ 28  29  44 105]\n",
      " [ 30  33  41  77]]\n",
      "Validation Loss for P20 = 1.405346155166626\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_173/4145799004.py:68: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/tmp/ipykernel_173/4145799004.py:41: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 43/100, Train Loss: 1.3424659967422485\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.25      0.23      0.24       150\n",
      "           1       0.27      0.15      0.20       183\n",
      "           2       0.31      0.25      0.28       206\n",
      "           3       0.23      0.39      0.29       181\n",
      "\n",
      "    accuracy                           0.26       720\n",
      "   macro avg       0.26      0.26      0.25       720\n",
      "weighted avg       0.27      0.26      0.25       720\n",
      "\n",
      "[[34 13 34 69]\n",
      " [50 28 32 73]\n",
      " [25 31 52 98]\n",
      " [29 31 50 71]]\n",
      "Validation Loss for P20 = 1.4055285453796387\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_173/4145799004.py:68: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/tmp/ipykernel_173/4145799004.py:41: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 44/100, Train Loss: 1.4264041185379028\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.25      0.22      0.23       150\n",
      "           1       0.25      0.10      0.14       183\n",
      "           2       0.32      0.25      0.28       206\n",
      "           3       0.23      0.45      0.31       181\n",
      "\n",
      "    accuracy                           0.26       720\n",
      "   macro avg       0.26      0.26      0.24       720\n",
      "weighted avg       0.26      0.26      0.24       720\n",
      "\n",
      "[[ 33   7  34  76]\n",
      " [ 48  18  31  86]\n",
      " [ 23  23  52 108]\n",
      " [ 29  25  45  82]]\n",
      "Validation Loss for P20 = 1.414623498916626\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_173/4145799004.py:68: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/tmp/ipykernel_173/4145799004.py:41: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 45/100, Train Loss: 1.4397236108779907\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.26      0.24      0.25       150\n",
      "           1       0.27      0.13      0.17       183\n",
      "           2       0.32      0.23      0.27       206\n",
      "           3       0.24      0.45      0.31       181\n",
      "\n",
      "    accuracy                           0.26       720\n",
      "   macro avg       0.27      0.26      0.25       720\n",
      "weighted avg       0.27      0.26      0.25       720\n",
      "\n",
      "[[ 36   9  31  74]\n",
      " [ 50  23  28  82]\n",
      " [ 25  26  47 108]\n",
      " [ 30  28  41  82]]\n",
      "Validation Loss for P20 = 1.410177230834961\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_173/4145799004.py:68: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/tmp/ipykernel_173/4145799004.py:41: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 46/100, Train Loss: 1.3471945524215698\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.25      0.23      0.24       150\n",
      "           1       0.25      0.10      0.14       183\n",
      "           2       0.31      0.24      0.27       206\n",
      "           3       0.23      0.45      0.31       181\n",
      "\n",
      "    accuracy                           0.26       720\n",
      "   macro avg       0.26      0.26      0.24       720\n",
      "weighted avg       0.27      0.26      0.24       720\n",
      "\n",
      "[[ 35   7  33  75]\n",
      " [ 50  18  30  85]\n",
      " [ 24  23  50 109]\n",
      " [ 29  23  47  82]]\n",
      "Validation Loss for P20 = 1.4093114137649536\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_173/4145799004.py:68: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/tmp/ipykernel_173/4145799004.py:41: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 47/100, Train Loss: 1.3278999328613281\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.24      0.21      0.23       150\n",
      "           1       0.27      0.11      0.16       183\n",
      "           2       0.31      0.22      0.26       206\n",
      "           3       0.24      0.47      0.32       181\n",
      "\n",
      "    accuracy                           0.26       720\n",
      "   macro avg       0.26      0.26      0.24       720\n",
      "weighted avg       0.27      0.26      0.24       720\n",
      "\n",
      "[[ 32   7  33  78]\n",
      " [ 50  21  28  84]\n",
      " [ 23  26  46 111]\n",
      " [ 28  25  43  85]]\n",
      "Validation Loss for P20 = 1.4151554107666016\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_173/4145799004.py:68: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/tmp/ipykernel_173/4145799004.py:41: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 48/100, Train Loss: 1.381652593612671\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.24      0.23      0.23       150\n",
      "           1       0.26      0.13      0.17       183\n",
      "           2       0.31      0.20      0.25       206\n",
      "           3       0.24      0.46      0.31       181\n",
      "\n",
      "    accuracy                           0.25       720\n",
      "   macro avg       0.26      0.26      0.24       720\n",
      "weighted avg       0.26      0.25      0.24       720\n",
      "\n",
      "[[ 34  13  28  75]\n",
      " [ 50  24  25  84]\n",
      " [ 28  26  42 110]\n",
      " [ 29  30  39  83]]\n",
      "Validation Loss for P20 = 1.4105792045593262\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_173/4145799004.py:68: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/tmp/ipykernel_173/4145799004.py:41: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 49/100, Train Loss: 1.4803730249404907\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.24      0.21      0.23       150\n",
      "           1       0.25      0.12      0.16       183\n",
      "           2       0.29      0.19      0.23       206\n",
      "           3       0.24      0.48      0.32       181\n",
      "\n",
      "    accuracy                           0.25       720\n",
      "   macro avg       0.25      0.25      0.23       720\n",
      "weighted avg       0.26      0.25      0.23       720\n",
      "\n",
      "[[ 32  11  32  75]\n",
      " [ 49  22  25  87]\n",
      " [ 26  27  40 113]\n",
      " [ 27  27  41  86]]\n",
      "Validation Loss for P20 = 1.4192806482315063\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_173/4145799004.py:68: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/tmp/ipykernel_173/4145799004.py:41: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 50/100, Train Loss: 1.2935930490493774\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_173/4145799004.py:68: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.26      0.24      0.25       150\n",
      "           1       0.27      0.14      0.18       183\n",
      "           2       0.31      0.22      0.26       206\n",
      "           3       0.24      0.45      0.31       181\n",
      "\n",
      "    accuracy                           0.26       720\n",
      "   macro avg       0.27      0.26      0.25       720\n",
      "weighted avg       0.27      0.26      0.25       720\n",
      "\n",
      "[[ 36  10  34  70]\n",
      " [ 51  25  25  82]\n",
      " [ 25  27  45 109]\n",
      " [ 29  29  42  81]]\n",
      "Validation Loss for P20 = 1.4126050472259521\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_173/4145799004.py:41: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 51/100, Train Loss: 1.3113785982131958\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_173/4145799004.py:68: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.25      0.24      0.24       150\n",
      "           1       0.29      0.13      0.18       183\n",
      "           2       0.30      0.23      0.26       206\n",
      "           3       0.24      0.45      0.32       181\n",
      "\n",
      "    accuracy                           0.26       720\n",
      "   macro avg       0.27      0.26      0.25       720\n",
      "weighted avg       0.27      0.26      0.25       720\n",
      "\n",
      "[[ 36   8  35  71]\n",
      " [ 50  24  29  80]\n",
      " [ 28  27  47 104]\n",
      " [ 30  24  45  82]]\n",
      "Validation Loss for P20 = 1.4124188423156738\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_173/4145799004.py:41: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 52/100, Train Loss: 1.453054666519165\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_173/4145799004.py:68: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.25      0.25      0.25       150\n",
      "           1       0.28      0.14      0.18       183\n",
      "           2       0.31      0.22      0.26       206\n",
      "           3       0.24      0.45      0.31       181\n",
      "\n",
      "    accuracy                           0.26       720\n",
      "   macro avg       0.27      0.26      0.25       720\n",
      "weighted avg       0.27      0.26      0.25       720\n",
      "\n",
      "[[ 37   9  32  72]\n",
      " [ 52  25  25  81]\n",
      " [ 29  28  45 104]\n",
      " [ 31  28  41  81]]\n",
      "Validation Loss for P20 = 1.4115707874298096\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_173/4145799004.py:41: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 53/100, Train Loss: 1.359265923500061\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_173/4145799004.py:68: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.26      0.25      0.26       150\n",
      "           1       0.27      0.14      0.18       183\n",
      "           2       0.33      0.21      0.25       206\n",
      "           3       0.24      0.45      0.31       181\n",
      "\n",
      "    accuracy                           0.26       720\n",
      "   macro avg       0.27      0.26      0.25       720\n",
      "weighted avg       0.27      0.26      0.25       720\n",
      "\n",
      "[[ 38  10  30  72]\n",
      " [ 52  25  21  85]\n",
      " [ 28  28  43 107]\n",
      " [ 30  31  38  82]]\n",
      "Validation Loss for P20 = 1.4090899229049683\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_173/4145799004.py:41: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 54/100, Train Loss: 1.4168074131011963\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_173/4145799004.py:68: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.25      0.21      0.23       150\n",
      "           1       0.27      0.13      0.18       183\n",
      "           2       0.31      0.23      0.27       206\n",
      "           3       0.24      0.46      0.31       181\n",
      "\n",
      "    accuracy                           0.26       720\n",
      "   macro avg       0.27      0.26      0.25       720\n",
      "weighted avg       0.27      0.26      0.25       720\n",
      "\n",
      "[[ 31   9  35  75]\n",
      " [ 45  24  27  87]\n",
      " [ 23  27  48 108]\n",
      " [ 25  29  44  83]]\n",
      "Validation Loss for P20 = 1.4180448055267334\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_173/4145799004.py:41: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 55/100, Train Loss: 1.4061158895492554\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_173/4145799004.py:68: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.24      0.19      0.22       150\n",
      "           1       0.29      0.16      0.20       183\n",
      "           2       0.32      0.22      0.26       206\n",
      "           3       0.23      0.46      0.31       181\n",
      "\n",
      "    accuracy                           0.26       720\n",
      "   macro avg       0.27      0.26      0.25       720\n",
      "weighted avg       0.28      0.26      0.25       720\n",
      "\n",
      "[[ 29  12  33  76]\n",
      " [ 39  29  22  93]\n",
      " [ 25  28  46 107]\n",
      " [ 26  31  41  83]]\n",
      "Validation Loss for P20 = 1.4163790941238403\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_173/4145799004.py:41: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 56/100, Train Loss: 1.3115838766098022\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.25      0.21      0.23       150\n",
      "           1       0.27      0.13      0.18       183\n",
      "           2       0.31      0.21      0.25       206\n",
      "           3       0.23      0.46      0.31       181\n",
      "\n",
      "    accuracy                           0.25       720\n",
      "   macro avg       0.26      0.25      0.24       720\n",
      "weighted avg       0.27      0.25      0.24       720\n",
      "\n",
      "[[ 32  10  33  75]\n",
      " [ 43  24  25  91]\n",
      " [ 25  27  44 110]\n",
      " [ 28  29  41  83]]\n",
      "Validation Loss for P20 = 1.422773838043213\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_173/4145799004.py:68: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/tmp/ipykernel_173/4145799004.py:41: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 57/100, Train Loss: 1.2994753122329712\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.25      0.24      0.25       150\n",
      "           1       0.28      0.14      0.18       183\n",
      "           2       0.31      0.21      0.25       206\n",
      "           3       0.24      0.46      0.32       181\n",
      "\n",
      "    accuracy                           0.26       720\n",
      "   macro avg       0.27      0.26      0.25       720\n",
      "weighted avg       0.27      0.26      0.25       720\n",
      "\n",
      "[[ 36   9  33  72]\n",
      " [ 48  25  25  85]\n",
      " [ 28  27  43 108]\n",
      " [ 31  27  39  84]]\n",
      "Validation Loss for P20 = 1.413655161857605\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_173/4145799004.py:68: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/tmp/ipykernel_173/4145799004.py:41: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 58/100, Train Loss: 1.439710021018982\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.24      0.21      0.22       150\n",
      "           1       0.28      0.14      0.18       183\n",
      "           2       0.30      0.22      0.26       206\n",
      "           3       0.24      0.46      0.31       181\n",
      "\n",
      "    accuracy                           0.26       720\n",
      "   macro avg       0.27      0.26      0.24       720\n",
      "weighted avg       0.27      0.26      0.25       720\n",
      "\n",
      "[[ 31   9  34  76]\n",
      " [ 42  25  28  88]\n",
      " [ 27  28  46 105]\n",
      " [ 27  27  44  83]]\n",
      "Validation Loss for P20 = 1.4210704565048218\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_173/4145799004.py:68: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/tmp/ipykernel_173/4145799004.py:41: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 59/100, Train Loss: 1.3030771017074585\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.26      0.25      0.25       150\n",
      "           1       0.27      0.12      0.17       183\n",
      "           2       0.31      0.21      0.25       206\n",
      "           3       0.24      0.46      0.31       181\n",
      "\n",
      "    accuracy                           0.26       720\n",
      "   macro avg       0.27      0.26      0.25       720\n",
      "weighted avg       0.27      0.26      0.24       720\n",
      "\n",
      "[[ 37  10  32  71]\n",
      " [ 46  22  24  91]\n",
      " [ 28  26  43 109]\n",
      " [ 32  24  41  84]]\n",
      "Validation Loss for P20 = 1.4159802198410034\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_173/4145799004.py:68: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/tmp/ipykernel_173/4145799004.py:41: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 60/100, Train Loss: 1.3301799297332764\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.24      0.23      0.23       150\n",
      "           1       0.29      0.13      0.18       183\n",
      "           2       0.32      0.23      0.27       206\n",
      "           3       0.24      0.46      0.31       181\n",
      "\n",
      "    accuracy                           0.26       720\n",
      "   macro avg       0.27      0.26      0.25       720\n",
      "weighted avg       0.28      0.26      0.25       720\n",
      "\n",
      "[[ 34   8  36  72]\n",
      " [ 47  23  25  88]\n",
      " [ 27  25  48 106]\n",
      " [ 33  22  43  83]]\n",
      "Validation Loss for P20 = 1.4198089838027954\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_173/4145799004.py:68: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/tmp/ipykernel_173/4145799004.py:41: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 61/100, Train Loss: 1.3628511428833008\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_173/4145799004.py:68: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.26      0.24      0.25       150\n",
      "           1       0.28      0.12      0.17       183\n",
      "           2       0.28      0.19      0.23       206\n",
      "           3       0.24      0.47      0.31       181\n",
      "\n",
      "    accuracy                           0.25       720\n",
      "   macro avg       0.26      0.26      0.24       720\n",
      "weighted avg       0.26      0.25      0.24       720\n",
      "\n",
      "[[ 36   8  33  73]\n",
      " [ 48  22  25  88]\n",
      " [ 28  24  40 114]\n",
      " [ 28  25  43  85]]\n",
      "Validation Loss for P20 = 1.419862151145935\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_173/4145799004.py:41: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 62/100, Train Loss: 1.4140413999557495\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_173/4145799004.py:68: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.25      0.25      0.25       150\n",
      "           1       0.31      0.12      0.17       183\n",
      "           2       0.30      0.22      0.26       206\n",
      "           3       0.24      0.46      0.31       181\n",
      "\n",
      "    accuracy                           0.26       720\n",
      "   macro avg       0.27      0.26      0.25       720\n",
      "weighted avg       0.28      0.26      0.25       720\n",
      "\n",
      "[[ 37   8  35  70]\n",
      " [ 49  22  28  84]\n",
      " [ 29  21  46 110]\n",
      " [ 32  21  45  83]]\n",
      "Validation Loss for P20 = 1.4194167852401733\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_173/4145799004.py:41: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 63/100, Train Loss: 1.3660939931869507\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.25      0.24      0.25       150\n",
      "           1       0.29      0.11      0.16       183\n",
      "           2       0.29      0.20      0.24       206\n",
      "           3       0.24      0.48      0.32       181\n",
      "\n",
      "    accuracy                           0.26       720\n",
      "   macro avg       0.27      0.26      0.24       720\n",
      "weighted avg       0.27      0.26      0.24       720\n",
      "\n",
      "[[ 36   8  35  71]\n",
      " [ 47  20  26  90]\n",
      " [ 28  19  42 117]\n",
      " [ 32  21  42  86]]\n",
      "Validation Loss for P20 = 1.425620675086975\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_173/4145799004.py:68: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/tmp/ipykernel_173/4145799004.py:41: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 64/100, Train Loss: 1.333431601524353\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.24      0.23      0.24       150\n",
      "           1       0.28      0.10      0.15       183\n",
      "           2       0.31      0.22      0.26       206\n",
      "           3       0.24      0.47      0.32       181\n",
      "\n",
      "    accuracy                           0.26       720\n",
      "   macro avg       0.27      0.26      0.24       720\n",
      "weighted avg       0.27      0.26      0.24       720\n",
      "\n",
      "[[ 35   9  34  72]\n",
      " [ 49  19  27  88]\n",
      " [ 28  20  46 112]\n",
      " [ 34  21  41  85]]\n",
      "Validation Loss for P20 = 1.4249634742736816\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_173/4145799004.py:68: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/tmp/ipykernel_173/4145799004.py:41: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 65/100, Train Loss: 1.4336779117584229\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.24      0.22      0.23       150\n",
      "           1       0.28      0.09      0.14       183\n",
      "           2       0.30      0.22      0.26       206\n",
      "           3       0.24      0.48      0.32       181\n",
      "\n",
      "    accuracy                           0.25       720\n",
      "   macro avg       0.26      0.25      0.24       720\n",
      "weighted avg       0.27      0.25      0.24       720\n",
      "\n",
      "[[ 33   7  37  73]\n",
      " [ 45  17  27  94]\n",
      " [ 27  18  46 115]\n",
      " [ 31  19  44  87]]\n",
      "Validation Loss for P20 = 1.4335987567901611\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_173/4145799004.py:68: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/tmp/ipykernel_173/4145799004.py:41: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 66/100, Train Loss: 1.4160616397857666\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.26      0.27      0.26       150\n",
      "           1       0.29      0.11      0.16       183\n",
      "           2       0.32      0.21      0.26       206\n",
      "           3       0.24      0.47      0.32       181\n",
      "\n",
      "    accuracy                           0.26       720\n",
      "   macro avg       0.28      0.27      0.25       720\n",
      "weighted avg       0.28      0.26      0.25       720\n",
      "\n",
      "[[ 40   9  30  71]\n",
      " [ 49  21  23  90]\n",
      " [ 30  22  44 110]\n",
      " [ 34  20  42  85]]\n",
      "Validation Loss for P20 = 1.4190751314163208\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_173/4145799004.py:68: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/tmp/ipykernel_173/4145799004.py:41: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 67/100, Train Loss: 1.3226748704910278\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.27      0.28      0.27       150\n",
      "           1       0.28      0.10      0.15       183\n",
      "           2       0.31      0.21      0.25       206\n",
      "           3       0.23      0.46      0.31       181\n",
      "\n",
      "    accuracy                           0.26       720\n",
      "   macro avg       0.27      0.26      0.25       720\n",
      "weighted avg       0.28      0.26      0.25       720\n",
      "\n",
      "[[ 42   6  31  71]\n",
      " [ 50  19  25  89]\n",
      " [ 29  21  44 112]\n",
      " [ 35  21  42  83]]\n",
      "Validation Loss for P20 = 1.4192078113555908\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_173/4145799004.py:68: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/tmp/ipykernel_173/4145799004.py:41: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 68/100, Train Loss: 1.400561809539795\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.26      0.25      0.26       150\n",
      "           1       0.29      0.11      0.16       183\n",
      "           2       0.28      0.20      0.24       206\n",
      "           3       0.23      0.46      0.31       181\n",
      "\n",
      "    accuracy                           0.26       720\n",
      "   macro avg       0.27      0.26      0.24       720\n",
      "weighted avg       0.27      0.26      0.24       720\n",
      "\n",
      "[[ 38   7  35  70]\n",
      " [ 46  20  26  91]\n",
      " [ 28  21  42 115]\n",
      " [ 32  20  45  84]]\n",
      "Validation Loss for P20 = 1.4248809814453125\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_173/4145799004.py:68: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/tmp/ipykernel_173/4145799004.py:41: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 69/100, Train Loss: 1.3223838806152344\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.26      0.27      0.26       150\n",
      "           1       0.31      0.11      0.16       183\n",
      "           2       0.28      0.18      0.22       206\n",
      "           3       0.24      0.48      0.32       181\n",
      "\n",
      "    accuracy                           0.26       720\n",
      "   macro avg       0.27      0.26      0.24       720\n",
      "weighted avg       0.27      0.26      0.24       720\n",
      "\n",
      "[[ 40   7  32  71]\n",
      " [ 49  20  22  92]\n",
      " [ 30  20  37 119]\n",
      " [ 35  18  41  87]]\n",
      "Validation Loss for P20 = 1.4222854375839233\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_173/4145799004.py:68: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/tmp/ipykernel_173/4145799004.py:41: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 70/100, Train Loss: 1.4287675619125366\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.25      0.24      0.24       150\n",
      "           1       0.31      0.13      0.18       183\n",
      "           2       0.31      0.22      0.26       206\n",
      "           3       0.23      0.45      0.30       181\n",
      "\n",
      "    accuracy                           0.26       720\n",
      "   macro avg       0.27      0.26      0.25       720\n",
      "weighted avg       0.28      0.26      0.25       720\n",
      "\n",
      "[[ 36   7  35  72]\n",
      " [ 47  23  23  90]\n",
      " [ 27  23  45 111]\n",
      " [ 35  22  43  81]]\n",
      "Validation Loss for P20 = 1.423919677734375\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_173/4145799004.py:68: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/tmp/ipykernel_173/4145799004.py:41: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 71/100, Train Loss: 1.3738858699798584\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_173/4145799004.py:68: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.26      0.27      0.26       150\n",
      "           1       0.28      0.10      0.15       183\n",
      "           2       0.33      0.23      0.27       206\n",
      "           3       0.24      0.46      0.31       181\n",
      "\n",
      "    accuracy                           0.26       720\n",
      "   macro avg       0.28      0.26      0.25       720\n",
      "weighted avg       0.28      0.26      0.25       720\n",
      "\n",
      "[[ 40   8  31  71]\n",
      " [ 50  19  23  91]\n",
      " [ 30  21  47 108]\n",
      " [ 36  19  43  83]]\n",
      "Validation Loss for P20 = 1.4208563566207886\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_173/4145799004.py:41: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 72/100, Train Loss: 1.3723435401916504\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_173/4145799004.py:68: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.24      0.22      0.23       150\n",
      "           1       0.28      0.10      0.15       183\n",
      "           2       0.30      0.20      0.24       206\n",
      "           3       0.23      0.47      0.31       181\n",
      "\n",
      "    accuracy                           0.25       720\n",
      "   macro avg       0.26      0.25      0.23       720\n",
      "weighted avg       0.26      0.25      0.23       720\n",
      "\n",
      "[[ 33   6  32  79]\n",
      " [ 44  19  23  97]\n",
      " [ 29  21  41 115]\n",
      " [ 33  21  42  85]]\n",
      "Validation Loss for P20 = 1.425918459892273\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_173/4145799004.py:41: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 73/100, Train Loss: 1.3768868446350098\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_173/4145799004.py:68: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.27      0.26      0.26       150\n",
      "           1       0.31      0.11      0.17       183\n",
      "           2       0.32      0.23      0.27       206\n",
      "           3       0.24      0.48      0.32       181\n",
      "\n",
      "    accuracy                           0.27       720\n",
      "   macro avg       0.29      0.27      0.26       720\n",
      "weighted avg       0.29      0.27      0.26       720\n",
      "\n",
      "[[ 39   7  33  71]\n",
      " [ 46  21  25  91]\n",
      " [ 26  20  48 112]\n",
      " [ 34  19  42  86]]\n",
      "Validation Loss for P20 = 1.4276098012924194\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_173/4145799004.py:41: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 74/100, Train Loss: 1.316617488861084\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_173/4145799004.py:68: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.27      0.27      0.27       150\n",
      "           1       0.31      0.12      0.17       183\n",
      "           2       0.28      0.18      0.22       206\n",
      "           3       0.24      0.49      0.32       181\n",
      "\n",
      "    accuracy                           0.26       720\n",
      "   macro avg       0.27      0.26      0.25       720\n",
      "weighted avg       0.28      0.26      0.24       720\n",
      "\n",
      "[[ 40   8  30  72]\n",
      " [ 47  22  22  92]\n",
      " [ 31  21  37 117]\n",
      " [ 32  20  41  88]]\n",
      "Validation Loss for P20 = 1.4251359701156616\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_173/4145799004.py:41: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 75/100, Train Loss: 1.3346127271652222\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_173/4145799004.py:68: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.25      0.25      0.25       150\n",
      "           1       0.32      0.12      0.18       183\n",
      "           2       0.30      0.20      0.24       206\n",
      "           3       0.24      0.48      0.32       181\n",
      "\n",
      "    accuracy                           0.26       720\n",
      "   macro avg       0.28      0.26      0.25       720\n",
      "weighted avg       0.28      0.26      0.24       720\n",
      "\n",
      "[[ 37   7  32  74]\n",
      " [ 48  22  21  92]\n",
      " [ 29  20  41 116]\n",
      " [ 32  19  43  87]]\n",
      "Validation Loss for P20 = 1.4253123998641968\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_173/4145799004.py:41: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 76/100, Train Loss: 1.39272141456604\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_173/4145799004.py:68: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.27      0.27      0.27       150\n",
      "           1       0.30      0.10      0.15       183\n",
      "           2       0.30      0.19      0.23       206\n",
      "           3       0.24      0.49      0.32       181\n",
      "\n",
      "    accuracy                           0.26       720\n",
      "   macro avg       0.27      0.26      0.24       720\n",
      "weighted avg       0.28      0.26      0.24       720\n",
      "\n",
      "[[ 40   6  30  74]\n",
      " [ 49  18  20  96]\n",
      " [ 29  19  39 119]\n",
      " [ 32  17  43  89]]\n",
      "Validation Loss for P20 = 1.430331826210022\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_173/4145799004.py:41: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 77/100, Train Loss: 1.3191958665847778\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_173/4145799004.py:68: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.25      0.27      0.26       150\n",
      "           1       0.31      0.11      0.16       183\n",
      "           2       0.27      0.17      0.21       206\n",
      "           3       0.23      0.46      0.31       181\n",
      "\n",
      "    accuracy                           0.25       720\n",
      "   macro avg       0.27      0.25      0.24       720\n",
      "weighted avg       0.27      0.25      0.23       720\n",
      "\n",
      "[[ 40   5  33  72]\n",
      " [ 51  20  21  91]\n",
      " [ 32  20  36 118]\n",
      " [ 34  20  43  84]]\n",
      "Validation Loss for P20 = 1.4265968799591064\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_173/4145799004.py:41: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 78/100, Train Loss: 1.4080919027328491\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_173/4145799004.py:68: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.26      0.26      0.26       150\n",
      "           1       0.29      0.09      0.14       183\n",
      "           2       0.27      0.19      0.22       206\n",
      "           3       0.23      0.46      0.31       181\n",
      "\n",
      "    accuracy                           0.25       720\n",
      "   macro avg       0.26      0.25      0.23       720\n",
      "weighted avg       0.26      0.25      0.23       720\n",
      "\n",
      "[[ 39   4  36  71]\n",
      " [ 48  17  24  94]\n",
      " [ 31  19  39 117]\n",
      " [ 34  18  45  84]]\n",
      "Validation Loss for P20 = 1.4261431694030762\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_173/4145799004.py:41: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 79/100, Train Loss: 1.4090197086334229\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_173/4145799004.py:68: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.25      0.24      0.24       150\n",
      "           1       0.24      0.06      0.10       183\n",
      "           2       0.26      0.20      0.22       206\n",
      "           3       0.23      0.46      0.30       181\n",
      "\n",
      "    accuracy                           0.24       720\n",
      "   macro avg       0.24      0.24      0.22       720\n",
      "weighted avg       0.24      0.24      0.22       720\n",
      "\n",
      "[[ 36   3  40  71]\n",
      " [ 47  11  29  96]\n",
      " [ 29  16  41 120]\n",
      " [ 32  16  49  84]]\n",
      "Validation Loss for P20 = 1.4392848014831543\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_173/4145799004.py:41: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 80/100, Train Loss: 1.3619149923324585\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_173/4145799004.py:68: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.26      0.25      0.25       150\n",
      "           1       0.27      0.08      0.12       183\n",
      "           2       0.27      0.19      0.22       206\n",
      "           3       0.23      0.48      0.31       181\n",
      "\n",
      "    accuracy                           0.25       720\n",
      "   macro avg       0.26      0.25      0.23       720\n",
      "weighted avg       0.26      0.25      0.22       720\n",
      "\n",
      "[[ 37   4  36  73]\n",
      " [ 47  14  25  97]\n",
      " [ 30  16  39 121]\n",
      " [ 30  17  47  87]]\n",
      "Validation Loss for P20 = 1.4434516429901123\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_173/4145799004.py:41: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 81/100, Train Loss: 1.3831453323364258\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_173/4145799004.py:68: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.26      0.25      0.25       150\n",
      "           1       0.22      0.06      0.09       183\n",
      "           2       0.28      0.19      0.23       206\n",
      "           3       0.23      0.49      0.31       181\n",
      "\n",
      "    accuracy                           0.24       720\n",
      "   macro avg       0.25      0.25      0.22       720\n",
      "weighted avg       0.25      0.24      0.22       720\n",
      "\n",
      "[[ 37   4  32  77]\n",
      " [ 48  11  25  99]\n",
      " [ 28  16  39 123]\n",
      " [ 31  18  44  88]]\n",
      "Validation Loss for P20 = 1.4426054954528809\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_173/4145799004.py:41: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 82/100, Train Loss: 1.415124773979187\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_173/4145799004.py:68: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.24      0.23      0.24       150\n",
      "           1       0.22      0.06      0.09       183\n",
      "           2       0.26      0.19      0.22       206\n",
      "           3       0.23      0.48      0.31       181\n",
      "\n",
      "    accuracy                           0.24       720\n",
      "   macro avg       0.24      0.24      0.22       720\n",
      "weighted avg       0.24      0.24      0.21       720\n",
      "\n",
      "[[ 35   4  35  76]\n",
      " [ 49  11  31  92]\n",
      " [ 31  15  39 121]\n",
      " [ 32  19  43  87]]\n",
      "Validation Loss for P20 = 1.443824052810669\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_173/4145799004.py:41: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 83/100, Train Loss: 1.349381923675537\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_173/4145799004.py:68: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.24      0.23      0.23       150\n",
      "           1       0.24      0.07      0.10       183\n",
      "           2       0.28      0.18      0.22       206\n",
      "           3       0.23      0.50      0.32       181\n",
      "\n",
      "    accuracy                           0.24       720\n",
      "   macro avg       0.25      0.24      0.22       720\n",
      "weighted avg       0.25      0.24      0.22       720\n",
      "\n",
      "[[ 34   5  33  78]\n",
      " [ 47  12  26  98]\n",
      " [ 29  15  38 124]\n",
      " [ 31  19  41  90]]\n",
      "Validation Loss for P20 = 1.441904902458191\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_173/4145799004.py:41: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 84/100, Train Loss: 1.2657169103622437\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_173/4145799004.py:68: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.25      0.25      0.25       150\n",
      "           1       0.24      0.07      0.10       183\n",
      "           2       0.28      0.18      0.22       206\n",
      "           3       0.23      0.50      0.31       181\n",
      "\n",
      "    accuracy                           0.24       720\n",
      "   macro avg       0.25      0.25      0.22       720\n",
      "weighted avg       0.25      0.24      0.22       720\n",
      "\n",
      "[[ 37   5  30  78]\n",
      " [ 47  12  24 100]\n",
      " [ 30  14  37 125]\n",
      " [ 32  18  41  90]]\n",
      "Validation Loss for P20 = 1.4380468130111694\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_173/4145799004.py:41: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 85/100, Train Loss: 1.4805272817611694\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_173/4145799004.py:68: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.25      0.25      0.25       150\n",
      "           1       0.24      0.07      0.11       183\n",
      "           2       0.27      0.17      0.21       206\n",
      "           3       0.23      0.49      0.32       181\n",
      "\n",
      "    accuracy                           0.24       720\n",
      "   macro avg       0.25      0.25      0.22       720\n",
      "weighted avg       0.25      0.24      0.22       720\n",
      "\n",
      "[[ 38   5  31  76]\n",
      " [ 50  13  24  96]\n",
      " [ 31  17  36 122]\n",
      " [ 33  19  40  89]]\n",
      "Validation Loss for P20 = 1.4365437030792236\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_173/4145799004.py:41: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 86/100, Train Loss: 1.4127854108810425\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_173/4145799004.py:68: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.25      0.25      0.25       150\n",
      "           1       0.25      0.07      0.11       183\n",
      "           2       0.28      0.19      0.22       206\n",
      "           3       0.23      0.48      0.31       181\n",
      "\n",
      "    accuracy                           0.24       720\n",
      "   macro avg       0.25      0.25      0.22       720\n",
      "weighted avg       0.25      0.24      0.22       720\n",
      "\n",
      "[[ 37   4  32  77]\n",
      " [ 48  13  25  97]\n",
      " [ 30  17  39 120]\n",
      " [ 31  18  45  87]]\n",
      "Validation Loss for P20 = 1.4379585981369019\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_173/4145799004.py:41: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 87/100, Train Loss: 1.3399147987365723\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_173/4145799004.py:68: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.24      0.22      0.23       150\n",
      "           1       0.24      0.07      0.11       183\n",
      "           2       0.26      0.18      0.22       206\n",
      "           3       0.23      0.49      0.31       181\n",
      "\n",
      "    accuracy                           0.24       720\n",
      "   macro avg       0.24      0.24      0.22       720\n",
      "weighted avg       0.24      0.24      0.22       720\n",
      "\n",
      "[[ 33   5  36  76]\n",
      " [ 46  13  27  97]\n",
      " [ 28  17  38 123]\n",
      " [ 30  19  44  88]]\n",
      "Validation Loss for P20 = 1.4438918828964233\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_173/4145799004.py:41: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 88/100, Train Loss: 1.4325392246246338\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_173/4145799004.py:68: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.25      0.23      0.24       150\n",
      "           1       0.23      0.07      0.11       183\n",
      "           2       0.28      0.18      0.22       206\n",
      "           3       0.23      0.49      0.31       181\n",
      "\n",
      "    accuracy                           0.24       720\n",
      "   macro avg       0.25      0.24      0.22       720\n",
      "weighted avg       0.25      0.24      0.22       720\n",
      "\n",
      "[[ 34   6  34  76]\n",
      " [ 42  13  26 102]\n",
      " [ 30  17  38 121]\n",
      " [ 32  20  40  89]]\n",
      "Validation Loss for P20 = 1.4420650005340576\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_173/4145799004.py:41: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 89/100, Train Loss: 1.363416314125061\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_173/4145799004.py:68: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.24      0.23      0.24       150\n",
      "           1       0.24      0.07      0.11       183\n",
      "           2       0.28      0.18      0.22       206\n",
      "           3       0.23      0.50      0.32       181\n",
      "\n",
      "    accuracy                           0.24       720\n",
      "   macro avg       0.25      0.25      0.22       720\n",
      "weighted avg       0.25      0.24      0.22       720\n",
      "\n",
      "[[ 35   5  34  76]\n",
      " [ 47  13  27  96]\n",
      " [ 30  15  38 123]\n",
      " [ 32  22  37  90]]\n",
      "Validation Loss for P20 = 1.4478563070297241\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_173/4145799004.py:41: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 90/100, Train Loss: 1.3840723037719727\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_173/4145799004.py:68: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.25      0.24      0.24       150\n",
      "           1       0.23      0.08      0.12       183\n",
      "           2       0.28      0.18      0.22       206\n",
      "           3       0.23      0.50      0.32       181\n",
      "\n",
      "    accuracy                           0.25       720\n",
      "   macro avg       0.25      0.25      0.22       720\n",
      "weighted avg       0.25      0.25      0.22       720\n",
      "\n",
      "[[ 36   6  31  77]\n",
      " [ 45  14  26  98]\n",
      " [ 30  18  37 121]\n",
      " [ 33  22  36  90]]\n",
      "Validation Loss for P20 = 1.4470598697662354\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_173/4145799004.py:41: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 91/100, Train Loss: 1.3619394302368164\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_173/4145799004.py:68: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.24      0.23      0.24       150\n",
      "           1       0.25      0.07      0.11       183\n",
      "           2       0.27      0.19      0.22       206\n",
      "           3       0.24      0.50      0.32       181\n",
      "\n",
      "    accuracy                           0.25       720\n",
      "   macro avg       0.25      0.25      0.22       720\n",
      "weighted avg       0.25      0.25      0.22       720\n",
      "\n",
      "[[ 35   5  32  78]\n",
      " [ 46  13  34  90]\n",
      " [ 29  15  39 123]\n",
      " [ 33  20  37  91]]\n",
      "Validation Loss for P20 = 1.4501768350601196\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_173/4145799004.py:41: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 92/100, Train Loss: 1.3474868535995483\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_173/4145799004.py:68: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.25      0.24      0.24       150\n",
      "           1       0.24      0.07      0.11       183\n",
      "           2       0.28      0.18      0.22       206\n",
      "           3       0.24      0.51      0.33       181\n",
      "\n",
      "    accuracy                           0.25       720\n",
      "   macro avg       0.25      0.25      0.22       720\n",
      "weighted avg       0.25      0.25      0.22       720\n",
      "\n",
      "[[ 36   6  31  77]\n",
      " [ 48  13  25  97]\n",
      " [ 29  16  37 124]\n",
      " [ 32  19  37  93]]\n",
      "Validation Loss for P20 = 1.4460501670837402\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_173/4145799004.py:41: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 93/100, Train Loss: 1.416760802268982\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_173/4145799004.py:68: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.25      0.23      0.24       150\n",
      "           1       0.25      0.07      0.11       183\n",
      "           2       0.28      0.19      0.23       206\n",
      "           3       0.24      0.51      0.32       181\n",
      "\n",
      "    accuracy                           0.25       720\n",
      "   macro avg       0.25      0.25      0.23       720\n",
      "weighted avg       0.26      0.25      0.22       720\n",
      "\n",
      "[[ 35   5  33  77]\n",
      " [ 46  13  27  97]\n",
      " [ 28  15  39 124]\n",
      " [ 30  19  40  92]]\n",
      "Validation Loss for P20 = 1.4489227533340454\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_173/4145799004.py:41: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 94/100, Train Loss: 1.3858531713485718\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_173/4145799004.py:68: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.25      0.23      0.24       150\n",
      "           1       0.25      0.08      0.12       183\n",
      "           2       0.28      0.19      0.22       206\n",
      "           3       0.23      0.49      0.31       181\n",
      "\n",
      "    accuracy                           0.24       720\n",
      "   macro avg       0.25      0.25      0.22       720\n",
      "weighted avg       0.25      0.24      0.22       720\n",
      "\n",
      "[[ 35   6  33  76]\n",
      " [ 45  14  27  97]\n",
      " [ 29  16  39 122]\n",
      " [ 31  20  42  88]]\n",
      "Validation Loss for P20 = 1.4474579095840454\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_173/4145799004.py:41: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 95/100, Train Loss: 1.453468680381775\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_173/4145799004.py:68: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.25      0.23      0.24       150\n",
      "           1       0.26      0.09      0.13       183\n",
      "           2       0.28      0.18      0.22       206\n",
      "           3       0.24      0.51      0.32       181\n",
      "\n",
      "    accuracy                           0.25       720\n",
      "   macro avg       0.26      0.25      0.23       720\n",
      "weighted avg       0.26      0.25      0.23       720\n",
      "\n",
      "[[ 34   6  33  77]\n",
      " [ 44  16  25  98]\n",
      " [ 27  19  37 123]\n",
      " [ 30  20  39  92]]\n",
      "Validation Loss for P20 = 1.4538081884384155\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_173/4145799004.py:41: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 96/100, Train Loss: 1.3578640222549438\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_173/4145799004.py:68: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.24      0.23      0.24       150\n",
      "           1       0.23      0.07      0.11       183\n",
      "           2       0.28      0.18      0.22       206\n",
      "           3       0.24      0.51      0.32       181\n",
      "\n",
      "    accuracy                           0.24       720\n",
      "   macro avg       0.25      0.25      0.22       720\n",
      "weighted avg       0.25      0.24      0.22       720\n",
      "\n",
      "[[ 34   5  33  78]\n",
      " [ 46  13  26  98]\n",
      " [ 28  18  37 123]\n",
      " [ 31  21  37  92]]\n",
      "Validation Loss for P20 = 1.4543708562850952\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_173/4145799004.py:41: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 97/100, Train Loss: 1.4862966537475586\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_173/4145799004.py:68: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.26      0.24      0.25       150\n",
      "           1       0.23      0.07      0.11       183\n",
      "           2       0.28      0.18      0.22       206\n",
      "           3       0.24      0.51      0.32       181\n",
      "\n",
      "    accuracy                           0.25       720\n",
      "   macro avg       0.25      0.25      0.22       720\n",
      "weighted avg       0.25      0.25      0.22       720\n",
      "\n",
      "[[ 36   5  31  78]\n",
      " [ 46  13  26  98]\n",
      " [ 28  18  37 123]\n",
      " [ 31  21  37  92]]\n",
      "Validation Loss for P20 = 1.4508620500564575\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_173/4145799004.py:41: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 98/100, Train Loss: 1.3742969036102295\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_173/4145799004.py:68: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.25      0.22      0.23       150\n",
      "           1       0.27      0.08      0.13       183\n",
      "           2       0.29      0.20      0.24       206\n",
      "           3       0.23      0.50      0.31       181\n",
      "\n",
      "    accuracy                           0.25       720\n",
      "   macro avg       0.26      0.25      0.23       720\n",
      "weighted avg       0.26      0.25      0.23       720\n",
      "\n",
      "[[ 33   5  32  80]\n",
      " [ 41  15  25 102]\n",
      " [ 27  16  41 122]\n",
      " [ 30  20  41  90]]\n",
      "Validation Loss for P20 = 1.4593164920806885\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_173/4145799004.py:41: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 99/100, Train Loss: 1.3711893558502197\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.25      0.22      0.23       150\n",
      "           1       0.25      0.08      0.12       183\n",
      "           2       0.29      0.19      0.23       206\n",
      "           3       0.23      0.50      0.31       181\n",
      "\n",
      "    accuracy                           0.25       720\n",
      "   macro avg       0.26      0.25      0.23       720\n",
      "weighted avg       0.26      0.25      0.23       720\n",
      "\n",
      "[[ 33   6  33  78]\n",
      " [ 42  15  25 101]\n",
      " [ 26  16  40 124]\n",
      " [ 30  22  39  90]]\n",
      "Validation Loss for P20 = 1.4551116228103638\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_173/4145799004.py:68: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/tmp/ipykernel_173/4145799004.py:41: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 100/100, Train Loss: 1.3312634229660034\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.25      0.23      0.24       150\n",
      "           1       0.26      0.08      0.12       183\n",
      "           2       0.29      0.19      0.23       206\n",
      "           3       0.24      0.52      0.33       181\n",
      "\n",
      "    accuracy                           0.25       720\n",
      "   macro avg       0.26      0.25      0.23       720\n",
      "weighted avg       0.26      0.25      0.23       720\n",
      "\n",
      "[[ 34   6  32  78]\n",
      " [ 43  15  28  97]\n",
      " [ 29  16  39 122]\n",
      " [ 32  20  35  94]]\n",
      "Validation Loss for P20 = 1.4578160047531128\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_173/4145799004.py:68: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x7f46d040d0a0>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1000x700 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import confusion_matrix,classification_report\n",
    "from sklearn import preprocessing\n",
    "import matplotlib.pyplot as plt\n",
    "#subjectnames\n",
    "file_list_num = np.arange(len(newsubjectname))\n",
    "file_list_numd = np.arange(len(subjectnamesd))\n",
    "\n",
    "kf = KFold(n_splits=12)\n",
    "torch.manual_seed(42)\n",
    "torch.cuda.manual_seed(42)\n",
    "modellist = []\n",
    "modelid = 1\n",
    "#file_list_num\n",
    "#for i, (train_index, test_index) in enumerate(kf.split(file_list_num)):\n",
    "#for train_index in file_list_num:\n",
    "train_index = file_list_numd\n",
    "test_index = file_list_num\n",
    "print(f\"Fold {i}:\")\n",
    "print(f\"  Train: index={train_index}\")\n",
    "print(f\"  Test:  index={test_index}\")\n",
    "net = Net()\n",
    "net.to(device)\n",
    "optimizer = optim.Adam(net.parameters(), lr=0.000001)\n",
    "epochs = 100\n",
    "batch_sz = 20\n",
    "train_loss_epoch = []\n",
    "val_loss_epoch = []\n",
    "for epoch in range(epochs):\n",
    "  train_loss = []\n",
    "  for tr in train_index:\n",
    "    v = data_de1[subjectnamesd[tr]]\n",
    "    l = data_del[subjectnamesd[tr]]\n",
    "    #print(v[0].shape)\n",
    "    net.train()\n",
    "    for i in range(0,len(v),batch_sz):\n",
    "      #print(v[i].shape)\n",
    "      #for j in range(0,v[i].shape[0],batch_sz):\n",
    "      #print(newsubjectname[tr])\n",
    "      optimizer.zero_grad()\n",
    "      outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
    "      #print(\"Expout {}\",outputs.shape)\n",
    "      #print(\"Actual {}\",l[i:i+batch_sz].shape)\n",
    "      #print(l[i].shape)\n",
    "      loss = criterion(outputs, l[i:i+batch_sz].to(device, dtype=torch.float))\n",
    "      loss.backward()\n",
    "      train_loss.append(loss)\n",
    "      optimizer.step()\n",
    "  print(f'Epoch {epoch + 1}/{epochs}, Train Loss: {loss.item()}')\n",
    "  train_loss_epoch.append(torch.stack(train_loss).mean().cpu().detach().numpy())\n",
    "  #print(train_loss_epoch)\n",
    "  batch_sz = 20\n",
    "  expectedoutputamigos = []\n",
    "  actualoutputamigos = []\n",
    "\n",
    "  for tr in test_index:\n",
    "      net.eval()\n",
    "\n",
    "      v = data_c1d[newsubjectname[tr]]\n",
    "      l = data_c2[newsubjectname[tr]]\n",
    "      net.eval()\n",
    "      val_loss = []\n",
    "      with torch.no_grad():\n",
    "          for i in range(0,len(v),batch_sz):\n",
    "            #print(v[i].shape)\n",
    "            #for j in range(0,v[i].shape[0],batch_sz):\n",
    "            optimizer.zero_grad()\n",
    "            outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
    "            #print(outputs.shape)\n",
    "            #print(l[i:i+batch_sz].shape)\n",
    "            loss = criterion(outputs, l[i:i+batch_sz].to(device, dtype=torch.float))\n",
    "            val_loss.append(loss)\n",
    "            #actualoutputamigos.append(torch.round(outputs.cpu()))\n",
    "            #expectedoutputamigos.append(l[i:i+batch_sz])\n",
    "            actualoutputamigos.append(torch.argmax(torch.softmax(outputs.cpu(),dim=1),dim=1))\n",
    "            expectedoutputamigos.append(torch.argmax(l[i:i+batch_sz],dim=1).numpy())\n",
    "  val_loss_mean = torch.stack(val_loss).mean().cpu().detach().numpy()\n",
    "  val_loss_epoch.append(val_loss_mean)\n",
    "  expectedoutputamigos = np.concatenate( expectedoutputamigos, axis=0 )\n",
    "  actualoutputamigos = np.concatenate( actualoutputamigos, axis=0 )\n",
    "  #print(expectedoutput.shape)\n",
    "  #print(actualoutput.shape)\n",
    "  print(classification_report(expectedoutputamigos,actualoutputamigos))\n",
    "  print(confusion_matrix(expectedoutputamigos,actualoutputamigos))\n",
    "  print(f'Validation Loss for {newsubjectname[tr]} = {val_loss_mean}')\n",
    "plt.figure(figsize=(10,7))\n",
    "#print(len(train_loss_epoch))\n",
    "plt.plot(np.arange(epochs),train_loss_epoch,label='Train')\n",
    "plt.plot(np.arange(epochs),val_loss_epoch,label='Validation')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "629a6e47-a58b-496b-9740-4e35f730b5d6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
