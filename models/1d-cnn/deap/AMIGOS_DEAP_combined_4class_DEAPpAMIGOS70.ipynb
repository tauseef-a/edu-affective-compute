{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "lV6AUpSouNYI",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "lV6AUpSouNYI",
    "outputId": "e479380e-fbed-427b-87fd-cc146892b6da"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mounted at /content/drive\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "njT3xEyzuOSC",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2024-01-21T19:55:18.294674Z",
     "iopub.status.busy": "2024-01-21T19:55:18.294070Z",
     "iopub.status.idle": "2024-01-21T19:55:40.973243Z",
     "shell.execute_reply": "2024-01-21T19:55:40.972658Z",
     "shell.execute_reply.started": "2024-01-21T19:55:18.294651Z"
    },
    "id": "njT3xEyzuOSC",
    "outputId": "d85411f6-4f18-49ad-87f7-ea614f2e47f8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Archive:  AMIGOS.zip\n",
      "  inflating: AMIGOS/Data_Preprocessed_P01.mat  \n",
      "  inflating: AMIGOS/Data_Preprocessed_P02.mat  \n",
      "  inflating: AMIGOS/Data_Preprocessed_P03.mat  \n",
      "  inflating: AMIGOS/Data_Preprocessed_P04.mat  \n",
      "  inflating: AMIGOS/Data_Preprocessed_P05.mat  \n",
      "  inflating: AMIGOS/Data_Preprocessed_P06.mat  \n",
      "  inflating: AMIGOS/Data_Preprocessed_P07.mat  \n",
      "  inflating: AMIGOS/Data_Preprocessed_P08.mat  \n",
      "  inflating: AMIGOS/Data_Preprocessed_P09.mat  \n",
      "  inflating: AMIGOS/Data_Preprocessed_P10.mat  \n",
      "  inflating: AMIGOS/Data_Preprocessed_P11.mat  \n",
      "  inflating: AMIGOS/Data_Preprocessed_P12.mat  \n",
      "  inflating: AMIGOS/Data_Preprocessed_P13.mat  \n",
      "  inflating: AMIGOS/Data_Preprocessed_P14.mat  \n",
      "  inflating: AMIGOS/Data_Preprocessed_P15.mat  \n",
      "  inflating: AMIGOS/Data_Preprocessed_P16.mat  \n",
      "  inflating: AMIGOS/Data_Preprocessed_P17.mat  \n",
      "  inflating: AMIGOS/Data_Preprocessed_P18.mat  \n",
      "  inflating: AMIGOS/Data_Preprocessed_P19.mat  \n",
      "  inflating: AMIGOS/Data_Preprocessed_P20.mat  \n",
      "  inflating: AMIGOS/Data_Preprocessed_P21.mat  \n",
      "  inflating: AMIGOS/Data_Preprocessed_P22.mat  \n",
      "  inflating: AMIGOS/Data_Preprocessed_P23.mat  \n",
      "  inflating: AMIGOS/Data_Preprocessed_P24.mat  \n",
      "  inflating: AMIGOS/Data_Preprocessed_P25.mat  \n",
      "  inflating: AMIGOS/Data_Preprocessed_P26.mat  \n",
      "  inflating: AMIGOS/Data_Preprocessed_P27.mat  \n",
      "  inflating: AMIGOS/Data_Preprocessed_P28.mat  \n",
      "  inflating: AMIGOS/Data_Preprocessed_P29.mat  \n",
      "  inflating: AMIGOS/Data_Preprocessed_P30.mat  \n",
      "  inflating: AMIGOS/Data_Preprocessed_P31.mat  \n",
      "  inflating: AMIGOS/Data_Preprocessed_P32.mat  \n",
      "  inflating: AMIGOS/Data_Preprocessed_P33.mat  \n",
      "  inflating: AMIGOS/Data_Preprocessed_P34.mat  \n",
      "  inflating: AMIGOS/Data_Preprocessed_P35.mat  \n",
      "  inflating: AMIGOS/Data_Preprocessed_P36.mat  \n",
      "  inflating: AMIGOS/Data_Preprocessed_P37.mat  \n",
      "  inflating: AMIGOS/Data_Preprocessed_P38.mat  \n",
      "  inflating: AMIGOS/Data_Preprocessed_P39.mat  \n",
      "  inflating: AMIGOS/Data_Preprocessed_P40.mat  \n"
     ]
    }
   ],
   "source": [
    "!unzip \"AMIGOS.zip\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "GPftEcnHuJrY",
   "metadata": {
    "id": "GPftEcnHuJrY"
   },
   "outputs": [],
   "source": [
    "import scipy.io\n",
    "data = scipy.io.loadmat(\"AMIGOS/Data_Preprocessed_P32.mat\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "Hz_c9Dnoua7T",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Hz_c9Dnoua7T",
    "outputId": "09a9a543-7156-4279-eda3-45021ff3edf9"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 12)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#data['joined_data'][0][19].shape\n",
    "#data['labels_selfassessment'][0][15].shape\n",
    "#data['joined_data'].shape[1]\n",
    "#data['labels_selfassessment'][0][1][0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "SI3v-4-DTC60",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 463
    },
    "id": "SI3v-4-DTC60",
    "outputId": "390a5f34-c7ad-4e73-8513-95e2c0f068e7"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10191,)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.plot(data['joined_data'][0][16][384:,16])\n",
    "data['joined_data'][0][3][384:,16].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "WFGqncuxTz4s",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 463
    },
    "id": "WFGqncuxTz4s",
    "outputId": "2877bf49-f2b1-4a12-9a31-b245c833c2f6"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7bb4a0d7ec80>]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAiMAAAGsCAYAAAAPJKchAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/bCgiHAAAACXBIWXMAAA9hAAAPYQGoP6dpAACBjElEQVR4nO2deZwT9d3HPzk22fu+YZflPuRaQWBFFBRFtLTax9Yq9axafaDV0kOp9Wqr9FCrT4tarUqtVTzqUZWKFEVEOeRY7vvaBfZg7zvn7/lj8pvMTCbZZDfZTDLf9+vFixyT5DdJNvOZ7/H5GhhjDARBEARBEFHCGO0FEARBEAShb0iMEARBEAQRVUiMEARBEAQRVUiMEARBEAQRVUiMEARBEAQRVUiMEARBEAQRVUiMEARBEAQRVUiMEARBEAQRVUiMEARBEAQRVUiMEARBEAQRVWJKjKxfvx4LFixAcXExDAYD3nvvvZCfgzGGxx9/HKNGjYLVasWgQYPw6KOPhn+xBEEQBEEEhTnaCwiFzs5OTJo0Cbfeeiu+/e1v9+k57r77bnzyySd4/PHHMWHCBDQ1NaGpqSnMKyUIgiAIIlgMsTooz2Aw4N1338VVV10l3maz2XD//ffj9ddfR0tLC8aPH4/f//73mD17NgBg//79mDhxIvbs2YPRo0dHZ+EEQRAEQciIqTRNbyxevBgbN27EypUrsWvXLnznO9/B5ZdfjsOHDwMAPvjgAwwbNgwffvghhg4dirKyMtx2220UGSEIgiCIKBI3YqSqqgovv/wy3nrrLcyaNQvDhw/Hz372M1xwwQV4+eWXAQDHjh3DyZMn8dZbb+GVV17BihUrsG3bNlxzzTVRXj1BEARB6JeYqhkJxO7du+FyuTBq1CjZ7TabDTk5OQAAt9sNm82GV155RdzuxRdfxJQpU3Dw4EFK3RAEQRBEFIgbMdLR0QGTyYRt27bBZDLJ7ktNTQUAFBUVwWw2ywTL2LFjAQiRFRIjBEEQBDHwxI0YKS8vh8vlQn19PWbNmqW6zcyZM+F0OnH06FEMHz4cAHDo0CEAwJAhQwZsrQRBEARBeImpbpqOjg4cOXIEgCA+nnzyScyZMwfZ2dkoLS3F97//fXz55Zd44oknUF5ejrNnz2Lt2rWYOHEirrzySrjdbpx33nlITU3FU089BbfbjUWLFiE9PR2ffPJJlPeOIAiCIPRJTImRdevWYc6cOT6333TTTVixYgUcDgd++9vf4pVXXsHp06eRm5uLGTNm4JFHHsGECRMAAGfOnMGPfvQjfPLJJ0hJScH8+fPxxBNPIDs7e6B3hyAIgiAIxJgYIQiCIAgi/oib1l6CIAiCIGITEiMEQRAEQUSVmOimcbvdOHPmDNLS0mAwGKK9HIIgCIIggoAxhvb2dhQXF8No9B//iAkxcubMGZSUlER7GQRBEARB9IHq6moMHjzY7/0xIUbS0tIACDuTnp4e5dUQBEEQBBEMbW1tKCkpEY/j/ogJMcJTM+np6SRGCIIgCCLG6K3EggpYCYIgCIKIKiRGCIIgCIKIKiRGCIIgCIKIKiRGCIIgCIKIKiRGCIIgCIKIKiRGCIIgCIKIKiRGCIIgCIKIKiRGCIIgCIKIKiRGCIIgCIKIKiRGCIIgCIKIKiRGCIIgCIKIKiRGCIIgCIKIKiRG4oCDte247e9b0drliPZSCIIgCCJkSIxolC67E+9sP4XmTnuv2173wib8d38dlv1n/wCsjCAIgiDCC4kRjfLbj/ZjyZs7cdsrW3vdtskjWN7dcTrSyyIIgiCIsENiRKO87xEW2042B9zueEOneLkkOzmiayIIgiCISEBiRKNYzMF9NMtWeVMzjLFILYcgCIIgIgaJEY1iNZvEy2X3feRTnMoYw7ClH+GTfXXibe09zgFbH0EQBEGECxIjGiXJYpJd/8PqA7Lr26ua4VYEQtp65IKlx+HCk58cxLqD9RFZI0EQBEGEAxIjGiUvzSq7nmCSf1T/8+xG8fK/7jofANDjcMPudIu3v7XtFP7v0yO469XtcCmVC0EQBEFoBHO0F0Cok51skV13uLwi40xLt3j5X3dVYHJJpnj9f/+5Hf/dX4eZI3LgdAkCpNvhQlu3A1kp8uckCIIgCC1AYkSj2CXiAwDaJPUgq/fWAgCykhMwZUg2ACDNaka7zYn/7hdqSL480gijwfv4VhIjBEEQhEahNI1GsTldAIALR+UBANq6vfUg/9kjiJHFF48Ub0tL9NWV0sxMh42KWwmCIAhtQmJEo/Q4hMhIXqpQO8KLU8+22/D1iSYAwLxzCsTt05MSAj6fzekOeD9BEARBRAsSIxqlxyFERnLThNQKj4ys2VcHxoCJgzMwOMtrcuavQHV4XgoAyApbCYIgCEJLkBjRIC1ddtFZtSxHEBNHzwrX/7OnBgAw75xC2WMO13eIl39z1XjMHp2HTUsvgcXjV+JwkRghCIIgtAkVsGoMxhiueW4juuwujMhPxQUjcsX7Xt10El8cbgAAzB9f6O8pcMOMIbhhxhAAXidXiowQBEEQWoUiIxrjmXVHccQT5Zg9Kg/Zkg6YX723R7w8LC9V9ribzy8DAPx83mjZ7RaT0FKj7M4hCIIgCK1AkRENcbiuHU98clC8ftfs4UixmpGVnIBmiR38NycV+zz2V1eOxXemDsbYwnTZ7RQZIQiCILQORUY0xOOfHISbAXPHFuD4siuQ4+mkmTMmX7bdb64a7/NYs8mIc4ozYJSai8Dr3EqREYIgCEKrkBjRCJ/srcXqvYJh2X3zR8Ng8IqKTUcbxcs3n1+GjF7aeKVYTBQZIQiCILQNiREN4HC5ccc/tgEARhWkYkR+muz+ueO8fiIPLRgX0nObPTUjNJuGIAiC0CpUM6IBXt10Urz840tG+tx/3/wxyEq2YOH0UlnEJBiMnu3djMQIQRAEoU1IjGiAN7eeEi9/Y6JvcWqyxYyfXDqqT8/NxQhFRgiCIAitQmmaKPOXTw9jf00bAGD7A5eG/flNnoJWCowQBEEQWoXESBRp6bLj8U8OAQBKs5NlniLhgmd1XKRGCIIgCI1CYiSK/HNzlXh5xS3nReQ1TFQzQhAEQWgcEiNRYuuJJvxxtWBw9ujV430cVcMFT9O4qWaEIAiC0CgkRqLEjS9tES/PH18UsdcxiAWsEXsJgiAIgugXJEaCZGd1C2b94VPUt/X0+7k6bE502V0AgLlj8yNSK8LxeJ5RmoYgCILQLCRGguRby79EdVM3HvlwX7+f6/ODZwEAw3JT8MKNU/v9fIEgnxGCIAhC65AY6YV/bDqJsvs+Eq9zIdFXmjrt+PRAPQDgkrH5IZuYhQqJEYIgCELrkOlZLzzw3h7Z9YsVQ+tC4aNdNVj02nbxunIAXiTgBaxUM0IQBEFoFRIjKticLry6qQrnlWX53NdXvw7GmEyI5KRYMK0su89rDBY+xJdRZIQgCILQKCRGVHhpwwn8/uMDqvf1tUVW6ikCAJeOK4DZFPksmdFIdvAEQRCEtqGaERV2VDX7va8vB3XGGF7ccFx223XTSkN+nr4gzqahyAhBEAShUSgyooLZJC8qfX/RTByobcO9/9rdJzGy9WQzjjd0AhAm8GYnWzCpJDMcS+0V7sBKWoQgCILQKiRGVDAZ5QGjSSWZOFTXDqBvEYbXtwgpmmunluDOi4b3f4EhQGkagiAIQuuEnKZZv349FixYgOLiYhgMBrz33ntBP/bLL7+E2WzG5MmTQ33ZAUUaGLlwVJ5wWx8P6p02J/6zuxYA8N3zSsKzwBDgBazU2ksQBEFolZDFSGdnJyZNmoTly5eH9LiWlhbceOONuOSSS0J9yQHHKPH+uGJ8IQDJjJcQD+p/WnMI3Q4Xki0mnFuaGbY1BgsNyiMIgiC0Tshpmvnz52P+/Pkhv9Cdd96J66+/HiaTKaRoSiTpsDnx0a4zuHRcocySvSAjUbz87XMHA/CKEacrtIP6e5VnAACXjC2IuMGZGkZxUN6AvzRBEARBBMWAdNO8/PLLOHbsGB566KGgtrfZbGhra5P9iwT3v7sb9/5rN255eYvs9lPN3QCAxXNGwGIW3qJQIwyMMcz6w6do6LABAH508YhwLTskqJuGIAiC0DoRFyOHDx/Gfffdh1dffRVmc3CBmGXLliEjI0P8V1ISmVqLD3fVAAB2nmoVb2OM4YOdQjRjy/Em8fZQa0b+tOYQqpsEUVOSnYRRBWlhWXOo0KA8giAIQutEVIy4XC5cf/31eOSRRzBq1KigH7d06VK0traK/6qrqyOyPqNK1mT3aa8wOW+o14E1VDHy+eEG8fLM4bl9XGH/EWfTUDcNQRAEoVEi2trb3t6OrVu3YseOHVi8eDEAwO12gzEGs9mMTz75BBdffLHP46xWK6xWaySXBgCeGg75Qfqvnx8TL//o4pHiZbFFNogIg93pxs7qFvH6tKGRt333hzdNE7UlEARBEERAIipG0tPTsXv3btltzzzzDD799FO8/fbbGDp0aCRfvlfUykn/u78OAJCbakFigkm83RzCwLmvjjbIrl/kaQ+OBtTaSxAEQWidkMVIR0cHjhw5Il4/fvw4KisrkZ2djdLSUixduhSnT5/GK6+8AqPRiPHjx8sen5+fj8TERJ/bo4GyuYUxBptTUBs/vWy07D5ewOoKoi1l9V5B0Fw2rgAPfGMcclIjH+Xxh9iSrMM0DWNM7GCSXiYIgiC0Rcg1I1u3bkV5eTnKy8sBAEuWLEF5eTkefPBBAEBNTQ2qqqoCPYVmMCoOTq9v8damXH5OoXzbIGtGXG4mOq5eN70UJdnJ4VhqnzH20R8llnG63Pj2M1/isj+tR4/DhY921WDo0lV+hx8SBEEQ0SXkyMjs2bMDjqNfsWJFwMc//PDDePjhh0N92YgglSJ2pxu/fNebUsqS+I4A3jRNbwGGTccaxcsXjIhe4SpHrBnRkc/Iiq9OYHtVCwBgz+lWLHptOwDg2XVHce/lY6K4MoIgCEINXU/tlUZG5j21PvC23PSslzTN54fOAgDGD0pHgin6by+vGQkkIOOJv31xTBYB4e3bBEEQhHbR96A8SWiET9UFgD9cM9FnU9H0LIAWYYxh9V5hDs1dF0XH5EyJWDMR5XUMBI98sBcvf3lCdtuKr7zXiyTOugRBEIR2iP6pexTxZ+1+dfkgn9uC8Rk5VNeBk41dsJiNmD06eh00Uow6mU3DGPMRIkp4cTJBEAShLXQtRrodLtXb1dIr4myaAGLktx/tAwDMGpGLFKs2gk48+BPvzTRbTzbLruen+XYw6SVVRRAEEWvoWoyEQm9Texs6bPjC47r63fMiY1/fF4yeTzjeD8RfeGp1ACA31YpHr54gXk9MEN6EeBdkBEEQsYo2Tt81xK+uHKt6u7crRf2IdscrW8XLl40rCP/C+ogB3GcjyguJMGv21wMAHvjGOFw3rQRJCSasvGMGPjtQj1kj8/D9FzfHfaqKIAgiViExokCtXgQIbB7W2GETW0mnD83WlLkWXwqL4xLWY2c7sL+mDSajAVeXD0KyRfhazxiWgxnDcnCyUShOJi1CEAShTShNo8CfW6rowKpyRFu129s++vwNUyOzsD5iDKILKNb52NPBNHNELrIV/jCAfop4CYIgYhVdi5ExhWlBb8trL9TSNNxb5LtTByMjOSEsawsXPDISzwfif2w8CQC4ZEy+6v16eA8IgiBiGV2LkQO17bLrx5dd4XdbfwWsTpcbXx0VXFdvOr8svAsMA8Y49xlp6bKjprUHAHDBSHXHW29kZMCWRRAEQYSArsWIlMe/MylgrYfJTwHr3jNt6LK7kGY1Y2xhekTX2Bf4HsVTN83xhk7cvXIHDtS2iVEpABiel6q6vVEyLI8gCILQHlTA6uGaKYMD3m+UzKaRToDdfboVADC5NFPcRksY4jAqcNer23Cgth3vV57BuaWZAIDFc/w73hrFNM0ALK6fuNwMH+46g4rhOchPI8dYgiD0AUVGgsQkiZpID2oHatsAAOcUZwz0koIi3mbTuNxMll7bXtUCowFYOKPU72MMMVTA+srGE7h7ZSV++I9t0V4KQRDEgEFiJEikUQ9pquZAjXBgHFsUfDHsQBJvkRE++0fKtKHZKMpI8vsYryDTtihzuxmeXHMIALCjqgUnJPOSCIIg4hkSI0FiMkojI8IBze50Y3+NEBkZo8F6EUByII7uMsJGh83pc9ul4woDPkY6nVnDWgSbjjWivce7f3e+StERgiD0AYmRIJGmaXhkZNOxRnTaXchNtWJEvnrxZLQxxFmaxqIyN2juWPWWXo7R4CsktciPV1bKriu7vQiCIOIVEiNBYpS8U9z47NMDggX53LH5ssiJloileolgUCsSHpKTEvAxBpXPTmvUtHajocMGAHjhRsE4z2Iyxo2IJAiCCASJkSCRFbC6GRhjohiZ48dsSwt421qjvJAwobTj//N15b0+RipftPo+bDrWKF6e5fFLsbvcaOv2TUsRBEHEGyRGgsSkKGA9erYTVU1dsJiMuGCEutmWFuCrjpcC1nveqBQvr/nJhVgwqbjXx8RCzQif+HzX7OFITDAhPVHouj/bIRi6vbD+GB5ffZAiJQRBxCXkMxIkBoMBBoNwMHMxhm0nmwAAU4ZkIcWq3bcxng2/RhYE18Ek9bLTysDA9h4HACAtMQGMMWzwiJGZwwVhm5dmRVuPE/XtNticbjy6aj8AQRT/5NJR0Vk0QRBEhKDISAiYJEPnmjqFg0lxpv+WUi1gkLS1xjr8AB4qWouMrNpdgwkPf4IJD3+CHocLe8+0ob7dhqQEE6aWZQEQxAgAnG234bXNVeJjn157OCprJgiCiCTaPaXXIEajAXAzuBhDS5cdAJCpscF4SuJpSBx3uwWAxIS+6ehovQ/v7jiFv391ErNH5+Gp/3oFxcHadmw92QwAqBieg8QEEwAgz+O+uv1kM/4pESMEQRDxCImREOCREZvDhb+uPwZA+5GReBqUt3qP1/BscFZy0I+Tp2kGngt+/ylONXcDACqrW2T3fXW0EbtPC7dNGZIl3p6XKkRG/u6ZSMwZpPHvG0EQRF+gNE0I8CLWFV+dEG8blhe4rTTaeAtYY1+OSA/MR+o7gn5cNNM0bjcThYga2042Y+sJITIyVSJGijPlc2l+eOEwAECnnbprCIKIP3QtRvI9efmHF4wLanveUPOK5KA4cZA2Z9JwuC9HrGuRI/V9NwCTt/YO7BvR7XD53DYsNwUrbjkPALD5WCPq220wGw2YVJIpblOa7Y383D5rKG48vwwA0GXzfT6CIIhYR9diZHSh0I2REWTdh9LY7LtTByPHE07XKvEyKO/1LdV9fqwhSpGRbrtL5qKaYhHqQWaNzEWu53vT7rG3P2dQhlgvAgjfTYMBsJqNuG/+WCR77rO73HC63AO1CwRBEAMC1YyEgFKM3Hv5mCitJBRif1Ce3enG+5WnZbc9s/DcoB9vjFLNyE0vbcGWE03i9d9ePR5r99fjnrmj0Nhpk20rTdEAgqvs67fPQFqiGSajAUkWr1DpcbqRqmKLTxAEEauQGAkBae1BbqpF81ERQDooL3bVyH/21KChw46kBBN2PnQZGBisZlPvD/RgiMJsmiP17TIhAgBXlw/G1eWDAfgO/KsYluPzHDMkt1nNXvHRbXchVcPeNgRBEKFCp1chII2MDAqhmyOaGCTeKLEKt90vL82ExWwMSYgoGag0zf+tPSK7Pq5IPtXZYpb/6UnrRdQwGAxI8qRquu1UN0IQRHxBp1chII2MFGckBthSO8RDzciafXUAgO9MHdzn5/BYxAzI+2BzuvDvnWcAAL+5ajwmDc6QFaQC8unDuakW0eQsEMkWE7odLtWiWIIgiFiGIiMhII2MFGXEht9DrPuMNHXa0eWJBFw8uqDPz2MYwPehrtVbD/KtycWYODgTmckW2TbSyMjwvNSgnpcXuN7+ylZsOtaIC37/KX74j61hWDFBEER0ochICEjFiNIHQuvEqs/Ido876Yj81KC7ntTgn9xAvA2fHz4rXk5PVF+zVIyMLAhOjPDAXFVTF773/CYAwKnmbjhdbpipoJUgiBiGfsFCQNqVEXORkdjUInh9i2CFfm5pZr+eh78PAyHKdilcVtUwS75MI4KMjPgzT2vosAf1eIIgCK1CYiQEEiRnn0UxEhnxzqaJ7jr6gsvNxLktl40r7N+TiV1FkWdblbDm574/xf9yJPVHF4zM69frddj6NkCQIAhCK1CaBoABht43ApCe5A25F8dcZCT21MjeM61o7RYOtLNH9++AHelC3vr2Hvzvq9tx8dh8HDvbCZPRgIrhvu26Ut5fNBNtPQ6MyA8uMnLt1BK8sbUak0sycem4Avz9qxOob7eh2x7DrVIEQRDQuRgJ9bhkd3p/9IPpftACxgGMCISbDUcaAACXjivod00EF5yR0CJNnXZMe3QtAIiRnEmDM5CRFLjGpbd2XiUPLBiHb04uxvnDc2AwGPD2tlNAu426awiCiHkoTRMCPZIffaUbq1bxpmliQ4643AybjjXC6XLjqyONAICZvUQYgsEgRkb6/VQ+7D7d6nPbrH6mXtRItZoxc0SumOIRfUccLnTbXXjw/T040dAZ9tclCIKINCRGQuCGiiEAgGum9N3vYqDxmp7Fhhi5dcXX+N7zm3D7K1vxtcfBdOaI3H4/byQLWJMtviZsF4zs/5p7g1vEd9uduHvlDryy8SRmP74O9e09EX9tgiCIcKLrNE2oXHdeKcYWpWN0QVq0lxI0YktrVFcRHC43w+eHhLbYzw4K/+enWYOuqQhEJN8Hl4rQmzg48tOceWSkrceJTzzGcADw7vbT+OFFwyP++gRBEOGCIiMhYDQacG5pFlJiaC5ILLX27jrV4nObNC3RLyJYwNqjUrPRH8v6YOGRkV+8vUt2O6+1IQiCiBVIjMQ5sdRNs+7gWZ/bzg9DvQggTdOE5elkdClmxfzqyrHhfxEV/A3LS0uMHbFMEAQBkBiJe2LJZ4SnaKSEqxDUG1wJ/xux9YTQQXPt1BJ8ed/FuHXm0LC/hhrpEtGRlGDCwwvGAYjtoYgEQegTEiNxTqx00zR12rHTk6b5xeWjAQBlOckoDNNAwkjZwTPG8Na2agCCF8qgzCQYB6jTSup7M31YNrJShPk3bT1kgkYQRGxB8dw4ZyAHxPWHLw6fBWPAmMI03HXRcJRmJ2PqkOywPX+k0jRP/fcw2nucAIDzw9D1Ewr8dQHghxcOFw3ibE4KjRAEEVtQZCTOibTzaLj45yZhBs1Fo/JgMBjwjYnFYYuKABKfkTDLsqfXHhYv92ZyFm74sMaCdCsqhufAYhZ20uEiMUIQRGxBkZE4Jxa6ab61/Evs9AyXu3BU+M3CBML/PhyobQvfk/WBGyvK0ONwY87ofACAxSR019gpMkIQRIwRcmRk/fr1WLBgAYqLi2EwGPDee+8F3P6dd97BpZdeiry8PKSnp6OiogKrV6/u63ojQjg6R7UK3zWt1oy43UwUIgAwZUhWRF7HGIHamX9sPCle/uFFw8L2vMGSmGDCjy8ZiQkeT5MEk7CTdoqMEAQRY4QsRjo7OzFp0iQsX748qO3Xr1+PSy+9FKtWrcK2bdswZ84cLFiwADt27Ah5seEm3CF7LWKIYEtrODhQ2y5e3rj0YiQmRMafI9x28DanCx/sPAMA+OsNU7B0/sC08wYiwSz8OVOahiCIWCPkNM38+fMxf/78oLd/6qmnZNcfe+wxvP/++/jggw9QXl4e6ssTISJt7GCMhcdALEy8svEEHnx/LwBg5ogcFEVwEnK401WfHzyLth4nCtKtmDu2IDxP2k8snmGCDqdGlSdBEIQfBrxmxO12o729HdnZ/jslbDYbbDabeL2tLbq5+VhGKj4Y01ZKigsRAGHtnFHDawcfngP1+56oyDcmFmtmaKKFIiMEQcQoA95N8/jjj6OjowPf/e53/W6zbNkyZGRkiP9KSkoGcIXxhfQ4qdW6EQA4ryzCYiSMkZFOmxNr9wuzYL41ubj/TxgmEjyRESpgJQgi1hhQMfLaa6/hkUcewZtvvon8/Hy/2y1duhStra3iv+rq6gFcZXxhgCQyEsV19Mbk0syIPn84zd/W7KtDj8ONobkpmDAo8gPxgoUXsNooMkIQRIwxYGmalStX4rbbbsNbb72FuXPnBtzWarXCarUO0MriG4NEbmo5MuJvzkq48PqM9J/3K08DAL45qVhTNTg8MuLWarUyQRCEHwZEjLz++uu49dZbsXLlSlx55ZUD8ZKEB6OiZiSafLynBoOzkpFgMmLDkQaMKkjFoboOPPCNcRF/bUOYfEaaOu344rAwFfebGkrRALFj/U8QBKEkZDHS0dGBI0eOiNePHz+OyspKZGdno7S0FEuXLsXp06fxyiuvABBSMzfddBOefvppTJ8+HbW1tQCApKQkZGRoJ8Qdr0jP26N5jFp/6CzufHU7clMtSE9KwLGzneJ9I/NTI/764XKifXfHaTjdDBMGZWB4XuTXHQqRnExMEAQRSUKuGdm6dSvKy8vFttwlS5agvLwcDz74IACgpqYGVVVV4vbPP/88nE4nFi1ahKKiIvHf3XffHaZdIAIhjYxE84x5vWcib0OHXSZEAG8XSCQJx4wexhhe2ywYnX33PO0VVcujYKRICIKIHUKOjMyePTvgD92KFStk19etWxfqSxBhRFrSEM3D04YjDX7vGxAx4vm/P/UUu0+34ujZTiQlmHCVxlI0gLJzCjBpp5yFIAgiIDQoL84xaKC1t7a1R+a0qiTSxatAeApYeXTnwlG5SEsc2KF4wWDQSBSMIAgiVEiMxDlaKGC96aUtAe8fmpsS8TWEw2fk8U8OAQBmjYzUML/+ESueMgRBEEpIjMQ58gLW6BygDtYJUZEklbkz6YlmsSU1kogOrH18D3adahEvXxSxycL9QwvCkyAIoi/oWozo4QdbXsA68K/fZXeKl3/3PxN87h+o9lhjPwtY/7NH6AJLTDCiJDs5TKsKL1opViYIggiVAZ9NQwwssgLWKBygjjcInTNZyQn45qRinGruht3pxtNrDwMARuanDcg6+ju1d80+wf799/8zMUwrCj8GRQErQRBErKDryIgeMEQ5MrL7VCsAYFRBGgwGAxbNGSGLhgyExwjgfR/6EjGoburCkfoOmIwGzB7tf4xBtKHICEEQsQqJER0QLsOvvsCLPstLs8TbclIs4uWxRekDsg7v1N7Q+fRAPQBgypAsZCRpr4uGIy1gZTSehiCIGILSNDrAYDAAjEXMZ6S6qQs7qluwYGKRLBLjdLnR0GEDAJxT7BUdmckWPHr1eCRbTMiSCJNIYuiHIFu9V6gXuXiMdqMiAEVGCIKIXUiM6ACjAXAhcgeoO1/dhr1n2tBtd+La80rF23lEAQCumFAke8zC6UMishZ/GPvY2nu8oRNfHW2EwQB8Y2JR7w+IIlrwlCEIgugLlKbRAeEaEqeGy82w90wbAIj/cz72RBRunzUUJmkOIQp4Tc9CexNe2nAcgNDOOzhLm100HIPBIBmWF9219Aeb04Vlq/bjg51nor0UgiAGCIqM6IBITnM90eidM1OYkSi7b89poXh1+tCcsL9uqHjt4IN/jMvNsGp3DQDgummlvWytDYwGA1yMxfRsmre3ncJf1x8DACyYpD3bfYIgwg9FRnRAX1MUwcAFBwDYnd4jfZfdiSP1HQCACYOjP525L4PyKqtb0NhpR1qiWfP1IhxjjEdGmjrtuP/dPeJ16XeKIIj4hcQI5O2v8Uh/PTYCIU3NSIfQ7TvTBjcD8tOsKEhPVHvogNKXAta1+wVvkYtG5Q2IS2w46E8LsxZY8mal7HpbjyM6CyEIYkCJjV9Yol8YI3iAkkZGnBIxssvjLzJRA1ERQJKmCeEtWLtfKMCdO7Yg/AuKEMYIpuQijd3pxrqDZ2W3tXWTGCEIPUBiRAeEY2KtGowxmRhxSQ6Ae84It48fpA0x4m17De5dONtuw8G6dhgMwOzR2pxFo4YoPGMwu7HtZLN4Oc0zybmVxAhB6AISIzrAGxUIrxw51dyNth7v7BmXS56mAYBzirUhRkJNVW053gQAGJGXiszkgfFCCQdcjLhiMDLyxWEhKvLt8kEY7Jn/I/1+EQQRv+hajMTg73WfMBp5AWt4d1gaFQG8B8Buu0ssXh1XPDAOq73B25uDTdPwA+OMYdHvBAqF/pi7RZuvTwgCcMbwHGQkCZGRVbtqorkkgiAGCF2LEb0gJijCfHziqRiOy3Ok31HdDKeboSgjEcUZ0S9eBULzGem2u/DOjtMAgAtG5kZyWWGnv9OJo4Xd6cZOT53R1CFZcHiibG9sraYiVoLQASRGdIC3gDW8z7vntJCKyU+zAvCKER4xKS/N1EynUihmYFtPNsHudCMrOQGXjYud4lUgunOI+sPeM63iez40N0Vmkne6uTuKKyMIYiAgMaIDQm337HG48MB7e/DW1mq/2xw924HPDwmpDN4xw8XIgZp2AMCYQm2kaACp10rv78GGIw0AgEvGFmhGTAWLIULCM9LwFM2UIdkwGAyYP75QvK+liyIjBBHvkBjRAaEWb7644Tj+sekkfv72LtWDd7fdhUue+Fy8zotURTFSK4iR0YVp/Vh1eAlFU3x1pBEAcMGI2ErRANLISHTXESpbjgudNNOGCtOdb6ooQ7LFBAB48P09eL/ydNTWRhBE5CExogNC9Z7YeLRRvGxTccDcXyufQZNiFQ4aLjeDw+UWi1fHaEmMILjoUHOnXayFOX94bBWvArFpeuZ2M2w9KURGzivLBiAUXfNJz4frO/Dzt3ahx+GK2hqJ+MfpisF++DiCxIgOMCD4sABjTIxsAEC7Smvl/hqvGBk/KB0mo/A1cjGGw3UdsLvcSLOaUaKhwXLBRoc2HmsEY8CoglTka8A5NlRi0fTs6NkOtHQ5kJRgkvnSJCaYxMt2lxunmruisTxCBzzywV5MePgTVDcJ37Gqxi7M/uNneNEzKJOIPCRGdEAoB6gzrT1o6LCJ19tVOhl4TQgAvHTTeTB5nt/pZtjriSqMK04XW4q1gCHI+Ty8XuSCEbFjdCYlkhOaI8UXh4X3vLw0U2a7bzWbZNuR5wgRKV7+8gS6HS78df1RAMCi17bjRGMXfvPhviivTD+QGAFCiBvEJqEUNR6okadgOmz+IyNPXTsZ+emJMHkOIG43E2fVaMV5lROs8dsGz4HxgpGxl6IBYrNmZNMxIS2odLpNMMn/MilNQ0Qa/hu5W+GhREQeEiM6IBQjrKNnO2TXlWkaaRpnbJGQ0zd5XsDp9trDjx+knU4aQHKQDrBNVWMXqpq6YDYaMG1obIqRWKsZcbjc2Hycd9Jkye6rb7fJrseixT2hHc622/D2tlMBa0MYAw7XeSO/fCwBEXnondYBofiM8OJTjjJNc6q5Gx02JxJMBgzLSwEAmD1HeofLjX2eqMl4jdjAcwxBDOj58qg3XZAaoz9ChhirGbn37V1o7XYgN9WCySVyMaKMjDhJjRD9YMmblfjicAM6ehy4eeZQ1W1e31IFq1mSKkwwqW5HhB+KjOgAb1trMJGRTtl1ZWSET+MdkZ8m5vd5bcjxhk502V1ITDBiWF5q/xYdZoJJ0/B6kZkx2NLLiZTBXSSwO91419Oy+42JxTKjMwD43nmlsuuuWNgpDeNwufHrD/bhne2nor2UAedkY6dYm7RVMpBRLVq84qsT4mW7k1KDA0Vsnv6FiWCsweOBUA5QxzxpmmF5KTh2ttNHjPAD9oxh2eJt/Az2ZKNQiV6Wk+JzYIk2hl5s0hljYktzbIsRfkn73+1tJ5vF2pZfXjHW5/5vTS5GeWkmfryyEjurW+AkMdIv/rXtFF76UugOubp8UMwZ+vWHf233+tRkJicAEGqQvvHnDRgfYH6Wndp9BwyKjOgAMXTfy495XVsPmrscMBi89SA9ijODHVXCWcV0SU2FtAMCAEqytdPSy+ktfXGsoRNNnXZYzUZMGpw5cAsLM7EUGdl1qgUAcOXEIljMvj9FBoMBQ3JSYPV8vygy0j94ZAAAWrv142rLGJOZ5jmcwvdo07FGHKnvwHuVZ3we881JxQAEn6VYG60Qq5AY0QHioLxetnt67WEAQFF6IjKThLMHu8T0rK3HgYOe4q5zh2SKt/uIEQ35i3B6Gxa4o6oFgGBtr3ZgjBmCFJ5a4LCnPml0QWBzPB5lo8hIaEi/A3anG+s94xsA9S65eGXnqVYxagsI6SoA2HSsye9jvjetBIDwe0Hfu4Ehhn91iWAxBtlhsdnTYjmuOF08IEvFyM7qFjAGlGQnIT/NawimLDQsyU4Ky7rDSW/TbLd7Ij6TSzIHZkERIpam9vKuhZH5geuLzJ7vl4sKWIPm/crTGPbLVVi1uwaAEAVolwiQLrt+aiFW762VXeepl/0KGwMp5ZJiaruKCzURfkiM6ABjkIZf/AfqjguHq4qR7SdbAADnlsq7HiyKyEiphtM0/kKu2z1Fbcp9izVixYHV7WY4VCdERkYWBBYj/PtL6fvguXtlJQDg4X/vBQB8eqBedr+eIiP/3VcHAJg2VKhz45GRi8fkq25/3/wxsuio2kgMIvyQGNEBwVih9zhcqGntAQCMyE8VBYZDcgSorFY/YCco0hqjegm7R4NAgqyly45DYvop1sVIbDiwXv3sV+j2mJgNyUkJuC1vHafISHB0SoTG4CwhSimdNwXE99m+283Q3GkHAFQ3deFwfQdMRgMuHVsAAHC4hD8Of+/BDy8cBpPRIH7vwv1e/WPTSfxgxddk4qeAxIgOCMYIi89kSLOakZWcALNn3oxDki/lZ7LjFNXn0pqRBJMBgzK1l6ZBgMjIpwfq4fbMoymIwXk0amgxMnLsbAe+/7fN+OxgPXZWtwAQXFeVNUdKqGYkNLYc99ZC5Kcl4my7Taz1yk+zAohfMfL2tlMY9stVKP/NGnx5pAGfHRQiQlNKs5CbZgHgPcGyqbTtvnHHDPH3Ui06HAhHkKG7B97bg7UH6vHa5qqgttcLum7t1QvBFLDyAq8huckwGAxinp67FXbZnTjd0g0AGK7wEJGmafJSrZqaScPx+oz43rfuoFDYN8dP2DaW0HJk5PcfH8CGIw1iezgA/OX6c3t9nPe7qMGd0iDS97fb4cLznnkrEwZlwGgQnG2DPXBqnaZOO043d2PC4Ax02pz42Vs7xfueXXdUfC8uHpsvil67043K6hY8/skh2XMlJhgxfZi3S9BqNqLL7vIRLXanGwkmg6w1evepViz4ywYAwOZfXhLUSU1jp63XbfQERUYgNQWLTzxBjoBnyyc9kZEh2XJXVX42esxjhpadYkF2ikX2WIvZ+wbmec68tIa/wk7GGLZ56kXOHx67/iKcYD7raLF6b53s+sLppUE53XprRrS3T1rkS4UY+c8eoYBz0ZwRIZ/ta50f/mMrFvxlA55ZdwTznlovu08qyi4e4xUjDpcbi1/b7vNcV00eJLvO3yteM/LVkQY8u+4oJj3yCR75QD5ATyqCpF1LgaCvsxwSIzrAe7YcQIw0CmKjNEcoPjV7/nD52SifWTNCxVlVGmbXqhjxV8Ba327D6ZZuGA3AeWWxXS8CaHdq71eSAwNHGWHzBxfGWhRYWqOp0y7OjgKAQ3XtONXcDYvJiAtH5XrFSIxHRrrtLtS39+DrE8KJxB8+PohTzd2q204uycSogjQxglvfblPdVlnrJn2vzrbbcMNLW/D7jw+g2+GSubQCENNgQPDpxFhovx9ISIzogN48NgCpe6ogRni7Lp8HwmfWDM/3LTaMCTHi+V/5HuwW7e1TkWyJ/ayldyCgtn7opAdIztDcwIWrHGMQNSPvV57Gt5/5UhTVemXLcXmhakuXYG42rjgdyRazLFURq1Q1dmHKb9dg2qNrVe//2WWjZNeXLxRSgVxc+BMtZbnyLkCrWZhLY3O4sfl4o9/InPL2zgCdStJtO+366WgKBhIjOsAQhCtnlSdNUyqmaXhIUx4ZUTublYqR3FRtihFvmkb+JuzwdAhpbbBfXxE/aw0daz47WI8n1xzyuT1YMeLtpvH/Bb57ZSW2V7Xgz58e6dsiY5Cqxi6x8Jyz1RMpGFMoP8vnU7R5dCBWIyM1rd248I+f+fVJ2fqruRia6/2NykmxoDhDqN+w9mJmODJfERmRvFf8fVXjw11yB9dOm/8uGanzbWOHPeB69AaJER3Qm8eG0+UWf9SGiGkaeQErrxlREyPpSd6IQopWp92K/hvymw96ztgnDo4PMaI1n5GmTjtueflrVV8L3nbaG6ZexEi35MAU5+VfIk2ddlz4x89w5f99AYdLsCz/2Vs78bcNwuwZ5XwlLrZjvWbk14paDSlf3ncxclOtSEv0/gZNHJwhCnQe6eA8s/BcrLxjhnhd2QUofa+2nvTv1vrG19Wy690BWnabu7wCJMPjck0I6FqMaOT3OuL0Nq+kprUHTjeDxWxEoacK3JumYXC7GY43CGJkWJ7v2azVbMKoglQYDMAlGu1I8VdLwXO9owv9D8uKJYKJgg0ke063+r3P3EtLL6c3MbJb8hqpiRoVw2GGu4q29TjR2GHHycYuvL3NO4135ogc2fbncDGi4h8UK7jcTOx8U4NHQKRiZIJkzpQ1Qf59mzEsBzOG5eDx70zCP34wzacLkEdSalq7see03K2V/z62djmw0eNc/e1yoQC2O0D65T8eR1zAW59HCOjjL1fnGHuJjPB6kdLsZPEP0pumcWPFVydgc7phNvr3EHnt9hmobe3BSA0angHqtRQtXXZUNwn5Y2VYO1bR2tTePWe8QmHJpaNU0zW9Yeqlm4Zb+QNAjyP2DrJ94V8S4dFhc4q+LRxpMabZaMCoQiGiGcuRkcrqZjHqsPKOGVj4t80oL8nEDRVDMDwvVRTi6ZKIw+QSb8RTmqYpy0kWuwKvmTJY9fX4e/Xg+3t97nO4GBhj2HS8EYwJNWcjPE7C/iIjNa3dsnZivZwMBwuJER0gRgX83H/CU/Q3RGLjLrb2uhh+/aEQGnW6md+z2dxUq2brRQB1F9qdnuLVITnJyFK0K8cqWouM7D0jnFHee/kY3DV7OJZ/dgQ2pxtXTS4O+jlMHmHs8vPr/bXE5CvQWWm80GV3ygSYw+XG1pPymoakBG9KYkR+qpiiEAtYY9CzhU8dvnJiEWYMy8HG+y5GelICEhPk6ZfS7GSMzE9Fa7dDNl1cmqYZHcTJh7LGZNbIXCSYjKK1vsPFRIO5GcOyxffcXz1LxbJPe31NPaPrNI1eMPRSR1Al1ot4UzBcdEgdWGeNjF0fDjFVJdmfbSeEH5JYn0cjxWvupo2DDU/TTBgknKG+ett0zBmdh0VzRgT9HFz/qkVG3G4mOxAHytfHC/vOtMnEpsPllnXRvHzLebID9BBJOiCWIyP8wF/hMSbLT0/0ESKAILj+c/csbLj3YlkNW6IkTRNMW7myAyw/LRHPLPSa9NldbrEbb3JJFpItwlrUbN67VERyIKsFPUJiRAd4xYj6/Sc89SDSHy1ewNrY4XUJ/Mt1vbtlahWefpKeXe/whLanxPg8Gim91QcNJK3dDjEFyLs5zivLxsu3TAspnSdGRlR26sjZDlmHgh6m0e46Ja/DqWntwVFPgfmOBy7FnNH5soN0ocQNNFbFSGu3A1+f4FGInF62Fk6mLIrIhrR1X2ncqIayBfiu2cNlnYNdNicqT7UAELxMEgNERnZWez+z66aVAtDG36iWCFmMrF+/HgsWLEBxcTEMBgPee++9Xh+zbt06nHvuubBarRgxYgRWrFjRh6USfaU30zOxrVciRhKM8p784XkpyEiO3epvnnb64nCDODqc/8/P2uMB7sAazbMuxhhauuz4k6c+JDvFgszkvqfBAkVGlC2Xehg+tstzAOTwIXijClLFdKNJUoxZmOGt80qI0QLW7Seb4XAxlOUkY0R+cGZ5SixmI8pLM2EwAPMnFIX8+BH5qTAZDeJ7u+dMK+xON9ITzRielyKKHbXo3DZPN86VE4okNXx92o24JWQx0tnZiUmTJmH58uVBbX/8+HFceeWVmDNnDiorK3HPPffgtttuw+rVq0NeLNE3As0rYYxJDM+kaRp5Zfl5ZdmRW+AAwH9Atp1sxvynv0Bjhw0NHXYYDL2PsI8ltDCb5pl1RzH512tEl8qijP4NHwwUGdnqOVvmrdlfn2j28d6IN3YpOpR4hK+8RD3CJx1saY3RyAivkenvVO1/3jYdX913cVDDPNf+9CLx8rVTS8TLvJOGC+GJgzNhMBjEmpFulcgIHzkxZUhWr2lzvRKyGJk/fz5++9vf4uqrrw5q++eeew5Dhw7FE088gbFjx2Lx4sW45ppr8Kc//SnkxUYKQ5y7E4jFmyolrGfbbeh2uGA0yPvsExRipGJ476FRLWNSDCDiE4hLspLjwnlVSTR/6P64+qDs+m+uGt+v51POSZLC60Wk9Uy/eHtXv15Py7T1OETPH+7Twjtpzhkkb0//241T8fCCcbhQ8t7EkunZh7vOYNyDH+NUc5dXjPSzvivZYkZRRnD+NtK6EmmBO48u8RoWLoSTPDUj7T1O/GPjCZz7mzXYdKwRrV0OfOZpSZ5altVrQ4Feifiv8MaNGzF37lzZbfPmzcM999zj9zE2mw02m7dWoa2tze+2RO8EcuXkA/KKM5NkOVbe2itcNuDCkXmRXWSEMSnE1VdHhcr8kX0M+WqVaEdGpDVGgCBw+3sA4VEt5SyP+rYeVDV1wWgAZg7PxfLPhOm03PchHuEFwYMyk1CYniirazinWC5G5o4r8Hk8P8nQuhhxuxkWv7YDAHDB7z8Tbx/o+q4fXzIS/648jTsuHCbexgXdVkm0AwBKPOLwdEs3HvC0Az+//pisK2dsUbq3/Z4iIzIiXsBaW1uLggL5H0VBQQHa2trQ3a0+I2DZsmXIyMgQ/5WUlKhuRwRHoA4LtRQNIE/TjClKi/nWV2VkhE821aovSl+JtgOrMoUwuTSz389p8hMZ4QeD0YXpmp2JFG5498akkgxZMaXBAIwJwrjP4mlv1XqaZl+N7wloisU04H5ASy4dhXU/nyMreFUWxnKxrfYdlA7zG1OYhgSTUXPt91pBk900S5cuRWtrq/ivurq69wcRfvEafvminNbLkUZGCtL6l/PXAmaFu+L2qhYAwuyKeCLakZFd1XIxEo7iYJP44y3fKR4mP68sSwyRxzPvbD+FZf85AACYMCgTCZKD4rDclKBGMcRKN836w75Oq//+0QXigTyaSEWg2WgQT9QMBoNPl05LlwONnUK08JVbp3m2E+7T2jDLaBNxMVJYWIi6ujrZbXV1dUhPT0dSknruzmq1Ij09XfaP6DuBuml4ZERqeAbIIyP56bF/1qm0euZMHxbbhblKol0ct1PR6TGuqP9/u/4iI7zV87yybJnJF6D9g22ouN0MS97cKV6fNDhDFv4fF+SgR56m0XI3TY/DhT98LK87uv+KsUF5gwwE0nq6Oy8aLrvv5vPLZNdPNXeDMSGtlu9pseY1IxQZkRNxMVJRUYG1a+WjntesWYOKiopIv3Sv6OW7oOY+yjmpYngGeFt7AcHsJ9ZRRkY4EyWzK+IBfuYYre/2vjPy8PqYov6H1dVqRs60dIvurtOGZvsUIceb+dkxjxcQ55xBcjFSmh1cUWYsdNOMeeBjn9tmj9ZOzZo0MqL8fif7idBNLfPWugT6PdYzIRewdnR04MgR75ju48ePo7KyEtnZ2SgtLcXSpUtx+vRpvPLKKwCAO++8E3/5y1/wi1/8Arfeeis+/fRTvPnmm/joo4/CtxdEQALlKHmaZogyTSNR/wXpsS9G1CIj102Lv1qkaNaMtHY5UNvWAwD4wzUTYTIYwiJkvZER7wH0/Urv2PaC9EQwxpBiMaHT01Zpc7oAqPvivLfjNJ5ZdwTLrz83ZmqGlN4iGUkJMnvzwiA7RLTuMyJ8bl4++9lsNHfZNfU5ycSIok5HOS2ZI01Xqs3JIvoQGdm6dSvKy8tRXl4OAFiyZAnKy8vx4IMPAgBqampQVVUlbj906FB89NFHWLNmDSZNmoQnnngCf/vb3zBv3rww7QLRG/4OUK1dDrR0Ce6VpQHSNAVxkKZRi4zUtPZEYSWRJVohYLvTjT9+ItQzDMpMwnenluB//AwgCxXv1F7vbdw1mLtZGgwGrPv5HPF+W4CBefe8UYlDdR249E/r8dKG42FZY6Q5KLEmf+HGqQDkU2gLgzxh4DUjNo1GRnhhOWdobormxjVwwQ0IA/ekjC1Kx95H5uHAby6X3f6dKd4TH4MGvIC0SMiRkdmzZwd0d1RzV509ezZ27NgR6ksRYcJfX/vJJuEHPS/N6lP8Jj3rykiKXedVjsnoq7t/eunoKKwkskTLgXXl11V4dZNwEhLMELJQ4GKky+5EdVMXSrKTcaBOODhfIDkTzUuzIj3RjLYep9/W1b9+flR2/dcf7sMtM8s0URgZCD4n5bdXjcelnpbdRMnfaLDGclr3Gbl1xVbx8o8vGRnFlfjnbLu3fV1tcKhaIbHUvdqbpiE1IkWT3TREePF3gPJXvAoA6YlmjClMQ2ZyAsaGoQgx2phUjjXx5LzKGaizLqXnx4ovT4iXw+3dwrtpvjraiAv/+Bk2H2vEYY8YUQofq6eQ1V9k5J+bq3xuq2+3qWypHRhj+PyQ0F0idVOVHgeDTaXyg6dTg1N7lc6l92hUjFw0Sqhfye+lnfybk4TJ1D+UeJQAVMDqj/izniR8EL/8im+/2kwa8TEGA95fPBN2pzuolkGtY1I5g1Gb+BnrGP20wYaT/1t7GH/74hjeXTRT7HA40+r1DBqUFVz9QrBIU4aMAdc+v0m8rgyTBzrz73G4ZCF2zqnmLk3XRa3zuHdazUaMl3TNtHV7J8EG26LOO0GcGoyMbJZMHp47Nt9vB1y0+fElI+FwuXHv5WMCbvfbq8fjqvJiXDQqX3Y7FbCqQ5EReL8c8Yq3r10Oz7srDc84VrMJaYmxn6IBfE3P4hWvwV3kXuPJNYfQ1uPEYx/tBwAcqe9AjyQS4W9GSl8xBvjslGFyXkehNrK9srpFtYukJ0B9iRb4YKdQrDuuOF1muNXW451WHOyBm/sHOTR4Ws6dcy8clYe/3jA1yqvxz5QhWXjt9hmYVJIZcLv0xARcPKZANrQQoAJWf5AY0QH+xsp723p9IyPxhr/W3njDOID5aB59WPzadvG2v986DRMGh3cKstLxksPD5bJtPeLk+hc2o7nTLruPW6nPO6cAP754hHi7lttcGWNY50nRLJ0/VnZfgkq0rze0HBnh04evmlzscwCPJ8QaPtIiMkiM6AB/BVNVnpoRZSdNPKI8c9xw7xw/W8Y2A+nAylNBvLiyMD1RVSD0F3/eDX+5vtzvmgB52B8A9tcI6xxXlIEll40WZ4potbMEEEyzmjrtSDAZMKlELvJ+etkojMhPxbJvTwj6+bRaM9La5cBuj1j01x4bLwzkCUMsEfvFAESvqB2gpPlzf2maeEIZGRmcFZ8CzDAANSMcl5uBMYbcVAsaOux49vvnRuR1pGLkf2cPx9l2GxbOGKKaQqxp8daE3Pnqdtx/xVjcfuEwMMbwr+2nAHiLXnkUReltoSW4o+3YonRZhxsgGBX+d8lFKo/yD/87cKhNzYwiW040gTFgWF6Kput3wgLNplGFxIgOUBuUx4tX0xLNyEyOj7qQQEgjI98Jk/+FFvHawUf+tVxuhvp2Gxo67DAGOaitL0jdVWeOyA145txuk9eKPLHmIG6/cBgqq1vE23iEgc920VqUQMpOz7onhckpOEGjkZFNnnqRGcNyorySyCMO7aWaERmUptEBahbhp1uE7ofBWcma91gIB9LISGpi/GrwgSyO23umDVc8/QUA4Sw9UsPqpLNAQp1PwqMfXIyYjQYUedxKE1ScXbUGT12Eqw6HdyY5PVEtrcDNzvQgRqI9zFKrkBjRAWoOrA0ebwW9jF6XFsSlxUGrsj8G8oeuy+5Co6dIdHCY23mlFGcKz2009O4G/IMLhsqut/U40eNwiXNs/neOt3DVLA6N0+ZRwe1m2HtaWPf4IAfh9YZ05pRy8GC0aOywiXVHFToQIwMZvYwl4vdXORh08mVQ62s/2+ERI6k6ESMGfURGxB+6CP3S+XveSIqRZIsZW+6/BFaTqdco3r2Xj8H3zivBiPxUDF26CoDQMnr0bAcAYLRkxolZ43Najjd2ot3mRGKCEaPCZNAn9Wxxuhi0YLXzxWEhKjKmME0XJ0fe8yKdHICCJH5/lQkR79myNDIinNHmpgVnlhTrmCQ/wvH8gxfpqb3VzV2qtw/KjJwYAYKfHG0xG32Gqn26vx7HPZ46Q3O9xdoWjdZPcPhwvHOKM1Rtx/uCVIw43G4kIbpqhDGGe96oBABNDcOLJGKRuTY1cNSgNI0OUAsL6jkykpkUvwIs0lN799e0qd4ebtfVcDBrpFDoajBAHAhZluvtotJqZwlnZ7VQLzIxjL4tsjSNBkTY4foO8XI8F5arQQWsckiM6AC1eSV6qxmRFlemxXGaxp/BXbjYV9OuersWW6XHeFp493nqRYoyEmWdOVr13ODw4tVwihGj0SAKVi0Yny3/7Ih4+cIIeNRoESpgVYfEiA5QO1vmkZFcnURGpF4VcV0z4vk/Up0S/iIjozQYYk/yFETs8HTSjFAM8LOIBazRPygrcbrc2HuGi5HMsD63WCvTR8Vqc7qw8G+bZM67feX9SsHqvjDevUUkUAGrOiRG4P0Bj1e89sOSmpEOnUVGEqSRkfj1VYn01N4DtXIxMn1oNv5+6zRkJGnvPU30CFCX51dfOfbAW8CqvaPCYc+8nzSrGUPDbEootjT3UYRtP9mCL4804sNdNbL5OKEiteFfvjAyhnlahHxG1CExogO83hMCdqdbzKHrJTKSI9nPgjgWYJGc2tve40B1U7fstu9MLYmIBXw4UDqWzhktn55q1vCcFl68On5QRtin1/ZXhPEZP4Bg495X9nmibFnJCTi3NLPPzxNrUJpGnfiNVxMiSovwxk4hKmI2GpCpwTPaSJCRlID3F81EssUUts4ELRLJEDD3gpDSm+9HNLFKBuylWEy4eIxcjPBiTi2mafgcnXOKw+9qKw7L62PhLreoB4BOlenIwbL9ZDMAYHJJpi6MFzn+ZoXpHRIjOkDpM3LWU7yak2oJ+1mXlult5Hc8wM3dIhEZ4fUi6YlmtPUIByEtzxGRipGSbF+n4YR+1k5EEp4OG1MUfjFiNvavcHfXKW9kpNve97k+3AL+vKHZfX6OWEZ737roEr+niISIssNCb/UieoJ7Z9hVJtGu3V+HZ9cd7bMhGj9bn1rmPXgUZmhYjEjqhNRM2Xia5rXNVbhq+ZfocWhjYJ7bzbDH47zKO4LCibkfhbtNnXZxrhUAdPfxPXO5Gb46KogRPbiuSol0XVesQpERHaDssOCREb3Ui+gJHg1QTqK1O924/ZWtcDNgaG4yLh9fFPJz7/N0dyyYVITmLjtKspKRruFiYGlkRM2UTTrzprK6BTe/vAUr76gYkLUF4lRzNzpsTlhMRnHCcDgRh+X1QZTulAwcBNBnAbfpWCM6bE6kWc2YMCh8rcuxgLeAlZBCYkQH8FQM//I3dAjuq3oxPNMT1gThQNPjkJ/17jnTKkbGlEWowWBzusTIyLmlWbi6XPsGVVIxouaDkqCoHdp0rCniawoGnqIZnp/qs8ZwIJq99SEysvm4/D3q6mOa5usTwvNcNDovrmu41KCaEXX09S3QKcp5JWJkhNI0cUeiJzWhjIxI/UGau+whP++BmnbYXW5kJiegNFt7BmdqWGRiRC1N4/vzJ+0UiRYHPYXCkUjRAH03e2OM4cUNx2S39bVmZJuneHWaDutFKDKijq7FiF76vEWfEc91vVnB6wkeDVi1u1Z25ivN87d0h96OyTsoJg2Onc4HaWuvWmSkTeV9+MafN0R0TcFwoE4QI5FI0QC+3TTBtjafbOwS24F5nUdf0jRuN0NlVQsAIcqmN8S/H30cfoJG12JELygdWCkyEr9ID8AvfOE9i61p6REv98Ubgs9JiaWOJIspcGREq51APDISKTHiTdMwvLLxBMY/vBqfHzrb6+N2nfZ+B4oyhfeuLwWsh+s70G5zItliilj0R8t4tQipESkkRnSAsrW3gSIjcUtigvdPes2+OrjdDO/tOI3NxxvF2/uSpjlyVhhoNjaGDh4j8lNRlpOMaUOzkZnsW2j7rcnF+NHFI/DGHTNkDr3RxOZ0iROGByJN8+D7e9HjcGPZqv29Pm63GB3LEN+vbnvodSfbq5o9z5Opu3oRQNpQENVlaA79fRN0iNfxTx4ZyUuL3+m1eqXD5j1THZ6Xig931+CeNypR12YTb1dr+w0EYwwnPAfIstzwWpNHkiSLCZ/9bDZW3j5DNbWUYDLip5eNxvRhOfjL9eUAIicAguVofSdcbob0RHPE5rWomZ5J62v8wf1FJgzyipG9Z1rx969OhFQMy+tFpgzRX4oGgHh2SGJEDnXTwBs5iFcMEp+RHocL7R7DqrxUbYapib5TIklHmI0G/Pj1HT7buEL4Fdx9qhVL392F1m4HDAagLMxzUiKNwWAI6u+bR0766psRLg7WcX+R9IjV5nDTs5ON3jqi4gzfNJYUwfvEO7iP1yB9sq8On+yrg8Plxm2zhgX1+jwycu6QzFCXHhfQbBp1KDKiA/iX382YmKKxmIxITyItGm9MlxhIrfy6WnUbVwj+Elc/86VowFWWk4IkizbSGeGG19r0x1E0HByIcL0I4I2MPL/eW1NkMgUWPvtq2tBpdyEpwYTheSli1xYn2Lboli47jp0VomzlJfqMjCjT5oQAiREdIHVg5R4juamWmOmKIELj5/NGB7y/NzHy2YF63PzyFtS29siMsUYXxE69SKhwkRVtF9YjdUJtzqiC1Ii9Bo+MSH0ubI7AaRbeZdTtcMFsMvrU2IwuDG69XmGbjKwUfaaJld2NhACdGusA7/gZRp00OsDaS/6/NzFyy4qvAQCPKooaR8VQ8Wqo8DN9pVncQHPMU5szPC+CYsQTBemURIGUvjRS1My5lBEy5YRkf+yrEVI94yIwADBWoMiIOhQZ0QHcgdXtpk4aPdBbKiXYIXof7Dwjuz48L7bqRUKBn+nbXe6Q0ljhxO50i7UYwyIoRtRcXQMVNfMTGAB493/PByA9wREI1lp+p6cIdlwEBgDGCt63jtSIFBIjOsLNGGpbBb+JfA2Pfif6R2IvZ6mBDhxNnf7bfmOteDUUpC3RgaIEkaSqqQsuN0OyxYSCCP59mlUmddsCiBFexzIsLwXlfkzKXO7eI0puN8NGz3C8aUP1NRxPCkVG1CExogPE1l5AFCNFvVTPE7GLNDIyflA6LhqVBwC4qWIIAASc2nukvsPvfXEtRiQCLlpFrFVNQopmSE5KROu51Lw9AosR3wnC44rkw+2CiYwcPduBpk47khJMmBxD5nnhhmpG1KGaER0gdWBt9VhgZ+u0eEwPSM/yC9MT8cdrJgln3Yzh7xtPBmztPeSxIpcyuSQTN8wYggwV47B4wWg0wGI2wu50oydEH5ZwwVtth0R49k+CSueMPUA0aO8ZQYxIUyvjB6Xj2qkleGtbNdwsuDk3OzwTfycMzgjK1yRuoUF5quhajOjlu2CUmOxwK/CsZBIj8Yq07TI31YqsFAuyUizi+PdAEXVlZOS6aaV49KrxYt1RPJOUYILd6Y5aZEQUIzmRFSO8m0ZKoMgI9xc5Z5A3GmIwGPD7ayYiL82Kv3x2JKg6m10eB1c9R0UAGpTnDx3LU/1gkERGuBV4Vhyf5eodqRjJlIhOk9HXeVOJdLovAFwxoVAXQgTwRpSi1d7Li1dLIyxGpJGRQZlCutafGOm0OcUOn/HFGT73i8XxQZzZ7a8Rom7n6LiTBvCaUOrlZDhYSIzoAKnPSLMnMhLPIXe9kyQTI97PmYsRf87dNqcLOzzTVDnFmfqpLUpKiK7XyMlGT81IdmRrc8wSMTI8X+ja8ddNs7+mDYwBBelW5KnYAUgNFQPBGMOhATB0iwUoMqIOiREdIK8Z4ZERStPEK9LISEaSrxjxd+A40dAFu0Kp9GYTHk9E02ukrceBox5n0mERbqGWpml4u7a/DqJNx4TulwmDfKMigDwFHIia1h6025wwGw0Ylhu5tuVYwEA1I6roumbES3yHoXkotaPHCYen0ExtiikRH0gLWKVihB84nH5CI0c9k3knl2RiypAs5KRa4tb+XY1Uq/Bz2NbjGPDXvubZr8TLRRmRnRklTdNwczWb0w3GmE8XDy9ene6nFdd7ohP4NXlhdFluir6LVxH/s9D6CokRHcC/+9xDwmL2tXMm4gfpZ8vrEACvv4S/A8dRT/HqiPxUPPCNcZFboEaJpiX8oTpv4XCkxzRIW3u5GGFMaM9Vdtoc9KRWxvoxKeMnOr2d5fPniaTNfawgtvZSYESGviWqTuA/blyMZCUn0FyaOEaaprl0XIF42Vszov4ryCMjkbQi1zLcmTSYNtVQOVjbji3H1YfJSSMxz98wJeyvrcQhqQ8Znu9NCSmLWHscLpzw1LGM6mX2TG81I7/7+IDwPHE83yhYxDQNVY3IoMiIDjAqxEhmEtWLxDOJCSbcNXs4bA63TFjws1h/PiO8ZiGebd8DwSNHjiDcREPB6XJj3lPrAQBbfzUXuYpRDHyKbX6aFZedUxjW11ajtq1HvJyb4l2LzeESU1WA0ObtZsLJi7/xEcHUjDDGxPvPUenI0SsUGZFDYkQH8Lxutyf8TPUi8c+9l4/xuc3Eu6pUIiNuN/NGRvL1HRlxhNn0bM8Zb7t0XVuPjxg53iC875EuXOVIazaMRgMsJiPsLrdP8fJBSfeLv0hqMDUjJxq9qcLZo/P6uOr4gVp71aE0jQ4wKn5ISIzoE95EoRYZqW3rQZfdBbPRgNIIO4BqFd7yGuzQt2DZ7OlIAYQiciU8MjJ0gLpMbj6/DENykvGrK8cC8IoTm6KL6KCn6HR0gNSKNzLi/z3jZmflpZmqQ/r0hre1l9SIFIqM6ADlSQ219eoTk+SMzO1mMjMzHhUZkpOs2wMGb3l1hLlm5NXNJ8XLauZi3FRsoNJjQ3JS8PnP54jXrWYjOmy+axMLmgOIEamhoj+2n2wGAEwanNnHFccXNChPHRIjOsA3MkJiRI9I/SVcjMEoaWnnBx69Fq8CANdgwbiJBgtjDNVN3eJ1tU6dKtEGPjq1Oo2eWrLqpi6ZIRkvXh0aYF0Gg/8OrV9/sA/rD58Va9Uqhut3Uq8UGpSnTp9OgZYvX46ysjIkJiZi+vTp2LJlS8Dtn3rqKYwePRpJSUkoKSnBT37yE/T09AR8DBE+lJERStPoE+lIEmVHDS9eHaHTehGg926jvnCquVt2XS0yItrARzk9dtsrW8XLLrdXRAWalWMUO0Pk9DhceOnL4zhS3yGKkfPKssO63ljF4M3TEBJCFiNvvPEGlixZgoceegjbt2/HpEmTMG/ePNTX16tu/9prr+G+++7DQw89hP379+PFF1/EG2+8gV/+8pf9Xnx/0ct3QRkZobk0+sQkScsoz/713tYLSGf3hO+XQTkFWRkZae12iJO0S7K143Zb29YDu8uNBJMh4EgA76gJ+Xt2oFa+39kpFpoU7oFqRtQJWYw8+eSTuP3223HLLbdg3LhxeO6555CcnIyXXnpJdfuvvvoKM2fOxPXXX4+ysjJcdtlluO6663qNphDhQxkZSUskMaJHpKJUefbPp/XqtZMGCNxt1FeUU5B7FJGRak9UJDfVgmRLdLLmvJB1nMTY7KSnjqUkK1kmYpX4szZXDlwcoWORq4RqRtQJSYzY7XZs27YNc+fO9T6B0Yi5c+di48aNqo85//zzsW3bNlF8HDt2DKtWrcIVV1zh93VsNhva2tpk/yJJvPt/KSMjKVYqFdIjssiI5JjY1uNAfbsNwMC1l2oRkyePFc7IiFKM2BSRES5GSqKYouF1ItLoxgmxjiXwusSaEUX2SRkRiub+aQ+qGVEjpKNSQ0MDXC4XCgoKZLcXFBTgwIEDqo+5/vrr0dDQgAsuuACMMTidTtx5550B0zTLli3DI488EsrSiAAoxUiqlazg9YhJGhmRHHh4a2lemhXpOo6aRaKA9Ygn/ZVqNaPD5vSpGdFCvUiiyrTik02eCcK9FNV6a0bk75lSjBSkq5um6REalKdOxHv41q1bh8ceewzPPPMMtm/fjnfeeQcfffQRfvOb3/h9zNKlS9Ha2ir+q66ujvQy4xpllDVa4WAiukhbeaVpmmNivYh+oyKANzISrgJWp8uNAzXCQXlSieA8qoyMcDFSkhVFMWL2nVZ8siG4yIjRTzeNdNYOABRGePhfLEH1q+qEdFTKzc2FyWRCXV2d7Pa6ujoUFqrbGD/wwAO44YYbcNtttwEAJkyYgM7OTtxxxx24//77YTT66iGr1QqrlZR0uFC6J6ZSmka3mI0GON1MdsA93sBH1+s7r88jI+ESI8caOtHtcCHFYsKYwnR8eaTRp2aEd9tEs3iVT3m2Ob1Cibf1lvUSGREPrJKz/NYuB8560n6c/DQSIxxyYFUnpMiIxWLBlClTsHbtWvE2t9uNtWvXoqKiQvUxXV1dPoLDZBKUOIWpBgbfyAilafSK2nwabro1LJciI0D4xMhhT3RgZEGa+DfnUzPSHP3ICHdgtXuEEmPMmz7qQ2SEp3ikUGTEC0VG1An5FHnJkiW46aabMHXqVEybNg1PPfUUOjs7ccsttwAAbrzxRgwaNAjLli0DACxYsABPPvkkysvLMX36dBw5cgQPPPAAFixYIIoSIrIoIyNUwKpf1DpGvHbkOhcjhvC29vJ26RH5qbB6DvjSVIjbzcTIyGAtiBHPbJrWbge67IJoGhSgrRdQr3+QmrxxqGbEi9dnhOSIlJCPStdeey3Onj2LBx98ELW1tZg8eTI+/vhjsai1qqpKFgn51a9+BYPBgF/96lc4ffo08vLysGDBAjz66KPh2wsiINLIiMloEH8YCf2hNPZySQbk6dnwDPDOpglXa6/UuyXB89zSVEhDhw12pxtGA1CUGb3IgcXktcF3uxlOtwhiIjfVIha3+kMtMsKjPSajQfyeUZrGiyjgorsMzdGnU+TFixdj8eLFqvetW7dO/gJmMx566CE89NBDfXkpIgxIu2mSLSa/EziJ+IcLU56mqW7qgt3phtVsjOrZuRYwRigyMjwvBXVtguN0tyRNww/aRRlJUZ0HJJ3ia3e5caZFWGsgszOO2myaU579uvn8MlQ3dWHeOYUBvUr0hmgHT2pEBsXrdYBUe6RQJ42u4QcFfvbPD4hDcgKbW+mBcLb2ut0MR+s9A/DyU8W0R4fNO7X34z21AKLvc+QrRoTISHFG72LEqFKMydM0owpS8cA3xoVxpXGCn3ZovUPxeh0gjYykkMeIrlFanp/21Cz0VhugB8Jpelbb1oNuhwtmowGl2cnISBL8W7j1OwAc9BS4FqRHN4VhkURl7E6JGAkhMiI9sHKBq/dImz+oZEQdXYsRvXTzyMUIRUb0jLJmJJQDT7xj4imHMIgRnqIZkpOMBJMR6SpipKVLGCB3Y8WQfr9efzAYDGJNi93pFmtGioOoY1E6sLrdTBS40ewQ0jLU2quOrsWIXpB2VlNbr74Ru2k8v4SnQ6gPiHdMJh4Z8Z2sGypH6+WDB7m3T5fNWzPC60iG5Ua/cJhHR6SRkWCiZUZFzUhDhw02DRTlahlq7VWHxAi8X454RVocR+6r+sboJzJCaRqvUHP1X4vg6FlvvQjgW4/idLlFYzAttL1K23u5x0gwaRZlzYhWinK1DNnBq0PfFh1glhQmcrdFQp+IBayeH8IzrZSm4ZhFoRaGyAhvl/ZERgwGuQisbeuBmwkRidxU7YiRqsYuNHQI6aOhQYwHUM6m8fqm0PfJH4a4P/3tG3Rk0gFmSZ6mN98AIr5xuoSDxqG6DrjdDDVimoZC6l532v4/l9jWyyMjCj+OujYhKpKfbpXNDIoWXIxsq2oGAIwrSg9ybIR8v3i9ySASI37xRkaiuw6tQWJEB3AzJ4DEiN7hB4ul7+wWTLdcQn6/MModHVrArGh77ivtPQ5RbAzzRBeMilqdhg7hfi1ERQBvzQi3sA8mKgL41oyI4jaItmC94q0ZITUihcSIDkiQihEziRFCgAuTwvREmCm/L0Yo+lvAyu3189OsSE9M8Dy3cB9P02hOjHh+F441CGIk2E4YpQMrdWcFAUVGVKFfIB1gkqVp6CMnBEJx2tQD3shI/55HagPP4bU6/ADU0C7UZeSmWvr3YmGCp2m4kAo2zSL+tIjdWcG3BesV0YE1yuvQGnRk0gHSAtYkStPomu9OHSxeprNYOV47+P6pEW+9iDfVwZ+b2/DXetp689O0ERlJUNStDA7yO2EARUZChbpp1CExogOkLXZUM6JvrplSAgAYlpsinsWSH4SAKUwFrKINvCQyYlR009R7xEiRRg7avCWXE6yYkM6mae9xoK3HGdLj9UikfUa67S58uOuMzGAvFiDTCR1gotZewoPotOlyo7aVig2lhKu1l0dGhsnEiPd+xpjmakZ4wS0n2DSLtGakxvN9Sk80B9mJo08MER7b+4O/f42vjjZiXFE6Vt09KzIvEgHoyKQDpAWsZESkb3htgMPlRg0/O8+gyAggNYTr+3O8tOE4DnvcV4dke4tApScELjcTvTxyNFIzIuW6aaVI8xTe9obX9IyJYqSIxG1AIqxF8NXRRgDAvpq2CL1CZKAjkw6Q/hCGaTo6EaNIbb9reJqGDh4A+h8Zae124Ncf7hOvF0pEntRLxMUYznoiI3kaiYzcf8VYmI0G/PO26Vj27QlBP07qmcFTT/kacJTVMt5BefRjLEXXsbRrppRg5ohc0QsgXpEWrbb3xFYekQgvPDLWZXfB7hK+C1QzIsDP8g/VdYAx5g2nB4nyb0tanyUdVtnc6YDdKQiePI0UsN5+4TDcUDEk5Joyac1IvcfePj+Nvk+BiHRkJFbRtRi5fnpptJcwIEg9JGaOyI3iSohow9M0Ns/B0Gw0IDtZe6mCaCBNZ67aXYsrJxaF9Pgfvb5D9bkArwMrAPzkjUrxspYKyvuyFqmZ2x9XHwQADCJx2wuRm9rbYXOKl0cVRH8AYyjoWozoiU1LL8Hplm6MH5QR7aUQUURZM5STatGEHbkWkEYp/rn5ZMhiZEdVi3hZOZBSGmTZeKyxT+vTIlyMSA+C9nD46ccxStfacHLEU68EIOaKiGNrtUSfKcxIlOWwCX1iUYqRFG2kCbSAtHZmSE7/UrfJFnmUwRSngo+LLGnRL28ZJ9QxGCIXGXl100nxsivGCgSpgJUgdARP03C02M0RLSxmI0Z4BttlJgfXTeKPiuE5suumEOtPYgWvxvIe+OaMzovKWmKFSH4T3t52SrzsiLEIFYkRgtARyloGrXRzaIW5YwsAAA5n/7xGfnnFWNn1ONUi4lm+9Cw82LZgvTJQDqyRSANFEhIjBKEjlAPxHDEWyo00FokpXMiP9USdnv7eZB8zM4PBgHjM1CidZQHfFBUhZ6Bm08SYFiExQhB65oOdZ6K9BE0hNYULlaGeOhN/0SajIjwyuSQz5NfQGnyPpJr23NKsqKwlVpB6s0QSiowQBBEzfO+8kmgvQVPwbiNbH9I0/Mffnz8J71qa4Olou2bKYNXtYgm14YLKuiRCHRaB2MiUIV4hGFtShMQIQegO6RTnBZOKo7gS7eGNjIT+U87FiL90jEk8cPPtYj9v4+2m8b5f8ZiOCieRjIxIoyGx5vBKYoQgdMaGey8WL5dkJQfYUn8kiHb5rpAfy3/7/fm2GMUDtxBFiAMtIomMeA98oTrX6o1I1oxI02UxpkXIZ4Qg9EZhRiLW/ORCtNucKM0hMSKFdxs5IxAZ4SLFLnG/jXWUZ/lKHxvCl4hGRiRqJMa0CIkRgtAjIwvSor0ETdKfs1Z+HPBbM+K5vcchiJF4qK1QppqUreOEL963LPxyQZqmoQJWgiCIWKUfHhDeyIj6AZm7sPZ4UkDxEEVQBncS4kBgRRpDBGfTxHKahr45BEEQHsTx7n147KnmbtlzKOEipdsuiBHlnKBYRBkFiod9ijS9Te09UNuGy59aj9V7a0N+7v01beJliowQBEHEKOGYG7LrVIvq7TyKwNuG4yFNowwCxUO0J9KIgtfPl2zJGztxoLYdP/zHtn69ToxpERIjBEEQSkL9HT/bbhMvt3Y7VLeJh1ZeJcp9oiF5vdNbZORkY2efntetcFOm1l6CIIgYpa9yQXoQ/t60UvXnVjx5Q4dNdbtYIg4agqJA4Ohbpz30tnIA2F/bJrseW1KExAhBEIRIX4eYfXmkQbysnEsjPrfi+pzR+SG9hhaJx2hPpInUoLzmTnlEjmpGCIIgYpS+Hlt5ZGRMYXAt0wYDkJ4Uf9Ntr5+uHhUivAQqkpYKlLTE0Jw3tp1sBgDkpVk9z9WX1UUPEiMEQRAe+tp2ybcfEsBETtp5kpdqFVt9Yxml22xWcvwJrHBjCFA00tbjFC9np1hCet7mLjsA72cQawO5SYwQBEF48B4nQvslP97QAQC4ZGxBUNsXZSSG9PxaRamnslPUU1SEl0CRkbPtPeLlUB16jzUIha/nD88N8ArahcQIQRCEglAjIzxNMyw3xe820hRQYZyIEYOiEiYjDlNP4SZQzUh9m7eo2RlCaKO9xyF6jAzOSgJAkRGCIIiYJxQx4nYz1LYKZ7TFmUl+t5OKkaIM/9vFEsqTd6fLHZ2FxBCBRg7US1rEXSGoiete2CS2l3OhS629BEEQMc62quagt61vt8HhYjAZDchP85+mqG7ytv/GTWREUfF75cSiKK0kdgg0KK9ekqYJVow0dNiw57S3rbcgXfhuUWSEIAgiRvnX9tMAvJN1g+F0SxcAoQ7EHKQDabzWjKQlUpomWNTqkvqSptl7Ru4vkpUsFL5SZIQgCCJGOVLXHvJjaniKJoTUS7ykaaSRkW9OKo7iSmKHQJGRsx2hp2n2KcQI79KKLSlCYoQgCKJf1LQIYiSU1Eu8REakgZFQfTH0ijj/SOU+WWQkyPqbvWda5c/v+T/GAiMkRgiCIDhXnzso5MecaRVqQYoygxcY+enx0QIrLRnpsDn9b0iIiG9ZmGpG9kkm9d43f4zoihtqmibaaR0SIwRBEB4uP0cowEyzBn+Wf7pZECODAnTSKLGaTaEtTKNkJnuNubKSQzPp0iuBvGyk3TTB1Ix02pw47vEX+fr+ubjzouHi84dSwLrkjUrMffJz9Dj6NhcnHJAYIQiC8GA2Cb/k1oTgxUJfakbikXhwlB0I/Ln89jhcaJc4sAYTGTlQ2w7GgPw0q2gDH6pxn9vN8M6O0zh6thPrDp4N6jGRgMQIQRCEhwSPGHG6g++mqWsLvWYkHuFCjgiMPzd4ab0IIERGekudVDcJnVzD8rxme7wmJdjIyLOfHw1uwwjTJzGyfPlylJWVITExEdOnT8eWLVsCbt/S0oJFixahqKgIVqsVo0aNwqpVq/q0YIIgiEhhNgo/iU5XcL/kLjdDg6cDIpDHiB4I1b5cr3gLTOXfMV4vIi0E7k1Q1HqEsLQ7S/wYghQjf1x9ULws7eYZaEIWI2+88QaWLFmChx56CNu3b8ekSZMwb9481NfXq25vt9tx6aWX4sSJE3j77bdx8OBBvPDCCxg0KPRCMYIgiEjCz+4dQXYyNHbY4GbCASAnNbAYufn8MgDATy8d1a81apVpQ3OivYTYwF9kxFMvIk339Rah486/3OhMeHoeGQm9IDWacjLkXqwnn3wSt99+O2655RYAwHPPPYePPvoIL730Eu677z6f7V966SU0NTXhq6++QkKCYIhTVlbWv1UTBEFEgASPaVmwhlO8XiQvrfcpvA9+YxyumFCEiYMz+rdIjbHuZ7NxqK4dF43Ki/ZSYgJ/NSP1knTfQY/fTW91I1yMSFvFjWIBa+hixGiInhwJKTJit9uxbds2zJ071/sERiPmzp2LjRs3qj7m3//+NyoqKrBo0SIUFBRg/PjxeOyxx+By+a/atdlsaGtrk/0jCIKINFxQuILI1wPAmZbgO2mMRgOmDc1GYgjFsbFAWW4KLjunMNrLiBn8He/FyIikRbw3UVzT5hsZ4d9hN+u9XbetxyG7Hs1MW0hipKGhAS6XCwUF8jHZBQUFqK2tVX3MsWPH8Pbbb8PlcmHVqlV44IEH8MQTT+C3v/2t39dZtmwZMjIyxH8lJSWhLJMgCKJPJBi9P4nBREf4tN6iENp6CX0jPd5LxQIXI9L6D1cvtUunm4UCVj6pF5B3NfUWWWnssMvXFitipC+43W7k5+fj+eefx5QpU3Dttdfi/vvvx3PPPef3MUuXLkVra6v4r7q6OtLLJAiCkHWEBFM3wsXIYBIjRJBILfSlgQteCF2YHlxkpNvuQoNHTJRkJYu3y8RIL5GRv391Iqg1DwQh1Yzk5ubCZDKhrq5OdntdXR0KC9XDdEVFRUhISIDJ5A1Njh07FrW1tbDb7bBYfI1yrFYrrFZ9V6YTBDHwWMze8zOHkwG9+HhxK/hiEiNEkMgiI5LLTZ2CsMhJtcBsNMDpZgHrPo7UdwAQum8ykr0DCkOJjGQmywcbRtOENaTIiMViwZQpU7B27VrxNrfbjbVr16KiokL1MTNnzsSRI0fgllQFHzp0CEVFRapChCAIIlqYjQYxVG0LUNfGqVXJ2RNEIKSpEGmahouRrBSLKCgCRUY+2l0DABielyq7PRQx8n9rDwe36AEg5DTNkiVL8MILL+Dvf/879u/fj7vuugudnZ1id82NN96IpUuXitvfddddaGpqwt13341Dhw7ho48+wmOPPYZFixaFby8IgiDCgMFggMXTUWN39p6mIcMzIlQMktiIVCo0e8RIdrJF9GwJVDPy9YkmAMA3JhbJbjcZghMj72w/5eNjEs3pNCG39l577bU4e/YsHnzwQdTW1mLy5Mn4+OOPxaLWqqoqGCVFYCUlJVi9ejV+8pOfYOLEiRg0aBDuvvtu3HvvveHbC4IgiDBhMRthc7p7FSMuNxOLDgspMkIEiywyIvzf43Ch0y5E4rJTpZER/99B3sl1Xlm27HZpZKSp046MpARZnQpnyZs7fW5LT0zwuW2g6NPM58WLF2Px4sWq961bt87ntoqKCmzatKkvL0UQBDGgWM1GtAOw91LA2thhg8vNYDQAuamUciaCQ5am8cQimruEqIjZaECa1QyzJzrnL7Lhljj/5imcfw0GA4wGobX34ic+x48uHoGfXjZatk23XT0FOSQnWfX2gYBm0xAEQUgINk3D60VyU63iwYMgekPe2iv8z1tss1IsMBgMvdaMtHY74PCkcHJVnH+l0ZE/f3rE537eBaYkZgpYCYIg4h0+n6M3MVLnGWxG9SJEKKilTHhkJDtZiLDxmpGfvFEpDsOTwr+jWckJsg4wTm9uwA1+ZtAEO+k3EpAYIQiCkMDPOL8+0RxwO168mp9GYoQIHrXICO+kyU4RxAgXEwdq2/HYqv0+z8En/CpTNBxTL+5lSjFS7BHUFBkhCILQCPystLcptPViWy95IhHBo1YzohQj0u8en1Mj5WyHdyaSGr1GRtq9YuR3356gGq0ZaEiMEARBSPjWZGGieG/ulbyThjxGiFCQtfZ6vmLNoseI0M0iHVgndVflnPV89/L8TIruTYycahZqRm6dORTfm1bqXU9vi48gJEYIgiAkpFgFt+gumzPgdnUUGSH6gDwyItCkqBk5K0mjqH2/RDHiJzIiFRXJFvlgxk6bEztPtQCQD+UDeh+sF0n61NpLEAQRryRbhJ/FU346Dji8gDWfIiNEH+EHf2Wapr0nsBDmYsRfvVJLl3cab4pVfpif//QXqPIUxfLX4wKJIiMEQRAagUc83tl+OuB2vLWXDM+IUFCNjEis4JWo2d3U9xIZkaIc+Fgl6c7JSpaLkWhCkRGCIAgJnx2s73WbHodLPIAUZ9CQPCJ41GtGhEhGToogLkqzk0XRoDYsr7c0jRRpi7rNKTc7Gz8oAwDw2U9ni2Zp0YIiIwRBEBKG5KT0uk1NqxAVSUowIT2JzumI4JFFIbjpmaKA9aWbp4qbqLmwnvXjvqqGNDLCRQ8nh3fvmIwwGQ1R7aohMUIQBCHhwW+M7XWbWo8YKcpI1ERbJBE7yLUIA2PMa3rmEQcj8tPw8IJxAHy7umxOl1gTkh+UGGFwewRNY6fcX8QYzVCIAhIjBEEQEgo9aRerirMlx9tJQ/UiRGhIxStjQFuPU4x+8BoOwNue61ZERho81vEJJgMyktQH2+188DL8ZO4o8Tqfs6SMjGgJEiMEQRASEjwHAWXhnxSxeJWs4IkQUWZpuMdIisWExARvGy6PWijTNFKPEX9RuYzkBPzwomHidf5dVkZGtASJEYIgCAkJnqF3buZ/aipP05AYIUJF1k3DmKReRN5Jw43PlF/BYItXLZLhjbyIlQsfANi09JLQFh5hSIwQBEFISJCkZ/xFR8Q0TRA5e4KQIkvTwCsQshVixCSKET+RkV6+e0ajAQkm4Tl4moZ3gH1/RqnmhDSJEYIgCAn8BxwAbH4m91KahggHjEncV5WRET9pmvp2Ppem9+8ej47wyIj3tbQnokmMEARBSEgwen8Wnf4iI61UwEr0Ha/jKfO6ryYrIiOer2FfIyOAN8rnUERGspPVC1+jCYkRgiAICUaj1/zJqVIz4nYz0QGTIiNEXxBjbwxiW29msnrNiN8C1iDECI+M8Ahfo6cTJ9vPgL1oQmKEIAhCAS9iVasZaey0w+lmMBiAXA3+qBPaxyApTm3xtNtmKaIVJn/dNB2BJ/ZKsZjlaZrmLvUojBYgMUIQBKHAK0Z8IyO8eDU31SpuRxChYJSkacTISJAFrPVtoUdGxJoRP8WyWoD+kgiCIBSYPUWsajUjXsMziooQfYPPp2EMaOlWj4wYVFp7GWNiZCQY91WL2Suq3W6GZo9zK4kRgiCIGCBwZEQ4GBQE0c1AEKqIkRGgxRMZyfIpYPVN07T1OMUoR1CREZ6mcbnQ1uPwOr2mUAErQRCE5uEurE63b2SEt1bmUycN0Ud4Aaswl0aIVmT61IwI/0vTNLx4NS3RLHNr9Yc0TcNTNGlWM6zm3h870JAYIQiCUGAOUMDKIyPBhMkJQg2xtZcBraIY8efA6itGgomKAN4In00iRpROr1qBxAhBEIQCbnymlqY5204eI0T/4DUjPQ6X6I6qHHrnbe313iYangXZxSWtGWnUcPEqQGKEIAjCB35G6QxUM0IFrEQf4ZGRdptTvC1ZkXbhNSNMJTISbIpQ2trrz3ZeK5ijvQCCIAitwbtpOiQHC463m4YiI0Tf4DUj7T3C9yvVahbt38VtPFelBayheIwAUjHiQqfdBUC7YoQiIwRBEAp4GP3OV7fBLTkYuNwMDSG0VhKEGrxtt71HqBdJsfoWlHKfEVc/akbEAlaX9iMjJEYIgiAUNElGrbd6fCAAoLHDBjcTTKtyyH2V6CM8BcO/WylW3ySFN03jva2vYsThYpo2PANIjBAEQQSkx+kSL/OZNLmpVvFgQRChwtMnLZ5OmlQVMWJQmU0j1owEK0bMkm4aP9OBtQKJEYIgCAV2SQtDp80rRqhehAgHPGLBoxUpFv+RkXC09kp9RrQ4lwYgMUIQBOGD1Ab+6me+FC/Xh3hmShBq8NZxPpcmNdFXjPDAG69Zcri80Y2g0zRmr1+Od2IviRGCIIiYQNrSyzseAO+Qsnxq6yX6AY9YBErTGBUFrI0ddjAmREyU1vH+kLX2anhiL0BihCAIwge7wnm1xyGkauq4FTzNpSH6QYIiTRNIjPCSEZ6iyUmxBF2vZPWIkbYeB7p4a69GIyPkM0IQBKHA6ZabnbX1OLBmXx1e21wFgCIjRP9I8IiEyuoWAMKsGSVizYjnu9jY6REjIXRx8XRQbWuPeD1NRfhoAYqMEARBKHApxEhTpx0/en2HeJ0iI0R/sJjkkY1ki4rPiGJQHm8DzkgKXkzwQlle65SZbBG7dLQGiRGCIIheON3cLbtOVvBEf5DWIQHAicYun22Urb1tHjGSmRR8msXimc7LIyNarRcBSIwQBEH48MzCc2XXT7fIxYhWvRqI2OBAbbvs+o0VQ3y24Q6svLOXF7sqB+oFgju7dntqnjKTg3/sQENihCAIQsEVE4pk19cfapBdTw/hgEAQgfjeeSWYODjT53ZlNw1P04QiKJS1KCRGCIIgYow/XjNRvPzf/XWy+1JVTKoIoi8UZyap3m70HJ15moaLkVCEcKpVvm0oKZ6BhsQIQRCECt+ZWqIaPgfgM2GVIEJh9T0Xipd527gS5Wyalu7Q0zTKwtgMiowQBEHEHmr+DwTRX0YXpolttzOG5ahuE440TZJCjARrlhYN6C+NIAjCD1azb8slQYSDz342G4fq2jFrZK7q/V7TM3k3TX8iI1oeY0BihCAIwg/WBAoeE5FhcFYyBmcl+72fZwIZE7q5eAdOKJ1cyQnyQ3yuhsUI/aURBEH4gdtpE8RAI7V8/8fGk+Ll0mz/AkaJMk1TkqVeLKsF6C+NIAjCD5SmIaKF1CmV14sAQFpi8Gkai0JMD81N6f/CIkSfxMjy5ctRVlaGxMRETJ8+HVu2bAnqcStXroTBYMBVV13Vl5clCIIYUNQiI/fNHxOFlRB6QxoZaegQ7Nx/deXYfj2fVq3ggT6IkTfeeANLlizBQw89hO3bt2PSpEmYN28e6uvrAz7uxIkT+NnPfoZZs2b1ebEEQRADibJm5MeXjMQds4ZFaTWEnjBJhEN9m2DnntePmo9cjU7r5YQsRp588kncfvvtuOWWWzBu3Dg899xzSE5OxksvveT3MS6XCwsXLsQjjzyCYcPoD5kgiNhAmaYZV5ROHiPEgCANYrT0wfBMSU6KdotXgRDFiN1ux7Zt2zB37lzvExiNmDt3LjZu3Oj3cb/+9a+Rn5+PH/zgB0G9js1mQ1tbm+wfQRDEQKNM01jMJESIgUGapuGD9VL64fybE0+RkYaGBrhcLhQUFMhuLygoQG1trepjNmzYgBdffBEvvPBC0K+zbNkyZGRkiP9KSkpCWSZBEERYUIqRUIoHCaI/GCWhkaZOOwBf35Bg4N03V5cPCs/CIkREu2na29txww034IUXXkBurrqxixpLly5Fa2ur+K+6ujqCqyQIglBHenZ66bgCTCnNiuJqCD2hlg1M6YMj8Js/rMALN07VvBgJac9yc3NhMplQVycfGlVXV4fCwkKf7Y8ePYoTJ05gwYIF4m1ut1t4YbMZBw8exPDhw30eZ7VaYbVqO79FEET802X3zg15duG5VC9CDBhqnS8pfYiMFGYkojAjMRxLiighRUYsFgumTJmCtWvXire53W6sXbsWFRUVPtuPGTMGu3fvRmVlpfjvm9/8JubMmYPKykpKvxAEoWkmlWTCYACG5CTDbCJbJiK6JMfxrKSQ92zJkiW46aabMHXqVEybNg1PPfUUOjs7ccsttwAAbrzxRgwaNAjLli1DYmIixo8fL3t8ZmYmAPjcThAEoTUykhJQ+eBlSCRbeEIDJCfErwlfyGLk2muvxdmzZ/Hggw+itrYWkydPxscffywWtVZVVcFopD9cgiDig1AGkxFEJInnNKGBMc9IQA3T1taGjIwMtLa2Ij09PdrLIQiCIIiIU3bfR7LrJ353ZZRW0neCPX5TCIMgCIIgiKhCYoQgCIIgiKhCYoQgCIIgiKhCYoQgCIIgNMiEQRnRXsKAQWKEIAiCIDTIizdPxZAcwc79nOL4bt6IXwcVgiAIgohh8tMS8dGPZ+G9HafxzcnF0V5ORCExQhAEQRAaJdVqxvdnDIn2MiIOpWkIgiAIgogqJEYIgiAIgogqJEYIgiAIgogqJEYIgiAIgogqJEYIgiAIgogqJEYIgiAIgogqJEYIgiAIgogqJEYIgiAIgogqJEYIgiAIgogqJEYIgiAIgogqJEYIgiAIgogqJEYIgiAIgogqJEYIgiAIgogqMTG1lzEGAGhra4vySgiCIAiCCBZ+3ObHcX/EhBhpb28HAJSUlER5JQRBEARBhEp7ezsyMjL83m9gvckVDeB2u3HmzBmkpaXBYDCE7Xnb2tpQUlKC6upqpKenh+15tUS87yPtX+wT7/tI+xf7xPs+RnL/GGNob29HcXExjEb/lSExERkxGo0YPHhwxJ4/PT09Lr9gUuJ9H2n/Yp9430fav9gn3vcxUvsXKCLCoQJWgiAIgiCiCokRgiAIgiCiiq7FiNVqxUMPPQSr1RrtpUSMeN9H2r/YJ973kfYv9on3fdTC/sVEAStBEARBEPGLriMjBEEQBEFEHxIjBEEQBEFEFRIjBEEQBEFEFRIjBEEQBEFEFV2LkeXLl6OsrAyJiYmYPn06tmzZEu0lqbJ+/XosWLAAxcXFMBgMeO+992T3M8bw4IMPoqioCElJSZg7dy4OHz4s26apqQkLFy5Eeno6MjMz8YMf/AAdHR2ybXbt2oVZs2YhMTERJSUl+MMf/hDpXQMALFu2DOeddx7S0tKQn5+Pq666CgcPHpRt09PTg0WLFiEnJwepqan4n//5H9TV1cm2qaqqwpVXXonk5GTk5+fj5z//OZxOp2ybdevW4dxzz4XVasWIESOwYsWKSO8enn32WUycOFE0FKqoqMB//vOfuNg3NX73u9/BYDDgnnvuEW+L9X18+OGHYTAYZP/GjBkj3h/r+wcAp0+fxve//33k5OQgKSkJEyZMwNatW8X7Y/l3pqyszOfzMxgMWLRoEYD4+PxcLhceeOABDB06FElJSRg+fDh+85vfyGbCaPozZDpl5cqVzGKxsJdeeont3buX3X777SwzM5PV1dVFe2k+rFq1it1///3snXfeYQDYu+++K7v/d7/7HcvIyGDvvfce27lzJ/vmN7/Jhg4dyrq7u8VtLr/8cjZp0iS2adMm9sUXX7ARI0aw6667Try/tbWVFRQUsIULF7I9e/aw119/nSUlJbG//vWvEd+/efPmsZdffpnt2bOHVVZWsiuuuIKVlpayjo4OcZs777yTlZSUsLVr17KtW7eyGTNmsPPPP1+83+l0svHjx7O5c+eyHTt2sFWrVrHc3Fy2dOlScZtjx46x5ORktmTJErZv3z725z//mZlMJvbxxx9HdP/+/e9/s48++ogdOnSIHTx4kP3yl79kCQkJbM+ePTG/b0q2bNnCysrK2MSJE9ndd98t3h7r+/jQQw+xc845h9XU1Ij/zp49Gzf719TUxIYMGcJuvvlmtnnzZnbs2DG2evVqduTIEXGbWP6dqa+vl312a9asYQDYZ599xhiL/c+PMcYeffRRlpOTwz788EN2/Phx9tZbb7HU1FT29NNPi9to+TPUrRiZNm0aW7RokXjd5XKx4uJitmzZsiiuqneUYsTtdrPCwkL2xz/+UbytpaWFWa1W9vrrrzPGGNu3bx8DwL7++mtxm//85z/MYDCw06dPM8YYe+aZZ1hWVhaz2WziNvfeey8bPXp0hPfIl/r6egaAff7554wxYX8SEhLYW2+9JW6zf/9+BoBt3LiRMSYINqPRyGpra8Vtnn32WZaeni7u0y9+8Qt2zjnnyF7r2muvZfPmzYv0LvmQlZXF/va3v8XVvrW3t7ORI0eyNWvWsIsuukgUI/Gwjw899BCbNGmS6n3xsH/33nsvu+CCC/zeH2+/M3fffTcbPnw4c7vdcfH5McbYlVdeyW699VbZbd/+9rfZwoULGWPa/wx1maax2+3Ytm0b5s6dK95mNBoxd+5cbNy4MYorC53jx4+jtrZWti8ZGRmYPn26uC8bN25EZmYmpk6dKm4zd+5cGI1GbN68WdzmwgsvhMViEbeZN28eDh48iObm5gHaG4HW1lYAQHZ2NgBg27ZtcDgcsn0cM2YMSktLZfs4YcIEFBQUiNvMmzcPbW1t2Lt3r7iN9Dn4NgP5mbtcLqxcuRKdnZ2oqKiIq31btGgRrrzySp91xMs+Hj58GMXFxRg2bBgWLlyIqqoqAPGxf//+978xdepUfOc730F+fj7Ky8vxwgsviPfH0++M3W7Hq6++iltvvRUGgyEuPj8AOP/887F27VocOnQIALBz505s2LAB8+fPB6D9z1CXYqShoQEul0v2xQKAgoIC1NbWRmlVfYOvN9C+1NbWIj8/X3a/2WxGdna2bBu155C+xkDgdrtxzz33YObMmRg/frz4+haLBZmZmT7rC2X9/rZpa2tDd3d3JHZHZPfu3UhNTYXVasWdd96Jd999F+PGjYuLfQOAlStXYvv27Vi2bJnPffGwj9OnT8eKFSvw8ccf49lnn8Xx48cxa9YstLe3x8X+HTt2DM8++yxGjhyJ1atX46677sKPf/xj/P3vf5etMR5+Z9577z20tLTg5ptvFl831j8/ALjvvvvwve99D2PGjEFCQgLKy8txzz33YOHChbJ1avUzjImpvYR+WLRoEfbs2YMNGzZEeylhZfTo0aisrERrayvefvtt3HTTTfj888+jvaywUF1djbvvvhtr1qxBYmJitJcTEfjZJQBMnDgR06dPx5AhQ/Dmm28iKSkpiisLD263G1OnTsVjjz0GACgvL8eePXvw3HPP4aabbory6sLLiy++iPnz56O4uDjaSwkrb775Jv75z3/itddewznnnIPKykrcc889KC4ujonPUJeRkdzcXJhMJp9q6bq6OhQWFkZpVX2DrzfQvhQWFqK+vl52v9PpRFNTk2wbteeQvkakWbx4MT788EN89tlnGDx4sHh7YWEh7HY7WlpafNYXyvr9bZOenh7xA4rFYsGIESMwZcoULFu2DJMmTcLTTz8dF/u2bds21NfX49xzz4XZbIbZbMbnn3+O//u//4PZbEZBQUHM76OSzMxMjBo1CkeOHImLz7CoqAjjxo2T3TZ27FgxFRUvvzMnT57Ef//7X9x2223ibfHw+QHAz3/+czE6MmHCBNxwww34yU9+IkYrtf4Z6lKMWCwWTJkyBWvXrhVvc7vdWLt2LSoqKqK4stAZOnQoCgsLZfvS1taGzZs3i/tSUVGBlpYWbNu2Tdzm008/hdvtxvTp08Vt1q9fD4fDIW6zZs0ajB49GllZWRHdB8YYFi9ejHfffReffvophg4dKrt/ypQpSEhIkO3jwYMHUVVVJdvH3bt3y/6Q1qxZg/T0dPFHtqKiQvYcfJtofOZutxs2my0u9u2SSy7B7t27UVlZKf6bOnUqFi5cKF6O9X1U0tHRgaNHj6KoqCguPsOZM2f6tNMfOnQIQ4YMARAfvzMA8PLLLyM/Px9XXnmleFs8fH4A0NXVBaNRfkg3mUxwu90AYuAz7Ff5awyzcuVKZrVa2YoVK9i+ffvYHXfcwTIzM2XV0lqhvb2d7dixg+3YsYMBYE8++STbsWMHO3nyJGNMaNfKzMxk77//Ptu1axf71re+pdquVV5ezjZv3sw2bNjARo4cKWvXamlpYQUFBeyGG25ge/bsYStXrmTJyckD0tp71113sYyMDLZu3TpZ+11XV5e4zZ133slKS0vZp59+yrZu3coqKipYRUWFeD9vvbvssstYZWUl+/jjj1leXp5q693Pf/5ztn//frZ8+fIBab2777772Oeff86OHz/Odu3axe677z5mMBjYJ598EvP75g9pNw1jsb+PP/3pT9m6devY8ePH2Zdffsnmzp3LcnNzWX19fVzs35YtW5jZbGaPPvooO3z4MPvnP//JkpOT2auvvipuE+u/My6Xi5WWlrJ7773X575Y//wYY+ymm25igwYNElt733nnHZabm8t+8YtfiNto+TPUrRhhjLE///nPrLS0lFksFjZt2jS2adOmaC9Jlc8++4wB8Pl30003McaElq0HHniAFRQUMKvVyi655BJ28OBB2XM0Njay6667jqWmprL09HR2yy23sPb2dtk2O3fuZBdccAGzWq1s0KBB7He/+92A7J/avgFgL7/8srhNd3c3+9///V+WlZXFkpOT2dVXX81qampkz3PixAk2f/58lpSUxHJzc9lPf/pT5nA4ZNt89tlnbPLkycxisbBhw4bJXiNS3HrrrWzIkCHMYrGwvLw8dskll4hCJNb3zR9KMRLr+3jttdeyoqIiZrFY2KBBg9i1114r8+CI9f1jjLEPPviAjR8/nlmtVjZmzBj2/PPPy+6P9d+Z1atXMwA+a2YsPj6/trY2dvfdd7PS0lKWmJjIhg0bxu6//35ZC66WP0MDYxJ7NoIgCIIgiAFGlzUjBEEQBEFoBxIjBEEQBEFEFRIjBEEQBEFEFRIjBEEQBEFEFRIjBEEQBEFEFRIjBEEQBEFEFRIjBEEQBEFEFRIjBEEQBEFEFRIjBEEQBEFEFRIjBEEQBEFEFRIjBEEQBEFEFRIjBEEQBEFElf8HKWVCSBhcOrUAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import scipy.io\n",
    "y1 = scipy.signal.resample(data['joined_data'][0][16][:,16], 8000)\n",
    "plt.plot(y1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "81e9e46f-88cc-4ba9-a64f-347034bea365",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2024-01-23T13:00:37.787618Z",
     "iopub.status.busy": "2024-01-23T13:00:37.786456Z",
     "iopub.status.idle": "2024-01-23T13:00:37.799733Z",
     "shell.execute_reply": "2024-01-23T13:00:37.798639Z",
     "shell.execute_reply.started": "2024-01-23T13:00:37.787570Z"
    },
    "id": "81e9e46f-88cc-4ba9-a64f-347034bea365",
    "outputId": "bcb347b1-3a4c-4281-e78d-5555e64d6a27"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['AMIGOS/Data_Preprocessed_P33.mat', 'AMIGOS/Data_Preprocessed_P30.mat', 'AMIGOS/Data_Preprocessed_P13.mat', 'AMIGOS/Data_Preprocessed_P26.mat', 'AMIGOS/Data_Preprocessed_P37.mat', 'AMIGOS/Data_Preprocessed_P31.mat', 'AMIGOS/Data_Preprocessed_P10.mat', 'AMIGOS/Data_Preprocessed_P09.mat', 'AMIGOS/Data_Preprocessed_P05.mat', 'AMIGOS/Data_Preprocessed_P40.mat', 'AMIGOS/Data_Preprocessed_P35.mat', 'AMIGOS/Data_Preprocessed_P32.mat', 'AMIGOS/Data_Preprocessed_P22.mat', 'AMIGOS/Data_Preprocessed_P23.mat', 'AMIGOS/Data_Preprocessed_P17.mat', 'AMIGOS/Data_Preprocessed_P04.mat', 'AMIGOS/Data_Preprocessed_P12.mat', 'AMIGOS/Data_Preprocessed_P34.mat', 'AMIGOS/Data_Preprocessed_P29.mat', 'AMIGOS/Data_Preprocessed_P15.mat', 'AMIGOS/Data_Preprocessed_P02.mat', 'AMIGOS/Data_Preprocessed_P25.mat', 'AMIGOS/Data_Preprocessed_P18.mat', 'AMIGOS/Data_Preprocessed_P36.mat', 'AMIGOS/Data_Preprocessed_P16.mat', 'AMIGOS/Data_Preprocessed_P28.mat', 'AMIGOS/Data_Preprocessed_P03.mat', 'AMIGOS/Data_Preprocessed_P38.mat', 'AMIGOS/Data_Preprocessed_P39.mat', 'AMIGOS/Data_Preprocessed_P27.mat', 'AMIGOS/Data_Preprocessed_P01.mat', 'AMIGOS/Data_Preprocessed_P19.mat', 'AMIGOS/Data_Preprocessed_P06.mat', 'AMIGOS/Data_Preprocessed_P24.mat', 'AMIGOS/Data_Preprocessed_P11.mat', 'AMIGOS/Data_Preprocessed_P08.mat', 'AMIGOS/Data_Preprocessed_P21.mat', 'AMIGOS/Data_Preprocessed_P07.mat', 'AMIGOS/Data_Preprocessed_P14.mat', 'AMIGOS/Data_Preprocessed_P20.mat']\n",
      "['P33', 'P30', 'P13', 'P26', 'P37', 'P31', 'P10', 'P09', 'P05', 'P40', 'P35', 'P32', 'P22', 'P23', 'P17', 'P04', 'P12', 'P34', 'P29', 'P15', 'P02', 'P25', 'P18', 'P36', 'P16', 'P28', 'P03', 'P38', 'P39', 'P27', 'P01', 'P19', 'P06', 'P24', 'P11', 'P08', 'P21', 'P07', 'P14', 'P20']\n"
     ]
    }
   ],
   "source": [
    "import glob\n",
    "import os\n",
    "filelist = glob.glob('AMIGOS/*.mat')\n",
    "print(filelist)\n",
    "subjectnames = [fr[25:28] for fr in filelist]\n",
    "print(subjectnames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "74fe1cd7-c31d-44dd-8537-27f357d17096",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2024-01-23T13:00:43.548469Z",
     "iopub.status.busy": "2024-01-23T13:00:43.547543Z",
     "iopub.status.idle": "2024-01-23T13:01:17.995513Z",
     "shell.execute_reply": "2024-01-23T13:01:17.994188Z",
     "shell.execute_reply.started": "2024-01-23T13:00:43.548413Z"
    },
    "id": "74fe1cd7-c31d-44dd-8537-27f357d17096",
    "outputId": "b02ad912-56e9-45b3-dd39-d9d46bc0a2d4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "P33\n",
      "P30\n",
      "P13\n",
      "P26\n",
      "P37\n",
      "P31\n",
      "P10\n",
      "P09\n",
      "P05\n",
      "P40\n",
      "P35\n",
      "P22\n",
      "P23\n",
      "P17\n",
      "P04\n",
      "P12\n",
      "P34\n",
      "P29\n",
      "P15\n",
      "P02\n",
      "P25\n",
      "P18\n",
      "P36\n",
      "P16\n",
      "P03\n",
      "P38\n",
      "P39\n",
      "P27\n",
      "P01\n",
      "P19\n",
      "P06\n",
      "P11\n",
      "P21\n",
      "P07\n",
      "P14\n",
      "P20\n",
      "dict_keys(['P33', 'P30', 'P13', 'P26', 'P37', 'P31', 'P10', 'P09', 'P05', 'P40', 'P35', 'P22', 'P23', 'P17', 'P04', 'P12', 'P34', 'P29', 'P15', 'P02', 'P25', 'P18', 'P36', 'P16', 'P03', 'P38', 'P39', 'P27', 'P01', 'P19', 'P06', 'P11', 'P21', 'P07', 'P14', 'P20'])\n"
     ]
    }
   ],
   "source": [
    "import scipy.io\n",
    "import numpy as np\n",
    "data_am = {}\n",
    "skiplist = ['P28','P08','P24','P32']\n",
    "newsubjectname = []\n",
    "for sname in subjectnames:\n",
    "    if sname in skiplist:\n",
    "      continue\n",
    "    newsubjectname.append(sname)\n",
    "    dname = \"AMIGOS/Data_Preprocessed_\"+sname+\".mat\"\n",
    "    x = scipy.io.loadmat(dname)\n",
    "    print(sname)\n",
    "    samples = []\n",
    "    samples_labels = []\n",
    "    for i in range(x['joined_data'].shape[1]):\n",
    "        x1 = x['joined_data'][0][i]\n",
    "        x2 = scipy.signal.resample(x1[384:,16], 8064)\n",
    "        y1 = x['labels_selfassessment'][0][i][0][0:2]\n",
    "        samples.append(x2)\n",
    "        samples_labels.append(y1)\n",
    "    samples_stack = np.vstack(samples)\n",
    "    samples_labels_stack = np.vstack(samples_labels)\n",
    "    data_am[sname] = [samples_stack,samples_labels_stack]\n",
    "\n",
    "print(data_am.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "qnHCy6Wra5Fu",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "qnHCy6Wra5Fu",
    "outputId": "9d1b17db-cde0-45d9-96ac-fdac666f660f"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([3237180.31474926, 3110649.65303398, 3179062.7496687 , ...,\n",
       "       3514282.08715568, 3478618.13315719, 3540966.49534216])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_am['P01'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8976cde3-bc3f-4fcb-a8af-d624fcde1675",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2024-01-23T13:01:33.483964Z",
     "iopub.status.busy": "2024-01-23T13:01:33.482898Z",
     "iopub.status.idle": "2024-01-23T13:01:34.325503Z",
     "shell.execute_reply": "2024-01-23T13:01:34.324296Z",
     "shell.execute_reply.started": "2024-01-23T13:01:33.483923Z"
    },
    "id": "8976cde3-bc3f-4fcb-a8af-d624fcde1675",
    "outputId": "35ec17fd-7d92-4bb3-a961-3339979bfbc7"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "data_cam = {}\n",
    "for k,v in data_am.items():\n",
    "    y = v[0]\n",
    "    ym = np.mean(y,axis=-1).reshape(20,1)\n",
    "    ystd = np.std(y,axis=-1).reshape(20,1)\n",
    "    z = (y-ym)/ystd\n",
    "    #print(z.shape)\n",
    "    data_cam[k] = [z,v[1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "kgzh85M-Zyyx",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 448
    },
    "execution": {
     "iopub.execute_input": "2024-01-23T13:01:38.579913Z",
     "iopub.status.busy": "2024-01-23T13:01:38.578770Z",
     "iopub.status.idle": "2024-01-23T13:01:38.847211Z",
     "shell.execute_reply": "2024-01-23T13:01:38.846440Z",
     "shell.execute_reply.started": "2024-01-23T13:01:38.579876Z"
    },
    "id": "kgzh85M-Zyyx",
    "outputId": "10010e12-e6d0-4189-ccc0-b9350a6cf1af"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7fd0d9568580>]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(data_cam['P01'][0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "56JG3ogz-LUE",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2024-01-23T13:01:52.199557Z",
     "iopub.status.busy": "2024-01-23T13:01:52.199201Z",
     "iopub.status.idle": "2024-01-23T13:01:53.264313Z",
     "shell.execute_reply": "2024-01-23T13:01:53.262968Z",
     "shell.execute_reply.started": "2024-01-23T13:01:52.199529Z"
    },
    "id": "56JG3ogz-LUE",
    "outputId": "d239a446-2b69-4f9c-f45e-c880f8c64511"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 8064])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "data_c1d = {}\n",
    "BLOCK_SIZE=640\n",
    "BLOCK_STRIDE=60\n",
    "for k,v in data_cam.items():\n",
    "    datablocki = []\n",
    "    v1 = v[0]\n",
    "    v1 = v1[:,np.newaxis,:]\n",
    "    #print(v1.shape)\n",
    "    data_c1d[k] = torch.tensor(v1)\n",
    "print(data_c1d['P01'][0].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ce1ed7be-a882-45ec-810d-6b1c43af0af3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-22T10:04:28.619802Z",
     "iopub.status.busy": "2024-01-22T10:04:28.618700Z",
     "iopub.status.idle": "2024-01-22T10:04:28.688356Z",
     "shell.execute_reply": "2024-01-22T10:04:28.687618Z",
     "shell.execute_reply.started": "2024-01-22T10:04:28.619762Z"
    },
    "id": "ce1ed7be-a882-45ec-810d-6b1c43af0af3"
   },
   "outputs": [],
   "source": [
    "data_c2 = {}\n",
    "for k,v in data_cam.items():\n",
    "    y = v[1]\n",
    "    x_label = np.zeros((y.shape[0]),dtype='float64')\n",
    "    for i in range(y.shape[0]):\n",
    "        if (y[i][0] > 5):\n",
    "            x_label[i] = 1\n",
    "        else:\n",
    "            x_label[i] = 0\n",
    "\n",
    "    x_l = x_label\n",
    "    x_l = x_l.reshape(-1,1)\n",
    "    x_l = torch.tensor(x_l)\n",
    "    data_c2[k] = x_l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "fa943a48-8252-4c85-ab48-4e6cb0c101a4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-21T20:26:35.503245Z",
     "iopub.status.busy": "2024-01-21T20:26:35.502318Z",
     "iopub.status.idle": "2024-01-21T20:26:35.509003Z",
     "shell.execute_reply": "2024-01-21T20:26:35.508226Z",
     "shell.execute_reply.started": "2024-01-21T20:26:35.503218Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1.],\n",
       "        [1.],\n",
       "        [0.],\n",
       "        [1.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [0.],\n",
       "        [1.],\n",
       "        [0.],\n",
       "        [1.]], dtype=torch.float64)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_c2['P02']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "Pm5zhOqDgK79",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-23T13:02:28.217100Z",
     "iopub.status.busy": "2024-01-23T13:02:28.216629Z",
     "iopub.status.idle": "2024-01-23T13:02:28.233420Z",
     "shell.execute_reply": "2024-01-23T13:02:28.232648Z",
     "shell.execute_reply.started": "2024-01-23T13:02:28.217074Z"
    },
    "id": "Pm5zhOqDgK79"
   },
   "outputs": [],
   "source": [
    "data_c2 = {}\n",
    "maxnum = 3\n",
    "for k,v in data_cam.items():\n",
    "    y = v[1]\n",
    "    x_label = np.zeros((y.shape[0]),dtype='int32')\n",
    "    for i in range(y.shape[0]):\n",
    "        if (y[i][1] > 5 and y[i][0] > 5):\n",
    "            x_label[i] = 3\n",
    "        elif (y[i][1] <= 5 and y[i][0] > 5):\n",
    "            x_label[i] = 2\n",
    "        elif (y[i][1] > 5 and y[i][0] <= 5):\n",
    "            x_label[i] = 1\n",
    "        elif (y[i][1] <= 5 and y[i][0] <= 5):\n",
    "            x_label[i] = 0\n",
    "\n",
    "    x_l = np.zeros((x_label.size, maxnum+1))\n",
    "    x_l[np.arange(x_label.size), x_label] = 1\n",
    "\n",
    "    x_l = torch.tensor(x_l)\n",
    "    data_c2[k] = x_l\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "6d8e2d1b-cc85-483f-843a-8d7c4b9c5ec8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-22T10:14:03.574101Z",
     "iopub.status.busy": "2024-01-22T10:14:03.573139Z",
     "iopub.status.idle": "2024-01-22T10:14:03.578258Z",
     "shell.execute_reply": "2024-01-22T10:14:03.577561Z",
     "shell.execute_reply.started": "2024-01-22T10:14:03.574074Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([20, 4])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_c2['P01'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "48a74ab5-e71d-441a-b786-630c4abc3685",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-23T13:02:31.421764Z",
     "iopub.status.busy": "2024-01-23T13:02:31.421103Z",
     "iopub.status.idle": "2024-01-23T13:02:31.464022Z",
     "shell.execute_reply": "2024-01-23T13:02:31.462495Z",
     "shell.execute_reply.started": "2024-01-23T13:02:31.421733Z"
    },
    "id": "48a74ab5-e71d-441a-b786-630c4abc3685"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "#from torchinfo import Summary\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.c1=nn.Conv1d(1, 34, 10,stride=1)\n",
    "        self.mp1=nn.MaxPool1d(2)\n",
    "        self.norm1 = nn.BatchNorm1d(34)\n",
    "        self.d = nn.Dropout(p=0.63)\n",
    "        self.c2=nn.Conv1d(34, 30, 10,stride=1)\n",
    "        self.mp2=nn.MaxPool1d(2)\n",
    "        self.c3=nn.Conv1d(30, 10, 10,stride=1)\n",
    "        self.norm3 = nn.BatchNorm1d(10)\n",
    "        self.mp3=nn.MaxPool1d(2)\n",
    "        self.ft = nn.Flatten()\n",
    "\n",
    "        self.n1 = nn.Linear(20070,110)\n",
    "        #self.n1 = nn.Linear(19590,110)\n",
    "        self.normfc1=nn.BatchNorm1d(110)\n",
    "        self.d = nn.Dropout(p=0.63)\n",
    "        #self.d = nn.Dropout()\n",
    "        self.n2 = nn.Linear(110,100)\n",
    "        self.n3 = nn.Linear(100,4)\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.d(self.norm1(F.tanh(self.c1(x))))\n",
    "        #x=F.tanh(self.c1(x))\n",
    "        x = self.mp2(F.tanh(self.c2(x)))\n",
    "        #print(x.shape)\n",
    "        x = self.mp3(F.tanh(self.c3(x)))\n",
    "\n",
    "        #print(x.shape)\n",
    "        x = self.ft(x)\n",
    "        #print(x.shape)\n",
    "        x = F.tanh(self.n1(x))\n",
    "        x=self.normfc1(x)\n",
    "        #x=self.norm3(x)\n",
    "        x=self.d(x)\n",
    "\n",
    "        #x = F.softmax(self.n2(x),dim=-1)\n",
    "        x = F.tanh(self.n2(x))\n",
    "        #x = F.sigmoid(self.n3(x))\n",
    "\n",
    "        x = (self.n3(x))\n",
    "        #print(x.shape)\n",
    "        return x\n",
    "\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "#criterion = nn.BCELoss()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "624818a4-e9ca-4f32-9930-8ade33ca95df",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "execution": {
     "iopub.execute_input": "2024-01-21T20:39:25.503661Z",
     "iopub.status.busy": "2024-01-21T20:39:25.503127Z",
     "iopub.status.idle": "2024-01-21T20:39:41.152046Z",
     "shell.execute_reply": "2024-01-21T20:39:41.151535Z",
     "shell.execute_reply.started": "2024-01-21T20:39:25.503640Z"
    },
    "id": "624818a4-e9ca-4f32-9930-8ade33ca95df",
    "outputId": "7b50a269-a030-4ad0-b013-e506e2fb1233"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 0:\n",
      "  Train: index=[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23\n",
      " 24 25 26 27 28 29 30 31 32 33 34 35]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_203/3472248682.py:38: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1960: UserWarning: nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\n",
      "  warnings.warn(\"nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/60, Train Loss: 0.6609741449356079\n",
      "Epoch 2/60, Train Loss: 0.6968510746955872\n",
      "Epoch 3/60, Train Loss: 0.7063091397285461\n",
      "Epoch 4/60, Train Loss: 0.7129724025726318\n",
      "Epoch 5/60, Train Loss: 0.6755002737045288\n",
      "Epoch 6/60, Train Loss: 0.677463948726654\n",
      "Epoch 7/60, Train Loss: 0.7001715302467346\n",
      "Epoch 8/60, Train Loss: 0.641160249710083\n",
      "Epoch 9/60, Train Loss: 0.6524507403373718\n",
      "Epoch 10/60, Train Loss: 0.6981868147850037\n",
      "Epoch 11/60, Train Loss: 0.7125951051712036\n",
      "Epoch 12/60, Train Loss: 0.6761418581008911\n",
      "Epoch 13/60, Train Loss: 0.6650707125663757\n",
      "Epoch 14/60, Train Loss: 0.6498364806175232\n",
      "Epoch 15/60, Train Loss: 0.6750850081443787\n",
      "Epoch 16/60, Train Loss: 0.7362504005432129\n",
      "Epoch 17/60, Train Loss: 0.6782377362251282\n",
      "Epoch 18/60, Train Loss: 0.6005708575248718\n",
      "Epoch 19/60, Train Loss: 0.6484631896018982\n",
      "Epoch 20/60, Train Loss: 0.6615355610847473\n",
      "Epoch 21/60, Train Loss: 0.7476146817207336\n",
      "Epoch 22/60, Train Loss: 0.6450007557868958\n",
      "Epoch 23/60, Train Loss: 0.6990272998809814\n",
      "Epoch 24/60, Train Loss: 0.6960132718086243\n",
      "Epoch 25/60, Train Loss: 0.6487043499946594\n",
      "Epoch 26/60, Train Loss: 0.6940182447433472\n",
      "Epoch 27/60, Train Loss: 0.7425288558006287\n",
      "Epoch 28/60, Train Loss: 0.7695755958557129\n",
      "Epoch 29/60, Train Loss: 0.6488133072853088\n",
      "Epoch 30/60, Train Loss: 0.6783266067504883\n",
      "Epoch 31/60, Train Loss: 0.6386670470237732\n",
      "Epoch 32/60, Train Loss: 0.6566615700721741\n",
      "Epoch 33/60, Train Loss: 0.6245983242988586\n",
      "Epoch 34/60, Train Loss: 0.6381314396858215\n",
      "Epoch 35/60, Train Loss: 0.6594816446304321\n",
      "Epoch 36/60, Train Loss: 0.6990213394165039\n",
      "Epoch 37/60, Train Loss: 0.7033595442771912\n",
      "Epoch 38/60, Train Loss: 0.72736656665802\n",
      "Epoch 39/60, Train Loss: 0.6317784190177917\n",
      "Epoch 40/60, Train Loss: 0.695755660533905\n",
      "Epoch 41/60, Train Loss: 0.5978154540061951\n",
      "Epoch 42/60, Train Loss: 0.7467979788780212\n",
      "Epoch 43/60, Train Loss: 0.6905636191368103\n",
      "Epoch 44/60, Train Loss: 0.6623584628105164\n",
      "Epoch 45/60, Train Loss: 0.6861650347709656\n",
      "Epoch 46/60, Train Loss: 0.6978986859321594\n",
      "Epoch 47/60, Train Loss: 0.69769287109375\n",
      "Epoch 48/60, Train Loss: 0.6886689066886902\n",
      "Epoch 49/60, Train Loss: 0.6211285591125488\n",
      "Epoch 50/60, Train Loss: 0.7211494445800781\n",
      "Epoch 51/60, Train Loss: 0.645512580871582\n",
      "Epoch 52/60, Train Loss: 0.6711452603340149\n",
      "Epoch 53/60, Train Loss: 0.6328474283218384\n",
      "Epoch 54/60, Train Loss: 0.6318807005882263\n",
      "Epoch 55/60, Train Loss: 0.6630229353904724\n",
      "Epoch 56/60, Train Loss: 0.7082170844078064\n",
      "Epoch 57/60, Train Loss: 0.6603700518608093\n",
      "Epoch 58/60, Train Loss: 0.6021323204040527\n",
      "Epoch 59/60, Train Loss: 0.6721572875976562\n",
      "Epoch 60/60, Train Loss: 0.6605284214019775\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import confusion_matrix,classification_report\n",
    "from sklearn import preprocessing\n",
    "import matplotlib.pyplot as plt\n",
    "#subjectnames\n",
    "file_list_num = np.arange(len(newsubjectname))\n",
    "kf = KFold(n_splits=12)\n",
    "torch.manual_seed(42)\n",
    "torch.cuda.manual_seed(42)\n",
    "modellist = []\n",
    "modelid = 1\n",
    "#file_list_num\n",
    "#for i, (train_index, test_index) in enumerate(kf.split(file_list_num)):\n",
    "#for train_index in file_list_num:\n",
    "train_index = file_list_num\n",
    "print(f\"Fold {i}:\")\n",
    "print(f\"  Train: index={train_index}\")\n",
    "#print(f\"  Test:  index={test_index}\")\n",
    "net = Net()\n",
    "net.to(device)\n",
    "optimizer = optim.Adam(net.parameters(), lr=0.000001)\n",
    "epochs = 60\n",
    "batch_sz = 20\n",
    "train_loss_epoch = []\n",
    "val_loss_epoch = []\n",
    "for epoch in range(epochs):\n",
    "  train_loss = []\n",
    "  for tr in train_index:\n",
    "    v = data_c1d[newsubjectname[tr]]\n",
    "    l = data_c2[newsubjectname[tr]]\n",
    "    #print(v[0].shape)\n",
    "    net.train()\n",
    "    for i in range(0,len(v),batch_sz):\n",
    "      #print(v[i].shape)\n",
    "      #for j in range(0,v[i].shape[0],batch_sz):\n",
    "      #print(newsubjectname[tr])\n",
    "      optimizer.zero_grad()\n",
    "      outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
    "      #print(\"Expout {}\",outputs.shape)\n",
    "      #print(\"Actual {}\",l[i:i+batch_sz].shape)\n",
    "      #print(l[i].shape)\n",
    "      loss = criterion(outputs, l[i:i+batch_sz].to(device, dtype=torch.float))\n",
    "      loss.backward()\n",
    "      train_loss.append(loss)\n",
    "      optimizer.step()\n",
    "  print(f'Epoch {epoch + 1}/{epochs}, Train Loss: {loss.item()}')\n",
    "  train_loss_epoch.append(torch.stack(train_loss).mean().cpu().detach().numpy())\n",
    "\n",
    "  '''\n",
    "  for tr in test_index:\n",
    "      net.eval()\n",
    "      v = data_c1d[newsubjectname[tr]]\n",
    "      l = data_c2[newsubjectname[tr]]\n",
    "      net.eval()\n",
    "      with torch.no_grad():\n",
    "          for i in range(0,len(v),batch_sz):\n",
    "            #print(v[i].shape)\n",
    "            #for j in range(0,v[i].shape[0],batch_sz):\n",
    "            optimizer.zero_grad()\n",
    "            outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
    "            #print(outputs.shape)\n",
    "            #print(l[i].shape)\n",
    "            #outputs1 = torch.softmax(outputs,dim=-1)\n",
    "            loss = criterion(outputs, l[i:i+batch_sz].to(device, dtype=torch.float))\n",
    "            val_loss.append(loss)\n",
    "            #loss.backward()\n",
    "            actualoutput.append(torch.round(outputs.cpu()))\n",
    "            expectedoutput.append(l[i:i+batch_sz])\n",
    "            #actualoutput.append(torch.argmax(torch.softmax(outputs.cpu(),dim=1),dim=1))\n",
    "            #expectedoutput.append(torch.argmax(l[i:i+batch_sz],dim=1).numpy())\n",
    "  val_loss_mean = torch.stack(val_loss).mean().cpu().detach().numpy()\n",
    "  val_loss_epoch.append(val_loss_mean)\n",
    "  expectedoutput = np.concatenate( expectedoutput, axis=0 )\n",
    "  actualoutput = np.concatenate( actualoutput, axis=0 )\n",
    "  print(expectedoutput.shape)\n",
    "  print(actualoutput.shape)\n",
    "  print(classification_report(expectedoutput,actualoutput))\n",
    "  print(confusion_matrix(expectedoutput,actualoutput))\n",
    "  print(f'Validation Loss for {subjectnames[tr]} = {val_loss_mean}')\n",
    "  #break\n",
    "  '''\n",
    "#plt.figure(figsize=(10,7))\n",
    "#print(len(train_loss_epoch))\n",
    "#plt.plot(np.arange(epochs),train_loss_epoch,label='Train')\n",
    "#plt.plot(np.arange(epochs),val_loss_epoch,label='Validation')\n",
    "#plt.legend()\n",
    "#path = \"Model\"+str(modelid) +\".pt\"\n",
    "#path = \"ModelAMIGOS_Aro.pt\"\n",
    "#modelid = modelid+1\n",
    "#print(path)\n",
    "#torch.save(net.state_dict(), path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "5P36UViqRcul",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5P36UViqRcul",
    "outputId": "e071c001-0c26-4c44-ee20-9a315b022829"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-27-7929d1561c85>:33: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs_val = netValence(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "<ipython-input-27-7929d1561c85>:35: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs_aro = netArousal(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.39      0.22      0.28        41\n",
      "           2       0.56      0.12      0.20        42\n",
      "           3       0.24      0.52      0.33        27\n",
      "           4       0.36      0.50      0.42        50\n",
      "\n",
      "    accuracy                           0.33       160\n",
      "   macro avg       0.39      0.34      0.31       160\n",
      "weighted avg       0.40      0.33      0.31       160\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-27-7929d1561c85>:33: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs_val = netValence(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "<ipython-input-27-7929d1561c85>:35: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs_aro = netArousal(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.50      0.17      0.25        42\n",
      "           2       1.00      0.10      0.18        30\n",
      "           3       0.34      0.83      0.48        41\n",
      "           4       0.40      0.36      0.38        47\n",
      "\n",
      "    accuracy                           0.38       160\n",
      "   macro avg       0.56      0.36      0.32       160\n",
      "weighted avg       0.52      0.38      0.33       160\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-27-7929d1561c85>:33: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs_val = netValence(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "<ipython-input-27-7929d1561c85>:35: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs_aro = netArousal(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.21      0.19      0.20        31\n",
      "           2       0.57      0.12      0.20        34\n",
      "           3       0.29      0.53      0.37        43\n",
      "           4       0.48      0.40      0.44        52\n",
      "\n",
      "    accuracy                           0.34       160\n",
      "   macro avg       0.39      0.31      0.30       160\n",
      "weighted avg       0.39      0.34      0.32       160\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-27-7929d1561c85>:33: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs_val = netValence(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "<ipython-input-27-7929d1561c85>:35: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs_aro = netArousal(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.36      0.12      0.19        32\n",
      "           2       0.67      0.05      0.10        39\n",
      "           3       0.30      0.67      0.42        39\n",
      "           4       0.52      0.62      0.56        50\n",
      "\n",
      "    accuracy                           0.39       160\n",
      "   macro avg       0.46      0.37      0.32       160\n",
      "weighted avg       0.47      0.39      0.34       160\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-27-7929d1561c85>:33: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs_val = netValence(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "<ipython-input-27-7929d1561c85>:35: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs_aro = netArousal(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.44      0.10      0.16        42\n",
      "           2       0.33      0.07      0.12        28\n",
      "           3       0.21      0.77      0.33        26\n",
      "           4       0.48      0.36      0.41        64\n",
      "\n",
      "    accuracy                           0.31       160\n",
      "   macro avg       0.37      0.32      0.25       160\n",
      "weighted avg       0.40      0.31      0.28       160\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-27-7929d1561c85>:33: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs_val = netValence(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "<ipython-input-27-7929d1561c85>:35: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs_aro = netArousal(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.56      0.18      0.27        28\n",
      "           2       0.00      0.00      0.00        22\n",
      "           3       0.31      0.71      0.43        48\n",
      "           4       0.55      0.35      0.43        62\n",
      "\n",
      "    accuracy                           0.38       160\n",
      "   macro avg       0.35      0.31      0.28       160\n",
      "weighted avg       0.40      0.38      0.34       160\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-27-7929d1561c85>:33: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs_val = netValence(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "<ipython-input-27-7929d1561c85>:35: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs_aro = netArousal(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "<ipython-input-27-7929d1561c85>:33: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs_val = netValence(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "<ipython-input-27-7929d1561c85>:35: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs_aro = netArousal(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.17      0.03      0.05        33\n",
      "           2       0.00      0.00      0.00        37\n",
      "           3       0.27      0.76      0.39        41\n",
      "           4       0.37      0.29      0.32        49\n",
      "\n",
      "    accuracy                           0.29       160\n",
      "   macro avg       0.20      0.27      0.19       160\n",
      "weighted avg       0.22      0.29      0.21       160\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.26      0.20      0.23        25\n",
      "           2       1.00      0.14      0.24        37\n",
      "           3       0.20      0.55      0.29        33\n",
      "           4       0.50      0.34      0.40        65\n",
      "\n",
      "    accuracy                           0.31       160\n",
      "   macro avg       0.49      0.30      0.29       160\n",
      "weighted avg       0.52      0.31      0.31       160\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import confusion_matrix,classification_report\n",
    "from sklearn import preprocessing\n",
    "import matplotlib.pyplot as plt\n",
    "#subjectnames\n",
    "batch_sz = 20\n",
    "file_list_num = np.arange(len(subjectnames))\n",
    "modelid = 1\n",
    "netValence = Net()\n",
    "valmodelname = \"Valence_Model4\"+\".pt\"\n",
    "netValence.load_state_dict(torch.load(valmodelname))\n",
    "netValence.to(device)\n",
    "netArousal = Net()\n",
    "aromodelname = \"Model5\"+\".pt\"\n",
    "netArousal.load_state_dict(torch.load(aromodelname))\n",
    "netArousal.to(device)\n",
    "for i in range(0,32,4):\n",
    "\n",
    "    #optimizer = optim.Adam(net.parameters(), lr=0.000001)\n",
    "    expectedoutput = []\n",
    "    actualoutput = []\n",
    "    for tr in file_list_num[i:i+4]:\n",
    "        #net.eval()\n",
    "        v = data_c1d[subjectnames[tr]]\n",
    "        l = data_c3[subjectnames[tr]]\n",
    "        netValence.eval()\n",
    "        netArousal.eval()\n",
    "        with torch.no_grad():\n",
    "            for i in range(0,len(v),batch_sz):\n",
    "              #print(v[i].shape)\n",
    "              #for j in range(0,v[i].shape[0],batch_sz):\n",
    "              #optimizer.zero_grad()\n",
    "              outputs_val = netValence(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
    "              outputs_val1 = torch.round(outputs_val)\n",
    "              outputs_aro = netArousal(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
    "              outputs_aro1 = torch.round(outputs_aro)\n",
    "\n",
    "              #print(outputs_val1)\n",
    "              for j in range(0,outputs_aro1.shape[0]):\n",
    "                res = 0\n",
    "                if (outputs_val1[j][0] >= 1 and outputs_aro1[j][0] >= 1):\n",
    "                    res = 4\n",
    "                elif (outputs_val1[j][0] < 1 and outputs_aro1[j][0] >= 1):\n",
    "                    res = 3\n",
    "                elif (outputs_val1[j][0] >= 1 and outputs_aro1[j][0] < 1):\n",
    "                    res = 2\n",
    "                elif (outputs_val1[j][0] < 1 and outputs_aro1[j][0] < 1):\n",
    "                    res = 1\n",
    "                actualoutput.append(res)\n",
    "              #loss = criterion(outputs, l[i:i+batch_sz].to(device, dtype=torch.float))\n",
    "              #val_loss.append(loss)\n",
    "              #loss.backward()\n",
    "              #print(outputs.shape)\n",
    "              #print(l[i:i+batch_sz])\n",
    "              expectedoutput.append(l[i:i+batch_sz])\n",
    "              #actualoutput.append(actualoutput)\n",
    "      #val_loss_mean = torch.stack(val_loss).mean().cpu().detach().numpy()\n",
    "      #val_loss_epoch.append(val_loss_mean)\n",
    "    expectedoutput = np.concatenate( expectedoutput, axis=0 )\n",
    "      #actualoutput = np.concatenate( actualoutput, axis=0 )\n",
    "      #print(actualoutput)\n",
    "    #print(expectedoutput)\n",
    "    #print(actualoutput)\n",
    "    print(classification_report(expectedoutput,actualoutput))\n",
    "      #print(f'Validation Loss for {subjectnames[tr]} = {val_loss_mean}')\n",
    "      #break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9XuinMzzRq3R",
   "metadata": {
    "id": "9XuinMzzRq3R"
   },
   "outputs": [],
   "source": [
    "rm -rf Model*.pt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "8-a4aWI1C7If",
   "metadata": {
    "id": "8-a4aWI1C7If"
   },
   "outputs": [],
   "source": [
    "data_c3 = {}\n",
    "for k,v in data_c.items():\n",
    "    y = data_c[k][1]\n",
    "    x_label = np.zeros((y.shape[0]),dtype='int8')\n",
    "    for i in range(y.shape[0]):\n",
    "        if (y[i][0] > 5 and y[i][1] > 5):\n",
    "            x_label[i] = 4\n",
    "        elif (y[i][0] <= 5 and y[i][1] > 5):\n",
    "            x_label[i] = 3\n",
    "        elif (y[i][0] > 5 and y[i][1] <= 5):\n",
    "            x_label[i] = 2\n",
    "        elif (y[i][0] <= 5 and y[i][1] <= 5):\n",
    "            x_label[i] = 1\n",
    "    #x_l = np.zeros((x_label.size, x_label.max()+1))\n",
    "    #x_l[np.arange(x_label.size), x_label] = 1\n",
    "    #\n",
    "    #print(x_l.shape)\n",
    "    #x_l = x_l.reshape(-1,1,4)\n",
    "    #x_l = np.repeat(x_l, 117, axis=1)\n",
    "    #print(x_l.shape)\n",
    "    x_l = torch.tensor(x_label)\n",
    "    data_c3[k] = x_l\n",
    "    #print(data_c3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "538f2018-fa74-4426-9c36-d56fbeea2f5d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-23T13:02:48.198560Z",
     "iopub.status.busy": "2024-01-23T13:02:48.198131Z",
     "iopub.status.idle": "2024-01-23T13:02:48.209111Z",
     "shell.execute_reply": "2024-01-23T13:02:48.207645Z",
     "shell.execute_reply.started": "2024-01-23T13:02:48.198531Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['DEAP/s21.dat', 'DEAP/s25.dat', 'DEAP/s07.dat', 'DEAP/s22.dat', 'DEAP/s32.dat', 'DEAP/s10.dat', 'DEAP/s04.dat', 'DEAP/s23.dat', 'DEAP/s30.dat', 'DEAP/s06.dat', 'DEAP/s31.dat', 'DEAP/s16.dat', 'DEAP/s15.dat', 'DEAP/s08.dat', 'DEAP/s28.dat', 'DEAP/s17.dat', 'DEAP/s26.dat', 'DEAP/s02.dat', 'DEAP/s19.dat', 'DEAP/s18.dat', 'DEAP/s03.dat', 'DEAP/s29.dat', 'DEAP/s24.dat', 'DEAP/s05.dat', 'DEAP/s14.dat', 'DEAP/s12.dat', 'DEAP/s11.dat', 'DEAP/s27.dat', 'DEAP/s20.dat', 'DEAP/s09.dat', 'DEAP/s13.dat', 'DEAP/s01.dat']\n",
      "['s21', 's25', 's07', 's22', 's32', 's10', 's04', 's23', 's30', 's06', 's31', 's16', 's15', 's08', 's28', 's17', 's26', 's02', 's19', 's18', 's03', 's29', 's24', 's05', 's14', 's12', 's11', 's27', 's20', 's09', 's13', 's01']\n"
     ]
    }
   ],
   "source": [
    "import glob\n",
    "import os\n",
    "filelistd = glob.glob('DEAP/*.dat')\n",
    "print(filelistd)\n",
    "subjectnamesd = [fr[5:8] for fr in filelistd]\n",
    "print(subjectnamesd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "dcb43263-e6f0-4f6f-97fd-ffd8fe6efb21",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-23T13:02:50.736879Z",
     "iopub.status.busy": "2024-01-23T13:02:50.736495Z",
     "iopub.status.idle": "2024-01-23T13:03:05.080144Z",
     "shell.execute_reply": "2024-01-23T13:03:05.078837Z",
     "shell.execute_reply.started": "2024-01-23T13:02:50.736851Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['s21', 's25', 's07', 's22', 's32', 's10', 's04', 's23', 's30', 's06', 's31', 's16', 's15', 's08', 's28', 's17', 's26', 's02', 's19', 's18', 's03', 's29', 's24', 's05', 's14', 's12', 's11', 's27', 's20', 's09', 's13', 's01'])\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "datad = {}\n",
    "for sname in subjectnamesd:\n",
    "    dname = \"DEAP/\"+sname+\".dat\"\n",
    "    f = open(dname, 'rb')\n",
    "    x = pickle.load(f, encoding='latin1')\n",
    "    datad[sname] = x\n",
    "print(datad.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9e192455-a6bc-45f1-b641-9fde46b3586c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-23T13:03:12.830156Z",
     "iopub.status.busy": "2024-01-23T13:03:12.829657Z",
     "iopub.status.idle": "2024-01-23T13:03:12.976918Z",
     "shell.execute_reply": "2024-01-23T13:03:12.975532Z",
     "shell.execute_reply.started": "2024-01-23T13:03:12.830114Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "data_de = {}\n",
    "for k,v in datad.items():\n",
    "    y = datad[k]['data'][:,36,:]\n",
    "    ym = np.mean(y,axis=-1).reshape(40,1)\n",
    "    ystd = np.std(y,axis=-1).reshape(40,1)\n",
    "    z = (y-ym)/ystd\n",
    "    data_de[k] = [z,datad[k]['labels']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b1f12cea-e417-4f5d-b827-53bc3a41b517",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-23T13:03:15.660205Z",
     "iopub.status.busy": "2024-01-23T13:03:15.659798Z",
     "iopub.status.idle": "2024-01-23T13:03:15.805198Z",
     "shell.execute_reply": "2024-01-23T13:03:15.804253Z",
     "shell.execute_reply.started": "2024-01-23T13:03:15.660155Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 8064])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "data_de1 = {}\n",
    "for k,v in data_de.items():\n",
    "    datablocki = []\n",
    "    v1=np.vstack(v[0])\n",
    "    v1 = v1[:,np.newaxis,:]\n",
    "    data_de1[k] = torch.tensor(v1)\n",
    "print(data_de1['s01'][0].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "79b2bfa1-9d78-4f7d-b0f0-17c05654fbaa",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-23T13:03:18.169706Z",
     "iopub.status.busy": "2024-01-23T13:03:18.169333Z",
     "iopub.status.idle": "2024-01-23T13:03:18.181086Z",
     "shell.execute_reply": "2024-01-23T13:03:18.180188Z",
     "shell.execute_reply.started": "2024-01-23T13:03:18.169677Z"
    }
   },
   "outputs": [],
   "source": [
    "data_del = {}\n",
    "ximax = 3\n",
    "for k,v in data_de.items():\n",
    "    y = data_de[k][1]\n",
    "    x_label = np.zeros((y.shape[0]),dtype='int64')\n",
    "    for i in range(y.shape[0]):\n",
    "        if (y[i][0] > 5 and y[i][1] > 5):\n",
    "            x_label[i] = 3\n",
    "        elif (y[i][0] <= 5 and y[i][1] > 5):\n",
    "            x_label[i] = 2\n",
    "        elif (y[i][0] > 5 and y[i][1] <= 5):\n",
    "            x_label[i] = 1\n",
    "        elif (y[i][0] <= 5 and y[i][1] <= 5):\n",
    "            x_label[i] = 0\n",
    "    x_l = np.zeros((x_label.size, ximax+1))\n",
    "    x_l[np.arange(x_label.size), x_label] = 1\n",
    "    #x_l = x_label\n",
    "    #\n",
    "    #print(x_l.shape)\n",
    "    x_l = x_l.reshape(-1,4)\n",
    "\n",
    "    x_l = torch.tensor(x_l)\n",
    "    data_del[k] = x_l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3510574e-92c7-4f83-8ea3-b1c842ec8792",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-22T10:36:12.597926Z",
     "iopub.status.busy": "2024-01-22T10:36:12.597240Z",
     "iopub.status.idle": "2024-01-22T10:36:12.603447Z",
     "shell.execute_reply": "2024-01-22T10:36:12.602820Z",
     "shell.execute_reply.started": "2024-01-22T10:36:12.597899Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([40, 4])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_del['s01'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "00a549ca-dc77-4ef8-a2ce-948a31cb944d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-21T21:26:54.344614Z",
     "iopub.status.busy": "2024-01-21T21:26:54.343936Z",
     "iopub.status.idle": "2024-01-21T21:26:55.114174Z",
     "shell.execute_reply": "2024-01-21T21:26:55.113433Z",
     "shell.execute_reply.started": "2024-01-21T21:26:54.344580Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 20:\n",
      "  Train: index=[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23\n",
      " 24 25 26 27 28 29 30 31]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_410/3061022090.py:39: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1960: UserWarning: nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\n",
      "  warnings.warn(\"nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.45      1.00      0.62       572\n",
      "         1.0       0.00      0.00      0.00       708\n",
      "\n",
      "    accuracy                           0.45      1280\n",
      "   macro avg       0.22      0.50      0.31      1280\n",
      "weighted avg       0.20      0.45      0.28      1280\n",
      "\n",
      "[[572   0]\n",
      " [708   0]]\n",
      "Validation Loss for s01 = 0.6970333456993103\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.9/dist-packages/sklearn/metrics/_classification.py:1334: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.9/dist-packages/sklearn/metrics/_classification.py:1334: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.9/dist-packages/sklearn/metrics/_classification.py:1334: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import confusion_matrix,classification_report\n",
    "from sklearn import preprocessing\n",
    "import matplotlib.pyplot as plt\n",
    "#subjectnames\n",
    "file_list_numd = np.arange(len(subjectnamesd))\n",
    "net = Net()\n",
    "net.to(device)\n",
    "optimizer = optim.Adam(net.parameters(), lr=0.000001)\n",
    "torch.manual_seed(42)\n",
    "torch.cuda.manual_seed(42)\n",
    "expectedoutputdeap = []\n",
    "actualoutputdeap = []\n",
    "val_loss = []\n",
    "expectedoutput = []\n",
    "actualoutput = []\n",
    "test_index = file_list_numd\n",
    "print(f\"Fold {i}:\")\n",
    "print(f\"  Train: index={test_index}\")\n",
    "#print(f\"  Test:  index={test_index}\")\n",
    "#net = Net()\n",
    "#net.to(device)\n",
    "#optimizer = optim.Adam(net.parameters(), lr=0.000001)\n",
    "#epochs = 60\n",
    "batch_sz = 20\n",
    "train_loss_epoch = []\n",
    "val_loss_epoch = []\n",
    "\n",
    "for tr in test_index:\n",
    "    net.eval()\n",
    "    v = data_de1[subjectnamesd[tr]]\n",
    "    l = data_del[subjectnamesd[tr]]\n",
    "    net.eval()\n",
    "    with torch.no_grad():\n",
    "        for i in range(0,len(v),batch_sz):\n",
    "          #print(v[i].shape)\n",
    "          #for j in range(0,v[i].shape[0],batch_sz):\n",
    "          optimizer.zero_grad()\n",
    "          outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
    "          #print(outputs.shape)\n",
    "          #print(l[i:i+batch_sz].shape)\n",
    "          loss = criterion(outputs, l[i:i+batch_sz].to(device, dtype=torch.float))\n",
    "          val_loss.append(loss)\n",
    "          actualoutputdeap.append(torch.round(outputs.cpu()))\n",
    "          expectedoutputdeap.append(l[i:i+batch_sz])\n",
    "          #actualoutput.append(torch.argmax(torch.softmax(outputs.cpu(),dim=1),dim=1))\n",
    "          #expectedoutput.append(torch.argmax(l[i:i+batch_sz],dim=1).numpy())\n",
    "val_loss_mean = torch.stack(val_loss).mean().cpu().detach().numpy()\n",
    "val_loss_epoch.append(val_loss_mean)\n",
    "expectedoutputdeap = np.concatenate( expectedoutputdeap, axis=0 )\n",
    "actualoutputdeap = np.concatenate( actualoutputdeap, axis=0 )\n",
    "#print(expectedoutput.shape)\n",
    "#print(actualoutput.shape)\n",
    "print(classification_report(expectedoutputdeap,actualoutputdeap))\n",
    "print(confusion_matrix(expectedoutputdeap,actualoutputdeap))\n",
    "print(f'Validation Loss for {subjectnamesd[tr]} = {val_loss_mean}')\n",
    "#break\n",
    "\n",
    "#plt.figure(figsize=(10,7))\n",
    "#print(len(train_loss_epoch))\n",
    "#plt.plot(np.arange(epochs),train_loss_epoch,label='Train')\n",
    "#plt.plot(np.arange(epochs),val_loss_epoch,label='Validation')\n",
    "#plt.legend()\n",
    "#path = \"Model\"+str(modelid) +\".pt\"\n",
    "#path = \"ModelAMIGOS_Aro.pt\"\n",
    "#modelid = modelid+1\n",
    "#print(path)\n",
    "#torch.save(net.state_dict(), path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "44278dac-15a4-400c-8676-184267c3942e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-23T13:09:55.482803Z",
     "iopub.status.busy": "2024-01-23T13:09:55.482444Z",
     "iopub.status.idle": "2024-01-23T13:12:25.217524Z",
     "shell.execute_reply": "2024-01-23T13:12:25.213432Z",
     "shell.execute_reply.started": "2024-01-23T13:09:55.482775Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 20:\n",
      "  Train: index=[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23\n",
      " 24 25 26 27 28 29 30 31 32 33 34 35]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_96/1313612177.py:43: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100, Train Loss: 1.5232149362564087\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_96/1313612177.py:68: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/tmp/ipykernel_96/1313612177.py:88: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.08      0.01      0.02        74\n",
      "           1       0.19      0.32      0.23        73\n",
      "           2       0.22      0.22      0.22       106\n",
      "           3       0.39      0.41      0.40       147\n",
      "\n",
      "    accuracy                           0.27       400\n",
      "   macro avg       0.22      0.24      0.22       400\n",
      "weighted avg       0.25      0.27      0.25       400\n",
      "\n",
      "[[ 1 28 17 28]\n",
      " [ 3 23 23 24]\n",
      " [ 3 35 23 45]\n",
      " [ 5 38 43 61]]\n",
      "Validation Loss for s21 = 1.366054892539978\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_96/1313612177.py:43: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/100, Train Loss: 1.360924482345581\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_96/1313612177.py:68: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/tmp/ipykernel_96/1313612177.py:88: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.13      0.14      0.13        74\n",
      "           1       0.16      0.32      0.21        73\n",
      "           2       0.23      0.22      0.22       106\n",
      "           3       0.45      0.24      0.31       147\n",
      "\n",
      "    accuracy                           0.23       400\n",
      "   macro avg       0.24      0.23      0.22       400\n",
      "weighted avg       0.28      0.23      0.24       400\n",
      "\n",
      "[[10 35 16 13]\n",
      " [13 23 22 15]\n",
      " [21 47 23 15]\n",
      " [31 41 40 35]]\n",
      "Validation Loss for s21 = 1.3570306301116943\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_96/1313612177.py:43: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/100, Train Loss: 1.378825068473816\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_96/1313612177.py:68: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/tmp/ipykernel_96/1313612177.py:88: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.19      0.45      0.26        74\n",
      "           1       0.21      0.19      0.20        73\n",
      "           2       0.21      0.18      0.19       106\n",
      "           3       0.48      0.21      0.29       147\n",
      "\n",
      "    accuracy                           0.24       400\n",
      "   macro avg       0.27      0.26      0.24       400\n",
      "weighted avg       0.31      0.24      0.24       400\n",
      "\n",
      "[[33 15 15 11]\n",
      " [26 14 22 11]\n",
      " [58 18 19 11]\n",
      " [60 20 36 31]]\n",
      "Validation Loss for s21 = 1.3509998321533203\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_96/1313612177.py:43: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/100, Train Loss: 1.3844245672225952\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_96/1313612177.py:68: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/tmp/ipykernel_96/1313612177.py:88: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.19      0.50      0.27        74\n",
      "           1       0.20      0.16      0.18        73\n",
      "           2       0.21      0.18      0.19       106\n",
      "           3       0.47      0.18      0.26       147\n",
      "\n",
      "    accuracy                           0.23       400\n",
      "   macro avg       0.27      0.26      0.23       400\n",
      "weighted avg       0.30      0.23      0.23       400\n",
      "\n",
      "[[37 13 14 10]\n",
      " [29 12 20 12]\n",
      " [66 14 19  7]\n",
      " [65 20 36 26]]\n",
      "Validation Loss for s21 = 1.3501675128936768\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_96/1313612177.py:43: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/100, Train Loss: 1.3959131240844727\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_96/1313612177.py:68: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/tmp/ipykernel_96/1313612177.py:88: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.18      0.50      0.27        74\n",
      "           1       0.18      0.14      0.15        73\n",
      "           2       0.20      0.15      0.17       106\n",
      "           3       0.45      0.19      0.27       147\n",
      "\n",
      "    accuracy                           0.23       400\n",
      "   macro avg       0.25      0.24      0.22       400\n",
      "weighted avg       0.29      0.23      0.22       400\n",
      "\n",
      "[[37 13 14 10]\n",
      " [32 10 17 14]\n",
      " [66 14 16 10]\n",
      " [66 20 33 28]]\n",
      "Validation Loss for s21 = 1.342175006866455\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_96/1313612177.py:43: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6/100, Train Loss: 1.45297372341156\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_96/1313612177.py:68: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/tmp/ipykernel_96/1313612177.py:88: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.18      0.50      0.27        74\n",
      "           1       0.16      0.14      0.15        73\n",
      "           2       0.22      0.15      0.18       106\n",
      "           3       0.50      0.20      0.29       147\n",
      "\n",
      "    accuracy                           0.23       400\n",
      "   macro avg       0.27      0.25      0.22       400\n",
      "weighted avg       0.30      0.23      0.23       400\n",
      "\n",
      "[[37 15 12 10]\n",
      " [34 10 17 12]\n",
      " [68 14 16  8]\n",
      " [66 24 27 30]]\n",
      "Validation Loss for s21 = 1.3465596437454224\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_96/1313612177.py:43: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7/100, Train Loss: 1.3328428268432617\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_96/1313612177.py:68: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/tmp/ipykernel_96/1313612177.py:88: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.18      0.50      0.26        74\n",
      "           1       0.18      0.15      0.16        73\n",
      "           2       0.20      0.13      0.16       106\n",
      "           3       0.48      0.20      0.28       147\n",
      "\n",
      "    accuracy                           0.23       400\n",
      "   macro avg       0.26      0.25      0.22       400\n",
      "weighted avg       0.29      0.23      0.22       400\n",
      "\n",
      "[[37 15 11 11]\n",
      " [36 11 14 12]\n",
      " [69 14 14  9]\n",
      " [66 21 31 29]]\n",
      "Validation Loss for s21 = 1.350050926208496\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_96/1313612177.py:43: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8/100, Train Loss: 1.3837321996688843\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_96/1313612177.py:68: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/tmp/ipykernel_96/1313612177.py:88: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/tmp/ipykernel_96/1313612177.py:43: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.18      0.50      0.27        74\n",
      "           1       0.18      0.16      0.17        73\n",
      "           2       0.19      0.11      0.14       106\n",
      "           3       0.43      0.19      0.26       147\n",
      "\n",
      "    accuracy                           0.22       400\n",
      "   macro avg       0.25      0.24      0.21       400\n",
      "weighted avg       0.27      0.22      0.22       400\n",
      "\n",
      "[[37 15  9 13]\n",
      " [34 12 13 14]\n",
      " [68 16 12 10]\n",
      " [66 23 30 28]]\n",
      "Validation Loss for s21 = 1.34157133102417\n",
      "Epoch 9/100, Train Loss: 1.3168014287948608\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_96/1313612177.py:68: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/tmp/ipykernel_96/1313612177.py:88: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.18      0.53      0.27        74\n",
      "           1       0.19      0.16      0.18        73\n",
      "           2       0.17      0.08      0.11       106\n",
      "           3       0.47      0.23      0.31       147\n",
      "\n",
      "    accuracy                           0.23       400\n",
      "   macro avg       0.25      0.25      0.22       400\n",
      "weighted avg       0.29      0.23      0.23       400\n",
      "\n",
      "[[39 13  9 13]\n",
      " [35 12 12 14]\n",
      " [69 16  9 12]\n",
      " [68 23 22 34]]\n",
      "Validation Loss for s21 = 1.3397036790847778\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_96/1313612177.py:43: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10/100, Train Loss: 1.2848080396652222\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_96/1313612177.py:68: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/tmp/ipykernel_96/1313612177.py:88: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.19      0.53      0.28        74\n",
      "           1       0.18      0.16      0.17        73\n",
      "           2       0.16      0.09      0.12       106\n",
      "           3       0.43      0.18      0.26       147\n",
      "\n",
      "    accuracy                           0.22       400\n",
      "   macro avg       0.24      0.24      0.21       400\n",
      "weighted avg       0.27      0.22      0.21       400\n",
      "\n",
      "[[39 13 10 12]\n",
      " [34 12 13 14]\n",
      " [68 18 10 10]\n",
      " [68 24 28 27]]\n",
      "Validation Loss for s21 = 1.3390028476715088\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_96/1313612177.py:43: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11/100, Train Loss: 1.437317132949829\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_96/1313612177.py:68: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/tmp/ipykernel_96/1313612177.py:88: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.18      0.50      0.26        74\n",
      "           1       0.19      0.16      0.18        73\n",
      "           2       0.16      0.08      0.10       106\n",
      "           3       0.45      0.24      0.31       147\n",
      "\n",
      "    accuracy                           0.23       400\n",
      "   macro avg       0.24      0.24      0.21       400\n",
      "weighted avg       0.27      0.23      0.22       400\n",
      "\n",
      "[[37 12 10 15]\n",
      " [34 12 12 15]\n",
      " [69 16  8 13]\n",
      " [67 24 21 35]]\n",
      "Validation Loss for s21 = 1.3319637775421143\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_96/1313612177.py:43: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12/100, Train Loss: 1.3874033689498901\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_96/1313612177.py:68: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/tmp/ipykernel_96/1313612177.py:88: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.18      0.50      0.26        74\n",
      "           1       0.19      0.16      0.18        73\n",
      "           2       0.16      0.09      0.12       106\n",
      "           3       0.41      0.19      0.26       147\n",
      "\n",
      "    accuracy                           0.22       400\n",
      "   macro avg       0.24      0.24      0.20       400\n",
      "weighted avg       0.26      0.22      0.21       400\n",
      "\n",
      "[[37 12 11 14]\n",
      " [34 12 12 15]\n",
      " [69 16 10 11]\n",
      " [67 23 29 28]]\n",
      "Validation Loss for s21 = 1.334141492843628\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_96/1313612177.py:43: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13/100, Train Loss: 1.390348196029663\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_96/1313612177.py:68: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/tmp/ipykernel_96/1313612177.py:88: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.18      0.50      0.27        74\n",
      "           1       0.18      0.18      0.18        73\n",
      "           2       0.17      0.09      0.12       106\n",
      "           3       0.43      0.19      0.26       147\n",
      "\n",
      "    accuracy                           0.22       400\n",
      "   macro avg       0.24      0.24      0.21       400\n",
      "weighted avg       0.27      0.22      0.21       400\n",
      "\n",
      "[[37 14 10 13]\n",
      " [34 13 12 14]\n",
      " [68 18 10 10]\n",
      " [65 26 28 28]]\n",
      "Validation Loss for s21 = 1.338241457939148\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_96/1313612177.py:43: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14/100, Train Loss: 1.3310455083847046\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_96/1313612177.py:68: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/tmp/ipykernel_96/1313612177.py:88: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/tmp/ipykernel_96/1313612177.py:43: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.19      0.55      0.28        74\n",
      "           1       0.18      0.14      0.15        73\n",
      "           2       0.17      0.10      0.13       106\n",
      "           3       0.43      0.18      0.26       147\n",
      "\n",
      "    accuracy                           0.22       400\n",
      "   macro avg       0.24      0.24      0.21       400\n",
      "weighted avg       0.27      0.22      0.21       400\n",
      "\n",
      "[[41 10 10 13]\n",
      " [37 10 12 14]\n",
      " [70 16 11  9]\n",
      " [69 21 30 27]]\n",
      "Validation Loss for s21 = 1.3335562944412231\n",
      "Epoch 15/100, Train Loss: 1.4889132976531982\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_96/1313612177.py:68: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/tmp/ipykernel_96/1313612177.py:88: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.19      0.55      0.28        74\n",
      "           1       0.18      0.14      0.16        73\n",
      "           2       0.16      0.08      0.11       106\n",
      "           3       0.47      0.22      0.30       147\n",
      "\n",
      "    accuracy                           0.23       400\n",
      "   macro avg       0.25      0.25      0.21       400\n",
      "weighted avg       0.28      0.23      0.22       400\n",
      "\n",
      "[[41 11  9 13]\n",
      " [37 10 12 14]\n",
      " [72 15  9 10]\n",
      " [69 19 26 33]]\n",
      "Validation Loss for s21 = 1.333701252937317\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_96/1313612177.py:43: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16/100, Train Loss: 1.4178032875061035\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_96/1313612177.py:68: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/tmp/ipykernel_96/1313612177.py:88: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.19      0.55      0.28        74\n",
      "           1       0.20      0.15      0.17        73\n",
      "           2       0.18      0.10      0.13       106\n",
      "           3       0.48      0.22      0.30       147\n",
      "\n",
      "    accuracy                           0.24       400\n",
      "   macro avg       0.26      0.26      0.22       400\n",
      "weighted avg       0.30      0.24      0.23       400\n",
      "\n",
      "[[41 10 10 13]\n",
      " [37 11 12 13]\n",
      " [72 15 11  8]\n",
      " [68 20 27 32]]\n",
      "Validation Loss for s21 = 1.3328561782836914\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_96/1313612177.py:43: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17/100, Train Loss: 1.393535852432251\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_96/1313612177.py:68: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/tmp/ipykernel_96/1313612177.py:88: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/tmp/ipykernel_96/1313612177.py:43: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.19      0.55      0.28        74\n",
      "           1       0.18      0.15      0.17        73\n",
      "           2       0.17      0.10      0.13       106\n",
      "           3       0.44      0.18      0.25       147\n",
      "\n",
      "    accuracy                           0.22       400\n",
      "   macro avg       0.25      0.25      0.21       400\n",
      "weighted avg       0.27      0.22      0.21       400\n",
      "\n",
      "[[41 11 10 12]\n",
      " [36 11 13 13]\n",
      " [71 16 11  8]\n",
      " [67 22 32 26]]\n",
      "Validation Loss for s21 = 1.3341606855392456\n",
      "Epoch 18/100, Train Loss: 1.3798311948776245\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_96/1313612177.py:68: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/tmp/ipykernel_96/1313612177.py:88: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/tmp/ipykernel_96/1313612177.py:43: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.19      0.54      0.28        74\n",
      "           1       0.18      0.15      0.16        73\n",
      "           2       0.16      0.10      0.13       106\n",
      "           3       0.44      0.18      0.25       147\n",
      "\n",
      "    accuracy                           0.22       400\n",
      "   macro avg       0.24      0.24      0.21       400\n",
      "weighted avg       0.27      0.22      0.21       400\n",
      "\n",
      "[[40 11 11 12]\n",
      " [36 11 13 13]\n",
      " [71 16 11  8]\n",
      " [66 23 32 26]]\n",
      "Validation Loss for s21 = 1.3303396701812744\n",
      "Epoch 19/100, Train Loss: 1.3317105770111084\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_96/1313612177.py:68: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/tmp/ipykernel_96/1313612177.py:88: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.19      0.55      0.28        74\n",
      "           1       0.20      0.16      0.18        73\n",
      "           2       0.16      0.10      0.13       106\n",
      "           3       0.46      0.18      0.25       147\n",
      "\n",
      "    accuracy                           0.23       400\n",
      "   macro avg       0.25      0.25      0.21       400\n",
      "weighted avg       0.28      0.23      0.21       400\n",
      "\n",
      "[[41 11 11 11]\n",
      " [37 12 12 12]\n",
      " [71 16 11  8]\n",
      " [67 21 33 26]]\n",
      "Validation Loss for s21 = 1.3414312601089478\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_96/1313612177.py:43: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20/100, Train Loss: 1.391959309577942\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_96/1313612177.py:68: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/tmp/ipykernel_96/1313612177.py:88: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.19      0.54      0.28        74\n",
      "           1       0.19      0.16      0.18        73\n",
      "           2       0.17      0.10      0.13       106\n",
      "           3       0.45      0.20      0.27       147\n",
      "\n",
      "    accuracy                           0.23       400\n",
      "   macro avg       0.25      0.25      0.22       400\n",
      "weighted avg       0.28      0.23      0.22       400\n",
      "\n",
      "[[40 12  9 13]\n",
      " [36 12 12 13]\n",
      " [70 16 11  9]\n",
      " [65 22 31 29]]\n",
      "Validation Loss for s21 = 1.3363065719604492\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_96/1313612177.py:43: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 21/100, Train Loss: 1.2739685773849487\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_96/1313612177.py:68: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/tmp/ipykernel_96/1313612177.py:88: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.19      0.54      0.28        74\n",
      "           1       0.18      0.16      0.17        73\n",
      "           2       0.19      0.10      0.13       106\n",
      "           3       0.43      0.20      0.28       147\n",
      "\n",
      "    accuracy                           0.23       400\n",
      "   macro avg       0.25      0.25      0.22       400\n",
      "weighted avg       0.28      0.23      0.22       400\n",
      "\n",
      "[[40 12  7 15]\n",
      " [35 12 11 15]\n",
      " [68 18 11  9]\n",
      " [64 24 29 30]]\n",
      "Validation Loss for s21 = 1.33707857131958\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_96/1313612177.py:43: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 22/100, Train Loss: 1.444475769996643\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_96/1313612177.py:68: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/tmp/ipykernel_96/1313612177.py:88: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.19      0.54      0.28        74\n",
      "           1       0.18      0.16      0.17        73\n",
      "           2       0.18      0.10      0.13       106\n",
      "           3       0.43      0.19      0.26       147\n",
      "\n",
      "    accuracy                           0.23       400\n",
      "   macro avg       0.25      0.25      0.21       400\n",
      "weighted avg       0.27      0.23      0.22       400\n",
      "\n",
      "[[40 11  9 14]\n",
      " [36 12 11 14]\n",
      " [68 18 11  9]\n",
      " [63 25 31 28]]\n",
      "Validation Loss for s21 = 1.3395650386810303\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_96/1313612177.py:43: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 23/100, Train Loss: 1.4776731729507446\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_96/1313612177.py:68: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/tmp/ipykernel_96/1313612177.py:88: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.19      0.55      0.28        74\n",
      "           1       0.20      0.16      0.18        73\n",
      "           2       0.20      0.11      0.14       106\n",
      "           3       0.44      0.19      0.27       147\n",
      "\n",
      "    accuracy                           0.23       400\n",
      "   macro avg       0.26      0.26      0.22       400\n",
      "weighted avg       0.29      0.23      0.22       400\n",
      "\n",
      "[[41 10  9 14]\n",
      " [37 12 10 14]\n",
      " [71 16 12  7]\n",
      " [68 21 30 28]]\n",
      "Validation Loss for s21 = 1.3384349346160889\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_96/1313612177.py:43: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 24/100, Train Loss: 1.3041068315505981\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_96/1313612177.py:68: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/tmp/ipykernel_96/1313612177.py:88: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.19      0.57      0.29        74\n",
      "           1       0.21      0.16      0.18        73\n",
      "           2       0.18      0.10      0.13       106\n",
      "           3       0.45      0.20      0.27       147\n",
      "\n",
      "    accuracy                           0.23       400\n",
      "   macro avg       0.26      0.26      0.22       400\n",
      "weighted avg       0.29      0.23      0.22       400\n",
      "\n",
      "[[42 10  9 13]\n",
      " [37 12 10 14]\n",
      " [71 16 11  8]\n",
      " [69 19 30 29]]\n",
      "Validation Loss for s21 = 1.3373844623565674\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_96/1313612177.py:43: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 25/100, Train Loss: 1.3178534507751465\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_96/1313612177.py:68: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/tmp/ipykernel_96/1313612177.py:88: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.19      0.55      0.29        74\n",
      "           1       0.18      0.15      0.17        73\n",
      "           2       0.17      0.10      0.13       106\n",
      "           3       0.43      0.18      0.26       147\n",
      "\n",
      "    accuracy                           0.23       400\n",
      "   macro avg       0.24      0.25      0.21       400\n",
      "weighted avg       0.27      0.23      0.21       400\n",
      "\n",
      "[[41 10  9 14]\n",
      " [37 11 11 14]\n",
      " [70 17 11  8]\n",
      " [65 22 33 27]]\n",
      "Validation Loss for s21 = 1.3378249406814575\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_96/1313612177.py:43: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 26/100, Train Loss: 1.4470902681350708\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_96/1313612177.py:68: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/tmp/ipykernel_96/1313612177.py:88: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.19      0.55      0.29        74\n",
      "           1       0.19      0.16      0.18        73\n",
      "           2       0.21      0.12      0.16       106\n",
      "           3       0.45      0.20      0.28       147\n",
      "\n",
      "    accuracy                           0.24       400\n",
      "   macro avg       0.26      0.26      0.23       400\n",
      "weighted avg       0.29      0.24      0.23       400\n",
      "\n",
      "[[41 10  9 14]\n",
      " [37 12 10 14]\n",
      " [69 16 13  8]\n",
      " [64 24 29 30]]\n",
      "Validation Loss for s21 = 1.337867021560669\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_96/1313612177.py:43: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 27/100, Train Loss: 1.3557045459747314\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_96/1313612177.py:68: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/tmp/ipykernel_96/1313612177.py:88: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.20      0.57      0.30        74\n",
      "           1       0.21      0.19      0.20        73\n",
      "           2       0.21      0.13      0.16       106\n",
      "           3       0.48      0.20      0.28       147\n",
      "\n",
      "    accuracy                           0.25       400\n",
      "   macro avg       0.28      0.27      0.24       400\n",
      "weighted avg       0.31      0.25      0.24       400\n",
      "\n",
      "[[42 10 10 12]\n",
      " [35 14 12 12]\n",
      " [66 19 14  7]\n",
      " [63 24 31 29]]\n",
      "Validation Loss for s21 = 1.3375166654586792\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_96/1313612177.py:43: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 28/100, Train Loss: 1.427163004875183\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_96/1313612177.py:68: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/tmp/ipykernel_96/1313612177.py:88: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.20      0.57      0.30        74\n",
      "           1       0.21      0.19      0.20        73\n",
      "           2       0.20      0.12      0.15       106\n",
      "           3       0.47      0.20      0.28       147\n",
      "\n",
      "    accuracy                           0.24       400\n",
      "   macro avg       0.27      0.27      0.23       400\n",
      "weighted avg       0.30      0.24      0.23       400\n",
      "\n",
      "[[42 10 10 12]\n",
      " [35 14 11 13]\n",
      " [66 19 13  8]\n",
      " [63 24 31 29]]\n",
      "Validation Loss for s21 = 1.336465835571289\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_96/1313612177.py:43: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 29/100, Train Loss: 1.4607257843017578\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_96/1313612177.py:68: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/tmp/ipykernel_96/1313612177.py:88: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.21      0.57      0.30        74\n",
      "           1       0.21      0.21      0.21        73\n",
      "           2       0.20      0.12      0.15       106\n",
      "           3       0.48      0.20      0.29       147\n",
      "\n",
      "    accuracy                           0.25       400\n",
      "   macro avg       0.28      0.27      0.24       400\n",
      "weighted avg       0.31      0.25      0.24       400\n",
      "\n",
      "[[42 11 10 11]\n",
      " [33 15 12 13]\n",
      " [66 19 13  8]\n",
      " [62 25 30 30]]\n",
      "Validation Loss for s21 = 1.3372416496276855\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_96/1313612177.py:43: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 30/100, Train Loss: 1.358583927154541\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_96/1313612177.py:68: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/tmp/ipykernel_96/1313612177.py:88: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.20      0.57      0.29        74\n",
      "           1       0.22      0.19      0.21        73\n",
      "           2       0.20      0.11      0.14       106\n",
      "           3       0.46      0.20      0.28       147\n",
      "\n",
      "    accuracy                           0.24       400\n",
      "   macro avg       0.27      0.27      0.23       400\n",
      "weighted avg       0.30      0.24      0.23       400\n",
      "\n",
      "[[42  9 10 13]\n",
      " [35 14 11 13]\n",
      " [68 17 12  9]\n",
      " [66 23 28 30]]\n",
      "Validation Loss for s21 = 1.3332672119140625\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_96/1313612177.py:43: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 31/100, Train Loss: 1.4645766019821167\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_96/1313612177.py:68: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/tmp/ipykernel_96/1313612177.py:88: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.20      0.57      0.30        74\n",
      "           1       0.22      0.21      0.21        73\n",
      "           2       0.22      0.13      0.16       106\n",
      "           3       0.48      0.20      0.28       147\n",
      "\n",
      "    accuracy                           0.25       400\n",
      "   macro avg       0.28      0.28      0.24       400\n",
      "weighted avg       0.31      0.25      0.24       400\n",
      "\n",
      "[[42 10 10 12]\n",
      " [34 15 12 12]\n",
      " [66 19 14  7]\n",
      " [66 23 29 29]]\n",
      "Validation Loss for s21 = 1.3418529033660889\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_96/1313612177.py:43: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 32/100, Train Loss: 1.330344319343567\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_96/1313612177.py:68: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/tmp/ipykernel_96/1313612177.py:88: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.20      0.57      0.30        74\n",
      "           1       0.22      0.21      0.21        73\n",
      "           2       0.21      0.12      0.15       106\n",
      "           3       0.47      0.20      0.28       147\n",
      "\n",
      "    accuracy                           0.25       400\n",
      "   macro avg       0.27      0.27      0.24       400\n",
      "weighted avg       0.31      0.25      0.24       400\n",
      "\n",
      "[[42 10 10 12]\n",
      " [34 15 11 13]\n",
      " [66 19 13  8]\n",
      " [66 24 28 29]]\n",
      "Validation Loss for s21 = 1.3418599367141724\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_96/1313612177.py:43: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 33/100, Train Loss: 1.3950233459472656\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_96/1313612177.py:68: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/tmp/ipykernel_96/1313612177.py:88: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.21      0.57      0.31        74\n",
      "           1       0.23      0.23      0.23        73\n",
      "           2       0.21      0.13      0.16       106\n",
      "           3       0.47      0.19      0.27       147\n",
      "\n",
      "    accuracy                           0.25       400\n",
      "   macro avg       0.28      0.28      0.24       400\n",
      "weighted avg       0.31      0.25      0.24       400\n",
      "\n",
      "[[42 10 10 12]\n",
      " [32 17 12 12]\n",
      " [65 20 14  7]\n",
      " [61 28 30 28]]\n",
      "Validation Loss for s21 = 1.3436951637268066\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_96/1313612177.py:43: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 34/100, Train Loss: 1.3912070989608765\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_96/1313612177.py:68: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/tmp/ipykernel_96/1313612177.py:88: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.20      0.57      0.30        74\n",
      "           1       0.22      0.21      0.21        73\n",
      "           2       0.21      0.13      0.16       106\n",
      "           3       0.48      0.20      0.28       147\n",
      "\n",
      "    accuracy                           0.25       400\n",
      "   macro avg       0.28      0.28      0.24       400\n",
      "weighted avg       0.31      0.25      0.24       400\n",
      "\n",
      "[[42 10 11 11]\n",
      " [33 15 12 13]\n",
      " [66 19 14  7]\n",
      " [65 23 30 29]]\n",
      "Validation Loss for s21 = 1.3389211893081665\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_96/1313612177.py:43: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 35/100, Train Loss: 1.3450068235397339\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_96/1313612177.py:68: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/tmp/ipykernel_96/1313612177.py:88: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.20      0.57      0.29        74\n",
      "           1       0.20      0.16      0.18        73\n",
      "           2       0.18      0.11      0.14       106\n",
      "           3       0.48      0.20      0.29       147\n",
      "\n",
      "    accuracy                           0.24       400\n",
      "   macro avg       0.26      0.26      0.23       400\n",
      "weighted avg       0.30      0.24      0.23       400\n",
      "\n",
      "[[42  9 11 12]\n",
      " [37 12 12 12]\n",
      " [68 17 12  9]\n",
      " [64 22 31 30]]\n",
      "Validation Loss for s21 = 1.3356077671051025\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_96/1313612177.py:43: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 36/100, Train Loss: 1.4202024936676025\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_96/1313612177.py:68: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/tmp/ipykernel_96/1313612177.py:88: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.20      0.57      0.29        74\n",
      "           1       0.23      0.19      0.21        73\n",
      "           2       0.20      0.12      0.15       106\n",
      "           3       0.47      0.20      0.28       147\n",
      "\n",
      "    accuracy                           0.24       400\n",
      "   macro avg       0.27      0.27      0.23       400\n",
      "weighted avg       0.30      0.24      0.23       400\n",
      "\n",
      "[[42  9 11 12]\n",
      " [36 14 11 12]\n",
      " [68 16 13  9]\n",
      " [65 23 30 29]]\n",
      "Validation Loss for s21 = 1.3391045331954956\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_96/1313612177.py:43: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 37/100, Train Loss: 1.4802887439727783\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_96/1313612177.py:68: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/tmp/ipykernel_96/1313612177.py:88: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.20      0.57      0.29        74\n",
      "           1       0.19      0.16      0.18        73\n",
      "           2       0.21      0.11      0.15       106\n",
      "           3       0.46      0.21      0.29       147\n",
      "\n",
      "    accuracy                           0.24       400\n",
      "   macro avg       0.27      0.26      0.23       400\n",
      "weighted avg       0.30      0.24      0.23       400\n",
      "\n",
      "[[42  9 11 12]\n",
      " [37 12  8 16]\n",
      " [68 18 12  8]\n",
      " [66 24 26 31]]\n",
      "Validation Loss for s21 = 1.3452842235565186\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_96/1313612177.py:43: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 38/100, Train Loss: 1.379934310913086\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_96/1313612177.py:68: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/tmp/ipykernel_96/1313612177.py:88: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.20      0.57      0.29        74\n",
      "           1       0.19      0.15      0.17        73\n",
      "           2       0.20      0.11      0.14       106\n",
      "           3       0.47      0.21      0.29       147\n",
      "\n",
      "    accuracy                           0.24       400\n",
      "   macro avg       0.26      0.26      0.22       400\n",
      "weighted avg       0.30      0.24      0.23       400\n",
      "\n",
      "[[42  9 11 12]\n",
      " [37 11 10 15]\n",
      " [69 17 12  8]\n",
      " [67 22 27 31]]\n",
      "Validation Loss for s21 = 1.345179557800293\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_96/1313612177.py:43: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 39/100, Train Loss: 1.5341004133224487\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_96/1313612177.py:68: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/tmp/ipykernel_96/1313612177.py:88: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.19      0.55      0.29        74\n",
      "           1       0.20      0.18      0.19        73\n",
      "           2       0.19      0.11      0.14       106\n",
      "           3       0.47      0.18      0.26       147\n",
      "\n",
      "    accuracy                           0.23       400\n",
      "   macro avg       0.26      0.26      0.22       400\n",
      "weighted avg       0.29      0.23      0.22       400\n",
      "\n",
      "[[41  9 12 12]\n",
      " [36 13 12 12]\n",
      " [69 18 12  7]\n",
      " [67 26 27 27]]\n",
      "Validation Loss for s21 = 1.347269058227539\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_96/1313612177.py:43: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 40/100, Train Loss: 1.3843803405761719\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_96/1313612177.py:68: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/tmp/ipykernel_96/1313612177.py:88: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.20      0.55      0.29        74\n",
      "           1       0.19      0.16      0.18        73\n",
      "           2       0.18      0.11      0.14       106\n",
      "           3       0.45      0.18      0.26       147\n",
      "\n",
      "    accuracy                           0.23       400\n",
      "   macro avg       0.25      0.25      0.22       400\n",
      "weighted avg       0.28      0.23      0.22       400\n",
      "\n",
      "[[41  9 12 12]\n",
      " [35 12 13 13]\n",
      " [68 18 12  8]\n",
      " [65 25 30 27]]\n",
      "Validation Loss for s21 = 1.3452262878417969\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_96/1313612177.py:43: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 41/100, Train Loss: 1.3632949590682983\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_96/1313612177.py:68: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/tmp/ipykernel_96/1313612177.py:88: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.20      0.57      0.29        74\n",
      "           1       0.20      0.18      0.19        73\n",
      "           2       0.20      0.13      0.16       106\n",
      "           3       0.50      0.18      0.27       147\n",
      "\n",
      "    accuracy                           0.24       400\n",
      "   macro avg       0.27      0.27      0.23       400\n",
      "weighted avg       0.31      0.24      0.23       400\n",
      "\n",
      "[[42  9 14  9]\n",
      " [36 13 11 13]\n",
      " [68 19 14  5]\n",
      " [65 25 30 27]]\n",
      "Validation Loss for s21 = 1.3465783596038818\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_96/1313612177.py:43: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 42/100, Train Loss: 1.4738821983337402\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_96/1313612177.py:68: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/tmp/ipykernel_96/1313612177.py:88: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.20      0.57      0.29        74\n",
      "           1       0.20      0.18      0.19        73\n",
      "           2       0.21      0.13      0.16       106\n",
      "           3       0.47      0.17      0.25       147\n",
      "\n",
      "    accuracy                           0.23       400\n",
      "   macro avg       0.27      0.26      0.22       400\n",
      "weighted avg       0.30      0.23      0.22       400\n",
      "\n",
      "[[42  9 13 10]\n",
      " [36 13 11 13]\n",
      " [69 18 14  5]\n",
      " [68 24 30 25]]\n",
      "Validation Loss for s21 = 1.3469454050064087\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_96/1313612177.py:43: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 43/100, Train Loss: 1.4378993511199951\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_96/1313612177.py:68: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/tmp/ipykernel_96/1313612177.py:88: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.19      0.55      0.29        74\n",
      "           1       0.21      0.18      0.19        73\n",
      "           2       0.22      0.15      0.18       106\n",
      "           3       0.47      0.17      0.25       147\n",
      "\n",
      "    accuracy                           0.24       400\n",
      "   macro avg       0.27      0.26      0.23       400\n",
      "weighted avg       0.31      0.24      0.23       400\n",
      "\n",
      "[[41  9 15  9]\n",
      " [36 13 12 12]\n",
      " [68 15 16  7]\n",
      " [67 24 31 25]]\n",
      "Validation Loss for s21 = 1.3450263738632202\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_96/1313612177.py:43: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 44/100, Train Loss: 1.386623501777649\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_96/1313612177.py:68: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/tmp/ipykernel_96/1313612177.py:88: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.19      0.55      0.29        74\n",
      "           1       0.19      0.16      0.18        73\n",
      "           2       0.22      0.13      0.16       106\n",
      "           3       0.48      0.20      0.28       147\n",
      "\n",
      "    accuracy                           0.24       400\n",
      "   macro avg       0.27      0.26      0.23       400\n",
      "weighted avg       0.30      0.24      0.23       400\n",
      "\n",
      "[[41  9 12 12]\n",
      " [37 12 11 13]\n",
      " [68 17 14  7]\n",
      " [66 25 27 29]]\n",
      "Validation Loss for s21 = 1.3457776308059692\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_96/1313612177.py:43: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 45/100, Train Loss: 1.3557099103927612\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_96/1313612177.py:68: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/tmp/ipykernel_96/1313612177.py:88: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/tmp/ipykernel_96/1313612177.py:43: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.19      0.55      0.29        74\n",
      "           1       0.19      0.16      0.18        73\n",
      "           2       0.22      0.12      0.16       106\n",
      "           3       0.46      0.20      0.28       147\n",
      "\n",
      "    accuracy                           0.24       400\n",
      "   macro avg       0.27      0.26      0.23       400\n",
      "weighted avg       0.30      0.24      0.23       400\n",
      "\n",
      "[[41  9 12 12]\n",
      " [37 12  8 16]\n",
      " [69 17 13  7]\n",
      " [66 25 26 30]]\n",
      "Validation Loss for s21 = 1.3464325666427612\n",
      "Epoch 46/100, Train Loss: 1.3788312673568726\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_96/1313612177.py:68: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/tmp/ipykernel_96/1313612177.py:88: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/tmp/ipykernel_96/1313612177.py:43: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.20      0.54      0.29        74\n",
      "           1       0.20      0.18      0.19        73\n",
      "           2       0.22      0.14      0.17       106\n",
      "           3       0.48      0.20      0.29       147\n",
      "\n",
      "    accuracy                           0.24       400\n",
      "   macro avg       0.27      0.27      0.23       400\n",
      "weighted avg       0.31      0.24      0.24       400\n",
      "\n",
      "[[40  9 14 11]\n",
      " [35 13 11 14]\n",
      " [66 17 15  8]\n",
      " [64 25 28 30]]\n",
      "Validation Loss for s21 = 1.3418914079666138\n",
      "Epoch 47/100, Train Loss: 1.4390630722045898\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_96/1313612177.py:68: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/tmp/ipykernel_96/1313612177.py:88: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/tmp/ipykernel_96/1313612177.py:43: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.19      0.55      0.29        74\n",
      "           1       0.19      0.16      0.18        73\n",
      "           2       0.22      0.14      0.17       106\n",
      "           3       0.46      0.18      0.25       147\n",
      "\n",
      "    accuracy                           0.23       400\n",
      "   macro avg       0.26      0.26      0.22       400\n",
      "weighted avg       0.30      0.23      0.22       400\n",
      "\n",
      "[[41  9 14 10]\n",
      " [36 12 11 14]\n",
      " [67 17 15  7]\n",
      " [67 25 29 26]]\n",
      "Validation Loss for s21 = 1.3510302305221558\n",
      "Epoch 48/100, Train Loss: 1.3369157314300537\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_96/1313612177.py:68: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/tmp/ipykernel_96/1313612177.py:88: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/tmp/ipykernel_96/1313612177.py:43: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.19      0.54      0.28        74\n",
      "           1       0.20      0.16      0.18        73\n",
      "           2       0.23      0.16      0.19       106\n",
      "           3       0.47      0.18      0.26       147\n",
      "\n",
      "    accuracy                           0.24       400\n",
      "   macro avg       0.27      0.26      0.23       400\n",
      "weighted avg       0.30      0.24      0.23       400\n",
      "\n",
      "[[40  9 14 11]\n",
      " [35 12 12 14]\n",
      " [68 15 17  6]\n",
      " [65 24 31 27]]\n",
      "Validation Loss for s21 = 1.344150185585022\n",
      "Epoch 49/100, Train Loss: 1.3386683464050293\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_96/1313612177.py:68: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/tmp/ipykernel_96/1313612177.py:88: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/tmp/ipykernel_96/1313612177.py:43: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.19      0.54      0.28        74\n",
      "           1       0.20      0.16      0.18        73\n",
      "           2       0.24      0.16      0.19       106\n",
      "           3       0.49      0.20      0.28       147\n",
      "\n",
      "    accuracy                           0.24       400\n",
      "   macro avg       0.28      0.27      0.23       400\n",
      "weighted avg       0.32      0.24      0.24       400\n",
      "\n",
      "[[40  9 15 10]\n",
      " [36 12 11 14]\n",
      " [69 14 17  6]\n",
      " [66 24 28 29]]\n",
      "Validation Loss for s21 = 1.3461822271347046\n",
      "Epoch 50/100, Train Loss: 1.4473263025283813\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_96/1313612177.py:68: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/tmp/ipykernel_96/1313612177.py:88: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.19      0.53      0.28        74\n",
      "           1       0.19      0.16      0.18        73\n",
      "           2       0.23      0.14      0.18       106\n",
      "           3       0.47      0.22      0.30       147\n",
      "\n",
      "    accuracy                           0.24       400\n",
      "   macro avg       0.27      0.26      0.23       400\n",
      "weighted avg       0.30      0.24      0.24       400\n",
      "\n",
      "[[39  9 14 12]\n",
      " [36 12  8 17]\n",
      " [68 16 15  7]\n",
      " [62 25 28 32]]\n",
      "Validation Loss for s21 = 1.3420357704162598\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_96/1313612177.py:43: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 51/100, Train Loss: 1.3523458242416382\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_96/1313612177.py:68: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/tmp/ipykernel_96/1313612177.py:88: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/tmp/ipykernel_96/1313612177.py:43: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.19      0.54      0.28        74\n",
      "           1       0.19      0.15      0.17        73\n",
      "           2       0.22      0.13      0.16       106\n",
      "           3       0.46      0.21      0.29       147\n",
      "\n",
      "    accuracy                           0.24       400\n",
      "   macro avg       0.26      0.26      0.23       400\n",
      "weighted avg       0.30      0.24      0.23       400\n",
      "\n",
      "[[40  9 14 11]\n",
      " [36 11 10 16]\n",
      " [69 14 14  9]\n",
      " [65 24 27 31]]\n",
      "Validation Loss for s21 = 1.3457462787628174\n",
      "Epoch 52/100, Train Loss: 1.3588125705718994\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_96/1313612177.py:68: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/tmp/ipykernel_96/1313612177.py:88: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/tmp/ipykernel_96/1313612177.py:43: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.19      0.54      0.29        74\n",
      "           1       0.18      0.15      0.17        73\n",
      "           2       0.23      0.14      0.17       106\n",
      "           3       0.47      0.22      0.30       147\n",
      "\n",
      "    accuracy                           0.24       400\n",
      "   macro avg       0.27      0.26      0.23       400\n",
      "weighted avg       0.30      0.24      0.24       400\n",
      "\n",
      "[[40  9 14 11]\n",
      " [36 11 10 16]\n",
      " [67 15 15  9]\n",
      " [63 25 27 32]]\n",
      "Validation Loss for s21 = 1.3478063344955444\n",
      "Epoch 53/100, Train Loss: 1.4894720315933228\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_96/1313612177.py:68: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/tmp/ipykernel_96/1313612177.py:88: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/tmp/ipykernel_96/1313612177.py:43: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.20      0.54      0.29        74\n",
      "           1       0.17      0.15      0.16        73\n",
      "           2       0.22      0.13      0.16       106\n",
      "           3       0.48      0.21      0.29       147\n",
      "\n",
      "    accuracy                           0.24       400\n",
      "   macro avg       0.26      0.26      0.23       400\n",
      "weighted avg       0.30      0.24      0.23       400\n",
      "\n",
      "[[40  9 14 11]\n",
      " [36 11 10 16]\n",
      " [68 17 14  7]\n",
      " [61 28 27 31]]\n",
      "Validation Loss for s21 = 1.342966079711914\n",
      "Epoch 54/100, Train Loss: 1.3452303409576416\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_96/1313612177.py:68: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/tmp/ipykernel_96/1313612177.py:88: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/tmp/ipykernel_96/1313612177.py:43: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.19      0.54      0.29        74\n",
      "           1       0.19      0.16      0.18        73\n",
      "           2       0.21      0.13      0.16       106\n",
      "           3       0.44      0.19      0.27       147\n",
      "\n",
      "    accuracy                           0.23       400\n",
      "   macro avg       0.26      0.26      0.22       400\n",
      "weighted avg       0.29      0.23      0.23       400\n",
      "\n",
      "[[40  9 14 11]\n",
      " [34 12 10 17]\n",
      " [68 16 14  8]\n",
      " [64 26 29 28]]\n",
      "Validation Loss for s21 = 1.3455488681793213\n",
      "Epoch 55/100, Train Loss: 1.3044630289077759\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_96/1313612177.py:68: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/tmp/ipykernel_96/1313612177.py:88: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.19      0.54      0.28        74\n",
      "           1       0.17      0.14      0.15        73\n",
      "           2       0.22      0.14      0.17       106\n",
      "           3       0.43      0.19      0.26       147\n",
      "\n",
      "    accuracy                           0.23       400\n",
      "   macro avg       0.25      0.25      0.22       400\n",
      "weighted avg       0.28      0.23      0.22       400\n",
      "\n",
      "[[40  9 14 11]\n",
      " [35 10 10 18]\n",
      " [68 15 15  8]\n",
      " [65 25 29 28]]\n",
      "Validation Loss for s21 = 1.3451762199401855\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_96/1313612177.py:43: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 56/100, Train Loss: 1.3549668788909912\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_96/1313612177.py:68: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/tmp/ipykernel_96/1313612177.py:88: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.19      0.54      0.28        74\n",
      "           1       0.15      0.11      0.13        73\n",
      "           2       0.21      0.13      0.16       106\n",
      "           3       0.43      0.20      0.28       147\n",
      "\n",
      "    accuracy                           0.23       400\n",
      "   macro avg       0.25      0.25      0.21       400\n",
      "weighted avg       0.28      0.23      0.22       400\n",
      "\n",
      "[[40  8 14 12]\n",
      " [35  8 11 19]\n",
      " [70 14 14  8]\n",
      " [66 22 29 30]]\n",
      "Validation Loss for s21 = 1.3410522937774658\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_96/1313612177.py:43: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 57/100, Train Loss: 1.3957834243774414\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_96/1313612177.py:68: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/tmp/ipykernel_96/1313612177.py:88: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.19      0.54      0.28        74\n",
      "           1       0.20      0.16      0.18        73\n",
      "           2       0.23      0.15      0.18       106\n",
      "           3       0.43      0.18      0.26       147\n",
      "\n",
      "    accuracy                           0.24       400\n",
      "   macro avg       0.26      0.26      0.23       400\n",
      "weighted avg       0.29      0.24      0.23       400\n",
      "\n",
      "[[40  9 14 11]\n",
      " [34 12 10 17]\n",
      " [68 14 16  8]\n",
      " [66 25 29 27]]\n",
      "Validation Loss for s21 = 1.3499150276184082\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_96/1313612177.py:43: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 58/100, Train Loss: 1.4516782760620117\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_96/1313612177.py:68: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/tmp/ipykernel_96/1313612177.py:88: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.19      0.54      0.28        74\n",
      "           1       0.19      0.15      0.17        73\n",
      "           2       0.22      0.13      0.16       106\n",
      "           3       0.42      0.19      0.26       147\n",
      "\n",
      "    accuracy                           0.23       400\n",
      "   macro avg       0.25      0.25      0.22       400\n",
      "weighted avg       0.28      0.23      0.22       400\n",
      "\n",
      "[[40  9 13 12]\n",
      " [35 11  9 18]\n",
      " [69 14 14  9]\n",
      " [67 24 28 28]]\n",
      "Validation Loss for s21 = 1.3484680652618408\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_96/1313612177.py:43: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 59/100, Train Loss: 1.3193386793136597\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_96/1313612177.py:68: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/tmp/ipykernel_96/1313612177.py:88: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.19      0.54      0.29        74\n",
      "           1       0.18      0.15      0.17        73\n",
      "           2       0.21      0.14      0.17       106\n",
      "           3       0.45      0.20      0.27       147\n",
      "\n",
      "    accuracy                           0.24       400\n",
      "   macro avg       0.26      0.26      0.22       400\n",
      "weighted avg       0.29      0.24      0.23       400\n",
      "\n",
      "[[40  9 15 10]\n",
      " [35 11 10 17]\n",
      " [67 16 15  8]\n",
      " [64 24 30 29]]\n",
      "Validation Loss for s21 = 1.3517009019851685\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_96/1313612177.py:43: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 60/100, Train Loss: 1.3536171913146973\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_96/1313612177.py:68: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/tmp/ipykernel_96/1313612177.py:88: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.19      0.51      0.28        74\n",
      "           1       0.17      0.15      0.16        73\n",
      "           2       0.20      0.13      0.16       106\n",
      "           3       0.47      0.21      0.29       147\n",
      "\n",
      "    accuracy                           0.23       400\n",
      "   macro avg       0.26      0.25      0.22       400\n",
      "weighted avg       0.29      0.23      0.23       400\n",
      "\n",
      "[[38 10 16 10]\n",
      " [34 11 11 17]\n",
      " [67 17 14  8]\n",
      " [61 25 30 31]]\n",
      "Validation Loss for s21 = 1.3522104024887085\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_96/1313612177.py:43: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 61/100, Train Loss: 1.2413394451141357\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_96/1313612177.py:68: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/tmp/ipykernel_96/1313612177.py:88: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.20      0.54      0.29        74\n",
      "           1       0.19      0.15      0.17        73\n",
      "           2       0.21      0.15      0.18       106\n",
      "           3       0.47      0.20      0.28       147\n",
      "\n",
      "    accuracy                           0.24       400\n",
      "   macro avg       0.27      0.26      0.23       400\n",
      "weighted avg       0.30      0.24      0.23       400\n",
      "\n",
      "[[40  9 15 10]\n",
      " [35 11 12 15]\n",
      " [67 15 16  8]\n",
      " [62 24 32 29]]\n",
      "Validation Loss for s21 = 1.3557754755020142\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_96/1313612177.py:43: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 62/100, Train Loss: 1.362406611442566\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_96/1313612177.py:68: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/tmp/ipykernel_96/1313612177.py:88: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.19      0.51      0.28        74\n",
      "           1       0.18      0.14      0.15        73\n",
      "           2       0.21      0.15      0.17       106\n",
      "           3       0.46      0.20      0.28       147\n",
      "\n",
      "    accuracy                           0.23       400\n",
      "   macro avg       0.26      0.25      0.22       400\n",
      "weighted avg       0.29      0.23      0.23       400\n",
      "\n",
      "[[38 10 16 10]\n",
      " [34 10 13 16]\n",
      " [69 13 16  8]\n",
      " [61 24 33 29]]\n",
      "Validation Loss for s21 = 1.3525029420852661\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_96/1313612177.py:43: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 63/100, Train Loss: 1.4767866134643555\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_96/1313612177.py:68: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/tmp/ipykernel_96/1313612177.py:88: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.19      0.50      0.27        74\n",
      "           1       0.13      0.10      0.11        73\n",
      "           2       0.21      0.15      0.18       106\n",
      "           3       0.46      0.22      0.30       147\n",
      "\n",
      "    accuracy                           0.23       400\n",
      "   macro avg       0.25      0.24      0.21       400\n",
      "weighted avg       0.28      0.23      0.23       400\n",
      "\n",
      "[[37 10 15 12]\n",
      " [35  7 13 18]\n",
      " [67 15 16  8]\n",
      " [60 23 31 33]]\n",
      "Validation Loss for s21 = 1.3491894006729126\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_96/1313612177.py:43: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 64/100, Train Loss: 1.3621740341186523\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_96/1313612177.py:68: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/tmp/ipykernel_96/1313612177.py:88: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.19      0.51      0.28        74\n",
      "           1       0.16      0.12      0.14        73\n",
      "           2       0.22      0.17      0.19       106\n",
      "           3       0.46      0.18      0.26       147\n",
      "\n",
      "    accuracy                           0.23       400\n",
      "   macro avg       0.26      0.25      0.22       400\n",
      "weighted avg       0.29      0.23      0.22       400\n",
      "\n",
      "[[38  9 17 10]\n",
      " [34  9 14 16]\n",
      " [66 16 18  6]\n",
      " [63 24 33 27]]\n",
      "Validation Loss for s21 = 1.3508623838424683\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_96/1313612177.py:43: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 65/100, Train Loss: 1.341933250427246\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_96/1313612177.py:68: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/tmp/ipykernel_96/1313612177.py:88: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.19      0.51      0.28        74\n",
      "           1       0.14      0.11      0.12        73\n",
      "           2       0.21      0.15      0.18       106\n",
      "           3       0.47      0.21      0.29       147\n",
      "\n",
      "    accuracy                           0.23       400\n",
      "   macro avg       0.25      0.25      0.22       400\n",
      "weighted avg       0.29      0.23      0.23       400\n",
      "\n",
      "[[38 10 16 10]\n",
      " [35  8 12 18]\n",
      " [68 15 16  7]\n",
      " [61 24 31 31]]\n",
      "Validation Loss for s21 = 1.3554949760437012\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_96/1313612177.py:43: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 66/100, Train Loss: 1.3175429105758667\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_96/1313612177.py:68: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/tmp/ipykernel_96/1313612177.py:88: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.19      0.53      0.28        74\n",
      "           1       0.12      0.08      0.10        73\n",
      "           2       0.24      0.19      0.21       106\n",
      "           3       0.46      0.20      0.28       147\n",
      "\n",
      "    accuracy                           0.23       400\n",
      "   macro avg       0.25      0.25      0.22       400\n",
      "weighted avg       0.29      0.23      0.23       400\n",
      "\n",
      "[[39  8 16 11]\n",
      " [36  6 14 17]\n",
      " [67 13 20  6]\n",
      " [60 23 35 29]]\n",
      "Validation Loss for s21 = 1.350942850112915\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_96/1313612177.py:43: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 67/100, Train Loss: 1.3374305963516235\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_96/1313612177.py:68: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/tmp/ipykernel_96/1313612177.py:88: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.19      0.51      0.27        74\n",
      "           1       0.12      0.08      0.10        73\n",
      "           2       0.23      0.18      0.20       106\n",
      "           3       0.45      0.20      0.27       147\n",
      "\n",
      "    accuracy                           0.23       400\n",
      "   macro avg       0.25      0.24      0.21       400\n",
      "weighted avg       0.28      0.23      0.22       400\n",
      "\n",
      "[[38  8 16 12]\n",
      " [36  6 13 18]\n",
      " [68 13 19  6]\n",
      " [61 24 33 29]]\n",
      "Validation Loss for s21 = 1.3500993251800537\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_96/1313612177.py:43: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 68/100, Train Loss: 1.3774054050445557\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_96/1313612177.py:68: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/tmp/ipykernel_96/1313612177.py:88: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/tmp/ipykernel_96/1313612177.py:43: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.20      0.53      0.28        74\n",
      "           1       0.14      0.10      0.11        73\n",
      "           2       0.22      0.18      0.20       106\n",
      "           3       0.45      0.20      0.27       147\n",
      "\n",
      "    accuracy                           0.23       400\n",
      "   macro avg       0.25      0.25      0.22       400\n",
      "weighted avg       0.29      0.23      0.23       400\n",
      "\n",
      "[[39  8 16 11]\n",
      " [34  7 15 17]\n",
      " [68 12 19  7]\n",
      " [59 23 36 29]]\n",
      "Validation Loss for s21 = 1.3552920818328857\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 69/100, Train Loss: 1.435598373413086\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_96/1313612177.py:68: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/tmp/ipykernel_96/1313612177.py:88: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.19      0.50      0.27        74\n",
      "           1       0.13      0.10      0.11        73\n",
      "           2       0.21      0.18      0.19       106\n",
      "           3       0.44      0.19      0.27       147\n",
      "\n",
      "    accuracy                           0.23       400\n",
      "   macro avg       0.25      0.24      0.21       400\n",
      "weighted avg       0.28      0.23      0.22       400\n",
      "\n",
      "[[37  8 18 11]\n",
      " [34  7 15 17]\n",
      " [66 14 19  7]\n",
      " [59 23 37 28]]\n",
      "Validation Loss for s21 = 1.3530389070510864\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_96/1313612177.py:43: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 70/100, Train Loss: 1.3690317869186401\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_96/1313612177.py:68: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/tmp/ipykernel_96/1313612177.py:88: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.18      0.49      0.27        74\n",
      "           1       0.15      0.11      0.13        73\n",
      "           2       0.24      0.19      0.21       106\n",
      "           3       0.45      0.20      0.28       147\n",
      "\n",
      "    accuracy                           0.23       400\n",
      "   macro avg       0.26      0.25      0.22       400\n",
      "weighted avg       0.29      0.23      0.23       400\n",
      "\n",
      "[[36  8 18 12]\n",
      " [34  8 14 17]\n",
      " [66 13 20  7]\n",
      " [59 25 33 30]]\n",
      "Validation Loss for s21 = 1.3541322946548462\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_96/1313612177.py:43: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 71/100, Train Loss: 1.3525530099868774\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_96/1313612177.py:68: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/tmp/ipykernel_96/1313612177.py:88: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.18      0.46      0.26        74\n",
      "           1       0.14      0.11      0.12        73\n",
      "           2       0.21      0.18      0.19       106\n",
      "           3       0.42      0.18      0.26       147\n",
      "\n",
      "    accuracy                           0.22       400\n",
      "   macro avg       0.24      0.23      0.21       400\n",
      "weighted avg       0.27      0.22      0.22       400\n",
      "\n",
      "[[34  9 19 12]\n",
      " [34  8 14 17]\n",
      " [63 16 19  8]\n",
      " [57 26 37 27]]\n",
      "Validation Loss for s21 = 1.3560209274291992\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_96/1313612177.py:43: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 72/100, Train Loss: 1.3604484796524048\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_96/1313612177.py:68: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/tmp/ipykernel_96/1313612177.py:88: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.18      0.47      0.27        74\n",
      "           1       0.15      0.11      0.13        73\n",
      "           2       0.22      0.20      0.21       106\n",
      "           3       0.44      0.18      0.26       147\n",
      "\n",
      "    accuracy                           0.23       400\n",
      "   macro avg       0.25      0.24      0.21       400\n",
      "weighted avg       0.28      0.23      0.22       400\n",
      "\n",
      "[[35  9 19 11]\n",
      " [33  8 16 16]\n",
      " [65 12 21  8]\n",
      " [57 24 39 27]]\n",
      "Validation Loss for s21 = 1.349756121635437\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_96/1313612177.py:43: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 73/100, Train Loss: 1.3597830533981323\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_96/1313612177.py:68: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/tmp/ipykernel_96/1313612177.py:88: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.18      0.46      0.26        74\n",
      "           1       0.15      0.11      0.13        73\n",
      "           2       0.23      0.18      0.20       106\n",
      "           3       0.43      0.22      0.29       147\n",
      "\n",
      "    accuracy                           0.23       400\n",
      "   macro avg       0.25      0.24      0.22       400\n",
      "weighted avg       0.28      0.23      0.23       400\n",
      "\n",
      "[[34  8 17 15]\n",
      " [34  8 12 19]\n",
      " [65 13 19  9]\n",
      " [57 24 34 32]]\n",
      "Validation Loss for s21 = 1.3465046882629395\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_96/1313612177.py:43: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 74/100, Train Loss: 1.3684860467910767\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_96/1313612177.py:68: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/tmp/ipykernel_96/1313612177.py:88: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.18      0.46      0.26        74\n",
      "           1       0.14      0.11      0.12        73\n",
      "           2       0.21      0.17      0.19       106\n",
      "           3       0.42      0.20      0.27       147\n",
      "\n",
      "    accuracy                           0.22       400\n",
      "   macro avg       0.24      0.23      0.21       400\n",
      "weighted avg       0.27      0.22      0.22       400\n",
      "\n",
      "[[34  9 18 13]\n",
      " [34  8 13 18]\n",
      " [64 15 18  9]\n",
      " [57 24 37 29]]\n",
      "Validation Loss for s21 = 1.3529609441757202\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_96/1313612177.py:43: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 75/100, Train Loss: 1.3131999969482422\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_96/1313612177.py:68: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/tmp/ipykernel_96/1313612177.py:88: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.18      0.47      0.27        74\n",
      "           1       0.18      0.14      0.16        73\n",
      "           2       0.22      0.18      0.20       106\n",
      "           3       0.43      0.20      0.28       147\n",
      "\n",
      "    accuracy                           0.23       400\n",
      "   macro avg       0.26      0.25      0.22       400\n",
      "weighted avg       0.29      0.23      0.23       400\n",
      "\n",
      "[[35  8 18 13]\n",
      " [33 10 13 17]\n",
      " [65 13 19  9]\n",
      " [57 24 36 30]]\n",
      "Validation Loss for s21 = 1.3519244194030762\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_96/1313612177.py:43: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 76/100, Train Loss: 1.300172209739685\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_96/1313612177.py:68: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/tmp/ipykernel_96/1313612177.py:88: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.19      0.49      0.27        74\n",
      "           1       0.14      0.11      0.12        73\n",
      "           2       0.21      0.16      0.18       106\n",
      "           3       0.45      0.20      0.28       147\n",
      "\n",
      "    accuracy                           0.23       400\n",
      "   macro avg       0.25      0.24      0.21       400\n",
      "weighted avg       0.28      0.23      0.22       400\n",
      "\n",
      "[[36  9 17 12]\n",
      " [34  8 14 17]\n",
      " [65 17 17  7]\n",
      " [58 25 34 30]]\n",
      "Validation Loss for s21 = 1.3556703329086304\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_96/1313612177.py:43: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 77/100, Train Loss: 1.3180750608444214\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_96/1313612177.py:68: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/tmp/ipykernel_96/1313612177.py:88: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.18      0.46      0.26        74\n",
      "           1       0.13      0.11      0.12        73\n",
      "           2       0.22      0.18      0.20       106\n",
      "           3       0.46      0.20      0.28       147\n",
      "\n",
      "    accuracy                           0.23       400\n",
      "   macro avg       0.25      0.24      0.21       400\n",
      "weighted avg       0.28      0.23      0.22       400\n",
      "\n",
      "[[34 10 18 12]\n",
      " [34  8 16 15]\n",
      " [64 16 19  7]\n",
      " [57 26 35 29]]\n",
      "Validation Loss for s21 = 1.3555519580841064\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_96/1313612177.py:43: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 78/100, Train Loss: 1.324057698249817\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_96/1313612177.py:68: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/tmp/ipykernel_96/1313612177.py:88: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.19      0.50      0.28        74\n",
      "           1       0.15      0.12      0.14        73\n",
      "           2       0.22      0.19      0.21       106\n",
      "           3       0.47      0.20      0.28       147\n",
      "\n",
      "    accuracy                           0.24       400\n",
      "   macro avg       0.26      0.25      0.22       400\n",
      "weighted avg       0.30      0.24      0.23       400\n",
      "\n",
      "[[37  9 17 11]\n",
      " [33  9 16 15]\n",
      " [63 16 20  7]\n",
      " [57 25 36 29]]\n",
      "Validation Loss for s21 = 1.3569163084030151\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_96/1313612177.py:43: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 79/100, Train Loss: 1.2869837284088135\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_96/1313612177.py:68: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/tmp/ipykernel_96/1313612177.py:88: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.20      0.53      0.29        74\n",
      "           1       0.16      0.12      0.14        73\n",
      "           2       0.24      0.19      0.21       106\n",
      "           3       0.48      0.22      0.30       147\n",
      "\n",
      "    accuracy                           0.25       400\n",
      "   macro avg       0.27      0.26      0.24       400\n",
      "weighted avg       0.31      0.25      0.25       400\n",
      "\n",
      "[[39  8 15 12]\n",
      " [34  9 14 16]\n",
      " [64 15 20  7]\n",
      " [57 24 34 32]]\n",
      "Validation Loss for s21 = 1.3530583381652832\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_96/1313612177.py:43: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 80/100, Train Loss: 1.3435570001602173\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_96/1313612177.py:68: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/tmp/ipykernel_96/1313612177.py:88: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/tmp/ipykernel_96/1313612177.py:43: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.20      0.53      0.28        74\n",
      "           1       0.14      0.10      0.11        73\n",
      "           2       0.23      0.18      0.20       106\n",
      "           3       0.45      0.20      0.28       147\n",
      "\n",
      "    accuracy                           0.24       400\n",
      "   macro avg       0.25      0.25      0.22       400\n",
      "weighted avg       0.29      0.24      0.23       400\n",
      "\n",
      "[[39  8 15 12]\n",
      " [35  7 14 17]\n",
      " [66 14 19  7]\n",
      " [60 22 35 30]]\n",
      "Validation Loss for s21 = 1.3560677766799927\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 81/100, Train Loss: 1.3422973155975342\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_96/1313612177.py:68: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/tmp/ipykernel_96/1313612177.py:88: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.18      0.46      0.26        74\n",
      "           1       0.14      0.11      0.12        73\n",
      "           2       0.21      0.18      0.19       106\n",
      "           3       0.46      0.20      0.28       147\n",
      "\n",
      "    accuracy                           0.23       400\n",
      "   macro avg       0.25      0.24      0.21       400\n",
      "weighted avg       0.29      0.23      0.23       400\n",
      "\n",
      "[[34 10 18 12]\n",
      " [33  8 16 16]\n",
      " [65 15 19  7]\n",
      " [57 24 36 30]]\n",
      "Validation Loss for s21 = 1.3571058511734009\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_96/1313612177.py:43: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 82/100, Train Loss: 1.4292372465133667\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_96/1313612177.py:68: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/tmp/ipykernel_96/1313612177.py:88: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/tmp/ipykernel_96/1313612177.py:43: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.19      0.50      0.28        74\n",
      "           1       0.14      0.11      0.12        73\n",
      "           2       0.23      0.18      0.20       106\n",
      "           3       0.47      0.22      0.30       147\n",
      "\n",
      "    accuracy                           0.24       400\n",
      "   macro avg       0.26      0.25      0.22       400\n",
      "weighted avg       0.29      0.24      0.24       400\n",
      "\n",
      "[[37  8 16 13]\n",
      " [33  8 16 16]\n",
      " [65 15 19  7]\n",
      " [57 25 33 32]]\n",
      "Validation Loss for s21 = 1.3578388690948486\n",
      "Epoch 83/100, Train Loss: 1.3256138563156128\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_96/1313612177.py:68: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/tmp/ipykernel_96/1313612177.py:88: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/tmp/ipykernel_96/1313612177.py:43: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.18      0.46      0.26        74\n",
      "           1       0.13      0.11      0.12        73\n",
      "           2       0.22      0.18      0.20       106\n",
      "           3       0.45      0.20      0.28       147\n",
      "\n",
      "    accuracy                           0.23       400\n",
      "   macro avg       0.25      0.24      0.21       400\n",
      "weighted avg       0.28      0.23      0.23       400\n",
      "\n",
      "[[34 10 18 12]\n",
      " [32  8 16 17]\n",
      " [64 16 19  7]\n",
      " [56 26 35 30]]\n",
      "Validation Loss for s21 = 1.356910228729248\n",
      "Epoch 84/100, Train Loss: 1.4603030681610107\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_96/1313612177.py:68: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/tmp/ipykernel_96/1313612177.py:88: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.18      0.46      0.26        74\n",
      "           1       0.14      0.11      0.12        73\n",
      "           2       0.24      0.19      0.21       106\n",
      "           3       0.48      0.23      0.31       147\n",
      "\n",
      "    accuracy                           0.24       400\n",
      "   macro avg       0.26      0.25      0.23       400\n",
      "weighted avg       0.30      0.24      0.24       400\n",
      "\n",
      "[[34 10 18 12]\n",
      " [32  8 15 18]\n",
      " [63 16 20  7]\n",
      " [57 24 32 34]]\n",
      "Validation Loss for s21 = 1.3560450077056885\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_96/1313612177.py:43: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 85/100, Train Loss: 1.3368724584579468\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_96/1313612177.py:68: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/tmp/ipykernel_96/1313612177.py:88: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/tmp/ipykernel_96/1313612177.py:43: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.19      0.51      0.28        74\n",
      "           1       0.16      0.12      0.14        73\n",
      "           2       0.23      0.18      0.20       106\n",
      "           3       0.45      0.20      0.27       147\n",
      "\n",
      "    accuracy                           0.24       400\n",
      "   macro avg       0.26      0.25      0.22       400\n",
      "weighted avg       0.29      0.24      0.23       400\n",
      "\n",
      "[[38  8 16 12]\n",
      " [35  9 13 16]\n",
      " [65 15 19  7]\n",
      " [59 24 35 29]]\n",
      "Validation Loss for s21 = 1.35835599899292\n",
      "Epoch 86/100, Train Loss: 1.2782659530639648\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_96/1313612177.py:68: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/tmp/ipykernel_96/1313612177.py:88: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/tmp/ipykernel_96/1313612177.py:43: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.18      0.46      0.26        74\n",
      "           1       0.16      0.14      0.15        73\n",
      "           2       0.20      0.16      0.18       106\n",
      "           3       0.45      0.20      0.27       147\n",
      "\n",
      "    accuracy                           0.23       400\n",
      "   macro avg       0.25      0.24      0.21       400\n",
      "weighted avg       0.28      0.23      0.22       400\n",
      "\n",
      "[[34 10 18 12]\n",
      " [33 10 14 16]\n",
      " [64 17 17  8]\n",
      " [58 24 36 29]]\n",
      "Validation Loss for s21 = 1.3577299118041992\n",
      "Epoch 87/100, Train Loss: 1.3259254693984985\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_96/1313612177.py:68: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/tmp/ipykernel_96/1313612177.py:88: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/tmp/ipykernel_96/1313612177.py:43: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.18      0.45      0.26        74\n",
      "           1       0.16      0.14      0.15        73\n",
      "           2       0.22      0.20      0.21       106\n",
      "           3       0.50      0.22      0.30       147\n",
      "\n",
      "    accuracy                           0.24       400\n",
      "   macro avg       0.27      0.25      0.23       400\n",
      "weighted avg       0.31      0.24      0.24       400\n",
      "\n",
      "[[33 11 20 10]\n",
      " [32 10 16 15]\n",
      " [62 16 21  7]\n",
      " [53 25 37 32]]\n",
      "Validation Loss for s21 = 1.353609323501587\n",
      "Epoch 88/100, Train Loss: 1.32947838306427\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_96/1313612177.py:68: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/tmp/ipykernel_96/1313612177.py:88: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.19      0.50      0.28        74\n",
      "           1       0.15      0.11      0.12        73\n",
      "           2       0.22      0.20      0.21       106\n",
      "           3       0.50      0.20      0.28       147\n",
      "\n",
      "    accuracy                           0.24       400\n",
      "   macro avg       0.27      0.25      0.22       400\n",
      "weighted avg       0.30      0.24      0.23       400\n",
      "\n",
      "[[37 10 19  8]\n",
      " [34  8 17 14]\n",
      " [64 14 21  7]\n",
      " [58 23 37 29]]\n",
      "Validation Loss for s21 = 1.35636305809021\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_96/1313612177.py:43: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 89/100, Train Loss: 1.3079051971435547\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_96/1313612177.py:68: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/tmp/ipykernel_96/1313612177.py:88: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.19      0.47      0.27        74\n",
      "           1       0.16      0.12      0.14        73\n",
      "           2       0.22      0.19      0.20       106\n",
      "           3       0.49      0.22      0.30       147\n",
      "\n",
      "    accuracy                           0.24       400\n",
      "   macro avg       0.26      0.25      0.23       400\n",
      "weighted avg       0.30      0.24      0.24       400\n",
      "\n",
      "[[35 11 18 10]\n",
      " [33  9 16 15]\n",
      " [64 14 20  8]\n",
      " [55 23 37 32]]\n",
      "Validation Loss for s21 = 1.3483011722564697\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_96/1313612177.py:43: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 90/100, Train Loss: 1.4159194231033325\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_96/1313612177.py:68: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/tmp/ipykernel_96/1313612177.py:88: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.18      0.46      0.26        74\n",
      "           1       0.14      0.11      0.12        73\n",
      "           2       0.22      0.19      0.20       106\n",
      "           3       0.48      0.21      0.29       147\n",
      "\n",
      "    accuracy                           0.23       400\n",
      "   macro avg       0.26      0.24      0.22       400\n",
      "weighted avg       0.29      0.23      0.23       400\n",
      "\n",
      "[[34 11 19 10]\n",
      " [33  8 17 15]\n",
      " [64 14 20  8]\n",
      " [55 24 37 31]]\n",
      "Validation Loss for s21 = 1.35740327835083\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_96/1313612177.py:43: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 91/100, Train Loss: 1.4044253826141357\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_96/1313612177.py:68: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/tmp/ipykernel_96/1313612177.py:88: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.18      0.46      0.26        74\n",
      "           1       0.16      0.14      0.15        73\n",
      "           2       0.21      0.18      0.19       106\n",
      "           3       0.50      0.21      0.30       147\n",
      "\n",
      "    accuracy                           0.23       400\n",
      "   macro avg       0.26      0.25      0.23       400\n",
      "weighted avg       0.30      0.23      0.24       400\n",
      "\n",
      "[[34 12 19  9]\n",
      " [33 10 16 14]\n",
      " [62 17 19  8]\n",
      " [55 24 37 31]]\n",
      "Validation Loss for s21 = 1.3598101139068604\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_96/1313612177.py:43: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 92/100, Train Loss: 1.3262112140655518\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_96/1313612177.py:68: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/tmp/ipykernel_96/1313612177.py:88: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.19      0.46      0.27        74\n",
      "           1       0.16      0.14      0.15        73\n",
      "           2       0.21      0.19      0.20       106\n",
      "           3       0.49      0.20      0.29       147\n",
      "\n",
      "    accuracy                           0.23       400\n",
      "   macro avg       0.26      0.25      0.23       400\n",
      "weighted avg       0.30      0.23      0.23       400\n",
      "\n",
      "[[34 12 20  8]\n",
      " [32 10 16 15]\n",
      " [60 18 20  8]\n",
      " [54 24 39 30]]\n",
      "Validation Loss for s21 = 1.3613977432250977\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_96/1313612177.py:43: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 93/100, Train Loss: 1.3387686014175415\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_96/1313612177.py:68: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/tmp/ipykernel_96/1313612177.py:88: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.19      0.46      0.27        74\n",
      "           1       0.16      0.15      0.16        73\n",
      "           2       0.19      0.16      0.17       106\n",
      "           3       0.48      0.20      0.29       147\n",
      "\n",
      "    accuracy                           0.23       400\n",
      "   macro avg       0.26      0.24      0.22       400\n",
      "weighted avg       0.29      0.23      0.23       400\n",
      "\n",
      "[[34 12 20  8]\n",
      " [32 11 16 14]\n",
      " [58 21 17 10]\n",
      " [55 24 38 30]]\n",
      "Validation Loss for s21 = 1.3621586561203003\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_96/1313612177.py:43: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 94/100, Train Loss: 1.294637680053711\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_96/1313612177.py:68: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/tmp/ipykernel_96/1313612177.py:88: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.19      0.47      0.27        74\n",
      "           1       0.14      0.11      0.12        73\n",
      "           2       0.22      0.20      0.21       106\n",
      "           3       0.48      0.20      0.29       147\n",
      "\n",
      "    accuracy                           0.23       400\n",
      "   macro avg       0.26      0.25      0.22       400\n",
      "weighted avg       0.29      0.23      0.23       400\n",
      "\n",
      "[[35 11 18 10]\n",
      " [33  8 17 15]\n",
      " [63 14 21  8]\n",
      " [54 23 40 30]]\n",
      "Validation Loss for s21 = 1.3605782985687256\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_96/1313612177.py:43: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 95/100, Train Loss: 1.282664179801941\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_96/1313612177.py:68: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/tmp/ipykernel_96/1313612177.py:88: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.19      0.47      0.27        74\n",
      "           1       0.15      0.12      0.13        73\n",
      "           2       0.20      0.17      0.18       106\n",
      "           3       0.47      0.20      0.28       147\n",
      "\n",
      "    accuracy                           0.23       400\n",
      "   macro avg       0.25      0.24      0.22       400\n",
      "weighted avg       0.29      0.23      0.23       400\n",
      "\n",
      "[[35 12 17 10]\n",
      " [32  9 18 14]\n",
      " [62 16 18 10]\n",
      " [55 24 38 30]]\n",
      "Validation Loss for s21 = 1.3589166402816772\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_96/1313612177.py:43: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 96/100, Train Loss: 1.4159339666366577\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_96/1313612177.py:68: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/tmp/ipykernel_96/1313612177.py:88: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.19      0.47      0.27        74\n",
      "           1       0.16      0.12      0.14        73\n",
      "           2       0.23      0.20      0.21       106\n",
      "           3       0.48      0.21      0.29       147\n",
      "\n",
      "    accuracy                           0.24       400\n",
      "   macro avg       0.26      0.25      0.23       400\n",
      "weighted avg       0.30      0.24      0.24       400\n",
      "\n",
      "[[35 11 18 10]\n",
      " [33  9 15 16]\n",
      " [63 14 21  8]\n",
      " [56 23 37 31]]\n",
      "Validation Loss for s21 = 1.3625742197036743\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_96/1313612177.py:43: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 97/100, Train Loss: 1.3196262121200562\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_96/1313612177.py:68: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/tmp/ipykernel_96/1313612177.py:88: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.18      0.45      0.26        74\n",
      "           1       0.16      0.12      0.14        73\n",
      "           2       0.24      0.22      0.23       106\n",
      "           3       0.48      0.22      0.30       147\n",
      "\n",
      "    accuracy                           0.24       400\n",
      "   macro avg       0.26      0.25      0.23       400\n",
      "weighted avg       0.30      0.24      0.24       400\n",
      "\n",
      "[[33 11 20 10]\n",
      " [33  9 16 15]\n",
      " [60 13 23 10]\n",
      " [54 23 38 32]]\n",
      "Validation Loss for s21 = 1.356074571609497\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_96/1313612177.py:43: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 98/100, Train Loss: 1.2641769647598267\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_96/1313612177.py:68: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/tmp/ipykernel_96/1313612177.py:88: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.19      0.45      0.26        74\n",
      "           1       0.18      0.15      0.16        73\n",
      "           2       0.25      0.22      0.23       106\n",
      "           3       0.46      0.21      0.29       147\n",
      "\n",
      "    accuracy                           0.24       400\n",
      "   macro avg       0.27      0.26      0.24       400\n",
      "weighted avg       0.30      0.24      0.25       400\n",
      "\n",
      "[[33 12 17 12]\n",
      " [31 11 15 16]\n",
      " [61 13 23  9]\n",
      " [53 25 38 31]]\n",
      "Validation Loss for s21 = 1.3624770641326904\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_96/1313612177.py:43: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 99/100, Train Loss: 1.4348547458648682\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_96/1313612177.py:68: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/tmp/ipykernel_96/1313612177.py:88: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/tmp/ipykernel_96/1313612177.py:43: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.19      0.45      0.26        74\n",
      "           1       0.19      0.15      0.17        73\n",
      "           2       0.25      0.22      0.23       106\n",
      "           3       0.44      0.22      0.29       147\n",
      "\n",
      "    accuracy                           0.25       400\n",
      "   macro avg       0.27      0.26      0.24       400\n",
      "weighted avg       0.30      0.25      0.25       400\n",
      "\n",
      "[[33 13 16 12]\n",
      " [31 11 14 17]\n",
      " [60 12 23 11]\n",
      " [54 23 38 32]]\n",
      "Validation Loss for s21 = 1.360675573348999\n",
      "Epoch 100/100, Train Loss: 1.3344166278839111\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_96/1313612177.py:68: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/tmp/ipykernel_96/1313612177.py:88: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.19      0.46      0.27        74\n",
      "           1       0.18      0.14      0.15        73\n",
      "           2       0.24      0.21      0.22       106\n",
      "           3       0.45      0.22      0.29       147\n",
      "\n",
      "    accuracy                           0.24       400\n",
      "   macro avg       0.26      0.26      0.23       400\n",
      "weighted avg       0.30      0.24      0.24       400\n",
      "\n",
      "[[34 11 17 12]\n",
      " [32 10 16 15]\n",
      " [60 12 22 12]\n",
      " [53 24 38 32]]\n",
      "Validation Loss for s21 = 1.359056830406189\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x7fd0a4370310>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1000x700 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import confusion_matrix,classification_report\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import preprocessing\n",
    "import matplotlib.pyplot as plt\n",
    "#subjectnames\n",
    "file_list_num = np.arange(len(newsubjectname))\n",
    "file_list_numd = np.arange(len(subjectnamesd))\n",
    "\n",
    "kf = KFold(n_splits=12)\n",
    "torch.manual_seed(42)\n",
    "torch.cuda.manual_seed(42)\n",
    "modellist = []\n",
    "modelid = 1\n",
    "#file_list_num\n",
    "#for i, (train_index, test_index) in enumerate(kf.split(file_list_num)):\n",
    "#for train_index in file_list_num:\n",
    "train_index = file_list_num\n",
    "#test_index = file_list_numd\n",
    "test_index_train, test_index_test = train_test_split(file_list_numd, test_size=0.30, random_state=42)\n",
    "print(f\"Fold {i}:\")\n",
    "print(f\"  Train: index={train_index}\")\n",
    "#print(f\"  Test:  index={test_index}\")\n",
    "net = Net()\n",
    "net.to(device)\n",
    "optimizer = optim.Adam(net.parameters(), lr=0.000001)\n",
    "epochs = 100\n",
    "batch_sz = 20\n",
    "train_loss_epoch = []\n",
    "val_loss_epoch = []\n",
    "for epoch in range(epochs):\n",
    "  train_loss = []\n",
    "  for tr in train_index:\n",
    "    v = data_c1d[newsubjectname[tr]]\n",
    "    l = data_c2[newsubjectname[tr]]\n",
    "    #print(v[0].shape)\n",
    "    net.train()\n",
    "    for i in range(0,len(v),batch_sz):\n",
    "      #print(v[i].shape)\n",
    "      #for j in range(0,v[i].shape[0],batch_sz):\n",
    "      #print(newsubjectname[tr])\n",
    "      optimizer.zero_grad()\n",
    "      outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
    "      #print(\"Expout {}\",outputs.shape)\n",
    "      #print(\"Actual {}\",l[i:i+batch_sz].shape)\n",
    "      #print(l[i].shape)\n",
    "      loss = criterion(outputs, l[i:i+batch_sz].to(device, dtype=torch.float))\n",
    "      loss.backward()\n",
    "      train_loss.append(loss)\n",
    "      optimizer.step()\n",
    "  print(f'Epoch {epoch + 1}/{epochs}, Train Loss: {loss.item()}')\n",
    "  train_loss_epoch.append(torch.stack(train_loss).mean().cpu().detach().numpy())\n",
    "  #print(train_loss_epoch)\n",
    "  batch_sz = 20\n",
    "  expectedoutputdeap = []\n",
    "  actualoutputdeap = []\n",
    "\n",
    "  for tr in test_index_train:\n",
    "    v = data_de1[subjectnamesd[tr]]\n",
    "    l = data_del[subjectnamesd[tr]]\n",
    "    #print(v[0].shape)\n",
    "    net.train()\n",
    "    for i in range(0,len(v),batch_sz):\n",
    "      #print(v[i].shape)\n",
    "      #for j in range(0,v[i].shape[0],batch_sz):\n",
    "      #print(newsubjectname[tr])\n",
    "      optimizer.zero_grad()\n",
    "      outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
    "      #print(\"Expout {}\",outputs.shape)\n",
    "      #print(\"Actual {}\",l[i:i+batch_sz].shape)\n",
    "      #print(l[i].shape)\n",
    "      loss = criterion(outputs, l[i:i+batch_sz].to(device, dtype=torch.float))\n",
    "      loss.backward()\n",
    "      train_loss.append(loss)\n",
    "      optimizer.step()\n",
    "\n",
    "  for tr in test_index_test:\n",
    "      net.eval()\n",
    "      v = data_de1[subjectnamesd[tr]]\n",
    "      l = data_del[subjectnamesd[tr]]\n",
    "      net.eval()\n",
    "      val_loss = []\n",
    "      with torch.no_grad():\n",
    "          for i in range(0,len(v),batch_sz):\n",
    "            #print(v[i].shape)\n",
    "            #for j in range(0,v[i].shape[0],batch_sz):\n",
    "            optimizer.zero_grad()\n",
    "            outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
    "            #print(outputs.shape)\n",
    "            #print(l[i:i+batch_sz].shape)\n",
    "            loss = criterion(outputs, l[i:i+batch_sz].to(device, dtype=torch.float))\n",
    "            val_loss.append(loss)\n",
    "            #actualoutputdeap.append(torch.round(outputs.cpu()))\n",
    "            #expectedoutputdeap.append(l[i:i+batch_sz])\n",
    "            actualoutputdeap.append(torch.argmax(torch.softmax(outputs.cpu(),dim=1),dim=1))\n",
    "            expectedoutputdeap.append(torch.argmax(l[i:i+batch_sz],dim=1).numpy())\n",
    "  val_loss_mean = torch.stack(val_loss).mean().cpu().detach().numpy()\n",
    "  val_loss_epoch.append(val_loss_mean)\n",
    "  expectedoutputdeap = np.concatenate( expectedoutputdeap, axis=0 )\n",
    "  actualoutputdeap = np.concatenate( actualoutputdeap, axis=0 )\n",
    "  #print(expectedoutput.shape)\n",
    "  #print(actualoutput.shape)\n",
    "  print(classification_report(expectedoutputdeap,actualoutputdeap))\n",
    "  print(confusion_matrix(expectedoutputdeap,actualoutputdeap))\n",
    "  print(f'Validation Loss for {subjectnamesd[tr]} = {val_loss_mean}')\n",
    "plt.figure(figsize=(10,7))\n",
    "#print(len(train_loss_epoch))\n",
    "plt.plot(np.arange(epochs),train_loss_epoch,label='Train')\n",
    "plt.plot(np.arange(epochs),val_loss_epoch,label='Validation')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82511330-d09b-4538-a8f5-32a8c2e5d91e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-23T13:23:28.057924Z",
     "iopub.status.busy": "2024-01-23T13:23:28.057100Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 20:\n",
      "  Train: index=[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23\n",
      " 24 25 26 27 28 29 30 31]\n",
      "  Test:  index=[34  0  4 29 15 19  5 11  1 24  2 33  3 32 23 27 10 22 18 25  6 20  7 14\n",
      " 28]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_96/2974510044.py:43: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n",
      "/tmp/ipykernel_96/2974510044.py:61: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100, Train Loss: 1.3577150106430054\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.21      0.07      0.11        43\n",
      "           1       0.26      0.28      0.27        61\n",
      "           2       0.35      0.26      0.30        61\n",
      "           3       0.24      0.42      0.31        55\n",
      "\n",
      "    accuracy                           0.27       220\n",
      "   macro avg       0.27      0.26      0.25       220\n",
      "weighted avg       0.27      0.27      0.25       220\n",
      "\n",
      "[[ 3 14  5 21]\n",
      " [ 5 17  9 30]\n",
      " [ 4 21 16 20]\n",
      " [ 2 14 16 23]]\n",
      "Validation Loss for P40 = 1.4187015295028687\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_96/2974510044.py:87: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/tmp/ipykernel_96/2974510044.py:43: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n",
      "/tmp/ipykernel_96/2974510044.py:61: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/100, Train Loss: 1.376932978630066\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.34      0.49      0.40        43\n",
      "           1       0.31      0.31      0.31        61\n",
      "           2       0.33      0.28      0.30        61\n",
      "           3       0.33      0.27      0.30        55\n",
      "\n",
      "    accuracy                           0.33       220\n",
      "   macro avg       0.33      0.34      0.33       220\n",
      "weighted avg       0.33      0.33      0.32       220\n",
      "\n",
      "[[21 11  6  5]\n",
      " [16 19 10 16]\n",
      " [16 18 17 10]\n",
      " [ 9 13 18 15]]\n",
      "Validation Loss for P40 = 1.411934733390808\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_96/2974510044.py:87: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/tmp/ipykernel_96/2974510044.py:43: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n",
      "/tmp/ipykernel_96/2974510044.py:61: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/100, Train Loss: 1.4020754098892212\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.32      0.56      0.41        43\n",
      "           1       0.30      0.30      0.30        61\n",
      "           2       0.38      0.28      0.32        61\n",
      "           3       0.30      0.22      0.25        55\n",
      "\n",
      "    accuracy                           0.32       220\n",
      "   macro avg       0.32      0.34      0.32       220\n",
      "weighted avg       0.33      0.32      0.31       220\n",
      "\n",
      "[[24 10  5  4]\n",
      " [19 18 10 14]\n",
      " [18 16 17 10]\n",
      " [14 16 13 12]]\n",
      "Validation Loss for P40 = 1.408593773841858\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_96/2974510044.py:87: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/tmp/ipykernel_96/2974510044.py:43: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n",
      "/tmp/ipykernel_96/2974510044.py:61: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/100, Train Loss: 1.4329832792282104\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.29      0.58      0.39        43\n",
      "           1       0.28      0.20      0.23        61\n",
      "           2       0.38      0.33      0.35        61\n",
      "           3       0.33      0.24      0.27        55\n",
      "\n",
      "    accuracy                           0.32       220\n",
      "   macro avg       0.32      0.34      0.31       220\n",
      "weighted avg       0.32      0.32      0.31       220\n",
      "\n",
      "[[25  8  5  5]\n",
      " [23 12 12 14]\n",
      " [21 12 20  8]\n",
      " [16 11 15 13]]\n",
      "Validation Loss for P40 = 1.408947229385376\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_96/2974510044.py:87: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/tmp/ipykernel_96/2974510044.py:43: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n",
      "/tmp/ipykernel_96/2974510044.py:61: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/100, Train Loss: 1.3117915391921997\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.28      0.58      0.38        43\n",
      "           1       0.27      0.18      0.22        61\n",
      "           2       0.39      0.34      0.37        61\n",
      "           3       0.31      0.20      0.24        55\n",
      "\n",
      "    accuracy                           0.31       220\n",
      "   macro avg       0.31      0.33      0.30       220\n",
      "weighted avg       0.31      0.31      0.30       220\n",
      "\n",
      "[[25  8  5  5]\n",
      " [25 11 12 13]\n",
      " [22 11 21  7]\n",
      " [17 11 16 11]]\n",
      "Validation Loss for P40 = 1.4100793600082397\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_96/2974510044.py:87: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/tmp/ipykernel_96/2974510044.py:43: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n",
      "/tmp/ipykernel_96/2974510044.py:61: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6/100, Train Loss: 1.4328091144561768\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.27      0.56      0.37        43\n",
      "           1       0.26      0.21      0.23        61\n",
      "           2       0.46      0.26      0.33        61\n",
      "           3       0.30      0.25      0.27        55\n",
      "\n",
      "    accuracy                           0.30       220\n",
      "   macro avg       0.32      0.32      0.30       220\n",
      "weighted avg       0.33      0.30      0.30       220\n",
      "\n",
      "[[24  9  3  7]\n",
      " [25 13  7 16]\n",
      " [22 13 16 10]\n",
      " [17 15  9 14]]\n",
      "Validation Loss for P40 = 1.3974103927612305\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_96/2974510044.py:87: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/tmp/ipykernel_96/2974510044.py:43: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n",
      "/tmp/ipykernel_96/2974510044.py:61: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7/100, Train Loss: 1.3446555137634277\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.28      0.58      0.38        43\n",
      "           1       0.25      0.21      0.23        61\n",
      "           2       0.45      0.25      0.32        61\n",
      "           3       0.29      0.24      0.26        55\n",
      "\n",
      "    accuracy                           0.30       220\n",
      "   macro avg       0.32      0.32      0.30       220\n",
      "weighted avg       0.32      0.30      0.29       220\n",
      "\n",
      "[[25  8  3  7]\n",
      " [25 13  7 16]\n",
      " [22 15 15  9]\n",
      " [18 16  8 13]]\n",
      "Validation Loss for P40 = 1.3959490060806274\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_96/2974510044.py:87: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/tmp/ipykernel_96/2974510044.py:43: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n",
      "/tmp/ipykernel_96/2974510044.py:61: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8/100, Train Loss: 1.4171262979507446\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.27      0.58      0.37        43\n",
      "           1       0.27      0.23      0.25        61\n",
      "           2       0.45      0.25      0.32        61\n",
      "           3       0.32      0.25      0.28        55\n",
      "\n",
      "    accuracy                           0.31       220\n",
      "   macro avg       0.33      0.33      0.31       220\n",
      "weighted avg       0.33      0.31      0.30       220\n",
      "\n",
      "[[25  8  3  7]\n",
      " [26 14  7 14]\n",
      " [22 15 15  9]\n",
      " [18 15  8 14]]\n",
      "Validation Loss for P40 = 1.3976202011108398\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_96/2974510044.py:87: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/tmp/ipykernel_96/2974510044.py:43: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n",
      "/tmp/ipykernel_96/2974510044.py:61: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9/100, Train Loss: 1.4436120986938477\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.26      0.56      0.36        43\n",
      "           1       0.27      0.23      0.25        61\n",
      "           2       0.46      0.26      0.33        61\n",
      "           3       0.31      0.24      0.27        55\n",
      "\n",
      "    accuracy                           0.30       220\n",
      "   macro avg       0.33      0.32      0.30       220\n",
      "weighted avg       0.33      0.30      0.30       220\n",
      "\n",
      "[[24  9  3  7]\n",
      " [27 14  7 13]\n",
      " [23 13 16  9]\n",
      " [18 15  9 13]]\n",
      "Validation Loss for P40 = 1.3932468891143799\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_96/2974510044.py:87: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/tmp/ipykernel_96/2974510044.py:43: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n",
      "/tmp/ipykernel_96/2974510044.py:61: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10/100, Train Loss: 1.4726126194000244\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.26      0.56      0.36        43\n",
      "           1       0.29      0.26      0.28        61\n",
      "           2       0.48      0.23      0.31        61\n",
      "           3       0.33      0.27      0.30        55\n",
      "\n",
      "    accuracy                           0.31       220\n",
      "   macro avg       0.34      0.33      0.31       220\n",
      "weighted avg       0.35      0.31      0.31       220\n",
      "\n",
      "[[24  9  3  7]\n",
      " [26 16  5 14]\n",
      " [23 15 14  9]\n",
      " [18 15  7 15]]\n",
      "Validation Loss for P40 = 1.3901711702346802\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_96/2974510044.py:87: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/tmp/ipykernel_96/2974510044.py:43: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n",
      "/tmp/ipykernel_96/2974510044.py:61: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11/100, Train Loss: 1.4617708921432495\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.27      0.60      0.37        43\n",
      "           1       0.31      0.26      0.28        61\n",
      "           2       0.47      0.23      0.31        61\n",
      "           3       0.34      0.25      0.29        55\n",
      "\n",
      "    accuracy                           0.32       220\n",
      "   macro avg       0.35      0.34      0.31       220\n",
      "weighted avg       0.35      0.32      0.31       220\n",
      "\n",
      "[[26  7  3  7]\n",
      " [28 16  5 12]\n",
      " [25 14 14  8]\n",
      " [18 15  8 14]]\n",
      "Validation Loss for P40 = 1.3884048461914062\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_96/2974510044.py:87: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/tmp/ipykernel_96/2974510044.py:43: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n",
      "/tmp/ipykernel_96/2974510044.py:61: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12/100, Train Loss: 1.3704133033752441\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.27      0.60      0.37        43\n",
      "           1       0.30      0.25      0.27        61\n",
      "           2       0.45      0.25      0.32        61\n",
      "           3       0.33      0.24      0.27        55\n",
      "\n",
      "    accuracy                           0.31       220\n",
      "   macro avg       0.34      0.33      0.31       220\n",
      "weighted avg       0.34      0.31      0.30       220\n",
      "\n",
      "[[26  7  3  7]\n",
      " [28 15  6 12]\n",
      " [25 13 15  8]\n",
      " [18 15  9 13]]\n",
      "Validation Loss for P40 = 1.3895094394683838\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_96/2974510044.py:87: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/tmp/ipykernel_96/2974510044.py:43: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n",
      "/tmp/ipykernel_96/2974510044.py:61: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13/100, Train Loss: 1.365146517753601\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.27      0.58      0.36        43\n",
      "           1       0.31      0.26      0.29        61\n",
      "           2       0.47      0.23      0.31        61\n",
      "           3       0.36      0.29      0.32        55\n",
      "\n",
      "    accuracy                           0.32       220\n",
      "   macro avg       0.35      0.34      0.32       220\n",
      "weighted avg       0.36      0.32      0.32       220\n",
      "\n",
      "[[25  7  4  7]\n",
      " [27 16  5 13]\n",
      " [25 13 14  9]\n",
      " [17 15  7 16]]\n",
      "Validation Loss for P40 = 1.3890589475631714\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_96/2974510044.py:87: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/tmp/ipykernel_96/2974510044.py:43: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n",
      "/tmp/ipykernel_96/2974510044.py:61: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14/100, Train Loss: 1.4408514499664307\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.27      0.60      0.37        43\n",
      "           1       0.31      0.23      0.26        61\n",
      "           2       0.45      0.23      0.30        61\n",
      "           3       0.35      0.29      0.32        55\n",
      "\n",
      "    accuracy                           0.32       220\n",
      "   macro avg       0.34      0.34      0.31       220\n",
      "weighted avg       0.35      0.32      0.31       220\n",
      "\n",
      "[[26  5  5  7]\n",
      " [28 14  5 14]\n",
      " [25 13 14  9]\n",
      " [19 13  7 16]]\n",
      "Validation Loss for P40 = 1.3850816488265991\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_96/2974510044.py:87: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/tmp/ipykernel_96/2974510044.py:43: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n",
      "/tmp/ipykernel_96/2974510044.py:61: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15/100, Train Loss: 1.5525652170181274\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.27      0.58      0.37        43\n",
      "           1       0.31      0.25      0.28        61\n",
      "           2       0.38      0.25      0.30        61\n",
      "           3       0.30      0.22      0.25        55\n",
      "\n",
      "    accuracy                           0.30       220\n",
      "   macro avg       0.32      0.32      0.30       220\n",
      "weighted avg       0.32      0.30      0.29       220\n",
      "\n",
      "[[25  6  5  7]\n",
      " [26 15  7 13]\n",
      " [25 13 15  8]\n",
      " [17 14 12 12]]\n",
      "Validation Loss for P40 = 1.3872101306915283\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_96/2974510044.py:87: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/tmp/ipykernel_96/2974510044.py:43: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n",
      "/tmp/ipykernel_96/2974510044.py:61: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16/100, Train Loss: 1.491980791091919\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.26      0.58      0.36        43\n",
      "           1       0.32      0.26      0.29        61\n",
      "           2       0.43      0.20      0.27        61\n",
      "           3       0.34      0.29      0.31        55\n",
      "\n",
      "    accuracy                           0.31       220\n",
      "   macro avg       0.34      0.33      0.31       220\n",
      "weighted avg       0.34      0.31      0.30       220\n",
      "\n",
      "[[25  6  5  7]\n",
      " [26 16  5 14]\n",
      " [25 14 12 10]\n",
      " [19 14  6 16]]\n",
      "Validation Loss for P40 = 1.3854228258132935\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_96/2974510044.py:87: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/tmp/ipykernel_96/2974510044.py:43: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n",
      "/tmp/ipykernel_96/2974510044.py:61: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17/100, Train Loss: 1.5585073232650757\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.26      0.56      0.35        43\n",
      "           1       0.33      0.28      0.30        61\n",
      "           2       0.42      0.21      0.28        61\n",
      "           3       0.34      0.27      0.30        55\n",
      "\n",
      "    accuracy                           0.31       220\n",
      "   macro avg       0.34      0.33      0.31       220\n",
      "weighted avg       0.34      0.31      0.31       220\n",
      "\n",
      "[[24  7  5  7]\n",
      " [26 17  5 13]\n",
      " [25 14 13  9]\n",
      " [18 14  8 15]]\n",
      "Validation Loss for P40 = 1.3841251134872437\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_96/2974510044.py:87: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/tmp/ipykernel_96/2974510044.py:43: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n",
      "/tmp/ipykernel_96/2974510044.py:61: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 18/100, Train Loss: 1.4253458976745605\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.26      0.56      0.36        43\n",
      "           1       0.31      0.26      0.29        61\n",
      "           2       0.40      0.20      0.26        61\n",
      "           3       0.36      0.31      0.33        55\n",
      "\n",
      "    accuracy                           0.31       220\n",
      "   macro avg       0.33      0.33      0.31       220\n",
      "weighted avg       0.34      0.31      0.31       220\n",
      "\n",
      "[[24  7  5  7]\n",
      " [26 16  6 13]\n",
      " [25 14 12 10]\n",
      " [17 14  7 17]]\n",
      "Validation Loss for P40 = 1.3863104581832886\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_96/2974510044.py:87: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/tmp/ipykernel_96/2974510044.py:43: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n",
      "/tmp/ipykernel_96/2974510044.py:61: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19/100, Train Loss: 1.3247933387756348\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.26      0.56      0.35        43\n",
      "           1       0.28      0.23      0.25        61\n",
      "           2       0.35      0.20      0.25        61\n",
      "           3       0.35      0.27      0.31        55\n",
      "\n",
      "    accuracy                           0.30       220\n",
      "   macro avg       0.31      0.31      0.29       220\n",
      "weighted avg       0.31      0.30      0.29       220\n",
      "\n",
      "[[24  7  6  6]\n",
      " [27 14  7 13]\n",
      " [25 15 12  9]\n",
      " [17 14  9 15]]\n",
      "Validation Loss for P40 = 1.3816759586334229\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_96/2974510044.py:87: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/tmp/ipykernel_96/2974510044.py:43: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n",
      "/tmp/ipykernel_96/2974510044.py:61: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20/100, Train Loss: 1.3253430128097534\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.26      0.56      0.36        43\n",
      "           1       0.32      0.26      0.29        61\n",
      "           2       0.39      0.23      0.29        61\n",
      "           3       0.36      0.27      0.31        55\n",
      "\n",
      "    accuracy                           0.31       220\n",
      "   macro avg       0.33      0.33      0.31       220\n",
      "weighted avg       0.34      0.31      0.31       220\n",
      "\n",
      "[[24  7  6  6]\n",
      " [26 16  7 12]\n",
      " [25 13 14  9]\n",
      " [17 14  9 15]]\n",
      "Validation Loss for P40 = 1.3790878057479858\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_96/2974510044.py:87: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/tmp/ipykernel_96/2974510044.py:43: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n",
      "/tmp/ipykernel_96/2974510044.py:61: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 21/100, Train Loss: 1.289635181427002\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.27      0.58      0.36        43\n",
      "           1       0.32      0.25      0.28        61\n",
      "           2       0.44      0.28      0.34        61\n",
      "           3       0.38      0.27      0.32        55\n",
      "\n",
      "    accuracy                           0.33       220\n",
      "   macro avg       0.35      0.34      0.32       220\n",
      "weighted avg       0.36      0.33      0.32       220\n",
      "\n",
      "[[25  6  6  6]\n",
      " [27 15  7 12]\n",
      " [25 12 17  7]\n",
      " [17 14  9 15]]\n",
      "Validation Loss for P40 = 1.383111596107483\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_96/2974510044.py:87: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/tmp/ipykernel_96/2974510044.py:43: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n",
      "/tmp/ipykernel_96/2974510044.py:61: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 22/100, Train Loss: 1.3949357271194458\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.26      0.56      0.36        43\n",
      "           1       0.33      0.26      0.29        61\n",
      "           2       0.45      0.30      0.36        61\n",
      "           3       0.39      0.29      0.33        55\n",
      "\n",
      "    accuracy                           0.34       220\n",
      "   macro avg       0.36      0.35      0.34       220\n",
      "weighted avg       0.37      0.34      0.33       220\n",
      "\n",
      "[[24  7  6  6]\n",
      " [26 16  7 12]\n",
      " [24 12 18  7]\n",
      " [17 13  9 16]]\n",
      "Validation Loss for P40 = 1.3776201009750366\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_96/2974510044.py:87: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/tmp/ipykernel_96/2974510044.py:43: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n",
      "/tmp/ipykernel_96/2974510044.py:61: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 23/100, Train Loss: 1.3574507236480713\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.27      0.60      0.37        43\n",
      "           1       0.30      0.20      0.24        61\n",
      "           2       0.45      0.28      0.34        61\n",
      "           3       0.36      0.29      0.32        55\n",
      "\n",
      "    accuracy                           0.32       220\n",
      "   macro avg       0.34      0.34      0.32       220\n",
      "weighted avg       0.35      0.32      0.31       220\n",
      "\n",
      "[[26  5  6  6]\n",
      " [30 12  6 13]\n",
      " [25 10 17  9]\n",
      " [17 13  9 16]]\n",
      "Validation Loss for P40 = 1.3777981996536255\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_96/2974510044.py:87: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/tmp/ipykernel_96/2974510044.py:43: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n",
      "/tmp/ipykernel_96/2974510044.py:61: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 24/100, Train Loss: 1.4168967008590698\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.26      0.58      0.36        43\n",
      "           1       0.30      0.21      0.25        61\n",
      "           2       0.44      0.26      0.33        61\n",
      "           3       0.38      0.31      0.34        55\n",
      "\n",
      "    accuracy                           0.32       220\n",
      "   macro avg       0.35      0.34      0.32       220\n",
      "weighted avg       0.35      0.32      0.32       220\n",
      "\n",
      "[[25  6  6  6]\n",
      " [29 13  6 13]\n",
      " [25 11 16  9]\n",
      " [17 13  8 17]]\n",
      "Validation Loss for P40 = 1.3765473365783691\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_96/2974510044.py:87: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/tmp/ipykernel_96/2974510044.py:43: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n",
      "/tmp/ipykernel_96/2974510044.py:61: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 25/100, Train Loss: 1.450889229774475\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.26      0.56      0.36        43\n",
      "           1       0.28      0.21      0.24        61\n",
      "           2       0.41      0.26      0.32        61\n",
      "           3       0.35      0.27      0.31        55\n",
      "\n",
      "    accuracy                           0.31       220\n",
      "   macro avg       0.33      0.33      0.31       220\n",
      "weighted avg       0.33      0.31      0.30       220\n",
      "\n",
      "[[24  7  6  6]\n",
      " [28 13  7 13]\n",
      " [24 12 16  9]\n",
      " [16 14 10 15]]\n",
      "Validation Loss for P40 = 1.377549409866333\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_96/2974510044.py:87: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/tmp/ipykernel_96/2974510044.py:43: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n",
      "/tmp/ipykernel_96/2974510044.py:61: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 26/100, Train Loss: 1.364749789237976\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.26      0.56      0.36        43\n",
      "           1       0.29      0.23      0.25        61\n",
      "           2       0.41      0.26      0.32        61\n",
      "           3       0.38      0.27      0.32        55\n",
      "\n",
      "    accuracy                           0.31       220\n",
      "   macro avg       0.33      0.33      0.31       220\n",
      "weighted avg       0.34      0.31      0.31       220\n",
      "\n",
      "[[24  7  7  5]\n",
      " [28 14  7 12]\n",
      " [24 13 16  8]\n",
      " [16 15  9 15]]\n",
      "Validation Loss for P40 = 1.3759098052978516\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_96/2974510044.py:87: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/tmp/ipykernel_96/2974510044.py:43: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n",
      "/tmp/ipykernel_96/2974510044.py:61: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 27/100, Train Loss: 1.3228174448013306\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.27      0.60      0.37        43\n",
      "           1       0.28      0.18      0.22        61\n",
      "           2       0.39      0.25      0.30        61\n",
      "           3       0.33      0.27      0.30        55\n",
      "\n",
      "    accuracy                           0.30       220\n",
      "   macro avg       0.32      0.33      0.30       220\n",
      "weighted avg       0.32      0.30      0.29       220\n",
      "\n",
      "[[26  5  7  5]\n",
      " [29 11  7 14]\n",
      " [25 10 15 11]\n",
      " [17 14  9 15]]\n",
      "Validation Loss for P40 = 1.3694981336593628\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_96/2974510044.py:87: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/tmp/ipykernel_96/2974510044.py:43: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n",
      "/tmp/ipykernel_96/2974510044.py:61: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 28/100, Train Loss: 1.3317664861679077\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.27      0.58      0.37        43\n",
      "           1       0.30      0.21      0.25        61\n",
      "           2       0.41      0.28      0.33        61\n",
      "           3       0.35      0.27      0.31        55\n",
      "\n",
      "    accuracy                           0.32       220\n",
      "   macro avg       0.33      0.34      0.31       220\n",
      "weighted avg       0.34      0.32      0.31       220\n",
      "\n",
      "[[25  6  6  6]\n",
      " [26 13  8 14]\n",
      " [24 12 17  8]\n",
      " [17 13 10 15]]\n",
      "Validation Loss for P40 = 1.3712488412857056\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_96/2974510044.py:87: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/tmp/ipykernel_96/2974510044.py:43: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n",
      "/tmp/ipykernel_96/2974510044.py:61: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 29/100, Train Loss: 1.3627420663833618\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.27      0.60      0.37        43\n",
      "           1       0.27      0.18      0.22        61\n",
      "           2       0.41      0.26      0.32        61\n",
      "           3       0.35      0.27      0.31        55\n",
      "\n",
      "    accuracy                           0.31       220\n",
      "   macro avg       0.32      0.33      0.30       220\n",
      "weighted avg       0.33      0.31      0.30       220\n",
      "\n",
      "[[26  5  7  5]\n",
      " [29 11  7 14]\n",
      " [25 11 16  9]\n",
      " [17 14  9 15]]\n",
      "Validation Loss for P40 = 1.3725799322128296\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_96/2974510044.py:87: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/tmp/ipykernel_96/2974510044.py:43: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n",
      "/tmp/ipykernel_96/2974510044.py:61: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 30/100, Train Loss: 1.346318244934082\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.27      0.60      0.37        43\n",
      "           1       0.26      0.16      0.20        61\n",
      "           2       0.44      0.33      0.38        61\n",
      "           3       0.36      0.25      0.30        55\n",
      "\n",
      "    accuracy                           0.32       220\n",
      "   macro avg       0.33      0.34      0.31       220\n",
      "weighted avg       0.34      0.32      0.31       220\n",
      "\n",
      "[[26  5  7  5]\n",
      " [29 10  8 14]\n",
      " [25 10 20  6]\n",
      " [17 14 10 14]]\n",
      "Validation Loss for P40 = 1.3713691234588623\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_96/2974510044.py:87: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/tmp/ipykernel_96/2974510044.py:43: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n",
      "/tmp/ipykernel_96/2974510044.py:61: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 31/100, Train Loss: 1.4610604047775269\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.26      0.60      0.37        43\n",
      "           1       0.24      0.15      0.18        61\n",
      "           2       0.44      0.30      0.35        61\n",
      "           3       0.38      0.29      0.33        55\n",
      "\n",
      "    accuracy                           0.31       220\n",
      "   macro avg       0.33      0.33      0.31       220\n",
      "weighted avg       0.33      0.31      0.30       220\n",
      "\n",
      "[[26  5  7  5]\n",
      " [30  9  8 14]\n",
      " [26 10 18  7]\n",
      " [17 14  8 16]]\n",
      "Validation Loss for P40 = 1.3704184293746948\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_96/2974510044.py:87: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/tmp/ipykernel_96/2974510044.py:43: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n",
      "/tmp/ipykernel_96/2974510044.py:61: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 32/100, Train Loss: 1.3887933492660522\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.27      0.60      0.37        43\n",
      "           1       0.26      0.16      0.20        61\n",
      "           2       0.44      0.33      0.38        61\n",
      "           3       0.38      0.27      0.32        55\n",
      "\n",
      "    accuracy                           0.32       220\n",
      "   macro avg       0.34      0.34      0.32       220\n",
      "weighted avg       0.34      0.32      0.31       220\n",
      "\n",
      "[[26  5  7  5]\n",
      " [29 10  8 14]\n",
      " [25 11 20  5]\n",
      " [18 12 10 15]]\n",
      "Validation Loss for P40 = 1.3713206052780151\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_96/2974510044.py:87: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/tmp/ipykernel_96/2974510044.py:43: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n",
      "/tmp/ipykernel_96/2974510044.py:61: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 33/100, Train Loss: 1.343510627746582\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.26      0.58      0.36        43\n",
      "           1       0.28      0.18      0.22        61\n",
      "           2       0.43      0.33      0.37        61\n",
      "           3       0.38      0.27      0.32        55\n",
      "\n",
      "    accuracy                           0.32       220\n",
      "   macro avg       0.34      0.34      0.32       220\n",
      "weighted avg       0.34      0.32      0.31       220\n",
      "\n",
      "[[25  5  8  5]\n",
      " [27 11  9 14]\n",
      " [25 11 20  5]\n",
      " [18 12 10 15]]\n",
      "Validation Loss for P40 = 1.3723267316818237\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_96/2974510044.py:87: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/tmp/ipykernel_96/2974510044.py:43: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n",
      "/tmp/ipykernel_96/2974510044.py:61: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 34/100, Train Loss: 1.3974851369857788\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.26      0.58      0.36        43\n",
      "           1       0.24      0.15      0.18        61\n",
      "           2       0.43      0.33      0.37        61\n",
      "           3       0.38      0.27      0.32        55\n",
      "\n",
      "    accuracy                           0.31       220\n",
      "   macro avg       0.33      0.33      0.31       220\n",
      "weighted avg       0.33      0.31      0.30       220\n",
      "\n",
      "[[25  5  8  5]\n",
      " [29  9  9 14]\n",
      " [25 11 20  5]\n",
      " [18 12 10 15]]\n",
      "Validation Loss for P40 = 1.3732337951660156\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_96/2974510044.py:87: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/tmp/ipykernel_96/2974510044.py:43: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n",
      "/tmp/ipykernel_96/2974510044.py:61: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 35/100, Train Loss: 1.4157565832138062\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.25      0.58      0.35        43\n",
      "           1       0.26      0.15      0.19        61\n",
      "           2       0.43      0.31      0.36        61\n",
      "           3       0.37      0.27      0.31        55\n",
      "\n",
      "    accuracy                           0.31       220\n",
      "   macro avg       0.33      0.33      0.30       220\n",
      "weighted avg       0.33      0.31      0.30       220\n",
      "\n",
      "[[25  5  8  5]\n",
      " [30  9  8 14]\n",
      " [27  8 19  7]\n",
      " [19 12  9 15]]\n",
      "Validation Loss for P40 = 1.3723512887954712\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_96/2974510044.py:87: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/tmp/ipykernel_96/2974510044.py:43: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n",
      "/tmp/ipykernel_96/2974510044.py:61: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 36/100, Train Loss: 1.3457058668136597\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.26      0.58      0.35        43\n",
      "           1       0.26      0.15      0.19        61\n",
      "           2       0.42      0.31      0.36        61\n",
      "           3       0.36      0.27      0.31        55\n",
      "\n",
      "    accuracy                           0.31       220\n",
      "   macro avg       0.32      0.33      0.30       220\n",
      "weighted avg       0.33      0.31      0.30       220\n",
      "\n",
      "[[25  5  8  5]\n",
      " [29  9  8 15]\n",
      " [26  9 19  7]\n",
      " [18 12 10 15]]\n",
      "Validation Loss for P40 = 1.3716118335723877\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_96/2974510044.py:87: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/tmp/ipykernel_96/2974510044.py:43: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n",
      "/tmp/ipykernel_96/2974510044.py:61: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 37/100, Train Loss: 1.3547197580337524\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.25      0.58      0.35        43\n",
      "           1       0.26      0.15      0.19        61\n",
      "           2       0.42      0.31      0.36        61\n",
      "           3       0.36      0.27      0.31        55\n",
      "\n",
      "    accuracy                           0.31       220\n",
      "   macro avg       0.32      0.33      0.30       220\n",
      "weighted avg       0.33      0.31      0.30       220\n",
      "\n",
      "[[25  5  8  5]\n",
      " [29  9  8 15]\n",
      " [27  8 19  7]\n",
      " [18 12 10 15]]\n",
      "Validation Loss for P40 = 1.3688300848007202\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_96/2974510044.py:87: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/tmp/ipykernel_96/2974510044.py:43: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n",
      "/tmp/ipykernel_96/2974510044.py:61: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 38/100, Train Loss: 1.3679405450820923\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.26      0.60      0.36        43\n",
      "           1       0.27      0.13      0.18        61\n",
      "           2       0.42      0.31      0.36        61\n",
      "           3       0.33      0.27      0.30        55\n",
      "\n",
      "    accuracy                           0.31       220\n",
      "   macro avg       0.32      0.33      0.30       220\n",
      "weighted avg       0.33      0.31      0.29       220\n",
      "\n",
      "[[26  3  8  6]\n",
      " [29  8  8 16]\n",
      " [27  7 19  8]\n",
      " [18 12 10 15]]\n",
      "Validation Loss for P40 = 1.36531400680542\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_96/2974510044.py:87: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/tmp/ipykernel_96/2974510044.py:43: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n",
      "/tmp/ipykernel_96/2974510044.py:61: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 39/100, Train Loss: 1.3019379377365112\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.25      0.58      0.35        43\n",
      "           1       0.27      0.15      0.19        61\n",
      "           2       0.43      0.31      0.36        61\n",
      "           3       0.35      0.27      0.31        55\n",
      "\n",
      "    accuracy                           0.31       220\n",
      "   macro avg       0.33      0.33      0.30       220\n",
      "weighted avg       0.33      0.31      0.30       220\n",
      "\n",
      "[[25  4  8  6]\n",
      " [29  9  8 15]\n",
      " [28  7 19  7]\n",
      " [18 13  9 15]]\n",
      "Validation Loss for P40 = 1.367820143699646\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_96/2974510044.py:87: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/tmp/ipykernel_96/2974510044.py:43: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n",
      "/tmp/ipykernel_96/2974510044.py:61: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 40/100, Train Loss: 1.3155720233917236\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.27      0.63      0.38        43\n",
      "           1       0.29      0.15      0.20        61\n",
      "           2       0.43      0.31      0.36        61\n",
      "           3       0.34      0.27      0.30        55\n",
      "\n",
      "    accuracy                           0.32       220\n",
      "   macro avg       0.33      0.34      0.31       220\n",
      "weighted avg       0.34      0.32      0.30       220\n",
      "\n",
      "[[27  3  7  6]\n",
      " [29  9  8 15]\n",
      " [27  7 19  8]\n",
      " [18 12 10 15]]\n",
      "Validation Loss for P40 = 1.3656175136566162\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_96/2974510044.py:87: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/tmp/ipykernel_96/2974510044.py:43: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n",
      "/tmp/ipykernel_96/2974510044.py:61: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 41/100, Train Loss: 1.4862536191940308\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.26      0.60      0.36        43\n",
      "           1       0.28      0.15      0.19        61\n",
      "           2       0.45      0.31      0.37        61\n",
      "           3       0.37      0.31      0.34        55\n",
      "\n",
      "    accuracy                           0.32       220\n",
      "   macro avg       0.34      0.34      0.32       220\n",
      "weighted avg       0.35      0.32      0.31       220\n",
      "\n",
      "[[26  4  7  6]\n",
      " [29  9  8 15]\n",
      " [27  7 19  8]\n",
      " [18 12  8 17]]\n",
      "Validation Loss for P40 = 1.364883303642273\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_96/2974510044.py:87: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/tmp/ipykernel_96/2974510044.py:43: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n",
      "/tmp/ipykernel_96/2974510044.py:61: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 42/100, Train Loss: 1.4487804174423218\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.26      0.60      0.36        43\n",
      "           1       0.27      0.15      0.19        61\n",
      "           2       0.45      0.31      0.37        61\n",
      "           3       0.36      0.29      0.32        55\n",
      "\n",
      "    accuracy                           0.32       220\n",
      "   macro avg       0.34      0.34      0.31       220\n",
      "weighted avg       0.34      0.32      0.31       220\n",
      "\n",
      "[[26  4  7  6]\n",
      " [29  9  8 15]\n",
      " [28  7 19  7]\n",
      " [18 13  8 16]]\n",
      "Validation Loss for P40 = 1.3659846782684326\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_96/2974510044.py:87: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/tmp/ipykernel_96/2974510044.py:43: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n",
      "/tmp/ipykernel_96/2974510044.py:61: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 43/100, Train Loss: 1.3972772359848022\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.26      0.60      0.37        43\n",
      "           1       0.26      0.15      0.19        61\n",
      "           2       0.45      0.31      0.37        61\n",
      "           3       0.36      0.29      0.32        55\n",
      "\n",
      "    accuracy                           0.32       220\n",
      "   macro avg       0.33      0.34      0.31       220\n",
      "weighted avg       0.34      0.32      0.31       220\n",
      "\n",
      "[[26  4  7  6]\n",
      " [29  9  8 15]\n",
      " [26  8 19  8]\n",
      " [18 13  8 16]]\n",
      "Validation Loss for P40 = 1.365352988243103\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_96/2974510044.py:87: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/tmp/ipykernel_96/2974510044.py:43: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n",
      "/tmp/ipykernel_96/2974510044.py:61: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 44/100, Train Loss: 1.4053857326507568\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.26      0.63      0.37        43\n",
      "           1       0.29      0.15      0.20        61\n",
      "           2       0.44      0.31      0.37        61\n",
      "           3       0.36      0.29      0.32        55\n",
      "\n",
      "    accuracy                           0.32       220\n",
      "   macro avg       0.34      0.34      0.31       220\n",
      "weighted avg       0.35      0.32      0.31       220\n",
      "\n",
      "[[27  3  7  6]\n",
      " [29  9  8 15]\n",
      " [28  7 19  7]\n",
      " [18 12  9 16]]\n",
      "Validation Loss for P40 = 1.3595128059387207\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_96/2974510044.py:87: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/tmp/ipykernel_96/2974510044.py:43: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n",
      "/tmp/ipykernel_96/2974510044.py:61: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 45/100, Train Loss: 1.43271803855896\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.26      0.63      0.36        43\n",
      "           1       0.31      0.15      0.20        61\n",
      "           2       0.42      0.26      0.32        61\n",
      "           3       0.35      0.31      0.33        55\n",
      "\n",
      "    accuracy                           0.31       220\n",
      "   macro avg       0.34      0.34      0.30       220\n",
      "weighted avg       0.34      0.31      0.30       220\n",
      "\n",
      "[[27  3  6  7]\n",
      " [30  9  8 14]\n",
      " [29  6 16 10]\n",
      " [19 11  8 17]]\n",
      "Validation Loss for P40 = 1.3556184768676758\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_96/2974510044.py:87: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/tmp/ipykernel_96/2974510044.py:43: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n",
      "/tmp/ipykernel_96/2974510044.py:61: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 46/100, Train Loss: 1.3850723505020142\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.25      0.60      0.36        43\n",
      "           1       0.26      0.15      0.19        61\n",
      "           2       0.44      0.30      0.35        61\n",
      "           3       0.37      0.29      0.33        55\n",
      "\n",
      "    accuracy                           0.31       220\n",
      "   macro avg       0.33      0.33      0.31       220\n",
      "weighted avg       0.34      0.31      0.30       220\n",
      "\n",
      "[[26  4  7  6]\n",
      " [30  9  8 14]\n",
      " [28  8 18  7]\n",
      " [18 13  8 16]]\n",
      "Validation Loss for P40 = 1.3566992282867432\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_96/2974510044.py:87: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/tmp/ipykernel_96/2974510044.py:43: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n",
      "/tmp/ipykernel_96/2974510044.py:61: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 47/100, Train Loss: 1.2890299558639526\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.26      0.63      0.37        43\n",
      "           1       0.26      0.13      0.17        61\n",
      "           2       0.41      0.25      0.31        61\n",
      "           3       0.35      0.31      0.33        55\n",
      "\n",
      "    accuracy                           0.30       220\n",
      "   macro avg       0.32      0.33      0.29       220\n",
      "weighted avg       0.32      0.30      0.29       220\n",
      "\n",
      "[[27  3  7  6]\n",
      " [30  8  8 15]\n",
      " [29  7 15 10]\n",
      " [18 13  7 17]]\n",
      "Validation Loss for P40 = 1.3530594110488892\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_96/2974510044.py:87: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/tmp/ipykernel_96/2974510044.py:43: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n",
      "/tmp/ipykernel_96/2974510044.py:61: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 48/100, Train Loss: 1.3442063331604004\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.26      0.63      0.37        43\n",
      "           1       0.23      0.11      0.15        61\n",
      "           2       0.39      0.26      0.31        61\n",
      "           3       0.35      0.29      0.32        55\n",
      "\n",
      "    accuracy                           0.30       220\n",
      "   macro avg       0.31      0.32      0.29       220\n",
      "weighted avg       0.31      0.30      0.28       220\n",
      "\n",
      "[[27  3  7  6]\n",
      " [30  7  9 15]\n",
      " [28  8 16  9]\n",
      " [18 12  9 16]]\n",
      "Validation Loss for P40 = 1.353440284729004\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_96/2974510044.py:87: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/tmp/ipykernel_96/2974510044.py:43: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n",
      "/tmp/ipykernel_96/2974510044.py:61: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 49/100, Train Loss: 1.2813643217086792\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.26      0.63      0.36        43\n",
      "           1       0.24      0.11      0.16        61\n",
      "           2       0.41      0.26      0.32        61\n",
      "           3       0.36      0.31      0.33        55\n",
      "\n",
      "    accuracy                           0.30       220\n",
      "   macro avg       0.32      0.33      0.29       220\n",
      "weighted avg       0.32      0.30      0.29       220\n",
      "\n",
      "[[27  3  7  6]\n",
      " [30  7  9 15]\n",
      " [28  8 16  9]\n",
      " [20 11  7 17]]\n",
      "Validation Loss for P40 = 1.360164999961853\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_96/2974510044.py:87: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/tmp/ipykernel_96/2974510044.py:43: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n",
      "/tmp/ipykernel_96/2974510044.py:61: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 50/100, Train Loss: 1.3960257768630981\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.25      0.58      0.35        43\n",
      "           1       0.24      0.13      0.17        61\n",
      "           2       0.41      0.26      0.32        61\n",
      "           3       0.36      0.31      0.33        55\n",
      "\n",
      "    accuracy                           0.30       220\n",
      "   macro avg       0.32      0.32      0.29       220\n",
      "weighted avg       0.32      0.30      0.29       220\n",
      "\n",
      "[[25  4  8  6]\n",
      " [30  8  8 15]\n",
      " [28  8 16  9]\n",
      " [18 13  7 17]]\n",
      "Validation Loss for P40 = 1.3592885732650757\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_96/2974510044.py:87: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/tmp/ipykernel_96/2974510044.py:43: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n",
      "/tmp/ipykernel_96/2974510044.py:61: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 51/100, Train Loss: 1.3857582807540894\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.25      0.60      0.36        43\n",
      "           1       0.25      0.13      0.17        61\n",
      "           2       0.43      0.26      0.33        61\n",
      "           3       0.35      0.31      0.33        55\n",
      "\n",
      "    accuracy                           0.30       220\n",
      "   macro avg       0.32      0.33      0.30       220\n",
      "weighted avg       0.33      0.30      0.29       220\n",
      "\n",
      "[[26  4  6  7]\n",
      " [30  8  8 15]\n",
      " [28  7 16 10]\n",
      " [18 13  7 17]]\n",
      "Validation Loss for P40 = 1.356626272201538\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_96/2974510044.py:87: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/tmp/ipykernel_96/2974510044.py:43: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n",
      "/tmp/ipykernel_96/2974510044.py:61: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 52/100, Train Loss: 1.389414668083191\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.25      0.58      0.35        43\n",
      "           1       0.28      0.16      0.21        61\n",
      "           2       0.42      0.25      0.31        61\n",
      "           3       0.36      0.31      0.33        55\n",
      "\n",
      "    accuracy                           0.30       220\n",
      "   macro avg       0.33      0.33      0.30       220\n",
      "weighted avg       0.33      0.30      0.29       220\n",
      "\n",
      "[[25  5  6  7]\n",
      " [29 10  8 14]\n",
      " [29  8 15  9]\n",
      " [18 13  7 17]]\n",
      "Validation Loss for P40 = 1.3588141202926636\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_96/2974510044.py:87: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/tmp/ipykernel_96/2974510044.py:43: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n",
      "/tmp/ipykernel_96/2974510044.py:61: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 53/100, Train Loss: 1.2856858968734741\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.26      0.58      0.36        43\n",
      "           1       0.26      0.15      0.19        61\n",
      "           2       0.42      0.26      0.32        61\n",
      "           3       0.33      0.31      0.32        55\n",
      "\n",
      "    accuracy                           0.30       220\n",
      "   macro avg       0.32      0.33      0.30       220\n",
      "weighted avg       0.32      0.30      0.29       220\n",
      "\n",
      "[[25  5  7  6]\n",
      " [29  9  8 15]\n",
      " [25  7 16 13]\n",
      " [18 13  7 17]]\n",
      "Validation Loss for P40 = 1.3567389249801636\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_96/2974510044.py:87: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/tmp/ipykernel_96/2974510044.py:43: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n",
      "/tmp/ipykernel_96/2974510044.py:61: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 54/100, Train Loss: 1.3728201389312744\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.26      0.63      0.37        43\n",
      "           1       0.27      0.13      0.18        61\n",
      "           2       0.42      0.26      0.32        61\n",
      "           3       0.35      0.31      0.33        55\n",
      "\n",
      "    accuracy                           0.31       220\n",
      "   macro avg       0.32      0.33      0.30       220\n",
      "weighted avg       0.33      0.31      0.29       220\n",
      "\n",
      "[[27  3  7  6]\n",
      " [30  8  8 15]\n",
      " [28  6 16 11]\n",
      " [18 13  7 17]]\n",
      "Validation Loss for P40 = 1.3568247556686401\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_96/2974510044.py:87: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/tmp/ipykernel_96/2974510044.py:43: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n",
      "/tmp/ipykernel_96/2974510044.py:61: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 55/100, Train Loss: 1.4129823446273804\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.26      0.63      0.37        43\n",
      "           1       0.29      0.15      0.20        61\n",
      "           2       0.41      0.26      0.32        61\n",
      "           3       0.36      0.31      0.33        55\n",
      "\n",
      "    accuracy                           0.31       220\n",
      "   macro avg       0.33      0.34      0.30       220\n",
      "weighted avg       0.34      0.31      0.30       220\n",
      "\n",
      "[[27  3  7  6]\n",
      " [30  9  9 13]\n",
      " [28  6 16 11]\n",
      " [18 13  7 17]]\n",
      "Validation Loss for P40 = 1.3566771745681763\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_96/2974510044.py:87: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/tmp/ipykernel_96/2974510044.py:43: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n",
      "/tmp/ipykernel_96/2974510044.py:61: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 56/100, Train Loss: 1.374547004699707\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.26      0.60      0.36        43\n",
      "           1       0.27      0.15      0.19        61\n",
      "           2       0.42      0.28      0.34        61\n",
      "           3       0.36      0.31      0.33        55\n",
      "\n",
      "    accuracy                           0.31       220\n",
      "   macro avg       0.33      0.33      0.31       220\n",
      "weighted avg       0.33      0.31      0.30       220\n",
      "\n",
      "[[26  4  7  6]\n",
      " [30  9  9 13]\n",
      " [26  7 17 11]\n",
      " [18 13  7 17]]\n",
      "Validation Loss for P40 = 1.3584575653076172\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_96/2974510044.py:87: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/tmp/ipykernel_96/2974510044.py:43: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n",
      "/tmp/ipykernel_96/2974510044.py:61: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 57/100, Train Loss: 1.4244225025177002\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.24      0.56      0.34        43\n",
      "           1       0.26      0.15      0.19        61\n",
      "           2       0.40      0.26      0.32        61\n",
      "           3       0.35      0.31      0.33        55\n",
      "\n",
      "    accuracy                           0.30       220\n",
      "   macro avg       0.32      0.32      0.29       220\n",
      "weighted avg       0.32      0.30      0.29       220\n",
      "\n",
      "[[24  5  8  6]\n",
      " [30  9  9 13]\n",
      " [26  7 16 12]\n",
      " [18 13  7 17]]\n",
      "Validation Loss for P40 = 1.360120177268982\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_96/2974510044.py:87: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/tmp/ipykernel_96/2974510044.py:43: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n",
      "/tmp/ipykernel_96/2974510044.py:61: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 58/100, Train Loss: 1.3907297849655151\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.25      0.56      0.35        43\n",
      "           1       0.28      0.16      0.21        61\n",
      "           2       0.41      0.28      0.33        61\n",
      "           3       0.36      0.31      0.33        55\n",
      "\n",
      "    accuracy                           0.31       220\n",
      "   macro avg       0.33      0.33      0.30       220\n",
      "weighted avg       0.33      0.31      0.30       220\n",
      "\n",
      "[[24  5  8  6]\n",
      " [29 10  9 13]\n",
      " [26  7 17 11]\n",
      " [17 14  7 17]]\n",
      "Validation Loss for P40 = 1.3589497804641724\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_96/2974510044.py:87: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/tmp/ipykernel_96/2974510044.py:43: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n",
      "/tmp/ipykernel_96/2974510044.py:61: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 59/100, Train Loss: 1.4015980958938599\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.24      0.53      0.33        43\n",
      "           1       0.28      0.16      0.21        61\n",
      "           2       0.41      0.26      0.32        61\n",
      "           3       0.37      0.33      0.35        55\n",
      "\n",
      "    accuracy                           0.30       220\n",
      "   macro avg       0.32      0.32      0.30       220\n",
      "weighted avg       0.33      0.30      0.30       220\n",
      "\n",
      "[[23  6  7  7]\n",
      " [29 10  9 13]\n",
      " [27  7 16 11]\n",
      " [17 13  7 18]]\n",
      "Validation Loss for P40 = 1.3579628467559814\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_96/2974510044.py:87: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/tmp/ipykernel_96/2974510044.py:43: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n",
      "/tmp/ipykernel_96/2974510044.py:61: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 60/100, Train Loss: 1.4828804731369019\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.25      0.56      0.34        43\n",
      "           1       0.29      0.16      0.21        61\n",
      "           2       0.41      0.26      0.32        61\n",
      "           3       0.37      0.33      0.35        55\n",
      "\n",
      "    accuracy                           0.31       220\n",
      "   macro avg       0.33      0.33      0.30       220\n",
      "weighted avg       0.33      0.31      0.30       220\n",
      "\n",
      "[[24  5  7  7]\n",
      " [29 10  9 13]\n",
      " [27  7 16 11]\n",
      " [17 13  7 18]]\n",
      "Validation Loss for P40 = 1.3506550788879395\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_96/2974510044.py:87: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/tmp/ipykernel_96/2974510044.py:43: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n",
      "/tmp/ipykernel_96/2974510044.py:61: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 61/100, Train Loss: 1.4110623598098755\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.25      0.56      0.35        43\n",
      "           1       0.29      0.16      0.21        61\n",
      "           2       0.43      0.30      0.35        61\n",
      "           3       0.37      0.33      0.35        55\n",
      "\n",
      "    accuracy                           0.32       220\n",
      "   macro avg       0.34      0.34      0.31       220\n",
      "weighted avg       0.34      0.32      0.31       220\n",
      "\n",
      "[[24  5  7  7]\n",
      " [29 10  9 13]\n",
      " [25  7 18 11]\n",
      " [17 12  8 18]]\n",
      "Validation Loss for P40 = 1.3539355993270874\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_96/2974510044.py:87: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/tmp/ipykernel_96/2974510044.py:43: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n",
      "/tmp/ipykernel_96/2974510044.py:61: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 62/100, Train Loss: 1.32073175907135\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.25      0.53      0.34        43\n",
      "           1       0.26      0.16      0.20        61\n",
      "           2       0.44      0.30      0.35        61\n",
      "           3       0.37      0.33      0.35        55\n",
      "\n",
      "    accuracy                           0.31       220\n",
      "   macro avg       0.33      0.33      0.31       220\n",
      "weighted avg       0.34      0.31      0.31       220\n",
      "\n",
      "[[23  6  7  7]\n",
      " [29 10  9 13]\n",
      " [23  9 18 11]\n",
      " [17 13  7 18]]\n",
      "Validation Loss for P40 = 1.3563579320907593\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_96/2974510044.py:87: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/tmp/ipykernel_96/2974510044.py:43: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n",
      "/tmp/ipykernel_96/2974510044.py:61: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 63/100, Train Loss: 1.4461166858673096\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.24      0.51      0.32        43\n",
      "           1       0.26      0.16      0.20        61\n",
      "           2       0.41      0.26      0.32        61\n",
      "           3       0.35      0.31      0.33        55\n",
      "\n",
      "    accuracy                           0.30       220\n",
      "   macro avg       0.31      0.31      0.29       220\n",
      "weighted avg       0.32      0.30      0.29       220\n",
      "\n",
      "[[22  7  7  7]\n",
      " [29 10  8 14]\n",
      " [25  9 16 11]\n",
      " [17 13  8 17]]\n",
      "Validation Loss for P40 = 1.3578623533248901\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_96/2974510044.py:87: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/tmp/ipykernel_96/2974510044.py:43: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n",
      "/tmp/ipykernel_96/2974510044.py:61: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 64/100, Train Loss: 1.3434969186782837\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.24      0.51      0.33        43\n",
      "           1       0.25      0.16      0.20        61\n",
      "           2       0.42      0.26      0.32        61\n",
      "           3       0.36      0.33      0.34        55\n",
      "\n",
      "    accuracy                           0.30       220\n",
      "   macro avg       0.32      0.32      0.30       220\n",
      "weighted avg       0.32      0.30      0.29       220\n",
      "\n",
      "[[22  7  7  7]\n",
      " [29 10  8 14]\n",
      " [24 10 16 11]\n",
      " [17 13  7 18]]\n",
      "Validation Loss for P40 = 1.3573757410049438\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_96/2974510044.py:87: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/tmp/ipykernel_96/2974510044.py:43: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n",
      "/tmp/ipykernel_96/2974510044.py:61: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 65/100, Train Loss: 1.37890625\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.23      0.51      0.32        43\n",
      "           1       0.26      0.16      0.20        61\n",
      "           2       0.41      0.25      0.31        61\n",
      "           3       0.36      0.33      0.34        55\n",
      "\n",
      "    accuracy                           0.30       220\n",
      "   macro avg       0.31      0.31      0.29       220\n",
      "weighted avg       0.32      0.30      0.29       220\n",
      "\n",
      "[[22  7  7  7]\n",
      " [29 10  8 14]\n",
      " [26  9 15 11]\n",
      " [17 13  7 18]]\n",
      "Validation Loss for P40 = 1.3571504354476929\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_96/2974510044.py:87: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/tmp/ipykernel_96/2974510044.py:43: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n",
      "/tmp/ipykernel_96/2974510044.py:61: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 66/100, Train Loss: 1.290066123008728\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.24      0.53      0.33        43\n",
      "           1       0.26      0.16      0.20        61\n",
      "           2       0.41      0.25      0.31        61\n",
      "           3       0.36      0.33      0.34        55\n",
      "\n",
      "    accuracy                           0.30       220\n",
      "   macro avg       0.32      0.32      0.30       220\n",
      "weighted avg       0.32      0.30      0.29       220\n",
      "\n",
      "[[23  6  7  7]\n",
      " [29 10  8 14]\n",
      " [26  9 15 11]\n",
      " [17 13  7 18]]\n",
      "Validation Loss for P40 = 1.3541266918182373\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_96/2974510044.py:87: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/tmp/ipykernel_96/2974510044.py:43: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n",
      "/tmp/ipykernel_96/2974510044.py:61: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 67/100, Train Loss: 1.407059669494629\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.24      0.56      0.34        43\n",
      "           1       0.29      0.16      0.21        61\n",
      "           2       0.39      0.25      0.30        61\n",
      "           3       0.36      0.33      0.34        55\n",
      "\n",
      "    accuracy                           0.30       220\n",
      "   macro avg       0.32      0.32      0.30       220\n",
      "weighted avg       0.33      0.30      0.29       220\n",
      "\n",
      "[[24  5  7  7]\n",
      " [29 10  8 14]\n",
      " [28  7 15 11]\n",
      " [17 12  8 18]]\n",
      "Validation Loss for P40 = 1.3546279668807983\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_96/2974510044.py:87: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/tmp/ipykernel_96/2974510044.py:43: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n",
      "/tmp/ipykernel_96/2974510044.py:61: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 68/100, Train Loss: 1.3274253606796265\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.25      0.56      0.34        43\n",
      "           1       0.29      0.16      0.21        61\n",
      "           2       0.41      0.26      0.32        61\n",
      "           3       0.36      0.33      0.34        55\n",
      "\n",
      "    accuracy                           0.31       220\n",
      "   macro avg       0.33      0.33      0.30       220\n",
      "weighted avg       0.33      0.31      0.30       220\n",
      "\n",
      "[[24  5  7  7]\n",
      " [29 10  8 14]\n",
      " [27  7 16 11]\n",
      " [17 12  8 18]]\n",
      "Validation Loss for P40 = 1.3556002378463745\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_96/2974510044.py:87: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/tmp/ipykernel_96/2974510044.py:43: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n",
      "/tmp/ipykernel_96/2974510044.py:61: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 69/100, Train Loss: 1.3875612020492554\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.24      0.53      0.33        43\n",
      "           1       0.27      0.16      0.20        61\n",
      "           2       0.41      0.26      0.32        61\n",
      "           3       0.35      0.31      0.33        55\n",
      "\n",
      "    accuracy                           0.30       220\n",
      "   macro avg       0.32      0.32      0.30       220\n",
      "weighted avg       0.32      0.30      0.29       220\n",
      "\n",
      "[[23  6  7  7]\n",
      " [29 10  8 14]\n",
      " [27  8 16 10]\n",
      " [17 13  8 17]]\n",
      "Validation Loss for P40 = 1.3579564094543457\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_96/2974510044.py:87: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/tmp/ipykernel_96/2974510044.py:43: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n",
      "/tmp/ipykernel_96/2974510044.py:61: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 70/100, Train Loss: 1.3685821294784546\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.24      0.53      0.33        43\n",
      "           1       0.26      0.16      0.20        61\n",
      "           2       0.38      0.25      0.30        61\n",
      "           3       0.35      0.31      0.33        55\n",
      "\n",
      "    accuracy                           0.30       220\n",
      "   macro avg       0.31      0.31      0.29       220\n",
      "weighted avg       0.32      0.30      0.29       220\n",
      "\n",
      "[[23  6  8  6]\n",
      " [29 10  8 14]\n",
      " [26  9 15 11]\n",
      " [17 13  8 17]]\n",
      "Validation Loss for P40 = 1.3608144521713257\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_96/2974510044.py:87: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/tmp/ipykernel_96/2974510044.py:43: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n",
      "/tmp/ipykernel_96/2974510044.py:61: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 71/100, Train Loss: 1.4091876745224\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.23      0.51      0.32        43\n",
      "           1       0.26      0.16      0.20        61\n",
      "           2       0.38      0.25      0.30        61\n",
      "           3       0.36      0.31      0.33        55\n",
      "\n",
      "    accuracy                           0.29       220\n",
      "   macro avg       0.31      0.31      0.29       220\n",
      "weighted avg       0.31      0.29      0.28       220\n",
      "\n",
      "[[22  7  9  5]\n",
      " [29 10  8 14]\n",
      " [26  9 15 11]\n",
      " [17 13  8 17]]\n",
      "Validation Loss for P40 = 1.356858491897583\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_96/2974510044.py:87: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/tmp/ipykernel_96/2974510044.py:43: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n",
      "/tmp/ipykernel_96/2974510044.py:61: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 72/100, Train Loss: 1.346399188041687\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.24      0.51      0.33        43\n",
      "           1       0.30      0.20      0.24        61\n",
      "           2       0.44      0.30      0.35        61\n",
      "           3       0.37      0.33      0.35        55\n",
      "\n",
      "    accuracy                           0.32       220\n",
      "   macro avg       0.34      0.33      0.32       220\n",
      "weighted avg       0.34      0.32      0.31       220\n",
      "\n",
      "[[22  7  8  6]\n",
      " [27 12  8 14]\n",
      " [24  8 18 11]\n",
      " [17 13  7 18]]\n",
      "Validation Loss for P40 = 1.3585398197174072\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_96/2974510044.py:87: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/tmp/ipykernel_96/2974510044.py:43: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n",
      "/tmp/ipykernel_96/2974510044.py:61: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 73/100, Train Loss: 1.3190163373947144\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.23      0.51      0.32        43\n",
      "           1       0.27      0.16      0.20        61\n",
      "           2       0.40      0.26      0.32        61\n",
      "           3       0.35      0.31      0.33        55\n",
      "\n",
      "    accuracy                           0.30       220\n",
      "   macro avg       0.31      0.31      0.29       220\n",
      "weighted avg       0.32      0.30      0.29       220\n",
      "\n",
      "[[22  7  7  7]\n",
      " [29 10  8 14]\n",
      " [26  8 16 11]\n",
      " [17 12  9 17]]\n",
      "Validation Loss for P40 = 1.3614696264266968\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_96/2974510044.py:87: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/tmp/ipykernel_96/2974510044.py:43: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n",
      "/tmp/ipykernel_96/2974510044.py:61: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 74/100, Train Loss: 1.3220555782318115\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.23      0.51      0.32        43\n",
      "           1       0.27      0.16      0.20        61\n",
      "           2       0.42      0.28      0.34        61\n",
      "           3       0.35      0.31      0.33        55\n",
      "\n",
      "    accuracy                           0.30       220\n",
      "   macro avg       0.32      0.32      0.30       220\n",
      "weighted avg       0.33      0.30      0.29       220\n",
      "\n",
      "[[22  7  7  7]\n",
      " [29 10  7 15]\n",
      " [27  8 17  9]\n",
      " [17 12  9 17]]\n",
      "Validation Loss for P40 = 1.3591349124908447\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_96/2974510044.py:87: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/tmp/ipykernel_96/2974510044.py:43: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n",
      "/tmp/ipykernel_96/2974510044.py:61: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 75/100, Train Loss: 1.3183058500289917\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.24      0.51      0.32        43\n",
      "           1       0.28      0.18      0.22        61\n",
      "           2       0.43      0.26      0.33        61\n",
      "           3       0.35      0.33      0.34        55\n",
      "\n",
      "    accuracy                           0.30       220\n",
      "   macro avg       0.33      0.32      0.30       220\n",
      "weighted avg       0.33      0.30      0.30       220\n",
      "\n",
      "[[22  7  6  8]\n",
      " [28 11  8 14]\n",
      " [26  8 16 11]\n",
      " [17 13  7 18]]\n",
      "Validation Loss for P40 = 1.3567306995391846\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_96/2974510044.py:87: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/tmp/ipykernel_96/2974510044.py:43: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n",
      "/tmp/ipykernel_96/2974510044.py:61: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 76/100, Train Loss: 1.3883304595947266\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.24      0.51      0.32        43\n",
      "           1       0.28      0.18      0.22        61\n",
      "           2       0.46      0.30      0.36        61\n",
      "           3       0.37      0.33      0.35        55\n",
      "\n",
      "    accuracy                           0.31       220\n",
      "   macro avg       0.34      0.33      0.31       220\n",
      "weighted avg       0.34      0.31      0.31       220\n",
      "\n",
      "[[22  7  6  8]\n",
      " [28 11  8 14]\n",
      " [26  8 18  9]\n",
      " [17 13  7 18]]\n",
      "Validation Loss for P40 = 1.3559483289718628\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_96/2974510044.py:87: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/tmp/ipykernel_96/2974510044.py:43: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n",
      "/tmp/ipykernel_96/2974510044.py:61: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 77/100, Train Loss: 1.3230546712875366\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.23      0.49      0.31        43\n",
      "           1       0.30      0.20      0.24        61\n",
      "           2       0.39      0.25      0.30        61\n",
      "           3       0.35      0.33      0.34        55\n",
      "\n",
      "    accuracy                           0.30       220\n",
      "   macro avg       0.32      0.31      0.30       220\n",
      "weighted avg       0.33      0.30      0.30       220\n",
      "\n",
      "[[21  8  7  7]\n",
      " [27 12  8 14]\n",
      " [26  8 15 12]\n",
      " [17 12  8 18]]\n",
      "Validation Loss for P40 = 1.3582454919815063\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_96/2974510044.py:87: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/tmp/ipykernel_96/2974510044.py:43: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n",
      "/tmp/ipykernel_96/2974510044.py:61: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 78/100, Train Loss: 1.4148764610290527\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.23      0.49      0.31        43\n",
      "           1       0.30      0.20      0.24        61\n",
      "           2       0.43      0.30      0.35        61\n",
      "           3       0.36      0.31      0.33        55\n",
      "\n",
      "    accuracy                           0.31       220\n",
      "   macro avg       0.33      0.32      0.31       220\n",
      "weighted avg       0.34      0.31      0.31       220\n",
      "\n",
      "[[21  8  7  7]\n",
      " [27 12  8 14]\n",
      " [26  8 18  9]\n",
      " [17 12  9 17]]\n",
      "Validation Loss for P40 = 1.3608901500701904\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_96/2974510044.py:87: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/tmp/ipykernel_96/2974510044.py:43: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n",
      "/tmp/ipykernel_96/2974510044.py:61: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 79/100, Train Loss: 1.4231817722320557\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.24      0.51      0.32        43\n",
      "           1       0.26      0.16      0.20        61\n",
      "           2       0.44      0.28      0.34        61\n",
      "           3       0.36      0.33      0.34        55\n",
      "\n",
      "    accuracy                           0.30       220\n",
      "   macro avg       0.32      0.32      0.30       220\n",
      "weighted avg       0.33      0.30      0.30       220\n",
      "\n",
      "[[22  7  7  7]\n",
      " [29 10  8 14]\n",
      " [25  8 17 11]\n",
      " [17 13  7 18]]\n",
      "Validation Loss for P40 = 1.3572815656661987\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_96/2974510044.py:87: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/tmp/ipykernel_96/2974510044.py:43: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n",
      "/tmp/ipykernel_96/2974510044.py:61: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 80/100, Train Loss: 1.3786617517471313\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.23      0.49      0.31        43\n",
      "           1       0.29      0.20      0.24        61\n",
      "           2       0.42      0.28      0.34        61\n",
      "           3       0.38      0.33      0.35        55\n",
      "\n",
      "    accuracy                           0.31       220\n",
      "   macro avg       0.33      0.32      0.31       220\n",
      "weighted avg       0.34      0.31      0.31       220\n",
      "\n",
      "[[21  8  8  6]\n",
      " [27 12  8 14]\n",
      " [26  8 17 10]\n",
      " [17 13  7 18]]\n",
      "Validation Loss for P40 = 1.3627207279205322\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_96/2974510044.py:87: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/tmp/ipykernel_96/2974510044.py:43: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n",
      "/tmp/ipykernel_96/2974510044.py:61: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 81/100, Train Loss: 1.307488203048706\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.22      0.44      0.30        43\n",
      "           1       0.29      0.20      0.23        61\n",
      "           2       0.40      0.30      0.34        61\n",
      "           3       0.35      0.31      0.33        55\n",
      "\n",
      "    accuracy                           0.30       220\n",
      "   macro avg       0.32      0.31      0.30       220\n",
      "weighted avg       0.32      0.30      0.30       220\n",
      "\n",
      "[[19  9  9  6]\n",
      " [26 12  9 14]\n",
      " [23  9 18 11]\n",
      " [17 12  9 17]]\n",
      "Validation Loss for P40 = 1.3648300170898438\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_96/2974510044.py:87: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/tmp/ipykernel_96/2974510044.py:43: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n",
      "/tmp/ipykernel_96/2974510044.py:61: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 82/100, Train Loss: 1.2977218627929688\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.24      0.49      0.32        43\n",
      "           1       0.29      0.18      0.22        61\n",
      "           2       0.44      0.31      0.37        61\n",
      "           3       0.36      0.33      0.34        55\n",
      "\n",
      "    accuracy                           0.31       220\n",
      "   macro avg       0.33      0.33      0.31       220\n",
      "weighted avg       0.34      0.31      0.31       220\n",
      "\n",
      "[[21  7  7  8]\n",
      " [27 11  9 14]\n",
      " [24  8 19 10]\n",
      " [17 12  8 18]]\n",
      "Validation Loss for P40 = 1.359713077545166\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_96/2974510044.py:87: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/tmp/ipykernel_96/2974510044.py:43: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n",
      "/tmp/ipykernel_96/2974510044.py:61: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 83/100, Train Loss: 1.3550732135772705\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.24      0.51      0.33        43\n",
      "           1       0.30      0.18      0.22        61\n",
      "           2       0.44      0.33      0.38        61\n",
      "           3       0.34      0.29      0.31        55\n",
      "\n",
      "    accuracy                           0.31       220\n",
      "   macro avg       0.33      0.33      0.31       220\n",
      "weighted avg       0.34      0.31      0.31       220\n",
      "\n",
      "[[22  6  7  8]\n",
      " [27 11  9 14]\n",
      " [24  8 20  9]\n",
      " [18 12  9 16]]\n",
      "Validation Loss for P40 = 1.3613938093185425\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_96/2974510044.py:87: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/tmp/ipykernel_96/2974510044.py:43: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n",
      "/tmp/ipykernel_96/2974510044.py:61: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 84/100, Train Loss: 1.378252387046814\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.24      0.49      0.32        43\n",
      "           1       0.30      0.18      0.22        61\n",
      "           2       0.45      0.33      0.38        61\n",
      "           3       0.36      0.33      0.34        55\n",
      "\n",
      "    accuracy                           0.32       220\n",
      "   macro avg       0.34      0.33      0.32       220\n",
      "weighted avg       0.34      0.32      0.32       220\n",
      "\n",
      "[[21  6  8  8]\n",
      " [27 11  9 14]\n",
      " [23  8 20 10]\n",
      " [18 12  7 18]]\n",
      "Validation Loss for P40 = 1.362697720527649\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_96/2974510044.py:87: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/tmp/ipykernel_96/2974510044.py:43: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n",
      "/tmp/ipykernel_96/2974510044.py:61: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 85/100, Train Loss: 1.3371638059616089\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.24      0.51      0.33        43\n",
      "           1       0.29      0.20      0.24        61\n",
      "           2       0.41      0.26      0.32        61\n",
      "           3       0.35      0.31      0.33        55\n",
      "\n",
      "    accuracy                           0.30       220\n",
      "   macro avg       0.32      0.32      0.30       220\n",
      "weighted avg       0.33      0.30      0.30       220\n",
      "\n",
      "[[22  7  7  7]\n",
      " [27 12  8 14]\n",
      " [26  9 16 10]\n",
      " [17 13  8 17]]\n",
      "Validation Loss for P40 = 1.3680768013000488\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_96/2974510044.py:87: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/tmp/ipykernel_96/2974510044.py:43: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n",
      "/tmp/ipykernel_96/2974510044.py:61: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 86/100, Train Loss: 1.2910698652267456\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.24      0.51      0.33        43\n",
      "           1       0.30      0.20      0.24        61\n",
      "           2       0.47      0.33      0.38        61\n",
      "           3       0.34      0.29      0.31        55\n",
      "\n",
      "    accuracy                           0.32       220\n",
      "   macro avg       0.34      0.33      0.32       220\n",
      "weighted avg       0.35      0.32      0.32       220\n",
      "\n",
      "[[22  7  6  8]\n",
      " [27 12  8 14]\n",
      " [24  8 20  9]\n",
      " [17 13  9 16]]\n",
      "Validation Loss for P40 = 1.3657582998275757\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_96/2974510044.py:87: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/tmp/ipykernel_96/2974510044.py:43: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n",
      "/tmp/ipykernel_96/2974510044.py:61: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 87/100, Train Loss: 1.3282743692398071\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.24      0.49      0.32        43\n",
      "           1       0.29      0.20      0.24        61\n",
      "           2       0.50      0.33      0.40        61\n",
      "           3       0.38      0.35      0.36        55\n",
      "\n",
      "    accuracy                           0.33       220\n",
      "   macro avg       0.35      0.34      0.33       220\n",
      "weighted avg       0.36      0.33      0.33       220\n",
      "\n",
      "[[21  8  6  8]\n",
      " [27 12  8 14]\n",
      " [24  8 20  9]\n",
      " [17 13  6 19]]\n",
      "Validation Loss for P40 = 1.3639754056930542\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_96/2974510044.py:87: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/tmp/ipykernel_96/2974510044.py:43: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n",
      "/tmp/ipykernel_96/2974510044.py:61: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 88/100, Train Loss: 1.3288655281066895\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.24      0.51      0.33        43\n",
      "           1       0.32      0.20      0.24        61\n",
      "           2       0.47      0.33      0.38        61\n",
      "           3       0.39      0.35      0.37        55\n",
      "\n",
      "    accuracy                           0.33       220\n",
      "   macro avg       0.35      0.35      0.33       220\n",
      "weighted avg       0.36      0.33      0.33       220\n",
      "\n",
      "[[22  6  7  8]\n",
      " [27 12  9 13]\n",
      " [24  8 20  9]\n",
      " [17 12  7 19]]\n",
      "Validation Loss for P40 = 1.363345980644226\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_96/2974510044.py:87: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/tmp/ipykernel_96/2974510044.py:43: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n",
      "/tmp/ipykernel_96/2974510044.py:61: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 89/100, Train Loss: 1.4200085401535034\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.23      0.47      0.31        43\n",
      "           1       0.29      0.20      0.23        61\n",
      "           2       0.53      0.33      0.40        61\n",
      "           3       0.37      0.35      0.36        55\n",
      "\n",
      "    accuracy                           0.32       220\n",
      "   macro avg       0.35      0.33      0.32       220\n",
      "weighted avg       0.36      0.32      0.33       220\n",
      "\n",
      "[[20  9  6  8]\n",
      " [27 12  6 16]\n",
      " [23  9 20  9]\n",
      " [18 12  6 19]]\n",
      "Validation Loss for P40 = 1.3635610342025757\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_96/2974510044.py:87: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/tmp/ipykernel_96/2974510044.py:43: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n",
      "/tmp/ipykernel_96/2974510044.py:61: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 90/100, Train Loss: 1.4287999868392944\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.23      0.47      0.31        43\n",
      "           1       0.29      0.21      0.25        61\n",
      "           2       0.49      0.30      0.37        61\n",
      "           3       0.36      0.33      0.34        55\n",
      "\n",
      "    accuracy                           0.31       220\n",
      "   macro avg       0.34      0.33      0.32       220\n",
      "weighted avg       0.35      0.31      0.32       220\n",
      "\n",
      "[[20  9  6  8]\n",
      " [27 13  7 14]\n",
      " [23 10 18 10]\n",
      " [18 13  6 18]]\n",
      "Validation Loss for P40 = 1.3686118125915527\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_96/2974510044.py:87: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/tmp/ipykernel_96/2974510044.py:43: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n",
      "/tmp/ipykernel_96/2974510044.py:61: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 91/100, Train Loss: 1.2888693809509277\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.23      0.49      0.31        43\n",
      "           1       0.32      0.21      0.25        61\n",
      "           2       0.45      0.30      0.36        61\n",
      "           3       0.38      0.33      0.35        55\n",
      "\n",
      "    accuracy                           0.32       220\n",
      "   macro avg       0.34      0.33      0.32       220\n",
      "weighted avg       0.35      0.32      0.32       220\n",
      "\n",
      "[[21  8  7  7]\n",
      " [27 13  8 13]\n",
      " [26  8 18  9]\n",
      " [18 12  7 18]]\n",
      "Validation Loss for P40 = 1.3686819076538086\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_96/2974510044.py:87: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/tmp/ipykernel_96/2974510044.py:43: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n",
      "/tmp/ipykernel_96/2974510044.py:61: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 92/100, Train Loss: 1.2750962972640991\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.24      0.51      0.32        43\n",
      "           1       0.32      0.21      0.25        61\n",
      "           2       0.45      0.30      0.36        61\n",
      "           3       0.37      0.31      0.34        55\n",
      "\n",
      "    accuracy                           0.32       220\n",
      "   macro avg       0.34      0.33      0.32       220\n",
      "weighted avg       0.35      0.32      0.32       220\n",
      "\n",
      "[[22  7  7  7]\n",
      " [27 13  8 13]\n",
      " [26  8 18  9]\n",
      " [18 13  7 17]]\n",
      "Validation Loss for P40 = 1.3665995597839355\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_96/2974510044.py:87: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/tmp/ipykernel_96/2974510044.py:43: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n",
      "/tmp/ipykernel_96/2974510044.py:61: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 93/100, Train Loss: 1.349128007888794\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.23      0.49      0.32        43\n",
      "           1       0.28      0.20      0.23        61\n",
      "           2       0.43      0.30      0.35        61\n",
      "           3       0.36      0.29      0.32        55\n",
      "\n",
      "    accuracy                           0.30       220\n",
      "   macro avg       0.32      0.32      0.30       220\n",
      "weighted avg       0.33      0.30      0.30       220\n",
      "\n",
      "[[21  8  7  7]\n",
      " [27 12  9 13]\n",
      " [24 10 18  9]\n",
      " [18 13  8 16]]\n",
      "Validation Loss for P40 = 1.3688373565673828\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_96/2974510044.py:87: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/tmp/ipykernel_96/2974510044.py:43: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n",
      "/tmp/ipykernel_96/2974510044.py:61: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 94/100, Train Loss: 1.2098267078399658\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.22      0.44      0.29        43\n",
      "           1       0.27      0.20      0.23        61\n",
      "           2       0.42      0.30      0.35        61\n",
      "           3       0.36      0.29      0.32        55\n",
      "\n",
      "    accuracy                           0.30       220\n",
      "   macro avg       0.32      0.31      0.30       220\n",
      "weighted avg       0.32      0.30      0.30       220\n",
      "\n",
      "[[19 10  7  7]\n",
      " [27 12  9 13]\n",
      " [24 10 18  9]\n",
      " [18 12  9 16]]\n",
      "Validation Loss for P40 = 1.3708794116973877\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_96/2974510044.py:87: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/tmp/ipykernel_96/2974510044.py:43: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n",
      "/tmp/ipykernel_96/2974510044.py:61: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 95/100, Train Loss: 1.3937057256698608\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.23      0.49      0.31        43\n",
      "           1       0.30      0.20      0.24        61\n",
      "           2       0.41      0.30      0.34        61\n",
      "           3       0.34      0.27      0.30        55\n",
      "\n",
      "    accuracy                           0.30       220\n",
      "   macro avg       0.32      0.31      0.30       220\n",
      "weighted avg       0.33      0.30      0.30       220\n",
      "\n",
      "[[21  8  7  7]\n",
      " [27 12  9 13]\n",
      " [26  8 18  9]\n",
      " [18 12 10 15]]\n",
      "Validation Loss for P40 = 1.3689371347427368\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_96/2974510044.py:87: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/tmp/ipykernel_96/2974510044.py:43: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n",
      "/tmp/ipykernel_96/2974510044.py:61: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 96/100, Train Loss: 1.3537944555282593\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.24      0.51      0.32        43\n",
      "           1       0.29      0.18      0.22        61\n",
      "           2       0.40      0.30      0.34        61\n",
      "           3       0.34      0.27      0.30        55\n",
      "\n",
      "    accuracy                           0.30       220\n",
      "   macro avg       0.32      0.31      0.30       220\n",
      "weighted avg       0.32      0.30      0.29       220\n",
      "\n",
      "[[22  7  8  6]\n",
      " [27 11  9 14]\n",
      " [26  8 18  9]\n",
      " [18 12 10 15]]\n",
      "Validation Loss for P40 = 1.3719031810760498\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_96/2974510044.py:87: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/tmp/ipykernel_96/2974510044.py:43: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n",
      "/tmp/ipykernel_96/2974510044.py:61: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 97/100, Train Loss: 1.381346583366394\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.22      0.47      0.30        43\n",
      "           1       0.26      0.16      0.20        61\n",
      "           2       0.42      0.31      0.36        61\n",
      "           3       0.35      0.29      0.32        55\n",
      "\n",
      "    accuracy                           0.30       220\n",
      "   macro avg       0.31      0.31      0.29       220\n",
      "weighted avg       0.32      0.30      0.29       220\n",
      "\n",
      "[[20  9  7  7]\n",
      " [27 10 10 14]\n",
      " [25  8 19  9]\n",
      " [18 12  9 16]]\n",
      "Validation Loss for P40 = 1.3717149496078491\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_96/2974510044.py:87: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/tmp/ipykernel_96/2974510044.py:43: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n",
      "/tmp/ipykernel_96/2974510044.py:61: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 98/100, Train Loss: 1.3547544479370117\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.23      0.49      0.31        43\n",
      "           1       0.32      0.20      0.24        61\n",
      "           2       0.41      0.31      0.36        61\n",
      "           3       0.36      0.29      0.32        55\n",
      "\n",
      "    accuracy                           0.31       220\n",
      "   macro avg       0.33      0.32      0.31       220\n",
      "weighted avg       0.34      0.31      0.31       220\n",
      "\n",
      "[[21  6  9  7]\n",
      " [27 12  9 13]\n",
      " [25  8 19  9]\n",
      " [18 12  9 16]]\n",
      "Validation Loss for P40 = 1.3695673942565918\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_96/2974510044.py:87: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/tmp/ipykernel_96/2974510044.py:43: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n",
      "/tmp/ipykernel_96/2974510044.py:61: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 99/100, Train Loss: 1.3498438596725464\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.23      0.42      0.29        43\n",
      "           1       0.26      0.18      0.21        61\n",
      "           2       0.45      0.34      0.39        61\n",
      "           3       0.35      0.33      0.34        55\n",
      "\n",
      "    accuracy                           0.31       220\n",
      "   macro avg       0.32      0.32      0.31       220\n",
      "weighted avg       0.33      0.31      0.31       220\n",
      "\n",
      "[[18  9  9  7]\n",
      " [24 11  9 17]\n",
      " [21 10 21  9]\n",
      " [17 12  8 18]]\n",
      "Validation Loss for P40 = 1.3638173341751099\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_96/2974510044.py:87: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/tmp/ipykernel_96/2974510044.py:43: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n",
      "/tmp/ipykernel_96/2974510044.py:61: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 100/100, Train Loss: 1.351833462715149\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.24      0.49      0.32        43\n",
      "           1       0.30      0.18      0.22        61\n",
      "           2       0.44      0.33      0.38        61\n",
      "           3       0.35      0.33      0.34        55\n",
      "\n",
      "    accuracy                           0.32       220\n",
      "   macro avg       0.33      0.33      0.32       220\n",
      "weighted avg       0.34      0.32      0.31       220\n",
      "\n",
      "[[21  6  9  7]\n",
      " [25 11  8 17]\n",
      " [24  8 20  9]\n",
      " [17 12  8 18]]\n",
      "Validation Loss for P40 = 1.3638700246810913\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_96/2974510044.py:87: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x7fd0304e5cd0>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import confusion_matrix,classification_report\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import preprocessing\n",
    "import matplotlib.pyplot as plt\n",
    "#subjectnames\n",
    "file_list_num = np.arange(len(newsubjectname))\n",
    "file_list_numd = np.arange(len(subjectnamesd))\n",
    "\n",
    "kf = KFold(n_splits=12)\n",
    "torch.manual_seed(42)\n",
    "torch.cuda.manual_seed(42)\n",
    "modellist = []\n",
    "modelid = 1\n",
    "#file_list_num\n",
    "#for i, (train_index, test_index) in enumerate(kf.split(file_list_num)):\n",
    "#for train_index in file_list_num:\n",
    "train_index = file_list_numd\n",
    "test_index_train, test_index_test = train_test_split(file_list_num, test_size=0.30, random_state=42)\n",
    "#test_index = file_list_num\n",
    "print(f\"Fold {i}:\")\n",
    "print(f\"  Train: index={train_index}\")\n",
    "print(f\"  Test:  index={test_index_train}\")\n",
    "net = Net()\n",
    "net.to(device)\n",
    "optimizer = optim.Adam(net.parameters(), lr=0.000001)\n",
    "epochs = 100\n",
    "batch_sz = 20\n",
    "train_loss_epoch = []\n",
    "val_loss_epoch = []\n",
    "for epoch in range(epochs):\n",
    "  train_loss = []\n",
    "  for tr in train_index:\n",
    "    v = data_de1[subjectnamesd[tr]]\n",
    "    l = data_del[subjectnamesd[tr]]\n",
    "    #print(v[0].shape)\n",
    "    net.train()\n",
    "    for i in range(0,len(v),batch_sz):\n",
    "      #print(v[i].shape)\n",
    "      #for j in range(0,v[i].shape[0],batch_sz):\n",
    "      #print(newsubjectname[tr])\n",
    "      optimizer.zero_grad()\n",
    "      outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
    "      #print(\"Expout {}\",outputs.shape)\n",
    "      #print(\"Actual {}\",l[i:i+batch_sz].shape)\n",
    "      #print(l[i].shape)\n",
    "      loss = criterion(outputs, l[i:i+batch_sz].to(device, dtype=torch.float))\n",
    "      loss.backward()\n",
    "      train_loss.append(loss)\n",
    "      optimizer.step()\n",
    "  for tr in test_index_train:\n",
    "    v = data_c1d[newsubjectname[tr]]\n",
    "    l = data_c2[newsubjectname[tr]]\n",
    "    #print(v[0].shape)\n",
    "    net.train()\n",
    "    for i in range(0,len(v),batch_sz):\n",
    "      #print(v[i].shape)\n",
    "      #for j in range(0,v[i].shape[0],batch_sz):\n",
    "      #print(newsubjectname[tr])\n",
    "      optimizer.zero_grad()\n",
    "      outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
    "      #print(\"Expout {}\",outputs.shape)\n",
    "      #print(\"Actual {}\",l[i:i+batch_sz].shape)\n",
    "      #print(l[i].shape)\n",
    "      loss = criterion(outputs, l[i:i+batch_sz].to(device, dtype=torch.float))\n",
    "      loss.backward()\n",
    "      train_loss.append(loss)\n",
    "      optimizer.step()\n",
    "  print(f'Epoch {epoch + 1}/{epochs}, Train Loss: {loss.item()}')\n",
    "  train_loss_epoch.append(torch.stack(train_loss).mean().cpu().detach().numpy())\n",
    "  #print(train_loss_epoch)\n",
    "  expectedoutputamigos = []\n",
    "  actualoutputamigos = []\n",
    "\n",
    "  for tr in test_index_test:\n",
    "      net.eval()\n",
    "\n",
    "      v = data_c1d[newsubjectname[tr]]\n",
    "      l = data_c2[newsubjectname[tr]]\n",
    "      net.eval()\n",
    "      val_loss = []\n",
    "      with torch.no_grad():\n",
    "          for i in range(0,len(v),batch_sz):\n",
    "            #print(v[i].shape)\n",
    "            #for j in range(0,v[i].shape[0],batch_sz):\n",
    "            optimizer.zero_grad()\n",
    "            outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
    "            #print(outputs.shape)\n",
    "            #print(l[i:i+batch_sz].shape)\n",
    "            loss = criterion(outputs, l[i:i+batch_sz].to(device, dtype=torch.float))\n",
    "            val_loss.append(loss)\n",
    "            #actualoutputamigos.append(torch.round(outputs.cpu()))\n",
    "            #expectedoutputamigos.append(l[i:i+batch_sz])\n",
    "            actualoutputamigos.append(torch.argmax(torch.softmax(outputs.cpu(),dim=1),dim=1))\n",
    "            expectedoutputamigos.append(torch.argmax(l[i:i+batch_sz],dim=1).numpy())\n",
    "  val_loss_mean = torch.stack(val_loss).mean().cpu().detach().numpy()\n",
    "  val_loss_epoch.append(val_loss_mean)\n",
    "  expectedoutputamigos = np.concatenate( expectedoutputamigos, axis=0 )\n",
    "  actualoutputamigos = np.concatenate( actualoutputamigos, axis=0 )\n",
    "  #print(expectedoutput.shape)\n",
    "  #print(actualoutput.shape)\n",
    "  print(classification_report(expectedoutputamigos,actualoutputamigos))\n",
    "  print(confusion_matrix(expectedoutputamigos,actualoutputamigos))\n",
    "  print(f'Validation Loss for {newsubjectname[tr]} = {val_loss_mean}')\n",
    "plt.figure(figsize=(10,7))\n",
    "#print(len(train_loss_epoch))\n",
    "plt.plot(np.arange(epochs),train_loss_epoch,label='Train')\n",
    "plt.plot(np.arange(epochs),val_loss_epoch,label='Validation')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "629a6e47-a58b-496b-9740-4e35f730b5d6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
