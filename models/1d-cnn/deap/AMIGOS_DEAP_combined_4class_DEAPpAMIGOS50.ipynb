{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "lV6AUpSouNYI",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "lV6AUpSouNYI",
    "outputId": "e479380e-fbed-427b-87fd-cc146892b6da"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mounted at /content/drive\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "njT3xEyzuOSC",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2024-01-21T19:55:18.294674Z",
     "iopub.status.busy": "2024-01-21T19:55:18.294070Z",
     "iopub.status.idle": "2024-01-21T19:55:40.973243Z",
     "shell.execute_reply": "2024-01-21T19:55:40.972658Z",
     "shell.execute_reply.started": "2024-01-21T19:55:18.294651Z"
    },
    "id": "njT3xEyzuOSC",
    "outputId": "d85411f6-4f18-49ad-87f7-ea614f2e47f8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Archive:  AMIGOS.zip\n",
      "  inflating: AMIGOS/Data_Preprocessed_P01.mat  \n",
      "  inflating: AMIGOS/Data_Preprocessed_P02.mat  \n",
      "  inflating: AMIGOS/Data_Preprocessed_P03.mat  \n",
      "  inflating: AMIGOS/Data_Preprocessed_P04.mat  \n",
      "  inflating: AMIGOS/Data_Preprocessed_P05.mat  \n",
      "  inflating: AMIGOS/Data_Preprocessed_P06.mat  \n",
      "  inflating: AMIGOS/Data_Preprocessed_P07.mat  \n",
      "  inflating: AMIGOS/Data_Preprocessed_P08.mat  \n",
      "  inflating: AMIGOS/Data_Preprocessed_P09.mat  \n",
      "  inflating: AMIGOS/Data_Preprocessed_P10.mat  \n",
      "  inflating: AMIGOS/Data_Preprocessed_P11.mat  \n",
      "  inflating: AMIGOS/Data_Preprocessed_P12.mat  \n",
      "  inflating: AMIGOS/Data_Preprocessed_P13.mat  \n",
      "  inflating: AMIGOS/Data_Preprocessed_P14.mat  \n",
      "  inflating: AMIGOS/Data_Preprocessed_P15.mat  \n",
      "  inflating: AMIGOS/Data_Preprocessed_P16.mat  \n",
      "  inflating: AMIGOS/Data_Preprocessed_P17.mat  \n",
      "  inflating: AMIGOS/Data_Preprocessed_P18.mat  \n",
      "  inflating: AMIGOS/Data_Preprocessed_P19.mat  \n",
      "  inflating: AMIGOS/Data_Preprocessed_P20.mat  \n",
      "  inflating: AMIGOS/Data_Preprocessed_P21.mat  \n",
      "  inflating: AMIGOS/Data_Preprocessed_P22.mat  \n",
      "  inflating: AMIGOS/Data_Preprocessed_P23.mat  \n",
      "  inflating: AMIGOS/Data_Preprocessed_P24.mat  \n",
      "  inflating: AMIGOS/Data_Preprocessed_P25.mat  \n",
      "  inflating: AMIGOS/Data_Preprocessed_P26.mat  \n",
      "  inflating: AMIGOS/Data_Preprocessed_P27.mat  \n",
      "  inflating: AMIGOS/Data_Preprocessed_P28.mat  \n",
      "  inflating: AMIGOS/Data_Preprocessed_P29.mat  \n",
      "  inflating: AMIGOS/Data_Preprocessed_P30.mat  \n",
      "  inflating: AMIGOS/Data_Preprocessed_P31.mat  \n",
      "  inflating: AMIGOS/Data_Preprocessed_P32.mat  \n",
      "  inflating: AMIGOS/Data_Preprocessed_P33.mat  \n",
      "  inflating: AMIGOS/Data_Preprocessed_P34.mat  \n",
      "  inflating: AMIGOS/Data_Preprocessed_P35.mat  \n",
      "  inflating: AMIGOS/Data_Preprocessed_P36.mat  \n",
      "  inflating: AMIGOS/Data_Preprocessed_P37.mat  \n",
      "  inflating: AMIGOS/Data_Preprocessed_P38.mat  \n",
      "  inflating: AMIGOS/Data_Preprocessed_P39.mat  \n",
      "  inflating: AMIGOS/Data_Preprocessed_P40.mat  \n"
     ]
    }
   ],
   "source": [
    "!unzip \"AMIGOS.zip\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "GPftEcnHuJrY",
   "metadata": {
    "id": "GPftEcnHuJrY"
   },
   "outputs": [],
   "source": [
    "import scipy.io\n",
    "data = scipy.io.loadmat(\"AMIGOS/Data_Preprocessed_P32.mat\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "Hz_c9Dnoua7T",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Hz_c9Dnoua7T",
    "outputId": "09a9a543-7156-4279-eda3-45021ff3edf9"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 12)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#data['joined_data'][0][19].shape\n",
    "#data['labels_selfassessment'][0][15].shape\n",
    "#data['joined_data'].shape[1]\n",
    "#data['labels_selfassessment'][0][1][0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "SI3v-4-DTC60",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 463
    },
    "id": "SI3v-4-DTC60",
    "outputId": "390a5f34-c7ad-4e73-8513-95e2c0f068e7"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10191,)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.plot(data['joined_data'][0][16][384:,16])\n",
    "data['joined_data'][0][3][384:,16].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "WFGqncuxTz4s",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 463
    },
    "id": "WFGqncuxTz4s",
    "outputId": "2877bf49-f2b1-4a12-9a31-b245c833c2f6"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7bb4a0d7ec80>]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import scipy.io\n",
    "y1 = scipy.signal.resample(data['joined_data'][0][16][:,16], 8000)\n",
    "plt.plot(y1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "81e9e46f-88cc-4ba9-a64f-347034bea365",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2024-01-23T12:58:09.463608Z",
     "iopub.status.busy": "2024-01-23T12:58:09.462995Z",
     "iopub.status.idle": "2024-01-23T12:58:09.476384Z",
     "shell.execute_reply": "2024-01-23T12:58:09.475019Z",
     "shell.execute_reply.started": "2024-01-23T12:58:09.463580Z"
    },
    "id": "81e9e46f-88cc-4ba9-a64f-347034bea365",
    "outputId": "bcb347b1-3a4c-4281-e78d-5555e64d6a27"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['AMIGOS/Data_Preprocessed_P33.mat', 'AMIGOS/Data_Preprocessed_P30.mat', 'AMIGOS/Data_Preprocessed_P13.mat', 'AMIGOS/Data_Preprocessed_P26.mat', 'AMIGOS/Data_Preprocessed_P37.mat', 'AMIGOS/Data_Preprocessed_P31.mat', 'AMIGOS/Data_Preprocessed_P10.mat', 'AMIGOS/Data_Preprocessed_P09.mat', 'AMIGOS/Data_Preprocessed_P05.mat', 'AMIGOS/Data_Preprocessed_P40.mat', 'AMIGOS/Data_Preprocessed_P35.mat', 'AMIGOS/Data_Preprocessed_P32.mat', 'AMIGOS/Data_Preprocessed_P22.mat', 'AMIGOS/Data_Preprocessed_P23.mat', 'AMIGOS/Data_Preprocessed_P17.mat', 'AMIGOS/Data_Preprocessed_P04.mat', 'AMIGOS/Data_Preprocessed_P12.mat', 'AMIGOS/Data_Preprocessed_P34.mat', 'AMIGOS/Data_Preprocessed_P29.mat', 'AMIGOS/Data_Preprocessed_P15.mat', 'AMIGOS/Data_Preprocessed_P02.mat', 'AMIGOS/Data_Preprocessed_P25.mat', 'AMIGOS/Data_Preprocessed_P18.mat', 'AMIGOS/Data_Preprocessed_P36.mat', 'AMIGOS/Data_Preprocessed_P16.mat', 'AMIGOS/Data_Preprocessed_P28.mat', 'AMIGOS/Data_Preprocessed_P03.mat', 'AMIGOS/Data_Preprocessed_P38.mat', 'AMIGOS/Data_Preprocessed_P39.mat', 'AMIGOS/Data_Preprocessed_P27.mat', 'AMIGOS/Data_Preprocessed_P01.mat', 'AMIGOS/Data_Preprocessed_P19.mat', 'AMIGOS/Data_Preprocessed_P06.mat', 'AMIGOS/Data_Preprocessed_P24.mat', 'AMIGOS/Data_Preprocessed_P11.mat', 'AMIGOS/Data_Preprocessed_P08.mat', 'AMIGOS/Data_Preprocessed_P21.mat', 'AMIGOS/Data_Preprocessed_P07.mat', 'AMIGOS/Data_Preprocessed_P14.mat', 'AMIGOS/Data_Preprocessed_P20.mat']\n",
      "['P33', 'P30', 'P13', 'P26', 'P37', 'P31', 'P10', 'P09', 'P05', 'P40', 'P35', 'P32', 'P22', 'P23', 'P17', 'P04', 'P12', 'P34', 'P29', 'P15', 'P02', 'P25', 'P18', 'P36', 'P16', 'P28', 'P03', 'P38', 'P39', 'P27', 'P01', 'P19', 'P06', 'P24', 'P11', 'P08', 'P21', 'P07', 'P14', 'P20']\n"
     ]
    }
   ],
   "source": [
    "import glob\n",
    "import os\n",
    "filelist = glob.glob('AMIGOS/*.mat')\n",
    "print(filelist)\n",
    "subjectnames = [fr[25:28] for fr in filelist]\n",
    "print(subjectnames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "74fe1cd7-c31d-44dd-8537-27f357d17096",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2024-01-23T12:58:17.171967Z",
     "iopub.status.busy": "2024-01-23T12:58:17.171541Z",
     "iopub.status.idle": "2024-01-23T12:58:57.244941Z",
     "shell.execute_reply": "2024-01-23T12:58:57.240698Z",
     "shell.execute_reply.started": "2024-01-23T12:58:17.171929Z"
    },
    "id": "74fe1cd7-c31d-44dd-8537-27f357d17096",
    "outputId": "b02ad912-56e9-45b3-dd39-d9d46bc0a2d4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "P33\n",
      "P30\n",
      "P13\n",
      "P26\n",
      "P37\n",
      "P31\n",
      "P10\n",
      "P09\n",
      "P05\n",
      "P40\n",
      "P35\n",
      "P22\n",
      "P23\n",
      "P17\n",
      "P04\n",
      "P12\n",
      "P34\n",
      "P29\n",
      "P15\n",
      "P02\n",
      "P25\n",
      "P18\n",
      "P36\n",
      "P16\n",
      "P03\n",
      "P38\n",
      "P39\n",
      "P27\n",
      "P01\n",
      "P19\n",
      "P06\n",
      "P11\n",
      "P21\n",
      "P07\n",
      "P14\n",
      "P20\n",
      "dict_keys(['P33', 'P30', 'P13', 'P26', 'P37', 'P31', 'P10', 'P09', 'P05', 'P40', 'P35', 'P22', 'P23', 'P17', 'P04', 'P12', 'P34', 'P29', 'P15', 'P02', 'P25', 'P18', 'P36', 'P16', 'P03', 'P38', 'P39', 'P27', 'P01', 'P19', 'P06', 'P11', 'P21', 'P07', 'P14', 'P20'])\n"
     ]
    }
   ],
   "source": [
    "import scipy.io\n",
    "import numpy as np\n",
    "data_am = {}\n",
    "skiplist = ['P28','P08','P24','P32']\n",
    "newsubjectname = []\n",
    "for sname in subjectnames:\n",
    "    if sname in skiplist:\n",
    "      continue\n",
    "    newsubjectname.append(sname)\n",
    "    dname = \"AMIGOS/Data_Preprocessed_\"+sname+\".mat\"\n",
    "    x = scipy.io.loadmat(dname)\n",
    "    print(sname)\n",
    "    samples = []\n",
    "    samples_labels = []\n",
    "    for i in range(x['joined_data'].shape[1]):\n",
    "        x1 = x['joined_data'][0][i]\n",
    "        x2 = scipy.signal.resample(x1[384:,16], 8064)\n",
    "        y1 = x['labels_selfassessment'][0][i][0][0:2]\n",
    "        samples.append(x2)\n",
    "        samples_labels.append(y1)\n",
    "    samples_stack = np.vstack(samples)\n",
    "    samples_labels_stack = np.vstack(samples_labels)\n",
    "    data_am[sname] = [samples_stack,samples_labels_stack]\n",
    "\n",
    "print(data_am.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "qnHCy6Wra5Fu",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "qnHCy6Wra5Fu",
    "outputId": "9d1b17db-cde0-45d9-96ac-fdac666f660f"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([3237180.31474926, 3110649.65303398, 3179062.7496687 , ...,\n",
       "       3514282.08715568, 3478618.13315719, 3540966.49534216])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_am['P01'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8976cde3-bc3f-4fcb-a8af-d624fcde1675",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2024-01-22T10:34:34.385913Z",
     "iopub.status.busy": "2024-01-22T10:34:34.385617Z",
     "iopub.status.idle": "2024-01-22T10:34:34.694156Z",
     "shell.execute_reply": "2024-01-22T10:34:34.693467Z",
     "shell.execute_reply.started": "2024-01-22T10:34:34.385891Z"
    },
    "id": "8976cde3-bc3f-4fcb-a8af-d624fcde1675",
    "outputId": "35ec17fd-7d92-4bb3-a961-3339979bfbc7"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "data_cam = {}\n",
    "for k,v in data_am.items():\n",
    "    y = v[0]\n",
    "    ym = np.mean(y,axis=-1).reshape(20,1)\n",
    "    ystd = np.std(y,axis=-1).reshape(20,1)\n",
    "    z = (y-ym)/ystd\n",
    "    #print(z.shape)\n",
    "    data_cam[k] = [z,v[1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "kgzh85M-Zyyx",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 448
    },
    "execution": {
     "iopub.execute_input": "2024-01-22T09:46:41.740505Z",
     "iopub.status.busy": "2024-01-22T09:46:41.739848Z",
     "iopub.status.idle": "2024-01-22T09:46:41.864825Z",
     "shell.execute_reply": "2024-01-22T09:46:41.864185Z",
     "shell.execute_reply.started": "2024-01-22T09:46:41.740481Z"
    },
    "id": "kgzh85M-Zyyx",
    "outputId": "10010e12-e6d0-4189-ccc0-b9350a6cf1af"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f4326733d90>]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(data_cam['P01'][0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "56JG3ogz-LUE",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2024-01-22T10:34:46.482788Z",
     "iopub.status.busy": "2024-01-22T10:34:46.482431Z",
     "iopub.status.idle": "2024-01-22T10:34:47.389085Z",
     "shell.execute_reply": "2024-01-22T10:34:47.388317Z",
     "shell.execute_reply.started": "2024-01-22T10:34:46.482764Z"
    },
    "id": "56JG3ogz-LUE",
    "outputId": "d239a446-2b69-4f9c-f45e-c880f8c64511"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 8064])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "data_c1d = {}\n",
    "BLOCK_SIZE=640\n",
    "BLOCK_STRIDE=60\n",
    "for k,v in data_cam.items():\n",
    "    datablocki = []\n",
    "    v1 = v[0]\n",
    "    v1 = v1[:,np.newaxis,:]\n",
    "    #print(v1.shape)\n",
    "    data_c1d[k] = torch.tensor(v1)\n",
    "print(data_c1d['P01'][0].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ce1ed7be-a882-45ec-810d-6b1c43af0af3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-22T10:04:28.619802Z",
     "iopub.status.busy": "2024-01-22T10:04:28.618700Z",
     "iopub.status.idle": "2024-01-22T10:04:28.688356Z",
     "shell.execute_reply": "2024-01-22T10:04:28.687618Z",
     "shell.execute_reply.started": "2024-01-22T10:04:28.619762Z"
    },
    "id": "ce1ed7be-a882-45ec-810d-6b1c43af0af3"
   },
   "outputs": [],
   "source": [
    "data_c2 = {}\n",
    "for k,v in data_cam.items():\n",
    "    y = v[1]\n",
    "    x_label = np.zeros((y.shape[0]),dtype='float64')\n",
    "    for i in range(y.shape[0]):\n",
    "        if (y[i][0] > 5):\n",
    "            x_label[i] = 1\n",
    "        else:\n",
    "            x_label[i] = 0\n",
    "\n",
    "    x_l = x_label\n",
    "    x_l = x_l.reshape(-1,1)\n",
    "    x_l = torch.tensor(x_l)\n",
    "    data_c2[k] = x_l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "fa943a48-8252-4c85-ab48-4e6cb0c101a4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-21T20:26:35.503245Z",
     "iopub.status.busy": "2024-01-21T20:26:35.502318Z",
     "iopub.status.idle": "2024-01-21T20:26:35.509003Z",
     "shell.execute_reply": "2024-01-21T20:26:35.508226Z",
     "shell.execute_reply.started": "2024-01-21T20:26:35.503218Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1.],\n",
       "        [1.],\n",
       "        [0.],\n",
       "        [1.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [0.],\n",
       "        [1.],\n",
       "        [0.],\n",
       "        [1.]], dtype=torch.float64)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_c2['P02']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "Pm5zhOqDgK79",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-22T10:35:28.468011Z",
     "iopub.status.busy": "2024-01-22T10:35:28.467644Z",
     "iopub.status.idle": "2024-01-22T10:35:28.537471Z",
     "shell.execute_reply": "2024-01-22T10:35:28.536717Z",
     "shell.execute_reply.started": "2024-01-22T10:35:28.467988Z"
    },
    "id": "Pm5zhOqDgK79"
   },
   "outputs": [],
   "source": [
    "data_c2 = {}\n",
    "maxnum = 3\n",
    "for k,v in data_cam.items():\n",
    "    y = v[1]\n",
    "    x_label = np.zeros((y.shape[0]),dtype='int32')\n",
    "    for i in range(y.shape[0]):\n",
    "        if (y[i][1] > 5 and y[i][0] > 5):\n",
    "            x_label[i] = 3\n",
    "        elif (y[i][1] <= 5 and y[i][0] > 5):\n",
    "            x_label[i] = 2\n",
    "        elif (y[i][1] > 5 and y[i][0] <= 5):\n",
    "            x_label[i] = 1\n",
    "        elif (y[i][1] <= 5 and y[i][0] <= 5):\n",
    "            x_label[i] = 0\n",
    "\n",
    "    x_l = np.zeros((x_label.size, maxnum+1))\n",
    "    x_l[np.arange(x_label.size), x_label] = 1\n",
    "\n",
    "    x_l = torch.tensor(x_l)\n",
    "    data_c2[k] = x_l\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "6d8e2d1b-cc85-483f-843a-8d7c4b9c5ec8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-22T10:14:03.574101Z",
     "iopub.status.busy": "2024-01-22T10:14:03.573139Z",
     "iopub.status.idle": "2024-01-22T10:14:03.578258Z",
     "shell.execute_reply": "2024-01-22T10:14:03.577561Z",
     "shell.execute_reply.started": "2024-01-22T10:14:03.574074Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([20, 4])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_c2['P01'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "48a74ab5-e71d-441a-b786-630c4abc3685",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-22T10:35:34.314031Z",
     "iopub.status.busy": "2024-01-22T10:35:34.313298Z",
     "iopub.status.idle": "2024-01-22T10:35:34.336569Z",
     "shell.execute_reply": "2024-01-22T10:35:34.335721Z",
     "shell.execute_reply.started": "2024-01-22T10:35:34.314003Z"
    },
    "id": "48a74ab5-e71d-441a-b786-630c4abc3685"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "#from torchinfo import Summary\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.c1=nn.Conv1d(1, 34, 10,stride=1)\n",
    "        self.mp1=nn.MaxPool1d(2)\n",
    "        self.norm1 = nn.BatchNorm1d(34)\n",
    "        self.d = nn.Dropout(p=0.63)\n",
    "        self.c2=nn.Conv1d(34, 30, 10,stride=1)\n",
    "        self.mp2=nn.MaxPool1d(2)\n",
    "        self.c3=nn.Conv1d(30, 10, 10,stride=1)\n",
    "        self.norm3 = nn.BatchNorm1d(10)\n",
    "        self.mp3=nn.MaxPool1d(2)\n",
    "        self.ft = nn.Flatten()\n",
    "\n",
    "        self.n1 = nn.Linear(20070,110)\n",
    "        #self.n1 = nn.Linear(19590,110)\n",
    "        self.normfc1=nn.BatchNorm1d(110)\n",
    "        self.d = nn.Dropout(p=0.63)\n",
    "        #self.d = nn.Dropout()\n",
    "        self.n2 = nn.Linear(110,100)\n",
    "        self.n3 = nn.Linear(100,4)\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.d(self.norm1(F.tanh(self.c1(x))))\n",
    "        #x=F.tanh(self.c1(x))\n",
    "        x = self.mp2(F.tanh(self.c2(x)))\n",
    "        #print(x.shape)\n",
    "        x = self.mp3(F.tanh(self.c3(x)))\n",
    "\n",
    "        #print(x.shape)\n",
    "        x = self.ft(x)\n",
    "        #print(x.shape)\n",
    "        x = F.tanh(self.n1(x))\n",
    "        x=self.normfc1(x)\n",
    "        #x=self.norm3(x)\n",
    "        x=self.d(x)\n",
    "\n",
    "        #x = F.softmax(self.n2(x),dim=-1)\n",
    "        x = F.tanh(self.n2(x))\n",
    "        #x = F.sigmoid(self.n3(x))\n",
    "\n",
    "        x = (self.n3(x))\n",
    "        #print(x.shape)\n",
    "        return x\n",
    "\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "#criterion = nn.BCELoss()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "624818a4-e9ca-4f32-9930-8ade33ca95df",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "execution": {
     "iopub.execute_input": "2024-01-21T20:39:25.503661Z",
     "iopub.status.busy": "2024-01-21T20:39:25.503127Z",
     "iopub.status.idle": "2024-01-21T20:39:41.152046Z",
     "shell.execute_reply": "2024-01-21T20:39:41.151535Z",
     "shell.execute_reply.started": "2024-01-21T20:39:25.503640Z"
    },
    "id": "624818a4-e9ca-4f32-9930-8ade33ca95df",
    "outputId": "7b50a269-a030-4ad0-b013-e506e2fb1233"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 0:\n",
      "  Train: index=[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23\n",
      " 24 25 26 27 28 29 30 31 32 33 34 35]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_203/3472248682.py:38: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1960: UserWarning: nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\n",
      "  warnings.warn(\"nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/60, Train Loss: 0.6609741449356079\n",
      "Epoch 2/60, Train Loss: 0.6968510746955872\n",
      "Epoch 3/60, Train Loss: 0.7063091397285461\n",
      "Epoch 4/60, Train Loss: 0.7129724025726318\n",
      "Epoch 5/60, Train Loss: 0.6755002737045288\n",
      "Epoch 6/60, Train Loss: 0.677463948726654\n",
      "Epoch 7/60, Train Loss: 0.7001715302467346\n",
      "Epoch 8/60, Train Loss: 0.641160249710083\n",
      "Epoch 9/60, Train Loss: 0.6524507403373718\n",
      "Epoch 10/60, Train Loss: 0.6981868147850037\n",
      "Epoch 11/60, Train Loss: 0.7125951051712036\n",
      "Epoch 12/60, Train Loss: 0.6761418581008911\n",
      "Epoch 13/60, Train Loss: 0.6650707125663757\n",
      "Epoch 14/60, Train Loss: 0.6498364806175232\n",
      "Epoch 15/60, Train Loss: 0.6750850081443787\n",
      "Epoch 16/60, Train Loss: 0.7362504005432129\n",
      "Epoch 17/60, Train Loss: 0.6782377362251282\n",
      "Epoch 18/60, Train Loss: 0.6005708575248718\n",
      "Epoch 19/60, Train Loss: 0.6484631896018982\n",
      "Epoch 20/60, Train Loss: 0.6615355610847473\n",
      "Epoch 21/60, Train Loss: 0.7476146817207336\n",
      "Epoch 22/60, Train Loss: 0.6450007557868958\n",
      "Epoch 23/60, Train Loss: 0.6990272998809814\n",
      "Epoch 24/60, Train Loss: 0.6960132718086243\n",
      "Epoch 25/60, Train Loss: 0.6487043499946594\n",
      "Epoch 26/60, Train Loss: 0.6940182447433472\n",
      "Epoch 27/60, Train Loss: 0.7425288558006287\n",
      "Epoch 28/60, Train Loss: 0.7695755958557129\n",
      "Epoch 29/60, Train Loss: 0.6488133072853088\n",
      "Epoch 30/60, Train Loss: 0.6783266067504883\n",
      "Epoch 31/60, Train Loss: 0.6386670470237732\n",
      "Epoch 32/60, Train Loss: 0.6566615700721741\n",
      "Epoch 33/60, Train Loss: 0.6245983242988586\n",
      "Epoch 34/60, Train Loss: 0.6381314396858215\n",
      "Epoch 35/60, Train Loss: 0.6594816446304321\n",
      "Epoch 36/60, Train Loss: 0.6990213394165039\n",
      "Epoch 37/60, Train Loss: 0.7033595442771912\n",
      "Epoch 38/60, Train Loss: 0.72736656665802\n",
      "Epoch 39/60, Train Loss: 0.6317784190177917\n",
      "Epoch 40/60, Train Loss: 0.695755660533905\n",
      "Epoch 41/60, Train Loss: 0.5978154540061951\n",
      "Epoch 42/60, Train Loss: 0.7467979788780212\n",
      "Epoch 43/60, Train Loss: 0.6905636191368103\n",
      "Epoch 44/60, Train Loss: 0.6623584628105164\n",
      "Epoch 45/60, Train Loss: 0.6861650347709656\n",
      "Epoch 46/60, Train Loss: 0.6978986859321594\n",
      "Epoch 47/60, Train Loss: 0.69769287109375\n",
      "Epoch 48/60, Train Loss: 0.6886689066886902\n",
      "Epoch 49/60, Train Loss: 0.6211285591125488\n",
      "Epoch 50/60, Train Loss: 0.7211494445800781\n",
      "Epoch 51/60, Train Loss: 0.645512580871582\n",
      "Epoch 52/60, Train Loss: 0.6711452603340149\n",
      "Epoch 53/60, Train Loss: 0.6328474283218384\n",
      "Epoch 54/60, Train Loss: 0.6318807005882263\n",
      "Epoch 55/60, Train Loss: 0.6630229353904724\n",
      "Epoch 56/60, Train Loss: 0.7082170844078064\n",
      "Epoch 57/60, Train Loss: 0.6603700518608093\n",
      "Epoch 58/60, Train Loss: 0.6021323204040527\n",
      "Epoch 59/60, Train Loss: 0.6721572875976562\n",
      "Epoch 60/60, Train Loss: 0.6605284214019775\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import confusion_matrix,classification_report\n",
    "from sklearn import preprocessing\n",
    "import matplotlib.pyplot as plt\n",
    "#subjectnames\n",
    "file_list_num = np.arange(len(newsubjectname))\n",
    "kf = KFold(n_splits=12)\n",
    "torch.manual_seed(42)\n",
    "torch.cuda.manual_seed(42)\n",
    "modellist = []\n",
    "modelid = 1\n",
    "#file_list_num\n",
    "#for i, (train_index, test_index) in enumerate(kf.split(file_list_num)):\n",
    "#for train_index in file_list_num:\n",
    "train_index = file_list_num\n",
    "print(f\"Fold {i}:\")\n",
    "print(f\"  Train: index={train_index}\")\n",
    "#print(f\"  Test:  index={test_index}\")\n",
    "net = Net()\n",
    "net.to(device)\n",
    "optimizer = optim.Adam(net.parameters(), lr=0.000001)\n",
    "epochs = 60\n",
    "batch_sz = 20\n",
    "train_loss_epoch = []\n",
    "val_loss_epoch = []\n",
    "for epoch in range(epochs):\n",
    "  train_loss = []\n",
    "  for tr in train_index:\n",
    "    v = data_c1d[newsubjectname[tr]]\n",
    "    l = data_c2[newsubjectname[tr]]\n",
    "    #print(v[0].shape)\n",
    "    net.train()\n",
    "    for i in range(0,len(v),batch_sz):\n",
    "      #print(v[i].shape)\n",
    "      #for j in range(0,v[i].shape[0],batch_sz):\n",
    "      #print(newsubjectname[tr])\n",
    "      optimizer.zero_grad()\n",
    "      outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
    "      #print(\"Expout {}\",outputs.shape)\n",
    "      #print(\"Actual {}\",l[i:i+batch_sz].shape)\n",
    "      #print(l[i].shape)\n",
    "      loss = criterion(outputs, l[i:i+batch_sz].to(device, dtype=torch.float))\n",
    "      loss.backward()\n",
    "      train_loss.append(loss)\n",
    "      optimizer.step()\n",
    "  print(f'Epoch {epoch + 1}/{epochs}, Train Loss: {loss.item()}')\n",
    "  train_loss_epoch.append(torch.stack(train_loss).mean().cpu().detach().numpy())\n",
    "\n",
    "  '''\n",
    "  for tr in test_index:\n",
    "      net.eval()\n",
    "      v = data_c1d[newsubjectname[tr]]\n",
    "      l = data_c2[newsubjectname[tr]]\n",
    "      net.eval()\n",
    "      with torch.no_grad():\n",
    "          for i in range(0,len(v),batch_sz):\n",
    "            #print(v[i].shape)\n",
    "            #for j in range(0,v[i].shape[0],batch_sz):\n",
    "            optimizer.zero_grad()\n",
    "            outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
    "            #print(outputs.shape)\n",
    "            #print(l[i].shape)\n",
    "            #outputs1 = torch.softmax(outputs,dim=-1)\n",
    "            loss = criterion(outputs, l[i:i+batch_sz].to(device, dtype=torch.float))\n",
    "            val_loss.append(loss)\n",
    "            #loss.backward()\n",
    "            actualoutput.append(torch.round(outputs.cpu()))\n",
    "            expectedoutput.append(l[i:i+batch_sz])\n",
    "            #actualoutput.append(torch.argmax(torch.softmax(outputs.cpu(),dim=1),dim=1))\n",
    "            #expectedoutput.append(torch.argmax(l[i:i+batch_sz],dim=1).numpy())\n",
    "  val_loss_mean = torch.stack(val_loss).mean().cpu().detach().numpy()\n",
    "  val_loss_epoch.append(val_loss_mean)\n",
    "  expectedoutput = np.concatenate( expectedoutput, axis=0 )\n",
    "  actualoutput = np.concatenate( actualoutput, axis=0 )\n",
    "  print(expectedoutput.shape)\n",
    "  print(actualoutput.shape)\n",
    "  print(classification_report(expectedoutput,actualoutput))\n",
    "  print(confusion_matrix(expectedoutput,actualoutput))\n",
    "  print(f'Validation Loss for {subjectnames[tr]} = {val_loss_mean}')\n",
    "  #break\n",
    "  '''\n",
    "#plt.figure(figsize=(10,7))\n",
    "#print(len(train_loss_epoch))\n",
    "#plt.plot(np.arange(epochs),train_loss_epoch,label='Train')\n",
    "#plt.plot(np.arange(epochs),val_loss_epoch,label='Validation')\n",
    "#plt.legend()\n",
    "#path = \"Model\"+str(modelid) +\".pt\"\n",
    "#path = \"ModelAMIGOS_Aro.pt\"\n",
    "#modelid = modelid+1\n",
    "#print(path)\n",
    "#torch.save(net.state_dict(), path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "5P36UViqRcul",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5P36UViqRcul",
    "outputId": "e071c001-0c26-4c44-ee20-9a315b022829"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-27-7929d1561c85>:33: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs_val = netValence(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "<ipython-input-27-7929d1561c85>:35: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs_aro = netArousal(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.39      0.22      0.28        41\n",
      "           2       0.56      0.12      0.20        42\n",
      "           3       0.24      0.52      0.33        27\n",
      "           4       0.36      0.50      0.42        50\n",
      "\n",
      "    accuracy                           0.33       160\n",
      "   macro avg       0.39      0.34      0.31       160\n",
      "weighted avg       0.40      0.33      0.31       160\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-27-7929d1561c85>:33: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs_val = netValence(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "<ipython-input-27-7929d1561c85>:35: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs_aro = netArousal(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.50      0.17      0.25        42\n",
      "           2       1.00      0.10      0.18        30\n",
      "           3       0.34      0.83      0.48        41\n",
      "           4       0.40      0.36      0.38        47\n",
      "\n",
      "    accuracy                           0.38       160\n",
      "   macro avg       0.56      0.36      0.32       160\n",
      "weighted avg       0.52      0.38      0.33       160\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-27-7929d1561c85>:33: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs_val = netValence(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "<ipython-input-27-7929d1561c85>:35: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs_aro = netArousal(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.21      0.19      0.20        31\n",
      "           2       0.57      0.12      0.20        34\n",
      "           3       0.29      0.53      0.37        43\n",
      "           4       0.48      0.40      0.44        52\n",
      "\n",
      "    accuracy                           0.34       160\n",
      "   macro avg       0.39      0.31      0.30       160\n",
      "weighted avg       0.39      0.34      0.32       160\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-27-7929d1561c85>:33: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs_val = netValence(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "<ipython-input-27-7929d1561c85>:35: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs_aro = netArousal(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.36      0.12      0.19        32\n",
      "           2       0.67      0.05      0.10        39\n",
      "           3       0.30      0.67      0.42        39\n",
      "           4       0.52      0.62      0.56        50\n",
      "\n",
      "    accuracy                           0.39       160\n",
      "   macro avg       0.46      0.37      0.32       160\n",
      "weighted avg       0.47      0.39      0.34       160\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-27-7929d1561c85>:33: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs_val = netValence(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "<ipython-input-27-7929d1561c85>:35: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs_aro = netArousal(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.44      0.10      0.16        42\n",
      "           2       0.33      0.07      0.12        28\n",
      "           3       0.21      0.77      0.33        26\n",
      "           4       0.48      0.36      0.41        64\n",
      "\n",
      "    accuracy                           0.31       160\n",
      "   macro avg       0.37      0.32      0.25       160\n",
      "weighted avg       0.40      0.31      0.28       160\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-27-7929d1561c85>:33: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs_val = netValence(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "<ipython-input-27-7929d1561c85>:35: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs_aro = netArousal(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.56      0.18      0.27        28\n",
      "           2       0.00      0.00      0.00        22\n",
      "           3       0.31      0.71      0.43        48\n",
      "           4       0.55      0.35      0.43        62\n",
      "\n",
      "    accuracy                           0.38       160\n",
      "   macro avg       0.35      0.31      0.28       160\n",
      "weighted avg       0.40      0.38      0.34       160\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-27-7929d1561c85>:33: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs_val = netValence(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "<ipython-input-27-7929d1561c85>:35: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs_aro = netArousal(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "<ipython-input-27-7929d1561c85>:33: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs_val = netValence(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "<ipython-input-27-7929d1561c85>:35: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs_aro = netArousal(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.17      0.03      0.05        33\n",
      "           2       0.00      0.00      0.00        37\n",
      "           3       0.27      0.76      0.39        41\n",
      "           4       0.37      0.29      0.32        49\n",
      "\n",
      "    accuracy                           0.29       160\n",
      "   macro avg       0.20      0.27      0.19       160\n",
      "weighted avg       0.22      0.29      0.21       160\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.26      0.20      0.23        25\n",
      "           2       1.00      0.14      0.24        37\n",
      "           3       0.20      0.55      0.29        33\n",
      "           4       0.50      0.34      0.40        65\n",
      "\n",
      "    accuracy                           0.31       160\n",
      "   macro avg       0.49      0.30      0.29       160\n",
      "weighted avg       0.52      0.31      0.31       160\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import confusion_matrix,classification_report\n",
    "from sklearn import preprocessing\n",
    "import matplotlib.pyplot as plt\n",
    "#subjectnames\n",
    "batch_sz = 20\n",
    "file_list_num = np.arange(len(subjectnames))\n",
    "modelid = 1\n",
    "netValence = Net()\n",
    "valmodelname = \"Valence_Model4\"+\".pt\"\n",
    "netValence.load_state_dict(torch.load(valmodelname))\n",
    "netValence.to(device)\n",
    "netArousal = Net()\n",
    "aromodelname = \"Model5\"+\".pt\"\n",
    "netArousal.load_state_dict(torch.load(aromodelname))\n",
    "netArousal.to(device)\n",
    "for i in range(0,32,4):\n",
    "\n",
    "    #optimizer = optim.Adam(net.parameters(), lr=0.000001)\n",
    "    expectedoutput = []\n",
    "    actualoutput = []\n",
    "    for tr in file_list_num[i:i+4]:\n",
    "        #net.eval()\n",
    "        v = data_c1d[subjectnames[tr]]\n",
    "        l = data_c3[subjectnames[tr]]\n",
    "        netValence.eval()\n",
    "        netArousal.eval()\n",
    "        with torch.no_grad():\n",
    "            for i in range(0,len(v),batch_sz):\n",
    "              #print(v[i].shape)\n",
    "              #for j in range(0,v[i].shape[0],batch_sz):\n",
    "              #optimizer.zero_grad()\n",
    "              outputs_val = netValence(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
    "              outputs_val1 = torch.round(outputs_val)\n",
    "              outputs_aro = netArousal(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
    "              outputs_aro1 = torch.round(outputs_aro)\n",
    "\n",
    "              #print(outputs_val1)\n",
    "              for j in range(0,outputs_aro1.shape[0]):\n",
    "                res = 0\n",
    "                if (outputs_val1[j][0] >= 1 and outputs_aro1[j][0] >= 1):\n",
    "                    res = 4\n",
    "                elif (outputs_val1[j][0] < 1 and outputs_aro1[j][0] >= 1):\n",
    "                    res = 3\n",
    "                elif (outputs_val1[j][0] >= 1 and outputs_aro1[j][0] < 1):\n",
    "                    res = 2\n",
    "                elif (outputs_val1[j][0] < 1 and outputs_aro1[j][0] < 1):\n",
    "                    res = 1\n",
    "                actualoutput.append(res)\n",
    "              #loss = criterion(outputs, l[i:i+batch_sz].to(device, dtype=torch.float))\n",
    "              #val_loss.append(loss)\n",
    "              #loss.backward()\n",
    "              #print(outputs.shape)\n",
    "              #print(l[i:i+batch_sz])\n",
    "              expectedoutput.append(l[i:i+batch_sz])\n",
    "              #actualoutput.append(actualoutput)\n",
    "      #val_loss_mean = torch.stack(val_loss).mean().cpu().detach().numpy()\n",
    "      #val_loss_epoch.append(val_loss_mean)\n",
    "    expectedoutput = np.concatenate( expectedoutput, axis=0 )\n",
    "      #actualoutput = np.concatenate( actualoutput, axis=0 )\n",
    "      #print(actualoutput)\n",
    "    #print(expectedoutput)\n",
    "    #print(actualoutput)\n",
    "    print(classification_report(expectedoutput,actualoutput))\n",
    "      #print(f'Validation Loss for {subjectnames[tr]} = {val_loss_mean}')\n",
    "      #break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9XuinMzzRq3R",
   "metadata": {
    "id": "9XuinMzzRq3R"
   },
   "outputs": [],
   "source": [
    "rm -rf Model*.pt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "8-a4aWI1C7If",
   "metadata": {
    "id": "8-a4aWI1C7If"
   },
   "outputs": [],
   "source": [
    "data_c3 = {}\n",
    "for k,v in data_c.items():\n",
    "    y = data_c[k][1]\n",
    "    x_label = np.zeros((y.shape[0]),dtype='int8')\n",
    "    for i in range(y.shape[0]):\n",
    "        if (y[i][0] > 5 and y[i][1] > 5):\n",
    "            x_label[i] = 4\n",
    "        elif (y[i][0] <= 5 and y[i][1] > 5):\n",
    "            x_label[i] = 3\n",
    "        elif (y[i][0] > 5 and y[i][1] <= 5):\n",
    "            x_label[i] = 2\n",
    "        elif (y[i][0] <= 5 and y[i][1] <= 5):\n",
    "            x_label[i] = 1\n",
    "    #x_l = np.zeros((x_label.size, x_label.max()+1))\n",
    "    #x_l[np.arange(x_label.size), x_label] = 1\n",
    "    #\n",
    "    #print(x_l.shape)\n",
    "    #x_l = x_l.reshape(-1,1,4)\n",
    "    #x_l = np.repeat(x_l, 117, axis=1)\n",
    "    #print(x_l.shape)\n",
    "    x_l = torch.tensor(x_label)\n",
    "    data_c3[k] = x_l\n",
    "    #print(data_c3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "538f2018-fa74-4426-9c36-d56fbeea2f5d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-22T10:35:45.304701Z",
     "iopub.status.busy": "2024-01-22T10:35:45.304413Z",
     "iopub.status.idle": "2024-01-22T10:35:45.309356Z",
     "shell.execute_reply": "2024-01-22T10:35:45.308693Z",
     "shell.execute_reply.started": "2024-01-22T10:35:45.304679Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['DEAP/s21.dat', 'DEAP/s25.dat', 'DEAP/s07.dat', 'DEAP/s22.dat', 'DEAP/s32.dat', 'DEAP/s10.dat', 'DEAP/s04.dat', 'DEAP/s23.dat', 'DEAP/s30.dat', 'DEAP/s06.dat', 'DEAP/s31.dat', 'DEAP/s16.dat', 'DEAP/s15.dat', 'DEAP/s08.dat', 'DEAP/s28.dat', 'DEAP/s17.dat', 'DEAP/s26.dat', 'DEAP/s02.dat', 'DEAP/s19.dat', 'DEAP/s18.dat', 'DEAP/s03.dat', 'DEAP/s29.dat', 'DEAP/s24.dat', 'DEAP/s05.dat', 'DEAP/s14.dat', 'DEAP/s12.dat', 'DEAP/s11.dat', 'DEAP/s27.dat', 'DEAP/s20.dat', 'DEAP/s09.dat', 'DEAP/s13.dat', 'DEAP/s01.dat']\n",
      "['s21', 's25', 's07', 's22', 's32', 's10', 's04', 's23', 's30', 's06', 's31', 's16', 's15', 's08', 's28', 's17', 's26', 's02', 's19', 's18', 's03', 's29', 's24', 's05', 's14', 's12', 's11', 's27', 's20', 's09', 's13', 's01']\n"
     ]
    }
   ],
   "source": [
    "import glob\n",
    "import os\n",
    "filelistd = glob.glob('DEAP/*.dat')\n",
    "print(filelistd)\n",
    "subjectnamesd = [fr[5:8] for fr in filelistd]\n",
    "print(subjectnamesd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "dcb43263-e6f0-4f6f-97fd-ffd8fe6efb21",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-22T10:35:47.557477Z",
     "iopub.status.busy": "2024-01-22T10:35:47.556853Z",
     "iopub.status.idle": "2024-01-22T10:35:53.897449Z",
     "shell.execute_reply": "2024-01-22T10:35:53.896713Z",
     "shell.execute_reply.started": "2024-01-22T10:35:47.557452Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['s21', 's25', 's07', 's22', 's32', 's10', 's04', 's23', 's30', 's06', 's31', 's16', 's15', 's08', 's28', 's17', 's26', 's02', 's19', 's18', 's03', 's29', 's24', 's05', 's14', 's12', 's11', 's27', 's20', 's09', 's13', 's01'])\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "datad = {}\n",
    "for sname in subjectnamesd:\n",
    "    dname = \"DEAP/\"+sname+\".dat\"\n",
    "    f = open(dname, 'rb')\n",
    "    x = pickle.load(f, encoding='latin1')\n",
    "    datad[sname] = x\n",
    "print(datad.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9e192455-a6bc-45f1-b641-9fde46b3586c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-22T10:35:57.451286Z",
     "iopub.status.busy": "2024-01-22T10:35:57.450621Z",
     "iopub.status.idle": "2024-01-22T10:35:57.507664Z",
     "shell.execute_reply": "2024-01-22T10:35:57.506947Z",
     "shell.execute_reply.started": "2024-01-22T10:35:57.451258Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "data_de = {}\n",
    "for k,v in datad.items():\n",
    "    y = datad[k]['data'][:,36,:]\n",
    "    ym = np.mean(y,axis=-1).reshape(40,1)\n",
    "    ystd = np.std(y,axis=-1).reshape(40,1)\n",
    "    z = (y-ym)/ystd\n",
    "    data_de[k] = [z,datad[k]['labels']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b1f12cea-e417-4f5d-b827-53bc3a41b517",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-22T10:36:04.912753Z",
     "iopub.status.busy": "2024-01-22T10:36:04.912103Z",
     "iopub.status.idle": "2024-01-22T10:36:05.201926Z",
     "shell.execute_reply": "2024-01-22T10:36:05.199378Z",
     "shell.execute_reply.started": "2024-01-22T10:36:04.912726Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 8064])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "data_de1 = {}\n",
    "for k,v in data_de.items():\n",
    "    datablocki = []\n",
    "    v1=np.vstack(v[0])\n",
    "    v1 = v1[:,np.newaxis,:]\n",
    "    data_de1[k] = torch.tensor(v1)\n",
    "print(data_de1['s01'][0].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "79b2bfa1-9d78-4f7d-b0f0-17c05654fbaa",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-22T10:36:09.598793Z",
     "iopub.status.busy": "2024-01-22T10:36:09.598227Z",
     "iopub.status.idle": "2024-01-22T10:36:09.606257Z",
     "shell.execute_reply": "2024-01-22T10:36:09.605585Z",
     "shell.execute_reply.started": "2024-01-22T10:36:09.598766Z"
    }
   },
   "outputs": [],
   "source": [
    "data_del = {}\n",
    "ximax = 3\n",
    "for k,v in data_de.items():\n",
    "    y = data_de[k][1]\n",
    "    x_label = np.zeros((y.shape[0]),dtype='int64')\n",
    "    for i in range(y.shape[0]):\n",
    "        if (y[i][0] > 5 and y[i][1] > 5):\n",
    "            x_label[i] = 3\n",
    "        elif (y[i][0] <= 5 and y[i][1] > 5):\n",
    "            x_label[i] = 2\n",
    "        elif (y[i][0] > 5 and y[i][1] <= 5):\n",
    "            x_label[i] = 1\n",
    "        elif (y[i][0] <= 5 and y[i][1] <= 5):\n",
    "            x_label[i] = 0\n",
    "    x_l = np.zeros((x_label.size, ximax+1))\n",
    "    x_l[np.arange(x_label.size), x_label] = 1\n",
    "    #x_l = x_label\n",
    "    #\n",
    "    #print(x_l.shape)\n",
    "    x_l = x_l.reshape(-1,4)\n",
    "\n",
    "    x_l = torch.tensor(x_l)\n",
    "    data_del[k] = x_l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3510574e-92c7-4f83-8ea3-b1c842ec8792",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-22T10:36:12.597926Z",
     "iopub.status.busy": "2024-01-22T10:36:12.597240Z",
     "iopub.status.idle": "2024-01-22T10:36:12.603447Z",
     "shell.execute_reply": "2024-01-22T10:36:12.602820Z",
     "shell.execute_reply.started": "2024-01-22T10:36:12.597899Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([40, 4])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_del['s01'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "00a549ca-dc77-4ef8-a2ce-948a31cb944d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-21T21:26:54.344614Z",
     "iopub.status.busy": "2024-01-21T21:26:54.343936Z",
     "iopub.status.idle": "2024-01-21T21:26:55.114174Z",
     "shell.execute_reply": "2024-01-21T21:26:55.113433Z",
     "shell.execute_reply.started": "2024-01-21T21:26:54.344580Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 20:\n",
      "  Train: index=[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23\n",
      " 24 25 26 27 28 29 30 31]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_410/3061022090.py:39: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1960: UserWarning: nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\n",
      "  warnings.warn(\"nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.45      1.00      0.62       572\n",
      "         1.0       0.00      0.00      0.00       708\n",
      "\n",
      "    accuracy                           0.45      1280\n",
      "   macro avg       0.22      0.50      0.31      1280\n",
      "weighted avg       0.20      0.45      0.28      1280\n",
      "\n",
      "[[572   0]\n",
      " [708   0]]\n",
      "Validation Loss for s01 = 0.6970333456993103\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.9/dist-packages/sklearn/metrics/_classification.py:1334: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.9/dist-packages/sklearn/metrics/_classification.py:1334: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.9/dist-packages/sklearn/metrics/_classification.py:1334: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import confusion_matrix,classification_report\n",
    "from sklearn import preprocessing\n",
    "import matplotlib.pyplot as plt\n",
    "#subjectnames\n",
    "file_list_numd = np.arange(len(subjectnamesd))\n",
    "net = Net()\n",
    "net.to(device)\n",
    "optimizer = optim.Adam(net.parameters(), lr=0.000001)\n",
    "torch.manual_seed(42)\n",
    "torch.cuda.manual_seed(42)\n",
    "expectedoutputdeap = []\n",
    "actualoutputdeap = []\n",
    "val_loss = []\n",
    "expectedoutput = []\n",
    "actualoutput = []\n",
    "test_index = file_list_numd\n",
    "print(f\"Fold {i}:\")\n",
    "print(f\"  Train: index={test_index}\")\n",
    "#print(f\"  Test:  index={test_index}\")\n",
    "#net = Net()\n",
    "#net.to(device)\n",
    "#optimizer = optim.Adam(net.parameters(), lr=0.000001)\n",
    "#epochs = 60\n",
    "batch_sz = 20\n",
    "train_loss_epoch = []\n",
    "val_loss_epoch = []\n",
    "\n",
    "for tr in test_index:\n",
    "    net.eval()\n",
    "    v = data_de1[subjectnamesd[tr]]\n",
    "    l = data_del[subjectnamesd[tr]]\n",
    "    net.eval()\n",
    "    with torch.no_grad():\n",
    "        for i in range(0,len(v),batch_sz):\n",
    "          #print(v[i].shape)\n",
    "          #for j in range(0,v[i].shape[0],batch_sz):\n",
    "          optimizer.zero_grad()\n",
    "          outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
    "          #print(outputs.shape)\n",
    "          #print(l[i:i+batch_sz].shape)\n",
    "          loss = criterion(outputs, l[i:i+batch_sz].to(device, dtype=torch.float))\n",
    "          val_loss.append(loss)\n",
    "          actualoutputdeap.append(torch.round(outputs.cpu()))\n",
    "          expectedoutputdeap.append(l[i:i+batch_sz])\n",
    "          #actualoutput.append(torch.argmax(torch.softmax(outputs.cpu(),dim=1),dim=1))\n",
    "          #expectedoutput.append(torch.argmax(l[i:i+batch_sz],dim=1).numpy())\n",
    "val_loss_mean = torch.stack(val_loss).mean().cpu().detach().numpy()\n",
    "val_loss_epoch.append(val_loss_mean)\n",
    "expectedoutputdeap = np.concatenate( expectedoutputdeap, axis=0 )\n",
    "actualoutputdeap = np.concatenate( actualoutputdeap, axis=0 )\n",
    "#print(expectedoutput.shape)\n",
    "#print(actualoutput.shape)\n",
    "print(classification_report(expectedoutputdeap,actualoutputdeap))\n",
    "print(confusion_matrix(expectedoutputdeap,actualoutputdeap))\n",
    "print(f'Validation Loss for {subjectnamesd[tr]} = {val_loss_mean}')\n",
    "#break\n",
    "\n",
    "#plt.figure(figsize=(10,7))\n",
    "#print(len(train_loss_epoch))\n",
    "#plt.plot(np.arange(epochs),train_loss_epoch,label='Train')\n",
    "#plt.plot(np.arange(epochs),val_loss_epoch,label='Validation')\n",
    "#plt.legend()\n",
    "#path = \"Model\"+str(modelid) +\".pt\"\n",
    "#path = \"ModelAMIGOS_Aro.pt\"\n",
    "#modelid = modelid+1\n",
    "#print(path)\n",
    "#torch.save(net.state_dict(), path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "44278dac-15a4-400c-8676-184267c3942e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-22T10:58:01.753440Z",
     "iopub.status.busy": "2024-01-22T10:58:01.753161Z",
     "iopub.status.idle": "2024-01-22T11:00:11.551237Z",
     "shell.execute_reply": "2024-01-22T11:00:11.550531Z",
     "shell.execute_reply.started": "2024-01-22T10:58:01.753419Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 0:\n",
      "  Train: index=[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23\n",
      " 24 25 26 27 28 29 30 31 32 33 34 35]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_233/2331385577.py:42: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100, Train Loss: 1.4774000644683838\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_233/2331385577.py:67: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/tmp/ipykernel_233/2331385577.py:87: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.17      0.04      0.06       132\n",
      "           1       0.24      0.18      0.21       127\n",
      "           2       0.20      0.21      0.21       161\n",
      "           3       0.32      0.50      0.39       220\n",
      "\n",
      "    accuracy                           0.27       640\n",
      "   macro avg       0.23      0.23      0.22       640\n",
      "weighted avg       0.24      0.27      0.24       640\n",
      "\n",
      "[[  5  20  28  79]\n",
      " [  3  23  43  58]\n",
      " [  5  22  34 100]\n",
      " [ 16  31  62 111]]\n",
      "Validation Loss for s05 = 1.3692142963409424\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_233/2331385577.py:42: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/100, Train Loss: 1.437269926071167\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_233/2331385577.py:67: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/tmp/ipykernel_233/2331385577.py:87: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.23      0.08      0.12       132\n",
      "           1       0.19      0.35      0.25       127\n",
      "           2       0.22      0.24      0.23       161\n",
      "           3       0.35      0.30      0.32       220\n",
      "\n",
      "    accuracy                           0.25       640\n",
      "   macro avg       0.25      0.24      0.23       640\n",
      "weighted avg       0.26      0.25      0.24       640\n",
      "\n",
      "[[11 53 28 40]\n",
      " [ 6 45 42 34]\n",
      " [10 64 38 49]\n",
      " [21 70 64 65]]\n",
      "Validation Loss for s05 = 1.362755537033081\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_233/2331385577.py:42: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/100, Train Loss: 1.4773787260055542\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_233/2331385577.py:67: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/tmp/ipykernel_233/2331385577.py:87: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.25      0.38      0.30       132\n",
      "           1       0.22      0.31      0.26       127\n",
      "           2       0.23      0.23      0.23       161\n",
      "           3       0.42      0.19      0.26       220\n",
      "\n",
      "    accuracy                           0.26       640\n",
      "   macro avg       0.28      0.28      0.26       640\n",
      "weighted avg       0.30      0.26      0.26       640\n",
      "\n",
      "[[50 38 26 18]\n",
      " [31 40 38 18]\n",
      " [53 50 37 21]\n",
      " [63 52 63 42]]\n",
      "Validation Loss for s05 = 1.3489049673080444\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_233/2331385577.py:42: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/100, Train Loss: 1.541350245475769\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_233/2331385577.py:67: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/tmp/ipykernel_233/2331385577.py:87: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.24      0.51      0.33       132\n",
      "           1       0.27      0.24      0.25       127\n",
      "           2       0.22      0.21      0.22       161\n",
      "           3       0.42      0.18      0.25       220\n",
      "\n",
      "    accuracy                           0.27       640\n",
      "   macro avg       0.29      0.28      0.26       640\n",
      "weighted avg       0.30      0.27      0.26       640\n",
      "\n",
      "[[67 22 26 17]\n",
      " [43 30 35 19]\n",
      " [81 26 34 20]\n",
      " [85 35 60 40]]\n",
      "Validation Loss for s05 = 1.342228889465332\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_233/2331385577.py:42: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/100, Train Loss: 1.4529680013656616\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_233/2331385577.py:67: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/tmp/ipykernel_233/2331385577.py:87: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.24      0.49      0.32       132\n",
      "           1       0.27      0.28      0.28       127\n",
      "           2       0.21      0.20      0.21       161\n",
      "           3       0.42      0.15      0.23       220\n",
      "\n",
      "    accuracy                           0.26       640\n",
      "   macro avg       0.29      0.28      0.26       640\n",
      "weighted avg       0.30      0.26      0.25       640\n",
      "\n",
      "[[65 27 27 13]\n",
      " [39 36 36 16]\n",
      " [80 31 33 17]\n",
      " [87 38 61 34]]\n",
      "Validation Loss for s05 = 1.3441811800003052\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_233/2331385577.py:42: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6/100, Train Loss: 1.4119383096694946\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_233/2331385577.py:67: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/tmp/ipykernel_233/2331385577.py:87: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.24      0.45      0.31       132\n",
      "           1       0.24      0.32      0.27       127\n",
      "           2       0.21      0.18      0.19       161\n",
      "           3       0.42      0.16      0.23       220\n",
      "\n",
      "    accuracy                           0.26       640\n",
      "   macro avg       0.28      0.28      0.25       640\n",
      "weighted avg       0.29      0.26      0.25       640\n",
      "\n",
      "[[59 38 22 13]\n",
      " [36 41 32 18]\n",
      " [68 46 29 18]\n",
      " [81 47 57 35]]\n",
      "Validation Loss for s05 = 1.3450205326080322\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_233/2331385577.py:42: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7/100, Train Loss: 1.4295382499694824\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_233/2331385577.py:67: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/tmp/ipykernel_233/2331385577.py:87: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.24      0.48      0.32       132\n",
      "           1       0.26      0.31      0.28       127\n",
      "           2       0.20      0.18      0.19       161\n",
      "           3       0.41      0.15      0.22       220\n",
      "\n",
      "    accuracy                           0.26       640\n",
      "   macro avg       0.28      0.28      0.25       640\n",
      "weighted avg       0.29      0.26      0.24       640\n",
      "\n",
      "[[63 34 22 13]\n",
      " [40 39 32 16]\n",
      " [77 37 29 18]\n",
      " [85 40 62 33]]\n",
      "Validation Loss for s05 = 1.3478193283081055\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_233/2331385577.py:42: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8/100, Train Loss: 1.3873264789581299\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_233/2331385577.py:67: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/tmp/ipykernel_233/2331385577.py:87: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.24      0.55      0.33       132\n",
      "           1       0.25      0.24      0.24       127\n",
      "           2       0.18      0.16      0.17       161\n",
      "           3       0.36      0.12      0.18       220\n",
      "\n",
      "    accuracy                           0.24       640\n",
      "   macro avg       0.26      0.27      0.23       640\n",
      "weighted avg       0.27      0.24      0.22       640\n",
      "\n",
      "[[73 23 22 14]\n",
      " [49 30 33 15]\n",
      " [90 28 26 17]\n",
      " [94 39 61 26]]\n",
      "Validation Loss for s05 = 1.3525031805038452\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_233/2331385577.py:42: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9/100, Train Loss: 1.4526582956314087\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_233/2331385577.py:67: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/tmp/ipykernel_233/2331385577.py:87: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/tmp/ipykernel_233/2331385577.py:42: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.24      0.56      0.34       132\n",
      "           1       0.25      0.24      0.24       127\n",
      "           2       0.18      0.16      0.17       161\n",
      "           3       0.34      0.11      0.16       220\n",
      "\n",
      "    accuracy                           0.24       640\n",
      "   macro avg       0.25      0.27      0.23       640\n",
      "weighted avg       0.26      0.24      0.22       640\n",
      "\n",
      "[[74 22 23 13]\n",
      " [49 30 32 16]\n",
      " [89 28 26 18]\n",
      " [93 40 63 24]]\n",
      "Validation Loss for s05 = 1.3512153625488281\n",
      "Epoch 10/100, Train Loss: 1.3990198373794556\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_233/2331385577.py:67: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/tmp/ipykernel_233/2331385577.py:87: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/tmp/ipykernel_233/2331385577.py:42: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.24      0.55      0.34       132\n",
      "           1       0.27      0.27      0.27       127\n",
      "           2       0.17      0.16      0.16       161\n",
      "           3       0.36      0.12      0.18       220\n",
      "\n",
      "    accuracy                           0.25       640\n",
      "   macro avg       0.26      0.27      0.24       640\n",
      "weighted avg       0.27      0.25      0.23       640\n",
      "\n",
      "[[73 23 23 13]\n",
      " [46 34 31 16]\n",
      " [89 29 25 18]\n",
      " [90 40 64 26]]\n",
      "Validation Loss for s05 = 1.350563645362854\n",
      "Epoch 11/100, Train Loss: 1.5076555013656616\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_233/2331385577.py:67: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/tmp/ipykernel_233/2331385577.py:87: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/tmp/ipykernel_233/2331385577.py:42: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.24      0.55      0.34       132\n",
      "           1       0.26      0.27      0.26       127\n",
      "           2       0.17      0.15      0.16       161\n",
      "           3       0.35      0.10      0.16       220\n",
      "\n",
      "    accuracy                           0.24       640\n",
      "   macro avg       0.25      0.27      0.23       640\n",
      "weighted avg       0.26      0.24      0.22       640\n",
      "\n",
      "[[73 23 24 12]\n",
      " [48 34 30 15]\n",
      " [88 33 24 16]\n",
      " [92 42 63 23]]\n",
      "Validation Loss for s05 = 1.3528691530227661\n",
      "Epoch 12/100, Train Loss: 1.3939199447631836\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_233/2331385577.py:67: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/tmp/ipykernel_233/2331385577.py:87: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/tmp/ipykernel_233/2331385577.py:42: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.23      0.56      0.32       132\n",
      "           1       0.22      0.17      0.20       127\n",
      "           2       0.17      0.14      0.16       161\n",
      "           3       0.39      0.14      0.21       220\n",
      "\n",
      "    accuracy                           0.23       640\n",
      "   macro avg       0.25      0.25      0.22       640\n",
      "weighted avg       0.27      0.23      0.22       640\n",
      "\n",
      "[[74 21 24 13]\n",
      " [57 22 31 17]\n",
      " [98 21 23 19]\n",
      " [98 34 57 31]]\n",
      "Validation Loss for s05 = 1.349905252456665\n",
      "Epoch 13/100, Train Loss: 1.4183496236801147\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_233/2331385577.py:67: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/tmp/ipykernel_233/2331385577.py:87: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/tmp/ipykernel_233/2331385577.py:42: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.24      0.56      0.34       132\n",
      "           1       0.23      0.24      0.23       127\n",
      "           2       0.18      0.14      0.15       161\n",
      "           3       0.42      0.15      0.23       220\n",
      "\n",
      "    accuracy                           0.25       640\n",
      "   macro avg       0.27      0.27      0.24       640\n",
      "weighted avg       0.29      0.25      0.23       640\n",
      "\n",
      "[[74 25 22 11]\n",
      " [50 30 30 17]\n",
      " [89 32 22 18]\n",
      " [94 42 50 34]]\n",
      "Validation Loss for s05 = 1.3487868309020996\n",
      "Epoch 14/100, Train Loss: 1.388541579246521\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_233/2331385577.py:67: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/tmp/ipykernel_233/2331385577.py:87: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/tmp/ipykernel_233/2331385577.py:42: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.23      0.56      0.33       132\n",
      "           1       0.23      0.20      0.21       127\n",
      "           2       0.18      0.14      0.16       161\n",
      "           3       0.41      0.17      0.24       220\n",
      "\n",
      "    accuracy                           0.25       640\n",
      "   macro avg       0.26      0.27      0.24       640\n",
      "weighted avg       0.28      0.25      0.23       640\n",
      "\n",
      "[[74 23 21 14]\n",
      " [52 26 29 20]\n",
      " [93 27 22 19]\n",
      " [96 39 48 37]]\n",
      "Validation Loss for s05 = 1.3490926027297974\n",
      "Epoch 15/100, Train Loss: 1.4620901346206665\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_233/2331385577.py:67: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/tmp/ipykernel_233/2331385577.py:87: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/tmp/ipykernel_233/2331385577.py:42: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.23      0.57      0.33       132\n",
      "           1       0.22      0.20      0.21       127\n",
      "           2       0.18      0.14      0.15       161\n",
      "           3       0.42      0.16      0.24       220\n",
      "\n",
      "    accuracy                           0.25       640\n",
      "   macro avg       0.26      0.27      0.23       640\n",
      "weighted avg       0.28      0.25      0.23       640\n",
      "\n",
      "[[75 24 21 12]\n",
      " [54 25 30 18]\n",
      " [95 25 22 19]\n",
      " [96 38 50 36]]\n",
      "Validation Loss for s05 = 1.348341941833496\n",
      "Epoch 16/100, Train Loss: 1.4164822101593018\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_233/2331385577.py:67: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/tmp/ipykernel_233/2331385577.py:87: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.23      0.56      0.33       132\n",
      "           1       0.21      0.20      0.21       127\n",
      "           2       0.20      0.14      0.17       161\n",
      "           3       0.40      0.16      0.23       220\n",
      "\n",
      "    accuracy                           0.25       640\n",
      "   macro avg       0.26      0.27      0.23       640\n",
      "weighted avg       0.28      0.25      0.23       640\n",
      "\n",
      "[[74 25 20 13]\n",
      " [53 26 26 22]\n",
      " [93 28 23 17]\n",
      " [97 42 46 35]]\n",
      "Validation Loss for s05 = 1.3482024669647217\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_233/2331385577.py:42: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17/100, Train Loss: 1.3563487529754639\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_233/2331385577.py:67: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/tmp/ipykernel_233/2331385577.py:87: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.24      0.55      0.34       132\n",
      "           1       0.23      0.24      0.23       127\n",
      "           2       0.21      0.14      0.17       161\n",
      "           3       0.41      0.18      0.25       220\n",
      "\n",
      "    accuracy                           0.26       640\n",
      "   macro avg       0.27      0.28      0.25       640\n",
      "weighted avg       0.29      0.26      0.24       640\n",
      "\n",
      "[[73 24 21 14]\n",
      " [47 30 26 24]\n",
      " [88 31 23 19]\n",
      " [95 44 42 39]]\n",
      "Validation Loss for s05 = 1.3517580032348633\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_233/2331385577.py:42: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 18/100, Train Loss: 1.491641879081726\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_233/2331385577.py:67: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/tmp/ipykernel_233/2331385577.py:87: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.24      0.55      0.34       132\n",
      "           1       0.21      0.24      0.22       127\n",
      "           2       0.19      0.13      0.15       161\n",
      "           3       0.39      0.15      0.22       220\n",
      "\n",
      "    accuracy                           0.25       640\n",
      "   macro avg       0.26      0.27      0.23       640\n",
      "weighted avg       0.27      0.25      0.23       640\n",
      "\n",
      "[[73 26 20 13]\n",
      " [49 30 25 23]\n",
      " [86 37 21 17]\n",
      " [94 47 45 34]]\n",
      "Validation Loss for s05 = 1.3534296751022339\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_233/2331385577.py:42: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19/100, Train Loss: 1.3547934293746948\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_233/2331385577.py:67: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/tmp/ipykernel_233/2331385577.py:87: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.24      0.57      0.34       132\n",
      "           1       0.22      0.23      0.22       127\n",
      "           2       0.19      0.14      0.16       161\n",
      "           3       0.39      0.15      0.21       220\n",
      "\n",
      "    accuracy                           0.25       640\n",
      "   macro avg       0.26      0.27      0.23       640\n",
      "weighted avg       0.28      0.25      0.23       640\n",
      "\n",
      "[[75 24 21 12]\n",
      " [49 29 27 22]\n",
      " [89 34 22 16]\n",
      " [97 44 47 32]]\n",
      "Validation Loss for s05 = 1.3541901111602783\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_233/2331385577.py:42: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20/100, Train Loss: 1.408991813659668\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_233/2331385577.py:67: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/tmp/ipykernel_233/2331385577.py:87: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.24      0.58      0.34       132\n",
      "           1       0.24      0.24      0.24       127\n",
      "           2       0.20      0.13      0.16       161\n",
      "           3       0.43      0.18      0.25       220\n",
      "\n",
      "    accuracy                           0.26       640\n",
      "   macro avg       0.28      0.28      0.25       640\n",
      "weighted avg       0.29      0.26      0.24       640\n",
      "\n",
      "[[76 24 21 11]\n",
      " [49 30 24 24]\n",
      " [93 30 21 17]\n",
      " [99 42 40 39]]\n",
      "Validation Loss for s05 = 1.3533389568328857\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_233/2331385577.py:42: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 21/100, Train Loss: 1.4151073694229126\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_233/2331385577.py:67: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/tmp/ipykernel_233/2331385577.py:87: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.24      0.55      0.33       132\n",
      "           1       0.24      0.26      0.25       127\n",
      "           2       0.18      0.14      0.15       161\n",
      "           3       0.40      0.13      0.20       220\n",
      "\n",
      "    accuracy                           0.25       640\n",
      "   macro avg       0.26      0.27      0.23       640\n",
      "weighted avg       0.28      0.25      0.23       640\n",
      "\n",
      "[[73 23 25 11]\n",
      " [49 33 26 19]\n",
      " [92 33 22 14]\n",
      " [93 47 51 29]]\n",
      "Validation Loss for s05 = 1.3559937477111816\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_233/2331385577.py:42: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 22/100, Train Loss: 1.402725100517273\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_233/2331385577.py:67: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/tmp/ipykernel_233/2331385577.py:87: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.23      0.57      0.33       132\n",
      "           1       0.22      0.20      0.21       127\n",
      "           2       0.19      0.13      0.16       161\n",
      "           3       0.44      0.18      0.26       220\n",
      "\n",
      "    accuracy                           0.25       640\n",
      "   macro avg       0.27      0.27      0.24       640\n",
      "weighted avg       0.29      0.25      0.24       640\n",
      "\n",
      "[[75 23 23 11]\n",
      " [55 25 24 23]\n",
      " [97 27 21 16]\n",
      " [98 41 41 40]]\n",
      "Validation Loss for s05 = 1.3506132364273071\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_233/2331385577.py:42: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 23/100, Train Loss: 1.4148390293121338\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_233/2331385577.py:67: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/tmp/ipykernel_233/2331385577.py:87: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.23      0.58      0.33       132\n",
      "           1       0.23      0.22      0.22       127\n",
      "           2       0.18      0.12      0.15       161\n",
      "           3       0.42      0.15      0.22       220\n",
      "\n",
      "    accuracy                           0.25       640\n",
      "   macro avg       0.26      0.27      0.23       640\n",
      "weighted avg       0.28      0.25      0.23       640\n",
      "\n",
      "[[76 23 23 10]\n",
      " [53 28 24 22]\n",
      " [98 29 20 14]\n",
      " [98 42 47 33]]\n",
      "Validation Loss for s05 = 1.3502261638641357\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_233/2331385577.py:42: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 24/100, Train Loss: 1.3746355772018433\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_233/2331385577.py:67: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/tmp/ipykernel_233/2331385577.py:87: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.24      0.57      0.34       132\n",
      "           1       0.25      0.26      0.25       127\n",
      "           2       0.20      0.14      0.17       161\n",
      "           3       0.44      0.16      0.24       220\n",
      "\n",
      "    accuracy                           0.26       640\n",
      "   macro avg       0.28      0.28      0.25       640\n",
      "weighted avg       0.30      0.26      0.24       640\n",
      "\n",
      "[[75 23 24 10]\n",
      " [48 33 24 22]\n",
      " [91 33 23 14]\n",
      " [94 45 45 36]]\n",
      "Validation Loss for s05 = 1.3540462255477905\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_233/2331385577.py:42: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 25/100, Train Loss: 1.35304856300354\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_233/2331385577.py:67: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/tmp/ipykernel_233/2331385577.py:87: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.24      0.57      0.33       132\n",
      "           1       0.25      0.24      0.24       127\n",
      "           2       0.20      0.15      0.17       161\n",
      "           3       0.45      0.16      0.24       220\n",
      "\n",
      "    accuracy                           0.26       640\n",
      "   macro avg       0.28      0.28      0.25       640\n",
      "weighted avg       0.30      0.26      0.24       640\n",
      "\n",
      "[[75 23 24 10]\n",
      " [51 30 26 20]\n",
      " [95 28 24 14]\n",
      " [95 40 49 36]]\n",
      "Validation Loss for s05 = 1.3572958707809448\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_233/2331385577.py:42: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 26/100, Train Loss: 1.378060221672058\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_233/2331385577.py:67: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/tmp/ipykernel_233/2331385577.py:87: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.25      0.55      0.34       132\n",
      "           1       0.26      0.28      0.27       127\n",
      "           2       0.19      0.16      0.17       161\n",
      "           3       0.43      0.14      0.21       220\n",
      "\n",
      "    accuracy                           0.26       640\n",
      "   macro avg       0.28      0.28      0.25       640\n",
      "weighted avg       0.30      0.26      0.24       640\n",
      "\n",
      "[[73 23 28  8]\n",
      " [45 36 27 19]\n",
      " [89 34 25 13]\n",
      " [90 47 53 30]]\n",
      "Validation Loss for s05 = 1.3617539405822754\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_233/2331385577.py:42: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 27/100, Train Loss: 1.3908096551895142\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_233/2331385577.py:67: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/tmp/ipykernel_233/2331385577.py:87: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.24      0.55      0.34       132\n",
      "           1       0.25      0.28      0.26       127\n",
      "           2       0.20      0.17      0.18       161\n",
      "           3       0.45      0.13      0.20       220\n",
      "\n",
      "    accuracy                           0.25       640\n",
      "   macro avg       0.28      0.28      0.25       640\n",
      "weighted avg       0.30      0.25      0.24       640\n",
      "\n",
      "[[72 24 28  8]\n",
      " [47 35 29 16]\n",
      " [87 36 27 11]\n",
      " [90 47 54 29]]\n",
      "Validation Loss for s05 = 1.3612966537475586\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_233/2331385577.py:42: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 28/100, Train Loss: 1.3665879964828491\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_233/2331385577.py:67: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/tmp/ipykernel_233/2331385577.py:87: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.25      0.54      0.34       132\n",
      "           1       0.24      0.28      0.26       127\n",
      "           2       0.19      0.16      0.17       161\n",
      "           3       0.44      0.14      0.21       220\n",
      "\n",
      "    accuracy                           0.25       640\n",
      "   macro avg       0.28      0.28      0.25       640\n",
      "weighted avg       0.30      0.25      0.24       640\n",
      "\n",
      "[[71 25 26 10]\n",
      " [46 36 28 17]\n",
      " [84 40 25 12]\n",
      " [86 52 51 31]]\n",
      "Validation Loss for s05 = 1.3618896007537842\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_233/2331385577.py:42: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 29/100, Train Loss: 1.3704768419265747\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_233/2331385577.py:67: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/tmp/ipykernel_233/2331385577.py:87: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.24      0.54      0.33       132\n",
      "           1       0.24      0.28      0.26       127\n",
      "           2       0.19      0.16      0.18       161\n",
      "           3       0.45      0.14      0.21       220\n",
      "\n",
      "    accuracy                           0.25       640\n",
      "   macro avg       0.28      0.28      0.25       640\n",
      "weighted avg       0.30      0.25      0.24       640\n",
      "\n",
      "[[71 24 27 10]\n",
      " [46 36 28 17]\n",
      " [88 37 26 10]\n",
      " [87 50 53 30]]\n",
      "Validation Loss for s05 = 1.3624930381774902\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_233/2331385577.py:42: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 30/100, Train Loss: 1.4267879724502563\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_233/2331385577.py:67: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/tmp/ipykernel_233/2331385577.py:87: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/tmp/ipykernel_233/2331385577.py:42: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.23      0.55      0.32       132\n",
      "           1       0.23      0.19      0.21       127\n",
      "           2       0.20      0.17      0.19       161\n",
      "           3       0.41      0.14      0.20       220\n",
      "\n",
      "    accuracy                           0.24       640\n",
      "   macro avg       0.27      0.26      0.23       640\n",
      "weighted avg       0.28      0.24      0.22       640\n",
      "\n",
      "[[73 21 27 11]\n",
      " [56 24 27 20]\n",
      " [98 23 28 12]\n",
      " [97 38 55 30]]\n",
      "Validation Loss for s05 = 1.358625054359436\n",
      "Epoch 31/100, Train Loss: 1.3525136709213257\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_233/2331385577.py:67: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/tmp/ipykernel_233/2331385577.py:87: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/tmp/ipykernel_233/2331385577.py:42: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.24      0.54      0.33       132\n",
      "           1       0.25      0.27      0.26       127\n",
      "           2       0.19      0.15      0.17       161\n",
      "           3       0.41      0.15      0.21       220\n",
      "\n",
      "    accuracy                           0.25       640\n",
      "   macro avg       0.27      0.28      0.24       640\n",
      "weighted avg       0.29      0.25      0.24       640\n",
      "\n",
      "[[71 22 28 11]\n",
      " [47 34 25 21]\n",
      " [90 33 24 14]\n",
      " [91 46 51 32]]\n",
      "Validation Loss for s05 = 1.3590471744537354\n",
      "Epoch 32/100, Train Loss: 1.4246585369110107\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_233/2331385577.py:67: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/tmp/ipykernel_233/2331385577.py:87: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/tmp/ipykernel_233/2331385577.py:42: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.23      0.55      0.33       132\n",
      "           1       0.24      0.22      0.23       127\n",
      "           2       0.21      0.19      0.20       161\n",
      "           3       0.41      0.13      0.19       220\n",
      "\n",
      "    accuracy                           0.25       640\n",
      "   macro avg       0.27      0.27      0.24       640\n",
      "weighted avg       0.29      0.25      0.23       640\n",
      "\n",
      "[[72 21 29 10]\n",
      " [52 28 29 18]\n",
      " [93 25 31 12]\n",
      " [92 43 57 28]]\n",
      "Validation Loss for s05 = 1.3610975742340088\n",
      "Epoch 33/100, Train Loss: 1.3488434553146362\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_233/2331385577.py:67: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/tmp/ipykernel_233/2331385577.py:87: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/tmp/ipykernel_233/2331385577.py:42: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.24      0.54      0.33       132\n",
      "           1       0.25      0.25      0.25       127\n",
      "           2       0.21      0.19      0.20       161\n",
      "           3       0.42      0.13      0.20       220\n",
      "\n",
      "    accuracy                           0.25       640\n",
      "   macro avg       0.28      0.28      0.24       640\n",
      "weighted avg       0.30      0.25      0.23       640\n",
      "\n",
      "[[71 22 29 10]\n",
      " [49 32 29 17]\n",
      " [89 31 30 11]\n",
      " [92 43 57 28]]\n",
      "Validation Loss for s05 = 1.360012173652649\n",
      "Epoch 34/100, Train Loss: 1.3948955535888672\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_233/2331385577.py:67: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/tmp/ipykernel_233/2331385577.py:87: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.24      0.54      0.33       132\n",
      "           1       0.24      0.26      0.25       127\n",
      "           2       0.21      0.18      0.19       161\n",
      "           3       0.41      0.12      0.19       220\n",
      "\n",
      "    accuracy                           0.25       640\n",
      "   macro avg       0.27      0.28      0.24       640\n",
      "weighted avg       0.29      0.25      0.23       640\n",
      "\n",
      "[[71 23 28 10]\n",
      " [49 33 27 18]\n",
      " [87 34 29 11]\n",
      " [88 48 57 27]]\n",
      "Validation Loss for s05 = 1.3580913543701172\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_233/2331385577.py:42: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 35/100, Train Loss: 1.4234675168991089\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_233/2331385577.py:67: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/tmp/ipykernel_233/2331385577.py:87: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.24      0.55      0.33       132\n",
      "           1       0.25      0.25      0.25       127\n",
      "           2       0.20      0.17      0.18       161\n",
      "           3       0.41      0.12      0.18       220\n",
      "\n",
      "    accuracy                           0.25       640\n",
      "   macro avg       0.27      0.27      0.24       640\n",
      "weighted avg       0.29      0.25      0.23       640\n",
      "\n",
      "[[73 23 28  8]\n",
      " [49 32 29 17]\n",
      " [89 32 28 12]\n",
      " [93 43 58 26]]\n",
      "Validation Loss for s05 = 1.356766700744629\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_233/2331385577.py:42: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 36/100, Train Loss: 1.3399924039840698\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_233/2331385577.py:67: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/tmp/ipykernel_233/2331385577.py:87: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.24      0.55      0.33       132\n",
      "           1       0.23      0.24      0.24       127\n",
      "           2       0.20      0.19      0.19       161\n",
      "           3       0.40      0.10      0.17       220\n",
      "\n",
      "    accuracy                           0.24       640\n",
      "   macro avg       0.27      0.27      0.23       640\n",
      "weighted avg       0.28      0.24      0.22       640\n",
      "\n",
      "[[72 23 31  6]\n",
      " [50 30 29 18]\n",
      " [89 31 30 11]\n",
      " [92 44 61 23]]\n",
      "Validation Loss for s05 = 1.363378643989563\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_233/2331385577.py:42: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 37/100, Train Loss: 1.3685110807418823\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_233/2331385577.py:67: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/tmp/ipykernel_233/2331385577.py:87: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.24      0.55      0.33       132\n",
      "           1       0.23      0.24      0.23       127\n",
      "           2       0.20      0.18      0.19       161\n",
      "           3       0.41      0.10      0.16       220\n",
      "\n",
      "    accuracy                           0.24       640\n",
      "   macro avg       0.27      0.27      0.23       640\n",
      "weighted avg       0.28      0.24      0.22       640\n",
      "\n",
      "[[73 24 30  5]\n",
      " [51 30 29 17]\n",
      " [91 31 29 10]\n",
      " [94 44 60 22]]\n",
      "Validation Loss for s05 = 1.3644435405731201\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_233/2331385577.py:42: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 38/100, Train Loss: 1.3625500202178955\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_233/2331385577.py:67: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/tmp/ipykernel_233/2331385577.py:87: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.24      0.55      0.33       132\n",
      "           1       0.24      0.24      0.24       127\n",
      "           2       0.20      0.19      0.20       161\n",
      "           3       0.41      0.10      0.16       220\n",
      "\n",
      "    accuracy                           0.24       640\n",
      "   macro avg       0.27      0.27      0.23       640\n",
      "weighted avg       0.29      0.24      0.22       640\n",
      "\n",
      "[[72 23 32  5]\n",
      " [51 30 29 17]\n",
      " [89 31 31 10]\n",
      " [93 43 62 22]]\n",
      "Validation Loss for s05 = 1.3677196502685547\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_233/2331385577.py:42: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 39/100, Train Loss: 1.445267915725708\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_233/2331385577.py:67: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/tmp/ipykernel_233/2331385577.py:87: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.24      0.52      0.33       132\n",
      "           1       0.23      0.25      0.24       127\n",
      "           2       0.20      0.20      0.20       161\n",
      "           3       0.42      0.10      0.16       220\n",
      "\n",
      "    accuracy                           0.24       640\n",
      "   macro avg       0.27      0.27      0.23       640\n",
      "weighted avg       0.29      0.24      0.22       640\n",
      "\n",
      "[[69 25 33  5]\n",
      " [49 32 31 15]\n",
      " [85 33 32 11]\n",
      " [85 47 66 22]]\n",
      "Validation Loss for s05 = 1.36882483959198\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_233/2331385577.py:42: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 40/100, Train Loss: 1.3417623043060303\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_233/2331385577.py:67: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/tmp/ipykernel_233/2331385577.py:87: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.24      0.55      0.33       132\n",
      "           1       0.25      0.24      0.25       127\n",
      "           2       0.20      0.20      0.20       161\n",
      "           3       0.40      0.09      0.15       220\n",
      "\n",
      "    accuracy                           0.24       640\n",
      "   macro avg       0.27      0.27      0.23       640\n",
      "weighted avg       0.29      0.24      0.22       640\n",
      "\n",
      "[[72 21 34  5]\n",
      " [51 31 30 15]\n",
      " [89 30 32 10]\n",
      " [90 44 66 20]]\n",
      "Validation Loss for s05 = 1.3676598072052002\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_233/2331385577.py:42: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 41/100, Train Loss: 1.467400312423706\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_233/2331385577.py:67: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/tmp/ipykernel_233/2331385577.py:87: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.24      0.54      0.33       132\n",
      "           1       0.24      0.24      0.24       127\n",
      "           2       0.20      0.20      0.20       161\n",
      "           3       0.41      0.10      0.15       220\n",
      "\n",
      "    accuracy                           0.24       640\n",
      "   macro avg       0.27      0.27      0.23       640\n",
      "weighted avg       0.29      0.24      0.22       640\n",
      "\n",
      "[[71 21 35  5]\n",
      " [48 31 32 16]\n",
      " [86 33 33  9]\n",
      " [91 44 64 21]]\n",
      "Validation Loss for s05 = 1.3676015138626099\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_233/2331385577.py:42: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 42/100, Train Loss: 1.42743718624115\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_233/2331385577.py:67: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/tmp/ipykernel_233/2331385577.py:87: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.24      0.53      0.33       132\n",
      "           1       0.24      0.24      0.24       127\n",
      "           2       0.20      0.20      0.20       161\n",
      "           3       0.42      0.11      0.18       220\n",
      "\n",
      "    accuracy                           0.25       640\n",
      "   macro avg       0.28      0.27      0.24       640\n",
      "weighted avg       0.29      0.25      0.23       640\n",
      "\n",
      "[[70 21 35  6]\n",
      " [48 31 31 17]\n",
      " [85 32 33 11]\n",
      " [87 45 63 25]]\n",
      "Validation Loss for s05 = 1.3663983345031738\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_233/2331385577.py:42: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 43/100, Train Loss: 1.3394041061401367\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_233/2331385577.py:67: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/tmp/ipykernel_233/2331385577.py:87: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.24      0.53      0.33       132\n",
      "           1       0.24      0.23      0.24       127\n",
      "           2       0.22      0.21      0.22       161\n",
      "           3       0.41      0.14      0.20       220\n",
      "\n",
      "    accuracy                           0.25       640\n",
      "   macro avg       0.28      0.28      0.25       640\n",
      "weighted avg       0.29      0.25      0.24       640\n",
      "\n",
      "[[70 19 32 11]\n",
      " [49 29 29 20]\n",
      " [84 31 34 12]\n",
      " [90 40 60 30]]\n",
      "Validation Loss for s05 = 1.3667447566986084\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_233/2331385577.py:42: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 44/100, Train Loss: 1.4256983995437622\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_233/2331385577.py:67: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/tmp/ipykernel_233/2331385577.py:87: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.24      0.52      0.33       132\n",
      "           1       0.23      0.24      0.23       127\n",
      "           2       0.21      0.23      0.22       161\n",
      "           3       0.39      0.09      0.15       220\n",
      "\n",
      "    accuracy                           0.24       640\n",
      "   macro avg       0.27      0.27      0.23       640\n",
      "weighted avg       0.28      0.24      0.22       640\n",
      "\n",
      "[[68 22 36  6]\n",
      " [47 30 34 16]\n",
      " [82 33 37  9]\n",
      " [89 45 66 20]]\n",
      "Validation Loss for s05 = 1.372226595878601\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_233/2331385577.py:42: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 45/100, Train Loss: 1.3553861379623413\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_233/2331385577.py:67: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/tmp/ipykernel_233/2331385577.py:87: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.24      0.55      0.33       132\n",
      "           1       0.24      0.23      0.23       127\n",
      "           2       0.21      0.21      0.21       161\n",
      "           3       0.41      0.11      0.17       220\n",
      "\n",
      "    accuracy                           0.25       640\n",
      "   macro avg       0.27      0.27      0.24       640\n",
      "weighted avg       0.29      0.25      0.23       640\n",
      "\n",
      "[[72 18 34  8]\n",
      " [50 29 31 17]\n",
      " [86 31 34 10]\n",
      " [92 44 60 24]]\n",
      "Validation Loss for s05 = 1.3694655895233154\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_233/2331385577.py:42: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 46/100, Train Loss: 1.419458031654358\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_233/2331385577.py:67: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/tmp/ipykernel_233/2331385577.py:87: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.24      0.54      0.33       132\n",
      "           1       0.23      0.21      0.22       127\n",
      "           2       0.20      0.22      0.21       161\n",
      "           3       0.40      0.10      0.16       220\n",
      "\n",
      "    accuracy                           0.24       640\n",
      "   macro avg       0.27      0.27      0.23       640\n",
      "weighted avg       0.28      0.24      0.22       640\n",
      "\n",
      "[[71 18 37  6]\n",
      " [49 27 34 17]\n",
      " [87 29 35 10]\n",
      " [88 42 68 22]]\n",
      "Validation Loss for s05 = 1.3722808361053467\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_233/2331385577.py:42: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 47/100, Train Loss: 1.2857557535171509\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_233/2331385577.py:67: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/tmp/ipykernel_233/2331385577.py:87: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.24      0.55      0.33       132\n",
      "           1       0.23      0.21      0.22       127\n",
      "           2       0.21      0.22      0.21       161\n",
      "           3       0.41      0.11      0.17       220\n",
      "\n",
      "    accuracy                           0.25       640\n",
      "   macro avg       0.27      0.27      0.24       640\n",
      "weighted avg       0.29      0.25      0.23       640\n",
      "\n",
      "[[72 18 34  8]\n",
      " [50 27 33 17]\n",
      " [87 29 35 10]\n",
      " [91 42 63 24]]\n",
      "Validation Loss for s05 = 1.3725793361663818\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_233/2331385577.py:42: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 48/100, Train Loss: 1.358134388923645\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_233/2331385577.py:67: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/tmp/ipykernel_233/2331385577.py:87: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/tmp/ipykernel_233/2331385577.py:42: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.23      0.53      0.32       132\n",
      "           1       0.22      0.20      0.21       127\n",
      "           2       0.21      0.22      0.22       161\n",
      "           3       0.40      0.10      0.17       220\n",
      "\n",
      "    accuracy                           0.24       640\n",
      "   macro avg       0.27      0.27      0.23       640\n",
      "weighted avg       0.29      0.24      0.22       640\n",
      "\n",
      "[[70 19 36  7]\n",
      " [51 26 33 17]\n",
      " [85 30 36 10]\n",
      " [93 41 63 23]]\n",
      "Validation Loss for s05 = 1.3738720417022705\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 49/100, Train Loss: 1.3495460748672485\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_233/2331385577.py:67: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/tmp/ipykernel_233/2331385577.py:87: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.24      0.52      0.32       132\n",
      "           1       0.21      0.18      0.19       127\n",
      "           2       0.21      0.22      0.22       161\n",
      "           3       0.41      0.13      0.19       220\n",
      "\n",
      "    accuracy                           0.24       640\n",
      "   macro avg       0.27      0.26      0.23       640\n",
      "weighted avg       0.29      0.24      0.23       640\n",
      "\n",
      "[[69 17 37  9]\n",
      " [49 23 35 20]\n",
      " [85 29 36 11]\n",
      " [90 40 62 28]]\n",
      "Validation Loss for s05 = 1.3757332563400269\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_233/2331385577.py:42: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 50/100, Train Loss: 1.3548469543457031\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_233/2331385577.py:67: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/tmp/ipykernel_233/2331385577.py:87: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.24      0.51      0.32       132\n",
      "           1       0.21      0.20      0.20       127\n",
      "           2       0.21      0.24      0.22       161\n",
      "           3       0.39      0.10      0.16       220\n",
      "\n",
      "    accuracy                           0.24       640\n",
      "   macro avg       0.26      0.26      0.23       640\n",
      "weighted avg       0.28      0.24      0.22       640\n",
      "\n",
      "[[67 20 38  7]\n",
      " [47 25 37 18]\n",
      " [84 29 38 10]\n",
      " [87 45 66 22]]\n",
      "Validation Loss for s05 = 1.374326229095459\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_233/2331385577.py:42: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 51/100, Train Loss: 1.316564679145813\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_233/2331385577.py:67: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/tmp/ipykernel_233/2331385577.py:87: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.24      0.53      0.33       132\n",
      "           1       0.20      0.18      0.19       127\n",
      "           2       0.21      0.22      0.21       161\n",
      "           3       0.41      0.12      0.18       220\n",
      "\n",
      "    accuracy                           0.24       640\n",
      "   macro avg       0.26      0.26      0.23       640\n",
      "weighted avg       0.28      0.24      0.22       640\n",
      "\n",
      "[[70 19 35  8]\n",
      " [51 23 33 20]\n",
      " [85 31 35 10]\n",
      " [90 41 63 26]]\n",
      "Validation Loss for s05 = 1.3727766275405884\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_233/2331385577.py:42: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 52/100, Train Loss: 1.3710222244262695\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_233/2331385577.py:67: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/tmp/ipykernel_233/2331385577.py:87: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.24      0.51      0.32       132\n",
      "           1       0.22      0.20      0.21       127\n",
      "           2       0.22      0.24      0.23       161\n",
      "           3       0.40      0.12      0.19       220\n",
      "\n",
      "    accuracy                           0.25       640\n",
      "   macro avg       0.27      0.27      0.24       640\n",
      "weighted avg       0.29      0.25      0.23       640\n",
      "\n",
      "[[67 20 35 10]\n",
      " [46 26 35 20]\n",
      " [84 28 38 11]\n",
      " [87 42 64 27]]\n",
      "Validation Loss for s05 = 1.3739137649536133\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_233/2331385577.py:42: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 53/100, Train Loss: 1.3952076435089111\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_233/2331385577.py:67: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/tmp/ipykernel_233/2331385577.py:87: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/tmp/ipykernel_233/2331385577.py:42: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.23      0.51      0.32       132\n",
      "           1       0.22      0.20      0.21       127\n",
      "           2       0.21      0.22      0.22       161\n",
      "           3       0.41      0.12      0.19       220\n",
      "\n",
      "    accuracy                           0.24       640\n",
      "   macro avg       0.27      0.26      0.23       640\n",
      "weighted avg       0.29      0.24      0.23       640\n",
      "\n",
      "[[67 21 35  9]\n",
      " [48 26 34 19]\n",
      " [84 30 36 11]\n",
      " [87 41 65 27]]\n",
      "Validation Loss for s05 = 1.3709421157836914\n",
      "Epoch 54/100, Train Loss: 1.3017338514328003\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_233/2331385577.py:67: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/tmp/ipykernel_233/2331385577.py:87: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/tmp/ipykernel_233/2331385577.py:42: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.23      0.50      0.32       132\n",
      "           1       0.22      0.21      0.22       127\n",
      "           2       0.21      0.22      0.22       161\n",
      "           3       0.37      0.10      0.16       220\n",
      "\n",
      "    accuracy                           0.24       640\n",
      "   macro avg       0.26      0.26      0.23       640\n",
      "weighted avg       0.27      0.24      0.22       640\n",
      "\n",
      "[[66 20 36 10]\n",
      " [47 27 34 19]\n",
      " [81 33 36 11]\n",
      " [88 43 66 23]]\n",
      "Validation Loss for s05 = 1.372377634048462\n",
      "Epoch 55/100, Train Loss: 1.3244026899337769\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_233/2331385577.py:67: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/tmp/ipykernel_233/2331385577.py:87: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/tmp/ipykernel_233/2331385577.py:42: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.23      0.52      0.32       132\n",
      "           1       0.22      0.20      0.21       127\n",
      "           2       0.21      0.22      0.22       161\n",
      "           3       0.37      0.10      0.16       220\n",
      "\n",
      "    accuracy                           0.24       640\n",
      "   macro avg       0.26      0.26      0.23       640\n",
      "weighted avg       0.27      0.24      0.22       640\n",
      "\n",
      "[[68 19 36  9]\n",
      " [48 26 34 19]\n",
      " [85 29 36 11]\n",
      " [90 42 65 23]]\n",
      "Validation Loss for s05 = 1.3703416585922241\n",
      "Epoch 56/100, Train Loss: 1.320701241493225\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_233/2331385577.py:67: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/tmp/ipykernel_233/2331385577.py:87: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/tmp/ipykernel_233/2331385577.py:42: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.24      0.52      0.33       132\n",
      "           1       0.22      0.20      0.21       127\n",
      "           2       0.21      0.22      0.22       161\n",
      "           3       0.40      0.12      0.18       220\n",
      "\n",
      "    accuracy                           0.24       640\n",
      "   macro avg       0.27      0.27      0.23       640\n",
      "weighted avg       0.28      0.24      0.23       640\n",
      "\n",
      "[[68 19 36  9]\n",
      " [47 26 35 19]\n",
      " [83 31 36 11]\n",
      " [88 42 64 26]]\n",
      "Validation Loss for s05 = 1.3716285228729248\n",
      "Epoch 57/100, Train Loss: 1.3954304456710815\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_233/2331385577.py:67: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/tmp/ipykernel_233/2331385577.py:87: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/tmp/ipykernel_233/2331385577.py:42: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.24      0.51      0.33       132\n",
      "           1       0.21      0.21      0.21       127\n",
      "           2       0.20      0.22      0.21       161\n",
      "           3       0.41      0.10      0.17       220\n",
      "\n",
      "    accuracy                           0.24       640\n",
      "   macro avg       0.27      0.26      0.23       640\n",
      "weighted avg       0.28      0.24      0.22       640\n",
      "\n",
      "[[67 22 36  7]\n",
      " [45 27 40 15]\n",
      " [81 33 36 11]\n",
      " [85 46 66 23]]\n",
      "Validation Loss for s05 = 1.3763550519943237\n",
      "Epoch 58/100, Train Loss: 1.3985223770141602\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_233/2331385577.py:67: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/tmp/ipykernel_233/2331385577.py:87: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.24      0.52      0.33       132\n",
      "           1       0.22      0.20      0.21       127\n",
      "           2       0.19      0.22      0.21       161\n",
      "           3       0.41      0.10      0.16       220\n",
      "\n",
      "    accuracy                           0.24       640\n",
      "   macro avg       0.26      0.26      0.22       640\n",
      "weighted avg       0.28      0.24      0.22       640\n",
      "\n",
      "[[69 20 37  6]\n",
      " [48 25 39 15]\n",
      " [86 29 35 11]\n",
      " [88 41 69 22]]\n",
      "Validation Loss for s05 = 1.3730636835098267\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_233/2331385577.py:42: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 59/100, Train Loss: 1.3349517583847046\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_233/2331385577.py:67: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/tmp/ipykernel_233/2331385577.py:87: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/tmp/ipykernel_233/2331385577.py:42: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.23      0.52      0.32       132\n",
      "           1       0.22      0.16      0.18       127\n",
      "           2       0.22      0.24      0.23       161\n",
      "           3       0.42      0.13      0.20       220\n",
      "\n",
      "    accuracy                           0.24       640\n",
      "   macro avg       0.27      0.26      0.23       640\n",
      "weighted avg       0.29      0.24      0.23       640\n",
      "\n",
      "[[69 17 37  9]\n",
      " [50 20 39 18]\n",
      " [91 20 39 11]\n",
      " [90 36 66 28]]\n",
      "Validation Loss for s05 = 1.371598720550537\n",
      "Epoch 60/100, Train Loss: 1.4390407800674438\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_233/2331385577.py:67: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/tmp/ipykernel_233/2331385577.py:87: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/tmp/ipykernel_233/2331385577.py:42: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.23      0.52      0.32       132\n",
      "           1       0.20      0.16      0.18       127\n",
      "           2       0.22      0.25      0.23       161\n",
      "           3       0.39      0.12      0.18       220\n",
      "\n",
      "    accuracy                           0.24       640\n",
      "   macro avg       0.26      0.26      0.23       640\n",
      "weighted avg       0.28      0.24      0.22       640\n",
      "\n",
      "[[68 18 37  9]\n",
      " [50 20 37 20]\n",
      " [86 23 40 12]\n",
      " [88 39 67 26]]\n",
      "Validation Loss for s05 = 1.372368574142456\n",
      "Epoch 61/100, Train Loss: 1.3681750297546387\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_233/2331385577.py:67: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/tmp/ipykernel_233/2331385577.py:87: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/tmp/ipykernel_233/2331385577.py:42: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.23      0.54      0.33       132\n",
      "           1       0.22      0.18      0.20       127\n",
      "           2       0.22      0.23      0.22       161\n",
      "           3       0.43      0.12      0.19       220\n",
      "\n",
      "    accuracy                           0.25       640\n",
      "   macro avg       0.28      0.27      0.23       640\n",
      "weighted avg       0.29      0.25      0.23       640\n",
      "\n",
      "[[71 18 36  7]\n",
      " [52 23 35 17]\n",
      " [89 25 37 10]\n",
      " [91 39 64 26]]\n",
      "Validation Loss for s05 = 1.3734773397445679\n",
      "Epoch 62/100, Train Loss: 1.4142258167266846\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_233/2331385577.py:67: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/tmp/ipykernel_233/2331385577.py:87: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/tmp/ipykernel_233/2331385577.py:42: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.24      0.52      0.32       132\n",
      "           1       0.20      0.16      0.18       127\n",
      "           2       0.22      0.25      0.23       161\n",
      "           3       0.45      0.12      0.19       220\n",
      "\n",
      "    accuracy                           0.24       640\n",
      "   macro avg       0.27      0.26      0.23       640\n",
      "weighted avg       0.30      0.24      0.23       640\n",
      "\n",
      "[[69 18 38  7]\n",
      " [50 20 42 15]\n",
      " [86 24 40 11]\n",
      " [88 39 66 27]]\n",
      "Validation Loss for s05 = 1.380395770072937\n",
      "Epoch 63/100, Train Loss: 1.435246229171753\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_233/2331385577.py:67: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/tmp/ipykernel_233/2331385577.py:87: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/tmp/ipykernel_233/2331385577.py:42: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.23      0.52      0.32       132\n",
      "           1       0.21      0.15      0.17       127\n",
      "           2       0.21      0.25      0.23       161\n",
      "           3       0.43      0.11      0.17       220\n",
      "\n",
      "    accuracy                           0.24       640\n",
      "   macro avg       0.27      0.26      0.22       640\n",
      "weighted avg       0.29      0.24      0.22       640\n",
      "\n",
      "[[69 17 39  7]\n",
      " [50 19 44 14]\n",
      " [90 20 40 11]\n",
      " [89 36 71 24]]\n",
      "Validation Loss for s05 = 1.379305124282837\n",
      "Epoch 64/100, Train Loss: 1.334001064300537\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_233/2331385577.py:67: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/tmp/ipykernel_233/2331385577.py:87: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/tmp/ipykernel_233/2331385577.py:42: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.24      0.53      0.33       132\n",
      "           1       0.22      0.20      0.21       127\n",
      "           2       0.22      0.24      0.23       161\n",
      "           3       0.40      0.10      0.17       220\n",
      "\n",
      "    accuracy                           0.25       640\n",
      "   macro avg       0.27      0.27      0.23       640\n",
      "weighted avg       0.29      0.25      0.22       640\n",
      "\n",
      "[[70 19 35  8]\n",
      " [49 25 38 15]\n",
      " [85 26 39 11]\n",
      " [88 42 67 23]]\n",
      "Validation Loss for s05 = 1.37678861618042\n",
      "Epoch 65/100, Train Loss: 1.337147831916809\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_233/2331385577.py:67: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/tmp/ipykernel_233/2331385577.py:87: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.24      0.52      0.33       132\n",
      "           1       0.21      0.19      0.20       127\n",
      "           2       0.20      0.24      0.22       161\n",
      "           3       0.38      0.08      0.13       220\n",
      "\n",
      "    accuracy                           0.23       640\n",
      "   macro avg       0.26      0.26      0.22       640\n",
      "weighted avg       0.27      0.23      0.21       640\n",
      "\n",
      "[[68 21 40  3]\n",
      " [47 24 41 15]\n",
      " [84 26 39 12]\n",
      " [85 42 75 18]]\n",
      "Validation Loss for s05 = 1.3799552917480469\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_233/2331385577.py:42: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 66/100, Train Loss: 1.3533462285995483\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_233/2331385577.py:67: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/tmp/ipykernel_233/2331385577.py:87: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.23      0.52      0.32       132\n",
      "           1       0.19      0.16      0.17       127\n",
      "           2       0.21      0.25      0.23       161\n",
      "           3       0.39      0.09      0.14       220\n",
      "\n",
      "    accuracy                           0.23       640\n",
      "   macro avg       0.26      0.25      0.22       640\n",
      "weighted avg       0.27      0.23      0.21       640\n",
      "\n",
      "[[68 20 40  4]\n",
      " [50 20 43 14]\n",
      " [84 24 41 12]\n",
      " [89 40 72 19]]\n",
      "Validation Loss for s05 = 1.3800326585769653\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_233/2331385577.py:42: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 67/100, Train Loss: 1.4002256393432617\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_233/2331385577.py:67: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/tmp/ipykernel_233/2331385577.py:87: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.24      0.52      0.33       132\n",
      "           1       0.20      0.18      0.19       127\n",
      "           2       0.22      0.24      0.23       161\n",
      "           3       0.42      0.11      0.18       220\n",
      "\n",
      "    accuracy                           0.24       640\n",
      "   macro avg       0.27      0.26      0.23       640\n",
      "weighted avg       0.29      0.24      0.22       640\n",
      "\n",
      "[[69 20 37  6]\n",
      " [49 23 39 16]\n",
      " [84 26 39 12]\n",
      " [84 47 64 25]]\n",
      "Validation Loss for s05 = 1.3778891563415527\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_233/2331385577.py:42: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 68/100, Train Loss: 1.429205060005188\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_233/2331385577.py:67: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/tmp/ipykernel_233/2331385577.py:87: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.24      0.53      0.33       132\n",
      "           1       0.21      0.17      0.18       127\n",
      "           2       0.21      0.24      0.22       161\n",
      "           3       0.40      0.10      0.17       220\n",
      "\n",
      "    accuracy                           0.24       640\n",
      "   macro avg       0.26      0.26      0.23       640\n",
      "weighted avg       0.28      0.24      0.22       640\n",
      "\n",
      "[[70 17 38  7]\n",
      " [49 21 42 15]\n",
      " [88 22 39 12]\n",
      " [87 41 69 23]]\n",
      "Validation Loss for s05 = 1.3768508434295654\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_233/2331385577.py:42: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 69/100, Train Loss: 1.2866817712783813\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_233/2331385577.py:67: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/tmp/ipykernel_233/2331385577.py:87: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.24      0.52      0.33       132\n",
      "           1       0.19      0.17      0.18       127\n",
      "           2       0.23      0.27      0.25       161\n",
      "           3       0.42      0.11      0.17       220\n",
      "\n",
      "    accuracy                           0.25       640\n",
      "   macro avg       0.27      0.27      0.23       640\n",
      "weighted avg       0.29      0.25      0.23       640\n",
      "\n",
      "[[68 20 37  7]\n",
      " [50 22 40 15]\n",
      " [81 26 43 11]\n",
      " [85 46 65 24]]\n",
      "Validation Loss for s05 = 1.3795135021209717\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_233/2331385577.py:42: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 70/100, Train Loss: 1.2605758905410767\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_233/2331385577.py:67: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/tmp/ipykernel_233/2331385577.py:87: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.24      0.52      0.33       132\n",
      "           1       0.19      0.17      0.18       127\n",
      "           2       0.22      0.25      0.23       161\n",
      "           3       0.41      0.10      0.17       220\n",
      "\n",
      "    accuracy                           0.24       640\n",
      "   macro avg       0.27      0.26      0.23       640\n",
      "weighted avg       0.28      0.24      0.22       640\n",
      "\n",
      "[[69 20 37  6]\n",
      " [49 22 40 16]\n",
      " [84 26 40 11]\n",
      " [86 45 66 23]]\n",
      "Validation Loss for s05 = 1.382482647895813\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_233/2331385577.py:42: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 71/100, Train Loss: 1.3846772909164429\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_233/2331385577.py:67: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/tmp/ipykernel_233/2331385577.py:87: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.24      0.52      0.33       132\n",
      "           1       0.20      0.17      0.18       127\n",
      "           2       0.22      0.26      0.24       161\n",
      "           3       0.42      0.11      0.17       220\n",
      "\n",
      "    accuracy                           0.24       640\n",
      "   macro avg       0.27      0.26      0.23       640\n",
      "weighted avg       0.29      0.24      0.22       640\n",
      "\n",
      "[[69 18 38  7]\n",
      " [49 21 42 15]\n",
      " [85 23 42 11]\n",
      " [84 42 70 24]]\n",
      "Validation Loss for s05 = 1.3803107738494873\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_233/2331385577.py:42: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 72/100, Train Loss: 1.3835396766662598\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_233/2331385577.py:67: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/tmp/ipykernel_233/2331385577.py:87: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.24      0.51      0.33       132\n",
      "           1       0.19      0.17      0.18       127\n",
      "           2       0.21      0.25      0.23       161\n",
      "           3       0.43      0.10      0.17       220\n",
      "\n",
      "    accuracy                           0.24       640\n",
      "   macro avg       0.27      0.26      0.23       640\n",
      "weighted avg       0.29      0.24      0.22       640\n",
      "\n",
      "[[67 20 39  6]\n",
      " [48 22 42 15]\n",
      " [81 29 41 10]\n",
      " [83 45 69 23]]\n",
      "Validation Loss for s05 = 1.3832542896270752\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_233/2331385577.py:42: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 73/100, Train Loss: 1.3720115423202515\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_233/2331385577.py:67: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/tmp/ipykernel_233/2331385577.py:87: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.23      0.50      0.32       132\n",
      "           1       0.18      0.15      0.17       127\n",
      "           2       0.22      0.27      0.24       161\n",
      "           3       0.40      0.10      0.17       220\n",
      "\n",
      "    accuracy                           0.24       640\n",
      "   macro avg       0.26      0.26      0.22       640\n",
      "weighted avg       0.28      0.24      0.22       640\n",
      "\n",
      "[[66 18 41  7]\n",
      " [48 19 43 17]\n",
      " [83 25 43 10]\n",
      " [84 41 72 23]]\n",
      "Validation Loss for s05 = 1.3819793462753296\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_233/2331385577.py:42: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 74/100, Train Loss: 1.404496192932129\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_233/2331385577.py:67: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/tmp/ipykernel_233/2331385577.py:87: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/tmp/ipykernel_233/2331385577.py:42: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.23      0.48      0.32       132\n",
      "           1       0.21      0.17      0.19       127\n",
      "           2       0.23      0.29      0.26       161\n",
      "           3       0.44      0.13      0.20       220\n",
      "\n",
      "    accuracy                           0.25       640\n",
      "   macro avg       0.28      0.27      0.24       640\n",
      "weighted avg       0.30      0.25      0.24       640\n",
      "\n",
      "[[64 19 42  7]\n",
      " [46 22 42 17]\n",
      " [79 25 46 11]\n",
      " [84 41 67 28]]\n",
      "Validation Loss for s05 = 1.3827722072601318\n",
      "Epoch 75/100, Train Loss: 1.3727136850357056\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_233/2331385577.py:67: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/tmp/ipykernel_233/2331385577.py:87: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/tmp/ipykernel_233/2331385577.py:42: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.24      0.50      0.32       132\n",
      "           1       0.20      0.19      0.20       127\n",
      "           2       0.22      0.25      0.23       161\n",
      "           3       0.42      0.10      0.17       220\n",
      "\n",
      "    accuracy                           0.24       640\n",
      "   macro avg       0.27      0.26      0.23       640\n",
      "weighted avg       0.29      0.24      0.22       640\n",
      "\n",
      "[[66 21 40  5]\n",
      " [47 24 41 15]\n",
      " [80 28 41 12]\n",
      " [84 45 68 23]]\n",
      "Validation Loss for s05 = 1.379756212234497\n",
      "Epoch 76/100, Train Loss: 1.3480228185653687\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_233/2331385577.py:67: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/tmp/ipykernel_233/2331385577.py:87: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.23      0.46      0.31       132\n",
      "           1       0.20      0.19      0.19       127\n",
      "           2       0.24      0.29      0.26       161\n",
      "           3       0.42      0.11      0.18       220\n",
      "\n",
      "    accuracy                           0.24       640\n",
      "   macro avg       0.27      0.26      0.23       640\n",
      "weighted avg       0.29      0.24      0.23       640\n",
      "\n",
      "[[61 22 41  8]\n",
      " [46 24 41 16]\n",
      " [76 28 46 11]\n",
      " [83 46 66 25]]\n",
      "Validation Loss for s05 = 1.3817838430404663\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_233/2331385577.py:42: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 77/100, Train Loss: 1.5060080289840698\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_233/2331385577.py:67: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/tmp/ipykernel_233/2331385577.py:87: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/tmp/ipykernel_233/2331385577.py:42: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.23      0.48      0.31       132\n",
      "           1       0.21      0.19      0.20       127\n",
      "           2       0.25      0.29      0.27       161\n",
      "           3       0.43      0.13      0.20       220\n",
      "\n",
      "    accuracy                           0.25       640\n",
      "   macro avg       0.28      0.27      0.24       640\n",
      "weighted avg       0.30      0.25      0.24       640\n",
      "\n",
      "[[63 21 40  8]\n",
      " [46 24 39 18]\n",
      " [78 25 47 11]\n",
      " [84 44 64 28]]\n",
      "Validation Loss for s05 = 1.3825724124908447\n",
      "Epoch 78/100, Train Loss: 1.4122625589370728\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_233/2331385577.py:67: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/tmp/ipykernel_233/2331385577.py:87: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.24      0.48      0.32       132\n",
      "           1       0.22      0.18      0.20       127\n",
      "           2       0.24      0.29      0.26       161\n",
      "           3       0.45      0.13      0.20       220\n",
      "\n",
      "    accuracy                           0.25       640\n",
      "   macro avg       0.28      0.27      0.25       640\n",
      "weighted avg       0.30      0.25      0.24       640\n",
      "\n",
      "[[64 18 43  7]\n",
      " [47 23 40 17]\n",
      " [79 23 47 12]\n",
      " [81 41 69 29]]\n",
      "Validation Loss for s05 = 1.384273648262024\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_233/2331385577.py:42: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 79/100, Train Loss: 1.392377495765686\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_233/2331385577.py:67: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/tmp/ipykernel_233/2331385577.py:87: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.23      0.48      0.31       132\n",
      "           1       0.21      0.17      0.19       127\n",
      "           2       0.23      0.28      0.25       161\n",
      "           3       0.42      0.12      0.19       220\n",
      "\n",
      "    accuracy                           0.25       640\n",
      "   macro avg       0.27      0.26      0.24       640\n",
      "weighted avg       0.29      0.25      0.23       640\n",
      "\n",
      "[[63 18 43  8]\n",
      " [48 22 41 16]\n",
      " [78 25 45 13]\n",
      " [81 42 70 27]]\n",
      "Validation Loss for s05 = 1.385009527206421\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_233/2331385577.py:42: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 80/100, Train Loss: 1.3295687437057495\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_233/2331385577.py:67: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/tmp/ipykernel_233/2331385577.py:87: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.24      0.47      0.32       132\n",
      "           1       0.22      0.20      0.21       127\n",
      "           2       0.22      0.29      0.25       161\n",
      "           3       0.42      0.10      0.17       220\n",
      "\n",
      "    accuracy                           0.24       640\n",
      "   macro avg       0.27      0.26      0.23       640\n",
      "weighted avg       0.29      0.24      0.23       640\n",
      "\n",
      "[[62 21 45  4]\n",
      " [44 25 43 15]\n",
      " [75 27 46 13]\n",
      " [80 41 76 23]]\n",
      "Validation Loss for s05 = 1.388872742652893\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_233/2331385577.py:42: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 81/100, Train Loss: 1.2378238439559937\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_233/2331385577.py:67: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/tmp/ipykernel_233/2331385577.py:87: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.24      0.46      0.31       132\n",
      "           1       0.23      0.20      0.21       127\n",
      "           2       0.23      0.29      0.25       161\n",
      "           3       0.41      0.11      0.17       220\n",
      "\n",
      "    accuracy                           0.25       640\n",
      "   macro avg       0.28      0.27      0.24       640\n",
      "weighted avg       0.29      0.25      0.23       640\n",
      "\n",
      "[[61 22 43  6]\n",
      " [43 26 43 15]\n",
      " [75 26 47 13]\n",
      " [80 41 75 24]]\n",
      "Validation Loss for s05 = 1.389984130859375\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_233/2331385577.py:42: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 82/100, Train Loss: 1.2754987478256226\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_233/2331385577.py:67: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/tmp/ipykernel_233/2331385577.py:87: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.23      0.47      0.31       132\n",
      "           1       0.20      0.17      0.19       127\n",
      "           2       0.23      0.29      0.26       161\n",
      "           3       0.42      0.12      0.19       220\n",
      "\n",
      "    accuracy                           0.25       640\n",
      "   macro avg       0.27      0.26      0.24       640\n",
      "weighted avg       0.29      0.25      0.23       640\n",
      "\n",
      "[[62 22 41  7]\n",
      " [47 22 42 16]\n",
      " [77 24 46 14]\n",
      " [82 41 70 27]]\n",
      "Validation Loss for s05 = 1.3866076469421387\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_233/2331385577.py:42: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 83/100, Train Loss: 1.3192237615585327\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_233/2331385577.py:67: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/tmp/ipykernel_233/2331385577.py:87: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/tmp/ipykernel_233/2331385577.py:42: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.24      0.46      0.32       132\n",
      "           1       0.23      0.21      0.22       127\n",
      "           2       0.22      0.27      0.24       161\n",
      "           3       0.44      0.13      0.20       220\n",
      "\n",
      "    accuracy                           0.25       640\n",
      "   macro avg       0.28      0.27      0.25       640\n",
      "weighted avg       0.30      0.25      0.24       640\n",
      "\n",
      "[[61 22 42  7]\n",
      " [40 27 44 16]\n",
      " [76 27 44 14]\n",
      " [77 44 70 29]]\n",
      "Validation Loss for s05 = 1.391205072402954\n",
      "Epoch 84/100, Train Loss: 1.297536849975586\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_233/2331385577.py:67: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/tmp/ipykernel_233/2331385577.py:87: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/tmp/ipykernel_233/2331385577.py:42: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.24      0.48      0.32       132\n",
      "           1       0.23      0.20      0.21       127\n",
      "           2       0.23      0.31      0.27       161\n",
      "           3       0.40      0.10      0.16       220\n",
      "\n",
      "    accuracy                           0.25       640\n",
      "   macro avg       0.28      0.27      0.24       640\n",
      "weighted avg       0.29      0.25      0.23       640\n",
      "\n",
      "[[63 21 43  5]\n",
      " [43 25 44 15]\n",
      " [73 25 50 13]\n",
      " [83 39 76 22]]\n",
      "Validation Loss for s05 = 1.3918157815933228\n",
      "Epoch 85/100, Train Loss: 1.3362548351287842\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_233/2331385577.py:67: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/tmp/ipykernel_233/2331385577.py:87: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/tmp/ipykernel_233/2331385577.py:42: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.24      0.48      0.32       132\n",
      "           1       0.22      0.18      0.20       127\n",
      "           2       0.24      0.31      0.27       161\n",
      "           3       0.45      0.13      0.20       220\n",
      "\n",
      "    accuracy                           0.26       640\n",
      "   macro avg       0.29      0.28      0.25       640\n",
      "weighted avg       0.31      0.26      0.24       640\n",
      "\n",
      "[[64 19 43  6]\n",
      " [44 23 44 16]\n",
      " [75 23 50 13]\n",
      " [83 40 68 29]]\n",
      "Validation Loss for s05 = 1.387587308883667\n",
      "Epoch 86/100, Train Loss: 1.3405107259750366\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_233/2331385577.py:67: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/tmp/ipykernel_233/2331385577.py:87: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/tmp/ipykernel_233/2331385577.py:42: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.23      0.47      0.31       132\n",
      "           1       0.22      0.17      0.19       127\n",
      "           2       0.24      0.30      0.27       161\n",
      "           3       0.45      0.14      0.21       220\n",
      "\n",
      "    accuracy                           0.25       640\n",
      "   macro avg       0.28      0.27      0.25       640\n",
      "weighted avg       0.31      0.25      0.24       640\n",
      "\n",
      "[[62 20 42  8]\n",
      " [45 22 42 18]\n",
      " [79 22 48 12]\n",
      " [83 37 69 31]]\n",
      "Validation Loss for s05 = 1.3883612155914307\n",
      "Epoch 87/100, Train Loss: 1.3272969722747803\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_233/2331385577.py:67: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/tmp/ipykernel_233/2331385577.py:87: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/tmp/ipykernel_233/2331385577.py:42: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.24      0.47      0.31       132\n",
      "           1       0.22      0.19      0.20       127\n",
      "           2       0.24      0.30      0.27       161\n",
      "           3       0.42      0.14      0.21       220\n",
      "\n",
      "    accuracy                           0.26       640\n",
      "   macro avg       0.28      0.27      0.25       640\n",
      "weighted avg       0.30      0.26      0.24       640\n",
      "\n",
      "[[62 19 42  9]\n",
      " [44 24 42 17]\n",
      " [74 24 48 15]\n",
      " [82 41 67 30]]\n",
      "Validation Loss for s05 = 1.3918403387069702\n",
      "Epoch 88/100, Train Loss: 1.4271246194839478\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_233/2331385577.py:67: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/tmp/ipykernel_233/2331385577.py:87: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/tmp/ipykernel_233/2331385577.py:42: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.24      0.47      0.31       132\n",
      "           1       0.24      0.20      0.22       127\n",
      "           2       0.24      0.30      0.26       161\n",
      "           3       0.38      0.11      0.18       220\n",
      "\n",
      "    accuracy                           0.25       640\n",
      "   macro avg       0.27      0.27      0.24       640\n",
      "weighted avg       0.29      0.25      0.24       640\n",
      "\n",
      "[[62 18 43  9]\n",
      " [43 26 41 17]\n",
      " [75 24 48 14]\n",
      " [83 42 70 25]]\n",
      "Validation Loss for s05 = 1.3936116695404053\n",
      "Epoch 89/100, Train Loss: 1.2192624807357788\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_233/2331385577.py:67: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/tmp/ipykernel_233/2331385577.py:87: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/tmp/ipykernel_233/2331385577.py:42: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.24      0.48      0.32       132\n",
      "           1       0.22      0.19      0.20       127\n",
      "           2       0.24      0.32      0.28       161\n",
      "           3       0.42      0.12      0.18       220\n",
      "\n",
      "    accuracy                           0.26       640\n",
      "   macro avg       0.28      0.28      0.25       640\n",
      "weighted avg       0.30      0.26      0.24       640\n",
      "\n",
      "[[63 19 43  7]\n",
      " [44 24 43 16]\n",
      " [73 24 51 13]\n",
      " [81 41 72 26]]\n",
      "Validation Loss for s05 = 1.3967227935791016\n",
      "Epoch 90/100, Train Loss: 1.4161601066589355\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_233/2331385577.py:67: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/tmp/ipykernel_233/2331385577.py:87: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/tmp/ipykernel_233/2331385577.py:42: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.24      0.47      0.32       132\n",
      "           1       0.21      0.17      0.19       127\n",
      "           2       0.24      0.31      0.27       161\n",
      "           3       0.43      0.14      0.21       220\n",
      "\n",
      "    accuracy                           0.26       640\n",
      "   macro avg       0.28      0.27      0.25       640\n",
      "weighted avg       0.30      0.26      0.24       640\n",
      "\n",
      "[[62 19 44  7]\n",
      " [43 22 43 19]\n",
      " [72 24 50 15]\n",
      " [78 39 72 31]]\n",
      "Validation Loss for s05 = 1.396220088005066\n",
      "Epoch 91/100, Train Loss: 1.4675016403198242\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_233/2331385577.py:67: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/tmp/ipykernel_233/2331385577.py:87: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/tmp/ipykernel_233/2331385577.py:42: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.24      0.48      0.32       132\n",
      "           1       0.23      0.19      0.21       127\n",
      "           2       0.25      0.32      0.28       161\n",
      "           3       0.42      0.13      0.20       220\n",
      "\n",
      "    accuracy                           0.26       640\n",
      "   macro avg       0.29      0.28      0.25       640\n",
      "weighted avg       0.30      0.26      0.25       640\n",
      "\n",
      "[[63 18 43  8]\n",
      " [43 24 42 18]\n",
      " [72 24 51 14]\n",
      " [83 38 70 29]]\n",
      "Validation Loss for s05 = 1.395864486694336\n",
      "Epoch 92/100, Train Loss: 1.336756706237793\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_233/2331385577.py:67: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/tmp/ipykernel_233/2331385577.py:87: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/tmp/ipykernel_233/2331385577.py:42: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.24      0.47      0.31       132\n",
      "           1       0.23      0.18      0.20       127\n",
      "           2       0.25      0.31      0.28       161\n",
      "           3       0.43      0.15      0.22       220\n",
      "\n",
      "    accuracy                           0.26       640\n",
      "   macro avg       0.29      0.28      0.25       640\n",
      "weighted avg       0.30      0.26      0.25       640\n",
      "\n",
      "[[62 19 42  9]\n",
      " [43 23 42 19]\n",
      " [74 23 50 14]\n",
      " [83 37 68 32]]\n",
      "Validation Loss for s05 = 1.3942451477050781\n",
      "Epoch 93/100, Train Loss: 1.3585489988327026\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_233/2331385577.py:67: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/tmp/ipykernel_233/2331385577.py:87: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/tmp/ipykernel_233/2331385577.py:42: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.24      0.48      0.32       132\n",
      "           1       0.24      0.21      0.22       127\n",
      "           2       0.23      0.29      0.26       161\n",
      "           3       0.41      0.10      0.16       220\n",
      "\n",
      "    accuracy                           0.25       640\n",
      "   macro avg       0.28      0.27      0.24       640\n",
      "weighted avg       0.29      0.25      0.23       640\n",
      "\n",
      "[[63 21 44  4]\n",
      " [43 27 42 15]\n",
      " [77 24 47 13]\n",
      " [84 42 72 22]]\n",
      "Validation Loss for s05 = 1.395951747894287\n",
      "Epoch 94/100, Train Loss: 1.4264564514160156\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_233/2331385577.py:67: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/tmp/ipykernel_233/2331385577.py:87: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/tmp/ipykernel_233/2331385577.py:42: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.24      0.48      0.32       132\n",
      "           1       0.23      0.20      0.22       127\n",
      "           2       0.24      0.31      0.27       161\n",
      "           3       0.41      0.10      0.16       220\n",
      "\n",
      "    accuracy                           0.25       640\n",
      "   macro avg       0.28      0.28      0.24       640\n",
      "weighted avg       0.30      0.25      0.23       640\n",
      "\n",
      "[[64 20 44  4]\n",
      " [43 26 42 16]\n",
      " [74 25 50 12]\n",
      " [83 41 74 22]]\n",
      "Validation Loss for s05 = 1.3985813856124878\n",
      "Epoch 95/100, Train Loss: 1.1728626489639282\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_233/2331385577.py:67: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/tmp/ipykernel_233/2331385577.py:87: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/tmp/ipykernel_233/2331385577.py:42: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.24      0.49      0.33       132\n",
      "           1       0.24      0.20      0.22       127\n",
      "           2       0.24      0.31      0.27       161\n",
      "           3       0.43      0.12      0.19       220\n",
      "\n",
      "    accuracy                           0.26       640\n",
      "   macro avg       0.29      0.28      0.25       640\n",
      "weighted avg       0.31      0.26      0.24       640\n",
      "\n",
      "[[65 18 43  6]\n",
      " [45 25 42 15]\n",
      " [75 23 50 13]\n",
      " [83 39 72 26]]\n",
      "Validation Loss for s05 = 1.394736409187317\n",
      "Epoch 96/100, Train Loss: 1.3842865228652954\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_233/2331385577.py:67: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/tmp/ipykernel_233/2331385577.py:87: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/tmp/ipykernel_233/2331385577.py:42: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.24      0.48      0.32       132\n",
      "           1       0.25      0.21      0.23       127\n",
      "           2       0.25      0.34      0.29       161\n",
      "           3       0.42      0.10      0.17       220\n",
      "\n",
      "    accuracy                           0.26       640\n",
      "   macro avg       0.29      0.28      0.25       640\n",
      "weighted avg       0.31      0.26      0.24       640\n",
      "\n",
      "[[63 20 43  6]\n",
      " [43 27 42 15]\n",
      " [74 22 54 11]\n",
      " [83 39 75 23]]\n",
      "Validation Loss for s05 = 1.402900218963623\n",
      "Epoch 97/100, Train Loss: 1.321773886680603\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_233/2331385577.py:67: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/tmp/ipykernel_233/2331385577.py:87: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/tmp/ipykernel_233/2331385577.py:42: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.25      0.48      0.33       132\n",
      "           1       0.24      0.21      0.22       127\n",
      "           2       0.25      0.34      0.28       161\n",
      "           3       0.41      0.10      0.16       220\n",
      "\n",
      "    accuracy                           0.26       640\n",
      "   macro avg       0.28      0.28      0.25       640\n",
      "weighted avg       0.30      0.26      0.24       640\n",
      "\n",
      "[[63 19 45  5]\n",
      " [39 27 44 17]\n",
      " [70 27 54 10]\n",
      " [80 41 77 22]]\n",
      "Validation Loss for s05 = 1.401818037033081\n",
      "Epoch 98/100, Train Loss: 1.4538787603378296\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_233/2331385577.py:67: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/tmp/ipykernel_233/2331385577.py:87: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/tmp/ipykernel_233/2331385577.py:42: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.25      0.45      0.32       132\n",
      "           1       0.22      0.21      0.22       127\n",
      "           2       0.25      0.33      0.28       161\n",
      "           3       0.41      0.11      0.18       220\n",
      "\n",
      "    accuracy                           0.26       640\n",
      "   macro avg       0.28      0.28      0.25       640\n",
      "weighted avg       0.30      0.26      0.24       640\n",
      "\n",
      "[[59 21 46  6]\n",
      " [39 27 43 18]\n",
      " [66 30 53 12]\n",
      " [76 45 74 25]]\n",
      "Validation Loss for s05 = 1.4010124206542969\n",
      "Epoch 99/100, Train Loss: 1.253170371055603\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_233/2331385577.py:67: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/tmp/ipykernel_233/2331385577.py:87: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.25      0.47      0.33       132\n",
      "           1       0.23      0.20      0.22       127\n",
      "           2       0.25      0.35      0.29       161\n",
      "           3       0.40      0.10      0.17       220\n",
      "\n",
      "    accuracy                           0.26       640\n",
      "   macro avg       0.28      0.28      0.25       640\n",
      "weighted avg       0.30      0.26      0.24       640\n",
      "\n",
      "[[62 20 45  5]\n",
      " [39 26 44 18]\n",
      " [67 27 56 11]\n",
      " [79 41 77 23]]\n",
      "Validation Loss for s05 = 1.404590368270874\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_233/2331385577.py:42: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 100/100, Train Loss: 1.275201439857483\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_233/2331385577.py:67: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/tmp/ipykernel_233/2331385577.py:87: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.24      0.48      0.32       132\n",
      "           1       0.22      0.19      0.21       127\n",
      "           2       0.23      0.30      0.26       161\n",
      "           3       0.41      0.11      0.17       220\n",
      "\n",
      "    accuracy                           0.25       640\n",
      "   macro avg       0.28      0.27      0.24       640\n",
      "weighted avg       0.29      0.25      0.23       640\n",
      "\n",
      "[[64 19 44  5]\n",
      " [42 24 43 18]\n",
      " [74 26 49 12]\n",
      " [83 38 75 24]]\n",
      "Validation Loss for s05 = 1.400214672088623\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x7fdab0446400>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1000x700 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import confusion_matrix,classification_report\n",
    "from sklearn import preprocessing\n",
    "import matplotlib.pyplot as plt\n",
    "#subjectnames\n",
    "file_list_num = np.arange(len(newsubjectname))\n",
    "file_list_numd = np.arange(len(subjectnamesd))\n",
    "\n",
    "kf = KFold(n_splits=12)\n",
    "torch.manual_seed(42)\n",
    "torch.cuda.manual_seed(42)\n",
    "modellist = []\n",
    "modelid = 1\n",
    "#file_list_num\n",
    "#for i, (train_index, test_index) in enumerate(kf.split(file_list_num)):\n",
    "#for train_index in file_list_num:\n",
    "train_index = file_list_num\n",
    "#test_index = file_list_numd\n",
    "test_index_train, test_index_test = train_test_split(file_list_numd, test_size=0.50, random_state=42)\n",
    "print(f\"Fold {i}:\")\n",
    "print(f\"  Train: index={train_index}\")\n",
    "#print(f\"  Test:  index={test_index}\")\n",
    "net = Net()\n",
    "net.to(device)\n",
    "optimizer = optim.Adam(net.parameters(), lr=0.000001)\n",
    "epochs = 100\n",
    "batch_sz = 20\n",
    "train_loss_epoch = []\n",
    "val_loss_epoch = []\n",
    "for epoch in range(epochs):\n",
    "  train_loss = []\n",
    "  for tr in train_index:\n",
    "    v = data_c1d[newsubjectname[tr]]\n",
    "    l = data_c2[newsubjectname[tr]]\n",
    "    #print(v[0].shape)\n",
    "    net.train()\n",
    "    for i in range(0,len(v),batch_sz):\n",
    "      #print(v[i].shape)\n",
    "      #for j in range(0,v[i].shape[0],batch_sz):\n",
    "      #print(newsubjectname[tr])\n",
    "      optimizer.zero_grad()\n",
    "      outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
    "      #print(\"Expout {}\",outputs.shape)\n",
    "      #print(\"Actual {}\",l[i:i+batch_sz].shape)\n",
    "      #print(l[i].shape)\n",
    "      loss = criterion(outputs, l[i:i+batch_sz].to(device, dtype=torch.float))\n",
    "      loss.backward()\n",
    "      train_loss.append(loss)\n",
    "      optimizer.step()\n",
    "  print(f'Epoch {epoch + 1}/{epochs}, Train Loss: {loss.item()}')\n",
    "  train_loss_epoch.append(torch.stack(train_loss).mean().cpu().detach().numpy())\n",
    "  #print(train_loss_epoch)\n",
    "  batch_sz = 20\n",
    "  expectedoutputdeap = []\n",
    "  actualoutputdeap = []\n",
    "\n",
    "  for tr in test_index_train:\n",
    "    v = data_de1[subjectnamesd[tr]]\n",
    "    l = data_del[subjectnamesd[tr]]\n",
    "    #print(v[0].shape)\n",
    "    net.train()\n",
    "    for i in range(0,len(v),batch_sz):\n",
    "      #print(v[i].shape)\n",
    "      #for j in range(0,v[i].shape[0],batch_sz):\n",
    "      #print(newsubjectname[tr])\n",
    "      optimizer.zero_grad()\n",
    "      outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
    "      #print(\"Expout {}\",outputs.shape)\n",
    "      #print(\"Actual {}\",l[i:i+batch_sz].shape)\n",
    "      #print(l[i].shape)\n",
    "      loss = criterion(outputs, l[i:i+batch_sz].to(device, dtype=torch.float))\n",
    "      loss.backward()\n",
    "      train_loss.append(loss)\n",
    "      optimizer.step()\n",
    "\n",
    "  for tr in test_index_test:\n",
    "      net.eval()\n",
    "      v = data_de1[subjectnamesd[tr]]\n",
    "      l = data_del[subjectnamesd[tr]]\n",
    "      net.eval()\n",
    "      val_loss = []\n",
    "      with torch.no_grad():\n",
    "          for i in range(0,len(v),batch_sz):\n",
    "            #print(v[i].shape)\n",
    "            #for j in range(0,v[i].shape[0],batch_sz):\n",
    "            optimizer.zero_grad()\n",
    "            outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
    "            #print(outputs.shape)\n",
    "            #print(l[i:i+batch_sz].shape)\n",
    "            loss = criterion(outputs, l[i:i+batch_sz].to(device, dtype=torch.float))\n",
    "            val_loss.append(loss)\n",
    "            #actualoutputdeap.append(torch.round(outputs.cpu()))\n",
    "            #expectedoutputdeap.append(l[i:i+batch_sz])\n",
    "            actualoutputdeap.append(torch.argmax(torch.softmax(outputs.cpu(),dim=1),dim=1))\n",
    "            expectedoutputdeap.append(torch.argmax(l[i:i+batch_sz],dim=1).numpy())\n",
    "  val_loss_mean = torch.stack(val_loss).mean().cpu().detach().numpy()\n",
    "  val_loss_epoch.append(val_loss_mean)\n",
    "  expectedoutputdeap = np.concatenate( expectedoutputdeap, axis=0 )\n",
    "  actualoutputdeap = np.concatenate( actualoutputdeap, axis=0 )\n",
    "  #print(expectedoutput.shape)\n",
    "  #print(actualoutput.shape)\n",
    "  print(classification_report(expectedoutputdeap,actualoutputdeap))\n",
    "  print(confusion_matrix(expectedoutputdeap,actualoutputdeap))\n",
    "  print(f'Validation Loss for {subjectnamesd[tr]} = {val_loss_mean}')\n",
    "plt.figure(figsize=(10,7))\n",
    "#print(len(train_loss_epoch))\n",
    "plt.plot(np.arange(epochs),train_loss_epoch,label='Train')\n",
    "plt.plot(np.arange(epochs),val_loss_epoch,label='Validation')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "82511330-d09b-4538-a8f5-32a8c2e5d91e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-22T10:49:05.047046Z",
     "iopub.status.busy": "2024-01-22T10:49:05.046366Z",
     "iopub.status.idle": "2024-01-22T10:50:52.460318Z",
     "shell.execute_reply": "2024-01-22T10:50:52.459730Z",
     "shell.execute_reply.started": "2024-01-22T10:49:05.047019Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 39:\n",
      "  Train: index=[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23\n",
      " 24 25 26 27 28 29 30 31]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_233/2598240933.py:43: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n",
      "/tmp/ipykernel_233/2598240933.py:61: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100, Train Loss: 1.4469423294067383\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_233/2598240933.py:87: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.25      0.04      0.07        72\n",
      "           1       0.24      0.22      0.23        93\n",
      "           2       0.38      0.37      0.37       104\n",
      "           3       0.21      0.38      0.27        91\n",
      "\n",
      "    accuracy                           0.27       360\n",
      "   macro avg       0.27      0.25      0.24       360\n",
      "weighted avg       0.28      0.27      0.25       360\n",
      "\n",
      "[[ 3 14 13 42]\n",
      " [ 3 20 18 52]\n",
      " [ 4 26 38 36]\n",
      " [ 2 23 31 35]]\n",
      "Validation Loss for P31 = 1.3981918096542358\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_233/2598240933.py:43: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n",
      "/tmp/ipykernel_233/2598240933.py:61: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/100, Train Loss: 1.5537981986999512\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_233/2598240933.py:87: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.30      0.22      0.25        72\n",
      "           1       0.26      0.25      0.25        93\n",
      "           2       0.38      0.36      0.37       104\n",
      "           3       0.25      0.33      0.28        91\n",
      "\n",
      "    accuracy                           0.29       360\n",
      "   macro avg       0.30      0.29      0.29       360\n",
      "weighted avg       0.30      0.29      0.29       360\n",
      "\n",
      "[[16 15 14 27]\n",
      " [17 23 19 34]\n",
      " [12 26 37 29]\n",
      " [ 9 24 28 30]]\n",
      "Validation Loss for P31 = 1.4209502935409546\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_233/2598240933.py:43: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n",
      "/tmp/ipykernel_233/2598240933.py:61: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/100, Train Loss: 1.4078305959701538\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_233/2598240933.py:87: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.35      0.43      0.39        72\n",
      "           1       0.24      0.24      0.24        93\n",
      "           2       0.39      0.31      0.34       104\n",
      "           3       0.27      0.29      0.28        91\n",
      "\n",
      "    accuracy                           0.31       360\n",
      "   macro avg       0.31      0.32      0.31       360\n",
      "weighted avg       0.31      0.31      0.31       360\n",
      "\n",
      "[[31 14 10 17]\n",
      " [26 22 16 29]\n",
      " [18 29 32 25]\n",
      " [14 27 24 26]]\n",
      "Validation Loss for P31 = 1.4188883304595947\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_233/2598240933.py:43: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n",
      "/tmp/ipykernel_233/2598240933.py:61: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/100, Train Loss: 1.4455536603927612\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_233/2598240933.py:87: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.35      0.51      0.41        72\n",
      "           1       0.26      0.27      0.26        93\n",
      "           2       0.45      0.29      0.35       104\n",
      "           3       0.28      0.27      0.28        91\n",
      "\n",
      "    accuracy                           0.33       360\n",
      "   macro avg       0.33      0.34      0.33       360\n",
      "weighted avg       0.34      0.33      0.32       360\n",
      "\n",
      "[[37 15  7 13]\n",
      " [30 25 11 27]\n",
      " [22 29 30 23]\n",
      " [18 29 19 25]]\n",
      "Validation Loss for P31 = 1.4230189323425293\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_233/2598240933.py:43: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n",
      "/tmp/ipykernel_233/2598240933.py:61: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/100, Train Loss: 1.5083985328674316\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_233/2598240933.py:87: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.34      0.49      0.40        72\n",
      "           1       0.25      0.26      0.25        93\n",
      "           2       0.45      0.24      0.31       104\n",
      "           3       0.29      0.33      0.31        91\n",
      "\n",
      "    accuracy                           0.32       360\n",
      "   macro avg       0.33      0.33      0.32       360\n",
      "weighted avg       0.33      0.32      0.31       360\n",
      "\n",
      "[[35 17  5 15]\n",
      " [29 24 10 30]\n",
      " [22 29 25 28]\n",
      " [18 27 16 30]]\n",
      "Validation Loss for P31 = 1.4205690622329712\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_233/2598240933.py:43: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n",
      "/tmp/ipykernel_233/2598240933.py:61: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6/100, Train Loss: 1.245617151260376\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_233/2598240933.py:87: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.31      0.53      0.39        72\n",
      "           1       0.26      0.25      0.26        93\n",
      "           2       0.48      0.28      0.35       104\n",
      "           3       0.28      0.27      0.28        91\n",
      "\n",
      "    accuracy                           0.32       360\n",
      "   macro avg       0.33      0.33      0.32       360\n",
      "weighted avg       0.34      0.32      0.32       360\n",
      "\n",
      "[[38 14  8 12]\n",
      " [34 23  9 27]\n",
      " [25 24 29 26]\n",
      " [26 26 14 25]]\n",
      "Validation Loss for P31 = 1.426596760749817\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_233/2598240933.py:43: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n",
      "/tmp/ipykernel_233/2598240933.py:61: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7/100, Train Loss: 1.4034298658370972\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_233/2598240933.py:87: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.31      0.51      0.39        72\n",
      "           1       0.26      0.24      0.25        93\n",
      "           2       0.47      0.28      0.35       104\n",
      "           3       0.27      0.27      0.27        91\n",
      "\n",
      "    accuracy                           0.31       360\n",
      "   macro avg       0.33      0.33      0.31       360\n",
      "weighted avg       0.33      0.31      0.31       360\n",
      "\n",
      "[[37 14  7 14]\n",
      " [33 22 10 28]\n",
      " [25 23 29 27]\n",
      " [24 26 16 25]]\n",
      "Validation Loss for P31 = 1.4182466268539429\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_233/2598240933.py:43: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n",
      "/tmp/ipykernel_233/2598240933.py:61: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8/100, Train Loss: 1.469029426574707\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_233/2598240933.py:87: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.30      0.51      0.38        72\n",
      "           1       0.27      0.24      0.25        93\n",
      "           2       0.45      0.25      0.32       104\n",
      "           3       0.26      0.27      0.27        91\n",
      "\n",
      "    accuracy                           0.31       360\n",
      "   macro avg       0.32      0.32      0.30       360\n",
      "weighted avg       0.32      0.31      0.30       360\n",
      "\n",
      "[[37 14  6 15]\n",
      " [33 22 10 28]\n",
      " [28 21 26 29]\n",
      " [24 26 16 25]]\n",
      "Validation Loss for P31 = 1.4186336994171143\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_233/2598240933.py:43: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n",
      "/tmp/ipykernel_233/2598240933.py:61: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9/100, Train Loss: 1.4876998662948608\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_233/2598240933.py:87: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.28      0.49      0.36        72\n",
      "           1       0.26      0.26      0.26        93\n",
      "           2       0.50      0.20      0.29       104\n",
      "           3       0.28      0.31      0.29        91\n",
      "\n",
      "    accuracy                           0.30       360\n",
      "   macro avg       0.33      0.31      0.30       360\n",
      "weighted avg       0.34      0.30      0.29       360\n",
      "\n",
      "[[35 17  4 16]\n",
      " [34 24  6 29]\n",
      " [30 25 21 28]\n",
      " [24 28 11 28]]\n",
      "Validation Loss for P31 = 1.4204415082931519\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_233/2598240933.py:43: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n",
      "/tmp/ipykernel_233/2598240933.py:61: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10/100, Train Loss: 1.3908729553222656\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.30      0.56      0.39        72\n",
      "           1       0.25      0.22      0.23        93\n",
      "           2       0.48      0.22      0.30       104\n",
      "           3       0.28      0.30      0.29        91\n",
      "\n",
      "    accuracy                           0.31       360\n",
      "   macro avg       0.33      0.32      0.30       360\n",
      "weighted avg       0.33      0.31      0.30       360\n",
      "\n",
      "[[40 12  5 15]\n",
      " [36 20  8 29]\n",
      " [31 23 23 27]\n",
      " [28 24 12 27]]\n",
      "Validation Loss for P31 = 1.4190982580184937\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_233/2598240933.py:87: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/tmp/ipykernel_233/2598240933.py:43: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n",
      "/tmp/ipykernel_233/2598240933.py:61: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11/100, Train Loss: 1.4893856048583984\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_233/2598240933.py:87: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.29      0.57      0.39        72\n",
      "           1       0.27      0.22      0.24        93\n",
      "           2       0.55      0.22      0.32       104\n",
      "           3       0.27      0.31      0.29        91\n",
      "\n",
      "    accuracy                           0.31       360\n",
      "   macro avg       0.34      0.33      0.31       360\n",
      "weighted avg       0.35      0.31      0.30       360\n",
      "\n",
      "[[41 11  3 17]\n",
      " [36 20  5 32]\n",
      " [34 21 23 26]\n",
      " [29 23 11 28]]\n",
      "Validation Loss for P31 = 1.4192695617675781\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_233/2598240933.py:43: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n",
      "/tmp/ipykernel_233/2598240933.py:61: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12/100, Train Loss: 1.2976826429367065\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.29      0.56      0.38        72\n",
      "           1       0.25      0.20      0.23        93\n",
      "           2       0.55      0.23      0.32       104\n",
      "           3       0.28      0.32      0.30        91\n",
      "\n",
      "    accuracy                           0.31       360\n",
      "   macro avg       0.34      0.33      0.31       360\n",
      "weighted avg       0.35      0.31      0.30       360\n",
      "\n",
      "[[40 12  3 17]\n",
      " [37 19  6 31]\n",
      " [33 21 24 26]\n",
      " [28 23 11 29]]\n",
      "Validation Loss for P31 = 1.4179562330245972\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_233/2598240933.py:87: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/tmp/ipykernel_233/2598240933.py:43: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n",
      "/tmp/ipykernel_233/2598240933.py:61: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13/100, Train Loss: 1.4244340658187866\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_233/2598240933.py:87: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.29      0.54      0.37        72\n",
      "           1       0.25      0.18      0.21        93\n",
      "           2       0.48      0.25      0.33       104\n",
      "           3       0.27      0.31      0.29        91\n",
      "\n",
      "    accuracy                           0.31       360\n",
      "   macro avg       0.32      0.32      0.30       360\n",
      "weighted avg       0.33      0.31      0.30       360\n",
      "\n",
      "[[39 10  6 17]\n",
      " [37 17  8 31]\n",
      " [33 19 26 26]\n",
      " [27 22 14 28]]\n",
      "Validation Loss for P31 = 1.4104467630386353\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_233/2598240933.py:43: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n",
      "/tmp/ipykernel_233/2598240933.py:61: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14/100, Train Loss: 1.4070079326629639\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_233/2598240933.py:87: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.28      0.53      0.37        72\n",
      "           1       0.27      0.23      0.25        93\n",
      "           2       0.54      0.24      0.33       104\n",
      "           3       0.29      0.32      0.30        91\n",
      "\n",
      "    accuracy                           0.31       360\n",
      "   macro avg       0.35      0.33      0.31       360\n",
      "weighted avg       0.36      0.31      0.31       360\n",
      "\n",
      "[[38 12  5 17]\n",
      " [36 21  5 31]\n",
      " [35 20 25 24]\n",
      " [27 24 11 29]]\n",
      "Validation Loss for P31 = 1.4115021228790283\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_233/2598240933.py:43: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n",
      "/tmp/ipykernel_233/2598240933.py:61: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/tmp/ipykernel_233/2598240933.py:87: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/tmp/ipykernel_233/2598240933.py:43: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15/100, Train Loss: 1.494388222694397\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.28      0.54      0.37        72\n",
      "           1       0.27      0.23      0.24        93\n",
      "           2       0.54      0.25      0.34       104\n",
      "           3       0.28      0.30      0.29        91\n",
      "\n",
      "    accuracy                           0.31       360\n",
      "   macro avg       0.34      0.33      0.31       360\n",
      "weighted avg       0.35      0.31      0.31       360\n",
      "\n",
      "[[39 12  5 16]\n",
      " [37 21  6 29]\n",
      " [35 20 26 23]\n",
      " [27 26 11 27]]\n",
      "Validation Loss for P31 = 1.4150422811508179\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_233/2598240933.py:61: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/tmp/ipykernel_233/2598240933.py:87: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16/100, Train Loss: 1.3628250360488892\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.27      0.50      0.35        72\n",
      "           1       0.23      0.18      0.20        93\n",
      "           2       0.52      0.28      0.36       104\n",
      "           3       0.29      0.31      0.30        91\n",
      "\n",
      "    accuracy                           0.31       360\n",
      "   macro avg       0.33      0.32      0.30       360\n",
      "weighted avg       0.34      0.31      0.30       360\n",
      "\n",
      "[[36 12  7 17]\n",
      " [37 17  9 30]\n",
      " [34 19 29 22]\n",
      " [26 26 11 28]]\n",
      "Validation Loss for P31 = 1.4135979413986206\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_233/2598240933.py:43: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n",
      "/tmp/ipykernel_233/2598240933.py:61: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/tmp/ipykernel_233/2598240933.py:87: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17/100, Train Loss: 1.3378746509552002\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.27      0.50      0.35        72\n",
      "           1       0.26      0.23      0.24        93\n",
      "           2       0.54      0.24      0.33       104\n",
      "           3       0.29      0.33      0.31        91\n",
      "\n",
      "    accuracy                           0.31       360\n",
      "   macro avg       0.34      0.32      0.31       360\n",
      "weighted avg       0.35      0.31      0.31       360\n",
      "\n",
      "[[36 14  4 18]\n",
      " [34 21  7 31]\n",
      " [35 21 25 23]\n",
      " [26 25 10 30]]\n",
      "Validation Loss for P31 = 1.412085771560669\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_233/2598240933.py:43: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n",
      "/tmp/ipykernel_233/2598240933.py:61: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/tmp/ipykernel_233/2598240933.py:87: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/tmp/ipykernel_233/2598240933.py:43: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 18/100, Train Loss: 1.4130972623825073\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.28      0.50      0.36        72\n",
      "           1       0.25      0.24      0.24        93\n",
      "           2       0.53      0.26      0.35       104\n",
      "           3       0.30      0.31      0.31        91\n",
      "\n",
      "    accuracy                           0.31       360\n",
      "   macro avg       0.34      0.33      0.31       360\n",
      "weighted avg       0.35      0.31      0.31       360\n",
      "\n",
      "[[36 15  4 17]\n",
      " [35 22  9 27]\n",
      " [33 24 27 20]\n",
      " [25 27 11 28]]\n",
      "Validation Loss for P31 = 1.4170894622802734\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_233/2598240933.py:61: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/tmp/ipykernel_233/2598240933.py:87: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/tmp/ipykernel_233/2598240933.py:43: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19/100, Train Loss: 1.3931964635849\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.27      0.51      0.36        72\n",
      "           1       0.25      0.22      0.23        93\n",
      "           2       0.55      0.26      0.35       104\n",
      "           3       0.29      0.31      0.30        91\n",
      "\n",
      "    accuracy                           0.31       360\n",
      "   macro avg       0.34      0.32      0.31       360\n",
      "weighted avg       0.35      0.31      0.31       360\n",
      "\n",
      "[[37 14  4 17]\n",
      " [38 20  6 29]\n",
      " [35 20 27 22]\n",
      " [26 25 12 28]]\n",
      "Validation Loss for P31 = 1.4150089025497437\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_233/2598240933.py:61: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/tmp/ipykernel_233/2598240933.py:87: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/tmp/ipykernel_233/2598240933.py:43: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20/100, Train Loss: 1.482466459274292\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.27      0.51      0.36        72\n",
      "           1       0.26      0.23      0.24        93\n",
      "           2       0.51      0.26      0.34       104\n",
      "           3       0.28      0.27      0.28        91\n",
      "\n",
      "    accuracy                           0.31       360\n",
      "   macro avg       0.33      0.32      0.30       360\n",
      "weighted avg       0.34      0.31      0.30       360\n",
      "\n",
      "[[37 14  4 17]\n",
      " [38 21  6 28]\n",
      " [35 22 27 20]\n",
      " [25 25 16 25]]\n",
      "Validation Loss for P31 = 1.4147075414657593\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_233/2598240933.py:61: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/tmp/ipykernel_233/2598240933.py:87: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/tmp/ipykernel_233/2598240933.py:43: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 21/100, Train Loss: 1.4071382284164429\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.26      0.51      0.35        72\n",
      "           1       0.26      0.20      0.23        93\n",
      "           2       0.52      0.29      0.37       104\n",
      "           3       0.27      0.26      0.27        91\n",
      "\n",
      "    accuracy                           0.31       360\n",
      "   macro avg       0.33      0.32      0.30       360\n",
      "weighted avg       0.34      0.31      0.30       360\n",
      "\n",
      "[[37 12  7 16]\n",
      " [40 19  6 28]\n",
      " [35 18 30 21]\n",
      " [28 24 15 24]]\n",
      "Validation Loss for P31 = 1.4176466464996338\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_233/2598240933.py:61: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/tmp/ipykernel_233/2598240933.py:87: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/tmp/ipykernel_233/2598240933.py:43: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 22/100, Train Loss: 1.3111416101455688\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.26      0.51      0.35        72\n",
      "           1       0.26      0.20      0.23        93\n",
      "           2       0.51      0.28      0.36       104\n",
      "           3       0.27      0.26      0.27        91\n",
      "\n",
      "    accuracy                           0.30       360\n",
      "   macro avg       0.33      0.32      0.30       360\n",
      "weighted avg       0.33      0.30      0.30       360\n",
      "\n",
      "[[37 12  7 16]\n",
      " [41 19  5 28]\n",
      " [35 19 29 21]\n",
      " [28 23 16 24]]\n",
      "Validation Loss for P31 = 1.4154027700424194\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_233/2598240933.py:61: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/tmp/ipykernel_233/2598240933.py:87: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 23/100, Train Loss: 1.3128507137298584\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.26      0.51      0.35        72\n",
      "           1       0.27      0.20      0.23        93\n",
      "           2       0.56      0.28      0.37       104\n",
      "           3       0.28      0.30      0.29        91\n",
      "\n",
      "    accuracy                           0.31       360\n",
      "   macro avg       0.34      0.32      0.31       360\n",
      "weighted avg       0.35      0.31      0.31       360\n",
      "\n",
      "[[37 12  5 18]\n",
      " [41 19  5 28]\n",
      " [35 18 29 22]\n",
      " [29 22 13 27]]\n",
      "Validation Loss for P31 = 1.4217326641082764\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_233/2598240933.py:43: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n",
      "/tmp/ipykernel_233/2598240933.py:61: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/tmp/ipykernel_233/2598240933.py:87: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/tmp/ipykernel_233/2598240933.py:43: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 24/100, Train Loss: 1.342606782913208\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.26      0.53      0.35        72\n",
      "           1       0.26      0.19      0.22        93\n",
      "           2       0.47      0.28      0.35       104\n",
      "           3       0.30      0.27      0.29        91\n",
      "\n",
      "    accuracy                           0.31       360\n",
      "   macro avg       0.32      0.32      0.30       360\n",
      "weighted avg       0.33      0.31      0.30       360\n",
      "\n",
      "[[38 11  7 16]\n",
      " [42 18 10 23]\n",
      " [36 19 29 20]\n",
      " [29 21 16 25]]\n",
      "Validation Loss for P31 = 1.4203088283538818\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_233/2598240933.py:61: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/tmp/ipykernel_233/2598240933.py:87: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/tmp/ipykernel_233/2598240933.py:43: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 25/100, Train Loss: 1.2865228652954102\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.26      0.51      0.35        72\n",
      "           1       0.25      0.20      0.22        93\n",
      "           2       0.46      0.27      0.34       104\n",
      "           3       0.30      0.27      0.29        91\n",
      "\n",
      "    accuracy                           0.30       360\n",
      "   macro avg       0.32      0.32      0.30       360\n",
      "weighted avg       0.33      0.30      0.30       360\n",
      "\n",
      "[[37 13  6 16]\n",
      " [40 19 12 22]\n",
      " [35 21 28 20]\n",
      " [28 23 15 25]]\n",
      "Validation Loss for P31 = 1.4245516061782837\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_233/2598240933.py:61: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/tmp/ipykernel_233/2598240933.py:87: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/tmp/ipykernel_233/2598240933.py:43: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 26/100, Train Loss: 1.3690539598464966\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.27      0.51      0.35        72\n",
      "           1       0.23      0.18      0.20        93\n",
      "           2       0.49      0.23      0.31       104\n",
      "           3       0.30      0.33      0.32        91\n",
      "\n",
      "    accuracy                           0.30       360\n",
      "   macro avg       0.32      0.31      0.30       360\n",
      "weighted avg       0.33      0.30      0.29       360\n",
      "\n",
      "[[37 12  6 17]\n",
      " [40 17  8 28]\n",
      " [35 21 24 24]\n",
      " [27 23 11 30]]\n",
      "Validation Loss for P31 = 1.4200111627578735\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_233/2598240933.py:61: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/tmp/ipykernel_233/2598240933.py:87: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/tmp/ipykernel_233/2598240933.py:43: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 27/100, Train Loss: 1.2360960245132446\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.26      0.53      0.35        72\n",
      "           1       0.24      0.18      0.21        93\n",
      "           2       0.47      0.22      0.30       104\n",
      "           3       0.31      0.32      0.31        91\n",
      "\n",
      "    accuracy                           0.30       360\n",
      "   macro avg       0.32      0.31      0.29       360\n",
      "weighted avg       0.33      0.30      0.29       360\n",
      "\n",
      "[[38 11  5 18]\n",
      " [41 17 10 25]\n",
      " [37 21 23 23]\n",
      " [28 23 11 29]]\n",
      "Validation Loss for P31 = 1.4346076250076294\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_233/2598240933.py:61: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/tmp/ipykernel_233/2598240933.py:87: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/tmp/ipykernel_233/2598240933.py:43: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 28/100, Train Loss: 1.3657268285751343\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.28      0.54      0.37        72\n",
      "           1       0.24      0.17      0.20        93\n",
      "           2       0.50      0.25      0.33       104\n",
      "           3       0.33      0.37      0.35        91\n",
      "\n",
      "    accuracy                           0.32       360\n",
      "   macro avg       0.34      0.33      0.31       360\n",
      "weighted avg       0.35      0.32      0.31       360\n",
      "\n",
      "[[39 10  6 17]\n",
      " [39 16 10 28]\n",
      " [35 19 26 24]\n",
      " [26 21 10 34]]\n",
      "Validation Loss for P31 = 1.4282668828964233\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_233/2598240933.py:61: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/tmp/ipykernel_233/2598240933.py:87: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/tmp/ipykernel_233/2598240933.py:43: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 29/100, Train Loss: 1.3879879713058472\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.27      0.50      0.35        72\n",
      "           1       0.25      0.19      0.22        93\n",
      "           2       0.44      0.25      0.32       104\n",
      "           3       0.31      0.32      0.32        91\n",
      "\n",
      "    accuracy                           0.30       360\n",
      "   macro avg       0.32      0.32      0.30       360\n",
      "weighted avg       0.32      0.30      0.30       360\n",
      "\n",
      "[[36 12  7 17]\n",
      " [38 18 13 24]\n",
      " [35 20 26 23]\n",
      " [26 23 13 29]]\n",
      "Validation Loss for P31 = 1.4270673990249634\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_233/2598240933.py:61: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/tmp/ipykernel_233/2598240933.py:87: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/tmp/ipykernel_233/2598240933.py:43: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 30/100, Train Loss: 1.317696452140808\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.28      0.53      0.37        72\n",
      "           1       0.25      0.18      0.21        93\n",
      "           2       0.47      0.27      0.34       104\n",
      "           3       0.33      0.35      0.34        91\n",
      "\n",
      "    accuracy                           0.32       360\n",
      "   macro avg       0.33      0.33      0.32       360\n",
      "weighted avg       0.34      0.32      0.31       360\n",
      "\n",
      "[[38 11  6 17]\n",
      " [37 17 13 26]\n",
      " [34 20 28 22]\n",
      " [26 20 13 32]]\n",
      "Validation Loss for P31 = 1.431281328201294\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_233/2598240933.py:61: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/tmp/ipykernel_233/2598240933.py:87: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/tmp/ipykernel_233/2598240933.py:43: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 31/100, Train Loss: 1.4103068113327026\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.27      0.51      0.36        72\n",
      "           1       0.24      0.19      0.22        93\n",
      "           2       0.50      0.24      0.32       104\n",
      "           3       0.35      0.38      0.36        91\n",
      "\n",
      "    accuracy                           0.32       360\n",
      "   macro avg       0.34      0.33      0.32       360\n",
      "weighted avg       0.35      0.32      0.31       360\n",
      "\n",
      "[[37 13  5 17]\n",
      " [38 18 10 27]\n",
      " [34 23 25 22]\n",
      " [26 20 10 35]]\n",
      "Validation Loss for P31 = 1.4269521236419678\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_233/2598240933.py:61: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/tmp/ipykernel_233/2598240933.py:87: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 32/100, Train Loss: 1.2160062789916992\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.28      0.53      0.36        72\n",
      "           1       0.24      0.17      0.20        93\n",
      "           2       0.47      0.26      0.34       104\n",
      "           3       0.33      0.36      0.35        91\n",
      "\n",
      "    accuracy                           0.32       360\n",
      "   macro avg       0.33      0.33      0.31       360\n",
      "weighted avg       0.34      0.32      0.31       360\n",
      "\n",
      "[[38 11  6 17]\n",
      " [38 16 12 27]\n",
      " [35 19 27 23]\n",
      " [26 20 12 33]]\n",
      "Validation Loss for P31 = 1.430810570716858\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_233/2598240933.py:43: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n",
      "/tmp/ipykernel_233/2598240933.py:61: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/tmp/ipykernel_233/2598240933.py:87: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/tmp/ipykernel_233/2598240933.py:43: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 33/100, Train Loss: 1.423783302307129\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.27      0.50      0.35        72\n",
      "           1       0.25      0.18      0.21        93\n",
      "           2       0.46      0.26      0.33       104\n",
      "           3       0.34      0.37      0.36        91\n",
      "\n",
      "    accuracy                           0.32       360\n",
      "   macro avg       0.33      0.33      0.31       360\n",
      "weighted avg       0.34      0.32      0.31       360\n",
      "\n",
      "[[36 11  8 17]\n",
      " [37 17 13 26]\n",
      " [36 18 27 23]\n",
      " [25 21 11 34]]\n",
      "Validation Loss for P31 = 1.430283546447754\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_233/2598240933.py:61: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/tmp/ipykernel_233/2598240933.py:87: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/tmp/ipykernel_233/2598240933.py:43: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 34/100, Train Loss: 1.3803675174713135\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.27      0.51      0.36        72\n",
      "           1       0.25      0.17      0.20        93\n",
      "           2       0.43      0.27      0.33       104\n",
      "           3       0.32      0.33      0.32        91\n",
      "\n",
      "    accuracy                           0.31       360\n",
      "   macro avg       0.32      0.32      0.30       360\n",
      "weighted avg       0.32      0.31      0.30       360\n",
      "\n",
      "[[37 10  8 17]\n",
      " [37 16 15 25]\n",
      " [36 18 28 22]\n",
      " [26 21 14 30]]\n",
      "Validation Loss for P31 = 1.4288474321365356\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_233/2598240933.py:61: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/tmp/ipykernel_233/2598240933.py:87: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/tmp/ipykernel_233/2598240933.py:43: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 35/100, Train Loss: 1.3797653913497925\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.26      0.50      0.35        72\n",
      "           1       0.23      0.16      0.19        93\n",
      "           2       0.45      0.28      0.35       104\n",
      "           3       0.33      0.35      0.34        91\n",
      "\n",
      "    accuracy                           0.31       360\n",
      "   macro avg       0.32      0.32      0.31       360\n",
      "weighted avg       0.33      0.31      0.30       360\n",
      "\n",
      "[[36 10 10 16]\n",
      " [38 15 13 27]\n",
      " [36 18 29 21]\n",
      " [26 21 12 32]]\n",
      "Validation Loss for P31 = 1.429241418838501\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_233/2598240933.py:61: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/tmp/ipykernel_233/2598240933.py:87: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/tmp/ipykernel_233/2598240933.py:43: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 36/100, Train Loss: 1.3629201650619507\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.26      0.51      0.35        72\n",
      "           1       0.23      0.14      0.17        93\n",
      "           2       0.44      0.27      0.34       104\n",
      "           3       0.34      0.36      0.35        91\n",
      "\n",
      "    accuracy                           0.31       360\n",
      "   macro avg       0.32      0.32      0.30       360\n",
      "weighted avg       0.32      0.31      0.30       360\n",
      "\n",
      "[[37  9  9 17]\n",
      " [41 13 13 26]\n",
      " [37 17 28 22]\n",
      " [27 18 13 33]]\n",
      "Validation Loss for P31 = 1.4302183389663696\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_233/2598240933.py:61: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/tmp/ipykernel_233/2598240933.py:87: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/tmp/ipykernel_233/2598240933.py:43: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 37/100, Train Loss: 1.4064387083053589\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.26      0.53      0.35        72\n",
      "           1       0.23      0.15      0.18        93\n",
      "           2       0.50      0.23      0.32       104\n",
      "           3       0.35      0.40      0.37        91\n",
      "\n",
      "    accuracy                           0.31       360\n",
      "   macro avg       0.33      0.33      0.30       360\n",
      "weighted avg       0.34      0.31      0.30       360\n",
      "\n",
      "[[38 11  6 17]\n",
      " [42 14 10 27]\n",
      " [39 18 24 23]\n",
      " [28 19  8 36]]\n",
      "Validation Loss for P31 = 1.4385771751403809\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_233/2598240933.py:61: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/tmp/ipykernel_233/2598240933.py:87: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/tmp/ipykernel_233/2598240933.py:43: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 38/100, Train Loss: 1.4865961074829102\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.26      0.49      0.34        72\n",
      "           1       0.25      0.18      0.21        93\n",
      "           2       0.46      0.25      0.33       104\n",
      "           3       0.36      0.40      0.37        91\n",
      "\n",
      "    accuracy                           0.32       360\n",
      "   macro avg       0.33      0.33      0.31       360\n",
      "weighted avg       0.34      0.32      0.31       360\n",
      "\n",
      "[[35 12  9 16]\n",
      " [38 17 12 26]\n",
      " [37 18 26 23]\n",
      " [26 20  9 36]]\n",
      "Validation Loss for P31 = 1.4374607801437378\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_233/2598240933.py:61: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/tmp/ipykernel_233/2598240933.py:87: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 39/100, Train Loss: 1.3019312620162964\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.26      0.49      0.34        72\n",
      "           1       0.27      0.19      0.23        93\n",
      "           2       0.45      0.24      0.31       104\n",
      "           3       0.36      0.40      0.37        91\n",
      "\n",
      "    accuracy                           0.32       360\n",
      "   macro avg       0.33      0.33      0.31       360\n",
      "weighted avg       0.34      0.32      0.31       360\n",
      "\n",
      "[[35 11 10 16]\n",
      " [37 18 12 26]\n",
      " [38 18 25 23]\n",
      " [26 20  9 36]]\n",
      "Validation Loss for P31 = 1.434249758720398\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_233/2598240933.py:43: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n",
      "/tmp/ipykernel_233/2598240933.py:61: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/tmp/ipykernel_233/2598240933.py:87: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/tmp/ipykernel_233/2598240933.py:43: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 40/100, Train Loss: 1.343324065208435\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.25      0.49      0.33        72\n",
      "           1       0.29      0.19      0.23        93\n",
      "           2       0.43      0.25      0.32       104\n",
      "           3       0.34      0.37      0.36        91\n",
      "\n",
      "    accuracy                           0.31       360\n",
      "   macro avg       0.33      0.33      0.31       360\n",
      "weighted avg       0.34      0.31      0.31       360\n",
      "\n",
      "[[35 11 10 16]\n",
      " [37 18 14 24]\n",
      " [39 14 26 25]\n",
      " [27 19 11 34]]\n",
      "Validation Loss for P31 = 1.4343427419662476\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_233/2598240933.py:61: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/tmp/ipykernel_233/2598240933.py:87: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 41/100, Train Loss: 1.2909495830535889\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.26      0.51      0.35        72\n",
      "           1       0.25      0.16      0.20        93\n",
      "           2       0.43      0.22      0.29       104\n",
      "           3       0.34      0.40      0.37        91\n",
      "\n",
      "    accuracy                           0.31       360\n",
      "   macro avg       0.32      0.32      0.30       360\n",
      "weighted avg       0.33      0.31      0.30       360\n",
      "\n",
      "[[37 11  8 16]\n",
      " [38 15 13 27]\n",
      " [39 15 23 27]\n",
      " [27 19  9 36]]\n",
      "Validation Loss for P31 = 1.4348095655441284\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_233/2598240933.py:43: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n",
      "/tmp/ipykernel_233/2598240933.py:61: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 42/100, Train Loss: 1.347305178642273\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_233/2598240933.py:87: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.27      0.53      0.35        72\n",
      "           1       0.26      0.17      0.21        93\n",
      "           2       0.42      0.24      0.30       104\n",
      "           3       0.34      0.36      0.35        91\n",
      "\n",
      "    accuracy                           0.31       360\n",
      "   macro avg       0.32      0.33      0.30       360\n",
      "weighted avg       0.33      0.31      0.30       360\n",
      "\n",
      "[[38 11  8 15]\n",
      " [38 16 15 24]\n",
      " [40 15 25 24]\n",
      " [27 19 12 33]]\n",
      "Validation Loss for P31 = 1.4370898008346558\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_233/2598240933.py:43: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n",
      "/tmp/ipykernel_233/2598240933.py:61: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 43/100, Train Loss: 1.2952289581298828\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.26      0.50      0.35        72\n",
      "           1       0.27      0.18      0.22        93\n",
      "           2       0.40      0.26      0.32       104\n",
      "           3       0.31      0.32      0.31        91\n",
      "\n",
      "    accuracy                           0.30       360\n",
      "   macro avg       0.31      0.32      0.30       360\n",
      "weighted avg       0.32      0.30      0.30       360\n",
      "\n",
      "[[36 11  9 16]\n",
      " [37 17 14 25]\n",
      " [37 16 27 24]\n",
      " [26 19 17 29]]\n",
      "Validation Loss for P31 = 1.4393426179885864\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_233/2598240933.py:87: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/tmp/ipykernel_233/2598240933.py:43: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n",
      "/tmp/ipykernel_233/2598240933.py:61: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/tmp/ipykernel_233/2598240933.py:87: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/tmp/ipykernel_233/2598240933.py:43: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 44/100, Train Loss: 1.3581489324569702\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.26      0.51      0.35        72\n",
      "           1       0.27      0.18      0.22        93\n",
      "           2       0.42      0.24      0.31       104\n",
      "           3       0.34      0.36      0.35        91\n",
      "\n",
      "    accuracy                           0.31       360\n",
      "   macro avg       0.32      0.32      0.31       360\n",
      "weighted avg       0.33      0.31      0.30       360\n",
      "\n",
      "[[37 11  9 15]\n",
      " [38 17 13 25]\n",
      " [39 15 25 25]\n",
      " [27 19 12 33]]\n",
      "Validation Loss for P31 = 1.4345635175704956\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_233/2598240933.py:61: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/tmp/ipykernel_233/2598240933.py:87: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/tmp/ipykernel_233/2598240933.py:43: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 45/100, Train Loss: 1.3382622003555298\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.26      0.49      0.34        72\n",
      "           1       0.27      0.19      0.23        93\n",
      "           2       0.44      0.27      0.33       104\n",
      "           3       0.33      0.35      0.34        91\n",
      "\n",
      "    accuracy                           0.31       360\n",
      "   macro avg       0.33      0.33      0.31       360\n",
      "weighted avg       0.33      0.31      0.31       360\n",
      "\n",
      "[[35 13  9 15]\n",
      " [36 18 14 25]\n",
      " [35 16 28 25]\n",
      " [27 19 13 32]]\n",
      "Validation Loss for P31 = 1.431372046470642\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_233/2598240933.py:61: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/tmp/ipykernel_233/2598240933.py:87: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 46/100, Train Loss: 1.2879228591918945\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.26      0.51      0.35        72\n",
      "           1       0.25      0.16      0.19        93\n",
      "           2       0.42      0.26      0.32       104\n",
      "           3       0.32      0.33      0.32        91\n",
      "\n",
      "    accuracy                           0.30       360\n",
      "   macro avg       0.31      0.32      0.30       360\n",
      "weighted avg       0.32      0.30      0.29       360\n",
      "\n",
      "[[37 12  8 15]\n",
      " [38 15 15 25]\n",
      " [37 15 27 25]\n",
      " [28 19 14 30]]\n",
      "Validation Loss for P31 = 1.4281373023986816\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_233/2598240933.py:43: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n",
      "/tmp/ipykernel_233/2598240933.py:61: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/tmp/ipykernel_233/2598240933.py:87: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/tmp/ipykernel_233/2598240933.py:43: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 47/100, Train Loss: 1.4048007726669312\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.26      0.49      0.33        72\n",
      "           1       0.26      0.16      0.20        93\n",
      "           2       0.41      0.24      0.30       104\n",
      "           3       0.34      0.38      0.36        91\n",
      "\n",
      "    accuracy                           0.31       360\n",
      "   macro avg       0.32      0.32      0.30       360\n",
      "weighted avg       0.32      0.31      0.30       360\n",
      "\n",
      "[[35 10 11 16]\n",
      " [38 15 14 26]\n",
      " [38 14 25 27]\n",
      " [26 19 11 35]]\n",
      "Validation Loss for P31 = 1.4243656396865845\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_233/2598240933.py:61: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/tmp/ipykernel_233/2598240933.py:87: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/tmp/ipykernel_233/2598240933.py:43: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 48/100, Train Loss: 1.2245649099349976\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.25      0.47      0.33        72\n",
      "           1       0.27      0.17      0.21        93\n",
      "           2       0.38      0.26      0.31       104\n",
      "           3       0.31      0.32      0.31        91\n",
      "\n",
      "    accuracy                           0.29       360\n",
      "   macro avg       0.30      0.31      0.29       360\n",
      "weighted avg       0.31      0.29      0.29       360\n",
      "\n",
      "[[34 11 12 15]\n",
      " [38 16 14 25]\n",
      " [37 15 27 25]\n",
      " [26 18 18 29]]\n",
      "Validation Loss for P31 = 1.4268791675567627\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n",
      "/tmp/ipykernel_233/2598240933.py:61: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/tmp/ipykernel_233/2598240933.py:87: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/tmp/ipykernel_233/2598240933.py:43: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 49/100, Train Loss: 1.3307541608810425\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.25      0.47      0.33        72\n",
      "           1       0.25      0.17      0.21        93\n",
      "           2       0.37      0.23      0.28       104\n",
      "           3       0.31      0.32      0.31        91\n",
      "\n",
      "    accuracy                           0.29       360\n",
      "   macro avg       0.29      0.30      0.28       360\n",
      "weighted avg       0.30      0.29      0.28       360\n",
      "\n",
      "[[34 12 11 15]\n",
      " [38 16 14 25]\n",
      " [38 16 24 26]\n",
      " [27 19 16 29]]\n",
      "Validation Loss for P31 = 1.4387096166610718\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_233/2598240933.py:61: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/tmp/ipykernel_233/2598240933.py:87: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/tmp/ipykernel_233/2598240933.py:43: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 50/100, Train Loss: 1.3321876525878906\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.25      0.46      0.33        72\n",
      "           1       0.26      0.19      0.22        93\n",
      "           2       0.42      0.25      0.31       104\n",
      "           3       0.32      0.35      0.34        91\n",
      "\n",
      "    accuracy                           0.30       360\n",
      "   macro avg       0.31      0.31      0.30       360\n",
      "weighted avg       0.32      0.30      0.30       360\n",
      "\n",
      "[[33 13 11 15]\n",
      " [36 18 12 27]\n",
      " [35 17 26 26]\n",
      " [26 20 13 32]]\n",
      "Validation Loss for P31 = 1.430764079093933\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_233/2598240933.py:61: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 51/100, Train Loss: 1.2895859479904175\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_233/2598240933.py:87: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.26      0.49      0.33        72\n",
      "           1       0.25      0.17      0.21        93\n",
      "           2       0.42      0.23      0.30       104\n",
      "           3       0.34      0.38      0.36        91\n",
      "\n",
      "    accuracy                           0.31       360\n",
      "   macro avg       0.32      0.32      0.30       360\n",
      "weighted avg       0.32      0.31      0.30       360\n",
      "\n",
      "[[35 11 10 16]\n",
      " [38 16 12 27]\n",
      " [38 17 24 25]\n",
      " [26 19 11 35]]\n",
      "Validation Loss for P31 = 1.4320794343948364\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_233/2598240933.py:43: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n",
      "/tmp/ipykernel_233/2598240933.py:61: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 52/100, Train Loss: 1.3192074298858643\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_233/2598240933.py:87: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.26      0.47      0.33        72\n",
      "           1       0.25      0.17      0.20        93\n",
      "           2       0.41      0.27      0.33       104\n",
      "           3       0.32      0.33      0.32        91\n",
      "\n",
      "    accuracy                           0.30       360\n",
      "   macro avg       0.31      0.31      0.30       360\n",
      "weighted avg       0.31      0.30      0.29       360\n",
      "\n",
      "[[34 11 12 15]\n",
      " [38 16 13 26]\n",
      " [35 17 28 24]\n",
      " [26 20 15 30]]\n",
      "Validation Loss for P31 = 1.427160620689392\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_233/2598240933.py:43: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n",
      "/tmp/ipykernel_233/2598240933.py:61: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 53/100, Train Loss: 1.437440276145935\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_233/2598240933.py:87: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.25      0.46      0.32        72\n",
      "           1       0.26      0.18      0.22        93\n",
      "           2       0.41      0.25      0.31       104\n",
      "           3       0.32      0.35      0.34        91\n",
      "\n",
      "    accuracy                           0.30       360\n",
      "   macro avg       0.31      0.31      0.30       360\n",
      "weighted avg       0.32      0.30      0.29       360\n",
      "\n",
      "[[33 12 12 15]\n",
      " [37 17 12 27]\n",
      " [36 17 26 25]\n",
      " [26 19 14 32]]\n",
      "Validation Loss for P31 = 1.4301353693008423\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_233/2598240933.py:43: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n",
      "/tmp/ipykernel_233/2598240933.py:61: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 54/100, Train Loss: 1.4076271057128906\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_233/2598240933.py:87: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.25      0.49      0.33        72\n",
      "           1       0.27      0.17      0.21        93\n",
      "           2       0.44      0.26      0.33       104\n",
      "           3       0.33      0.36      0.35        91\n",
      "\n",
      "    accuracy                           0.31       360\n",
      "   macro avg       0.32      0.32      0.30       360\n",
      "weighted avg       0.33      0.31      0.30       360\n",
      "\n",
      "[[35 10 10 17]\n",
      " [38 16 13 26]\n",
      " [38 15 27 24]\n",
      " [27 19 12 33]]\n",
      "Validation Loss for P31 = 1.4301795959472656\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_233/2598240933.py:43: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n",
      "/tmp/ipykernel_233/2598240933.py:61: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/tmp/ipykernel_233/2598240933.py:87: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/tmp/ipykernel_233/2598240933.py:43: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 55/100, Train Loss: 1.3066627979278564\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.26      0.49      0.33        72\n",
      "           1       0.25      0.15      0.19        93\n",
      "           2       0.44      0.27      0.33       104\n",
      "           3       0.32      0.36      0.34        91\n",
      "\n",
      "    accuracy                           0.31       360\n",
      "   macro avg       0.32      0.32      0.30       360\n",
      "weighted avg       0.32      0.31      0.30       360\n",
      "\n",
      "[[35  9 10 18]\n",
      " [38 14 14 27]\n",
      " [37 15 28 24]\n",
      " [27 19 12 33]]\n",
      "Validation Loss for P31 = 1.4279769659042358\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_233/2598240933.py:61: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/tmp/ipykernel_233/2598240933.py:87: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/tmp/ipykernel_233/2598240933.py:43: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 56/100, Train Loss: 1.2109092473983765\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.26      0.50      0.34        72\n",
      "           1       0.25      0.15      0.19        93\n",
      "           2       0.42      0.23      0.30       104\n",
      "           3       0.31      0.36      0.33        91\n",
      "\n",
      "    accuracy                           0.30       360\n",
      "   macro avg       0.31      0.31      0.29       360\n",
      "weighted avg       0.32      0.30      0.29       360\n",
      "\n",
      "[[36  8 10 18]\n",
      " [38 14 12 29]\n",
      " [38 15 24 27]\n",
      " [29 18 11 33]]\n",
      "Validation Loss for P31 = 1.4296525716781616\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_233/2598240933.py:61: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/tmp/ipykernel_233/2598240933.py:87: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 57/100, Train Loss: 1.3469241857528687\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.26      0.50      0.34        72\n",
      "           1       0.28      0.17      0.21        93\n",
      "           2       0.40      0.20      0.27       104\n",
      "           3       0.32      0.38      0.35        91\n",
      "\n",
      "    accuracy                           0.30       360\n",
      "   macro avg       0.31      0.31      0.29       360\n",
      "weighted avg       0.32      0.30      0.29       360\n",
      "\n",
      "[[36  8 10 18]\n",
      " [39 16 11 27]\n",
      " [39 15 21 29]\n",
      " [27 19 10 35]]\n",
      "Validation Loss for P31 = 1.4342864751815796\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_233/2598240933.py:43: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n",
      "/tmp/ipykernel_233/2598240933.py:61: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/tmp/ipykernel_233/2598240933.py:87: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/tmp/ipykernel_233/2598240933.py:43: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 58/100, Train Loss: 1.3350194692611694\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.26      0.51      0.35        72\n",
      "           1       0.25      0.14      0.18        93\n",
      "           2       0.43      0.25      0.32       104\n",
      "           3       0.31      0.36      0.34        91\n",
      "\n",
      "    accuracy                           0.30       360\n",
      "   macro avg       0.31      0.32      0.29       360\n",
      "weighted avg       0.32      0.30      0.29       360\n",
      "\n",
      "[[37  7 10 18]\n",
      " [39 13 12 29]\n",
      " [38 15 26 25]\n",
      " [27 18 13 33]]\n",
      "Validation Loss for P31 = 1.428281545639038\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_233/2598240933.py:61: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/tmp/ipykernel_233/2598240933.py:87: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 59/100, Train Loss: 1.2917940616607666\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.26      0.50      0.35        72\n",
      "           1       0.27      0.17      0.21        93\n",
      "           2       0.45      0.24      0.31       104\n",
      "           3       0.31      0.37      0.34        91\n",
      "\n",
      "    accuracy                           0.31       360\n",
      "   macro avg       0.32      0.32      0.30       360\n",
      "weighted avg       0.33      0.31      0.30       360\n",
      "\n",
      "[[36  9  9 18]\n",
      " [38 16 10 29]\n",
      " [36 15 25 28]\n",
      " [26 19 12 34]]\n",
      "Validation Loss for P31 = 1.4351199865341187\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_233/2598240933.py:43: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n",
      "/tmp/ipykernel_233/2598240933.py:61: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/tmp/ipykernel_233/2598240933.py:87: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/tmp/ipykernel_233/2598240933.py:43: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 60/100, Train Loss: 1.3691068887710571\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.27      0.51      0.35        72\n",
      "           1       0.27      0.17      0.21        93\n",
      "           2       0.43      0.23      0.30       104\n",
      "           3       0.32      0.37      0.35        91\n",
      "\n",
      "    accuracy                           0.31       360\n",
      "   macro avg       0.32      0.32      0.30       360\n",
      "weighted avg       0.33      0.31      0.30       360\n",
      "\n",
      "[[37  9 10 16]\n",
      " [38 16 11 28]\n",
      " [37 16 24 27]\n",
      " [27 19 11 34]]\n",
      "Validation Loss for P31 = 1.4414390325546265\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_233/2598240933.py:61: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/tmp/ipykernel_233/2598240933.py:87: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/tmp/ipykernel_233/2598240933.py:43: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 61/100, Train Loss: 1.381166934967041\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.26      0.50      0.35        72\n",
      "           1       0.25      0.16      0.20        93\n",
      "           2       0.42      0.25      0.31       104\n",
      "           3       0.32      0.36      0.34        91\n",
      "\n",
      "    accuracy                           0.31       360\n",
      "   macro avg       0.31      0.32      0.30       360\n",
      "weighted avg       0.32      0.31      0.30       360\n",
      "\n",
      "[[36  9 12 15]\n",
      " [38 15 12 28]\n",
      " [35 16 26 27]\n",
      " [27 19 12 33]]\n",
      "Validation Loss for P31 = 1.4380995035171509\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_233/2598240933.py:61: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/tmp/ipykernel_233/2598240933.py:87: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/tmp/ipykernel_233/2598240933.py:43: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 62/100, Train Loss: 1.4201364517211914\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.26      0.49      0.34        72\n",
      "           1       0.26      0.17      0.21        93\n",
      "           2       0.43      0.23      0.30       104\n",
      "           3       0.32      0.38      0.35        91\n",
      "\n",
      "    accuracy                           0.31       360\n",
      "   macro avg       0.32      0.32      0.30       360\n",
      "weighted avg       0.33      0.31      0.30       360\n",
      "\n",
      "[[35 10 11 16]\n",
      " [38 16 11 28]\n",
      " [35 16 24 29]\n",
      " [27 19 10 35]]\n",
      "Validation Loss for P31 = 1.4425429105758667\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_233/2598240933.py:61: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/tmp/ipykernel_233/2598240933.py:87: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/tmp/ipykernel_233/2598240933.py:43: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 63/100, Train Loss: 1.3525803089141846\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.25      0.46      0.32        72\n",
      "           1       0.27      0.18      0.22        93\n",
      "           2       0.39      0.22      0.28       104\n",
      "           3       0.32      0.36      0.34        91\n",
      "\n",
      "    accuracy                           0.29       360\n",
      "   macro avg       0.31      0.31      0.29       360\n",
      "weighted avg       0.31      0.29      0.29       360\n",
      "\n",
      "[[33 12 12 15]\n",
      " [37 17 12 27]\n",
      " [36 16 23 29]\n",
      " [27 19 12 33]]\n",
      "Validation Loss for P31 = 1.44371497631073\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_233/2598240933.py:61: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 64/100, Train Loss: 1.3731083869934082\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_233/2598240933.py:87: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.26      0.50      0.34        72\n",
      "           1       0.26      0.16      0.20        93\n",
      "           2       0.43      0.22      0.29       104\n",
      "           3       0.33      0.40      0.36        91\n",
      "\n",
      "    accuracy                           0.31       360\n",
      "   macro avg       0.32      0.32      0.30       360\n",
      "weighted avg       0.33      0.31      0.29       360\n",
      "\n",
      "[[36 10 11 15]\n",
      " [39 15 11 28]\n",
      " [37 14 23 30]\n",
      " [27 19  9 36]]\n",
      "Validation Loss for P31 = 1.4444704055786133\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_233/2598240933.py:43: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n",
      "/tmp/ipykernel_233/2598240933.py:61: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 65/100, Train Loss: 1.4437922239303589\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_233/2598240933.py:87: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.24      0.44      0.32        72\n",
      "           1       0.26      0.16      0.20        93\n",
      "           2       0.40      0.22      0.28       104\n",
      "           3       0.31      0.38      0.34        91\n",
      "\n",
      "    accuracy                           0.29       360\n",
      "   macro avg       0.30      0.30      0.29       360\n",
      "weighted avg       0.31      0.29      0.28       360\n",
      "\n",
      "[[32 11 11 18]\n",
      " [37 15 12 29]\n",
      " [35 15 23 31]\n",
      " [27 17 12 35]]\n",
      "Validation Loss for P31 = 1.4341763257980347\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_233/2598240933.py:43: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n",
      "/tmp/ipykernel_233/2598240933.py:61: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 66/100, Train Loss: 1.3055367469787598\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.25      0.44      0.32        72\n",
      "           1       0.28      0.18      0.22        93\n",
      "           2       0.38      0.22      0.28       104\n",
      "           3       0.31      0.38      0.34        91\n",
      "\n",
      "    accuracy                           0.30       360\n",
      "   macro avg       0.31      0.31      0.29       360\n",
      "weighted avg       0.31      0.30      0.29       360\n",
      "\n",
      "[[32 10 13 17]\n",
      " [35 17 12 29]\n",
      " [34 16 23 31]\n",
      " [27 17 12 35]]\n",
      "Validation Loss for P31 = 1.4376338720321655\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_233/2598240933.py:87: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/tmp/ipykernel_233/2598240933.py:43: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n",
      "/tmp/ipykernel_233/2598240933.py:61: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 67/100, Train Loss: 1.3136171102523804\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_233/2598240933.py:87: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.25      0.46      0.32        72\n",
      "           1       0.26      0.16      0.20        93\n",
      "           2       0.38      0.20      0.26       104\n",
      "           3       0.32      0.40      0.35        91\n",
      "\n",
      "    accuracy                           0.29       360\n",
      "   macro avg       0.30      0.30      0.28       360\n",
      "weighted avg       0.31      0.29      0.28       360\n",
      "\n",
      "[[33  9 13 17]\n",
      " [39 15 12 27]\n",
      " [35 15 21 33]\n",
      " [27 18 10 36]]\n",
      "Validation Loss for P31 = 1.4468138217926025\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_233/2598240933.py:43: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n",
      "/tmp/ipykernel_233/2598240933.py:61: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 68/100, Train Loss: 1.2362207174301147\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_233/2598240933.py:87: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.25      0.47      0.33        72\n",
      "           1       0.25      0.15      0.19        93\n",
      "           2       0.40      0.23      0.29       104\n",
      "           3       0.34      0.41      0.37        91\n",
      "\n",
      "    accuracy                           0.30       360\n",
      "   macro avg       0.31      0.32      0.29       360\n",
      "weighted avg       0.32      0.30      0.29       360\n",
      "\n",
      "[[34  9 12 17]\n",
      " [39 14 15 25]\n",
      " [35 15 24 30]\n",
      " [28 17  9 37]]\n",
      "Validation Loss for P31 = 1.4458695650100708\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_233/2598240933.py:43: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n",
      "/tmp/ipykernel_233/2598240933.py:61: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 69/100, Train Loss: 1.3049856424331665\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_233/2598240933.py:87: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.25      0.46      0.32        72\n",
      "           1       0.23      0.14      0.17        93\n",
      "           2       0.38      0.23      0.29       104\n",
      "           3       0.33      0.40      0.36        91\n",
      "\n",
      "    accuracy                           0.29       360\n",
      "   macro avg       0.30      0.31      0.29       360\n",
      "weighted avg       0.30      0.29      0.28       360\n",
      "\n",
      "[[33  9 14 16]\n",
      " [37 13 16 27]\n",
      " [36 15 24 29]\n",
      " [26 19 10 36]]\n",
      "Validation Loss for P31 = 1.4491362571716309\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_233/2598240933.py:43: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n",
      "/tmp/ipykernel_233/2598240933.py:61: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 70/100, Train Loss: 1.2988771200180054\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_233/2598240933.py:87: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.25      0.46      0.33        72\n",
      "           1       0.24      0.14      0.18        93\n",
      "           2       0.39      0.23      0.29       104\n",
      "           3       0.32      0.40      0.35        91\n",
      "\n",
      "    accuracy                           0.29       360\n",
      "   macro avg       0.30      0.31      0.29       360\n",
      "weighted avg       0.30      0.29      0.28       360\n",
      "\n",
      "[[33  9 13 17]\n",
      " [37 13 15 28]\n",
      " [34 14 24 32]\n",
      " [26 19 10 36]]\n",
      "Validation Loss for P31 = 1.4525940418243408\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_233/2598240933.py:43: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n",
      "/tmp/ipykernel_233/2598240933.py:61: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/tmp/ipykernel_233/2598240933.py:87: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/tmp/ipykernel_233/2598240933.py:43: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 71/100, Train Loss: 1.2745201587677002\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.24      0.40      0.30        72\n",
      "           1       0.27      0.16      0.20        93\n",
      "           2       0.37      0.26      0.31       104\n",
      "           3       0.33      0.41      0.36        91\n",
      "\n",
      "    accuracy                           0.30       360\n",
      "   macro avg       0.30      0.31      0.29       360\n",
      "weighted avg       0.31      0.30      0.29       360\n",
      "\n",
      "[[29  9 17 17]\n",
      " [34 15 18 26]\n",
      " [32 13 27 32]\n",
      " [25 18 11 37]]\n",
      "Validation Loss for P31 = 1.4468683004379272\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_233/2598240933.py:61: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/tmp/ipykernel_233/2598240933.py:87: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/tmp/ipykernel_233/2598240933.py:43: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 72/100, Train Loss: 1.3266946077346802\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.24      0.40      0.30        72\n",
      "           1       0.26      0.16      0.20        93\n",
      "           2       0.33      0.22      0.27       104\n",
      "           3       0.32      0.40      0.35        91\n",
      "\n",
      "    accuracy                           0.29       360\n",
      "   macro avg       0.29      0.30      0.28       360\n",
      "weighted avg       0.29      0.29      0.28       360\n",
      "\n",
      "[[29 10 16 17]\n",
      " [33 15 18 27]\n",
      " [33 14 23 34]\n",
      " [24 19 12 36]]\n",
      "Validation Loss for P31 = 1.4521087408065796\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_233/2598240933.py:61: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/tmp/ipykernel_233/2598240933.py:87: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/tmp/ipykernel_233/2598240933.py:43: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 73/100, Train Loss: 1.3099631071090698\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.23      0.40      0.30        72\n",
      "           1       0.27      0.14      0.18        93\n",
      "           2       0.35      0.24      0.29       104\n",
      "           3       0.33      0.42      0.37        91\n",
      "\n",
      "    accuracy                           0.29       360\n",
      "   macro avg       0.29      0.30      0.28       360\n",
      "weighted avg       0.30      0.29      0.28       360\n",
      "\n",
      "[[29  7 18 18]\n",
      " [35 13 17 28]\n",
      " [34 13 25 32]\n",
      " [26 16 11 38]]\n",
      "Validation Loss for P31 = 1.4451020956039429\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_233/2598240933.py:61: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/tmp/ipykernel_233/2598240933.py:87: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 74/100, Train Loss: 1.3680346012115479\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.23      0.39      0.29        72\n",
      "           1       0.27      0.14      0.18        93\n",
      "           2       0.36      0.26      0.30       104\n",
      "           3       0.34      0.42      0.37        91\n",
      "\n",
      "    accuracy                           0.29       360\n",
      "   macro avg       0.30      0.30      0.29       360\n",
      "weighted avg       0.30      0.29      0.29       360\n",
      "\n",
      "[[28  7 19 18]\n",
      " [35 13 19 26]\n",
      " [33 14 27 30]\n",
      " [27 15 11 38]]\n",
      "Validation Loss for P31 = 1.448761224746704\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_233/2598240933.py:43: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n",
      "/tmp/ipykernel_233/2598240933.py:61: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/tmp/ipykernel_233/2598240933.py:87: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 75/100, Train Loss: 1.313679575920105\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.24      0.39      0.29        72\n",
      "           1       0.26      0.15      0.19        93\n",
      "           2       0.36      0.27      0.31       104\n",
      "           3       0.34      0.42      0.37        91\n",
      "\n",
      "    accuracy                           0.30       360\n",
      "   macro avg       0.30      0.31      0.29       360\n",
      "weighted avg       0.31      0.30      0.29       360\n",
      "\n",
      "[[28  7 18 19]\n",
      " [33 14 20 26]\n",
      " [32 15 28 29]\n",
      " [25 17 11 38]]\n",
      "Validation Loss for P31 = 1.4438990354537964\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_233/2598240933.py:43: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n",
      "/tmp/ipykernel_233/2598240933.py:61: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/tmp/ipykernel_233/2598240933.py:87: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/tmp/ipykernel_233/2598240933.py:43: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 76/100, Train Loss: 1.3604440689086914\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.23      0.38      0.29        72\n",
      "           1       0.27      0.16      0.20        93\n",
      "           2       0.35      0.28      0.31       104\n",
      "           3       0.35      0.41      0.38        91\n",
      "\n",
      "    accuracy                           0.30       360\n",
      "   macro avg       0.30      0.31      0.29       360\n",
      "weighted avg       0.31      0.30      0.29       360\n",
      "\n",
      "[[27  8 20 17]\n",
      " [32 15 22 24]\n",
      " [33 15 29 27]\n",
      " [25 17 12 37]]\n",
      "Validation Loss for P31 = 1.4468507766723633\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_233/2598240933.py:61: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/tmp/ipykernel_233/2598240933.py:87: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/tmp/ipykernel_233/2598240933.py:43: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 77/100, Train Loss: 1.3244093656539917\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.24      0.38      0.29        72\n",
      "           1       0.25      0.14      0.18        93\n",
      "           2       0.35      0.28      0.31       104\n",
      "           3       0.35      0.42      0.38        91\n",
      "\n",
      "    accuracy                           0.30       360\n",
      "   macro avg       0.29      0.30      0.29       360\n",
      "weighted avg       0.30      0.30      0.29       360\n",
      "\n",
      "[[27  7 20 18]\n",
      " [31 13 23 26]\n",
      " [32 15 29 28]\n",
      " [24 17 12 38]]\n",
      "Validation Loss for P31 = 1.4444950819015503\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_233/2598240933.py:61: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/tmp/ipykernel_233/2598240933.py:87: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 78/100, Train Loss: 1.385205626487732\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.25      0.38      0.30        72\n",
      "           1       0.23      0.13      0.16        93\n",
      "           2       0.34      0.27      0.30       104\n",
      "           3       0.33      0.42      0.37        91\n",
      "\n",
      "    accuracy                           0.29       360\n",
      "   macro avg       0.29      0.30      0.28       360\n",
      "weighted avg       0.29      0.29      0.28       360\n",
      "\n",
      "[[27  9 19 17]\n",
      " [29 12 23 29]\n",
      " [30 15 28 31]\n",
      " [24 17 12 38]]\n",
      "Validation Loss for P31 = 1.4350807666778564\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_233/2598240933.py:43: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n",
      "/tmp/ipykernel_233/2598240933.py:61: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/tmp/ipykernel_233/2598240933.py:87: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/tmp/ipykernel_233/2598240933.py:43: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 79/100, Train Loss: 1.347246766090393\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.24      0.38      0.29        72\n",
      "           1       0.26      0.14      0.18        93\n",
      "           2       0.35      0.28      0.31       104\n",
      "           3       0.34      0.42      0.37        91\n",
      "\n",
      "    accuracy                           0.30       360\n",
      "   macro avg       0.30      0.30      0.29       360\n",
      "weighted avg       0.30      0.30      0.29       360\n",
      "\n",
      "[[27  7 20 18]\n",
      " [30 13 24 26]\n",
      " [31 13 29 31]\n",
      " [26 17 10 38]]\n",
      "Validation Loss for P31 = 1.4369534254074097\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_233/2598240933.py:61: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/tmp/ipykernel_233/2598240933.py:87: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/tmp/ipykernel_233/2598240933.py:43: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 80/100, Train Loss: 1.3149664402008057\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.24      0.40      0.30        72\n",
      "           1       0.24      0.14      0.18        93\n",
      "           2       0.40      0.28      0.33       104\n",
      "           3       0.34      0.41      0.37        91\n",
      "\n",
      "    accuracy                           0.30       360\n",
      "   macro avg       0.30      0.31      0.29       360\n",
      "weighted avg       0.31      0.30      0.29       360\n",
      "\n",
      "[[29  9 15 19]\n",
      " [37 13 18 25]\n",
      " [31 16 29 28]\n",
      " [26 17 11 37]]\n",
      "Validation Loss for P31 = 1.438946008682251\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_233/2598240933.py:61: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/tmp/ipykernel_233/2598240933.py:87: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/tmp/ipykernel_233/2598240933.py:43: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 81/100, Train Loss: 1.2973476648330688\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.24      0.40      0.30        72\n",
      "           1       0.29      0.18      0.23        93\n",
      "           2       0.38      0.27      0.31       104\n",
      "           3       0.31      0.36      0.34        91\n",
      "\n",
      "    accuracy                           0.30       360\n",
      "   macro avg       0.31      0.30      0.29       360\n",
      "weighted avg       0.31      0.30      0.29       360\n",
      "\n",
      "[[29  9 15 19]\n",
      " [33 17 17 26]\n",
      " [33 16 28 27]\n",
      " [28 16 14 33]]\n",
      "Validation Loss for P31 = 1.4356106519699097\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_233/2598240933.py:61: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 82/100, Train Loss: 1.3107093572616577\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.24      0.39      0.30        72\n",
      "           1       0.27      0.16      0.20        93\n",
      "           2       0.36      0.27      0.31       104\n",
      "           3       0.32      0.38      0.35        91\n",
      "\n",
      "    accuracy                           0.29       360\n",
      "   macro avg       0.30      0.30      0.29       360\n",
      "weighted avg       0.30      0.29      0.29       360\n",
      "\n",
      "[[28  9 17 18]\n",
      " [32 15 20 26]\n",
      " [30 16 28 30]\n",
      " [27 16 13 35]]\n",
      "Validation Loss for P31 = 1.4363092184066772\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_233/2598240933.py:87: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/tmp/ipykernel_233/2598240933.py:43: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n",
      "/tmp/ipykernel_233/2598240933.py:61: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/tmp/ipykernel_233/2598240933.py:87: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 83/100, Train Loss: 1.3166736364364624\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.24      0.39      0.30        72\n",
      "           1       0.26      0.15      0.19        93\n",
      "           2       0.38      0.32      0.35       104\n",
      "           3       0.34      0.38      0.36        91\n",
      "\n",
      "    accuracy                           0.31       360\n",
      "   macro avg       0.31      0.31      0.30       360\n",
      "weighted avg       0.31      0.31      0.30       360\n",
      "\n",
      "[[28  8 18 18]\n",
      " [33 14 22 24]\n",
      " [29 16 33 26]\n",
      " [27 16 13 35]]\n",
      "Validation Loss for P31 = 1.435693383216858\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_233/2598240933.py:43: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n",
      "/tmp/ipykernel_233/2598240933.py:61: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/tmp/ipykernel_233/2598240933.py:87: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 84/100, Train Loss: 1.3713232278823853\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.24      0.38      0.29        72\n",
      "           1       0.28      0.17      0.21        93\n",
      "           2       0.35      0.27      0.30       104\n",
      "           3       0.33      0.40      0.36        91\n",
      "\n",
      "    accuracy                           0.30       360\n",
      "   macro avg       0.30      0.30      0.29       360\n",
      "weighted avg       0.30      0.30      0.29       360\n",
      "\n",
      "[[27  9 19 17]\n",
      " [30 16 22 25]\n",
      " [30 16 28 30]\n",
      " [27 16 12 36]]\n",
      "Validation Loss for P31 = 1.4372150897979736\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_233/2598240933.py:43: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n",
      "/tmp/ipykernel_233/2598240933.py:61: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/tmp/ipykernel_233/2598240933.py:87: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/tmp/ipykernel_233/2598240933.py:43: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 85/100, Train Loss: 1.35194993019104\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.23      0.39      0.29        72\n",
      "           1       0.28      0.18      0.22        93\n",
      "           2       0.36      0.26      0.30       104\n",
      "           3       0.32      0.36      0.34        91\n",
      "\n",
      "    accuracy                           0.29       360\n",
      "   macro avg       0.30      0.30      0.29       360\n",
      "weighted avg       0.30      0.29      0.29       360\n",
      "\n",
      "[[28 10 17 17]\n",
      " [34 17 18 24]\n",
      " [32 16 27 29]\n",
      " [27 17 14 33]]\n",
      "Validation Loss for P31 = 1.4392861127853394\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_233/2598240933.py:61: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/tmp/ipykernel_233/2598240933.py:87: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/tmp/ipykernel_233/2598240933.py:43: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 86/100, Train Loss: 1.304158091545105\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.25      0.44      0.32        72\n",
      "           1       0.28      0.18      0.22        93\n",
      "           2       0.37      0.25      0.30       104\n",
      "           3       0.32      0.35      0.33        91\n",
      "\n",
      "    accuracy                           0.30       360\n",
      "   macro avg       0.30      0.31      0.29       360\n",
      "weighted avg       0.31      0.30      0.29       360\n",
      "\n",
      "[[32 10 13 17]\n",
      " [35 17 16 25]\n",
      " [35 16 26 27]\n",
      " [27 17 15 32]]\n",
      "Validation Loss for P31 = 1.4399698972702026\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_233/2598240933.py:61: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 87/100, Train Loss: 1.3460434675216675\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_233/2598240933.py:87: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.25      0.43      0.31        72\n",
      "           1       0.28      0.18      0.22        93\n",
      "           2       0.37      0.28      0.32       104\n",
      "           3       0.32      0.34      0.33        91\n",
      "\n",
      "    accuracy                           0.30       360\n",
      "   macro avg       0.31      0.31      0.30       360\n",
      "weighted avg       0.31      0.30      0.30       360\n",
      "\n",
      "[[31 10 15 16]\n",
      " [33 17 19 24]\n",
      " [34 16 29 25]\n",
      " [27 17 16 31]]\n",
      "Validation Loss for P31 = 1.4332188367843628\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_233/2598240933.py:43: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n",
      "/tmp/ipykernel_233/2598240933.py:61: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 88/100, Train Loss: 1.3378514051437378\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_233/2598240933.py:87: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.25      0.43      0.32        72\n",
      "           1       0.29      0.18      0.22        93\n",
      "           2       0.38      0.29      0.33       104\n",
      "           3       0.32      0.34      0.33        91\n",
      "\n",
      "    accuracy                           0.30       360\n",
      "   macro avg       0.31      0.31      0.30       360\n",
      "weighted avg       0.31      0.30      0.30       360\n",
      "\n",
      "[[31  9 16 16]\n",
      " [33 17 18 25]\n",
      " [33 16 30 25]\n",
      " [27 17 16 31]]\n",
      "Validation Loss for P31 = 1.4375272989273071\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_233/2598240933.py:43: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n",
      "/tmp/ipykernel_233/2598240933.py:61: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/tmp/ipykernel_233/2598240933.py:87: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 89/100, Train Loss: 1.3708651065826416\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.24      0.40      0.30        72\n",
      "           1       0.26      0.16      0.20        93\n",
      "           2       0.41      0.32      0.36       104\n",
      "           3       0.36      0.41      0.38        91\n",
      "\n",
      "    accuracy                           0.32       360\n",
      "   macro avg       0.32      0.32      0.31       360\n",
      "weighted avg       0.33      0.32      0.31       360\n",
      "\n",
      "[[29  9 17 17]\n",
      " [33 15 20 25]\n",
      " [31 16 33 24]\n",
      " [27 17 10 37]]\n",
      "Validation Loss for P31 = 1.4511812925338745\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_233/2598240933.py:43: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n",
      "/tmp/ipykernel_233/2598240933.py:61: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/tmp/ipykernel_233/2598240933.py:87: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/tmp/ipykernel_233/2598240933.py:43: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 90/100, Train Loss: 1.3191328048706055\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.25      0.42      0.31        72\n",
      "           1       0.25      0.15      0.19        93\n",
      "           2       0.39      0.31      0.34       104\n",
      "           3       0.36      0.41      0.38        91\n",
      "\n",
      "    accuracy                           0.31       360\n",
      "   macro avg       0.31      0.32      0.31       360\n",
      "weighted avg       0.32      0.31      0.31       360\n",
      "\n",
      "[[30  8 18 16]\n",
      " [33 14 22 24]\n",
      " [31 16 32 25]\n",
      " [27 17 10 37]]\n",
      "Validation Loss for P31 = 1.4530868530273438\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_233/2598240933.py:61: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/tmp/ipykernel_233/2598240933.py:87: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/tmp/ipykernel_233/2598240933.py:43: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 91/100, Train Loss: 1.3872308731079102\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.24      0.39      0.30        72\n",
      "           1       0.26      0.16      0.20        93\n",
      "           2       0.40      0.33      0.36       104\n",
      "           3       0.36      0.40      0.37        91\n",
      "\n",
      "    accuracy                           0.31       360\n",
      "   macro avg       0.31      0.32      0.31       360\n",
      "weighted avg       0.32      0.31      0.31       360\n",
      "\n",
      "[[28  9 19 16]\n",
      " [32 15 21 25]\n",
      " [30 16 34 24]\n",
      " [27 17 11 36]]\n",
      "Validation Loss for P31 = 1.4509594440460205\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_233/2598240933.py:61: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/tmp/ipykernel_233/2598240933.py:87: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/tmp/ipykernel_233/2598240933.py:43: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 92/100, Train Loss: 1.313848853111267\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.25      0.40      0.31        72\n",
      "           1       0.27      0.16      0.20        93\n",
      "           2       0.39      0.32      0.35       104\n",
      "           3       0.35      0.40      0.37        91\n",
      "\n",
      "    accuracy                           0.31       360\n",
      "   macro avg       0.31      0.32      0.31       360\n",
      "weighted avg       0.32      0.31      0.31       360\n",
      "\n",
      "[[29  8 19 16]\n",
      " [32 15 21 25]\n",
      " [30 16 33 25]\n",
      " [26 17 12 36]]\n",
      "Validation Loss for P31 = 1.4543410539627075\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_233/2598240933.py:61: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/tmp/ipykernel_233/2598240933.py:87: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/tmp/ipykernel_233/2598240933.py:43: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 93/100, Train Loss: 1.3468687534332275\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.24      0.39      0.30        72\n",
      "           1       0.25      0.15      0.19        93\n",
      "           2       0.37      0.30      0.33       104\n",
      "           3       0.34      0.40      0.37        91\n",
      "\n",
      "    accuracy                           0.30       360\n",
      "   macro avg       0.30      0.31      0.30       360\n",
      "weighted avg       0.31      0.30      0.30       360\n",
      "\n",
      "[[28  8 19 17]\n",
      " [32 14 22 25]\n",
      " [30 16 31 27]\n",
      " [27 17 11 36]]\n",
      "Validation Loss for P31 = 1.4513472318649292\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_233/2598240933.py:61: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/tmp/ipykernel_233/2598240933.py:87: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/tmp/ipykernel_233/2598240933.py:43: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 94/100, Train Loss: 1.4600716829299927\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.24      0.38      0.29        72\n",
      "           1       0.27      0.17      0.21        93\n",
      "           2       0.37      0.30      0.33       104\n",
      "           3       0.34      0.38      0.36        91\n",
      "\n",
      "    accuracy                           0.30       360\n",
      "   macro avg       0.30      0.31      0.30       360\n",
      "weighted avg       0.31      0.30      0.30       360\n",
      "\n",
      "[[27 10 19 16]\n",
      " [31 16 21 25]\n",
      " [30 16 31 27]\n",
      " [26 18 12 35]]\n",
      "Validation Loss for P31 = 1.438309907913208\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_233/2598240933.py:61: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/tmp/ipykernel_233/2598240933.py:87: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/tmp/ipykernel_233/2598240933.py:43: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 95/100, Train Loss: 1.2852060794830322\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.24      0.39      0.30        72\n",
      "           1       0.26      0.16      0.20        93\n",
      "           2       0.36      0.29      0.32       104\n",
      "           3       0.35      0.40      0.37        91\n",
      "\n",
      "    accuracy                           0.30       360\n",
      "   macro avg       0.30      0.31      0.30       360\n",
      "weighted avg       0.31      0.30      0.30       360\n",
      "\n",
      "[[28  8 20 16]\n",
      " [31 15 22 25]\n",
      " [30 17 30 27]\n",
      " [27 17 11 36]]\n",
      "Validation Loss for P31 = 1.4490795135498047\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_233/2598240933.py:61: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/tmp/ipykernel_233/2598240933.py:87: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 96/100, Train Loss: 1.2491992712020874\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.24      0.42      0.31        72\n",
      "           1       0.26      0.16      0.20        93\n",
      "           2       0.39      0.29      0.33       104\n",
      "           3       0.35      0.40      0.37        91\n",
      "\n",
      "    accuracy                           0.31       360\n",
      "   macro avg       0.31      0.32      0.30       360\n",
      "weighted avg       0.32      0.31      0.30       360\n",
      "\n",
      "[[30  9 17 16]\n",
      " [35 15 19 24]\n",
      " [32 16 30 26]\n",
      " [27 17 11 36]]\n",
      "Validation Loss for P31 = 1.456639051437378\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_233/2598240933.py:43: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n",
      "/tmp/ipykernel_233/2598240933.py:61: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 97/100, Train Loss: 1.3072054386138916\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.24      0.40      0.30        72\n",
      "           1       0.26      0.16      0.20        93\n",
      "           2       0.38      0.29      0.33       104\n",
      "           3       0.36      0.41      0.38        91\n",
      "\n",
      "    accuracy                           0.31       360\n",
      "   macro avg       0.31      0.31      0.30       360\n",
      "weighted avg       0.32      0.31      0.30       360\n",
      "\n",
      "[[29  9 18 16]\n",
      " [34 15 21 23]\n",
      " [31 16 30 27]\n",
      " [27 17 10 37]]\n",
      "Validation Loss for P31 = 1.4539234638214111\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_233/2598240933.py:87: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/tmp/ipykernel_233/2598240933.py:43: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n",
      "/tmp/ipykernel_233/2598240933.py:61: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/tmp/ipykernel_233/2598240933.py:87: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 98/100, Train Loss: 1.3938792943954468\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.23      0.39      0.29        72\n",
      "           1       0.27      0.17      0.21        93\n",
      "           2       0.38      0.28      0.32       104\n",
      "           3       0.36      0.42      0.39        91\n",
      "\n",
      "    accuracy                           0.31       360\n",
      "   macro avg       0.31      0.31      0.30       360\n",
      "weighted avg       0.32      0.31      0.30       360\n",
      "\n",
      "[[28 10 18 16]\n",
      " [33 16 20 24]\n",
      " [32 16 29 27]\n",
      " [27 17  9 38]]\n",
      "Validation Loss for P31 = 1.4486186504364014\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_233/2598240933.py:43: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n",
      "/tmp/ipykernel_233/2598240933.py:61: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/tmp/ipykernel_233/2598240933.py:87: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 99/100, Train Loss: 1.3783003091812134\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.23      0.38      0.29        72\n",
      "           1       0.27      0.17      0.21        93\n",
      "           2       0.37      0.28      0.32       104\n",
      "           3       0.36      0.42      0.39        91\n",
      "\n",
      "    accuracy                           0.31       360\n",
      "   macro avg       0.31      0.31      0.30       360\n",
      "weighted avg       0.31      0.31      0.30       360\n",
      "\n",
      "[[27 10 19 16]\n",
      " [31 16 21 25]\n",
      " [31 17 29 27]\n",
      " [27 16 10 38]]\n",
      "Validation Loss for P31 = 1.4492075443267822\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_233/2598240933.py:43: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 100/100, Train Loss: 1.3592942953109741\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.23      0.36      0.28        72\n",
      "           1       0.26      0.16      0.20        93\n",
      "           2       0.38      0.32      0.35       104\n",
      "           3       0.35      0.40      0.37        91\n",
      "\n",
      "    accuracy                           0.31       360\n",
      "   macro avg       0.31      0.31      0.30       360\n",
      "weighted avg       0.31      0.31      0.30       360\n",
      "\n",
      "[[26 10 20 16]\n",
      " [31 15 22 25]\n",
      " [30 16 33 25]\n",
      " [26 17 12 36]]\n",
      "Validation Loss for P31 = 1.447343111038208\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_233/2598240933.py:61: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/tmp/ipykernel_233/2598240933.py:87: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x7fdab0d077c0>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1000x700 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import confusion_matrix,classification_report\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import preprocessing\n",
    "import matplotlib.pyplot as plt\n",
    "#subjectnames\n",
    "file_list_num = np.arange(len(newsubjectname))\n",
    "file_list_numd = np.arange(len(subjectnamesd))\n",
    "\n",
    "kf = KFold(n_splits=12)\n",
    "torch.manual_seed(42)\n",
    "torch.cuda.manual_seed(42)\n",
    "modellist = []\n",
    "modelid = 1\n",
    "#file_list_num\n",
    "#for i, (train_index, test_index) in enumerate(kf.split(file_list_num)):\n",
    "#for train_index in file_list_num:\n",
    "train_index = file_list_numd\n",
    "test_index_train, test_index_test = train_test_split(file_list_num, test_size=0.50, random_state=42)\n",
    "#test_index = file_list_num\n",
    "print(f\"Fold {i}:\")\n",
    "print(f\"  Train: index={train_index}\")\n",
    "#print(f\"  Test:  index={test_index}\")\n",
    "net = Net()\n",
    "net.to(device)\n",
    "optimizer = optim.Adam(net.parameters(), lr=0.000001)\n",
    "epochs = 100\n",
    "batch_sz = 20\n",
    "train_loss_epoch = []\n",
    "val_loss_epoch = []\n",
    "for epoch in range(epochs):\n",
    "  train_loss = []\n",
    "  for tr in train_index:\n",
    "    v = data_de1[subjectnamesd[tr]]\n",
    "    l = data_del[subjectnamesd[tr]]\n",
    "    #print(v[0].shape)\n",
    "    net.train()\n",
    "    for i in range(0,len(v),batch_sz):\n",
    "      #print(v[i].shape)\n",
    "      #for j in range(0,v[i].shape[0],batch_sz):\n",
    "      #print(newsubjectname[tr])\n",
    "      optimizer.zero_grad()\n",
    "      outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
    "      #print(\"Expout {}\",outputs.shape)\n",
    "      #print(\"Actual {}\",l[i:i+batch_sz].shape)\n",
    "      #print(l[i].shape)\n",
    "      loss = criterion(outputs, l[i:i+batch_sz].to(device, dtype=torch.float))\n",
    "      loss.backward()\n",
    "      train_loss.append(loss)\n",
    "      optimizer.step()\n",
    "  for tr in test_index_train:\n",
    "    v = data_c1d[newsubjectname[tr]]\n",
    "    l = data_c2[newsubjectname[tr]]\n",
    "    #print(v[0].shape)\n",
    "    net.train()\n",
    "    for i in range(0,len(v),batch_sz):\n",
    "      #print(v[i].shape)\n",
    "      #for j in range(0,v[i].shape[0],batch_sz):\n",
    "      #print(newsubjectname[tr])\n",
    "      optimizer.zero_grad()\n",
    "      outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
    "      #print(\"Expout {}\",outputs.shape)\n",
    "      #print(\"Actual {}\",l[i:i+batch_sz].shape)\n",
    "      #print(l[i].shape)\n",
    "      loss = criterion(outputs, l[i:i+batch_sz].to(device, dtype=torch.float))\n",
    "      loss.backward()\n",
    "      train_loss.append(loss)\n",
    "      optimizer.step()\n",
    "  print(f'Epoch {epoch + 1}/{epochs}, Train Loss: {loss.item()}')\n",
    "  train_loss_epoch.append(torch.stack(train_loss).mean().cpu().detach().numpy())\n",
    "  #print(train_loss_epoch)\n",
    "  expectedoutputamigos = []\n",
    "  actualoutputamigos = []\n",
    "\n",
    "  for tr in test_index_test:\n",
    "      net.eval()\n",
    "\n",
    "      v = data_c1d[newsubjectname[tr]]\n",
    "      l = data_c2[newsubjectname[tr]]\n",
    "      net.eval()\n",
    "      val_loss = []\n",
    "      with torch.no_grad():\n",
    "          for i in range(0,len(v),batch_sz):\n",
    "            #print(v[i].shape)\n",
    "            #for j in range(0,v[i].shape[0],batch_sz):\n",
    "            optimizer.zero_grad()\n",
    "            outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
    "            #print(outputs.shape)\n",
    "            #print(l[i:i+batch_sz].shape)\n",
    "            loss = criterion(outputs, l[i:i+batch_sz].to(device, dtype=torch.float))\n",
    "            val_loss.append(loss)\n",
    "            #actualoutputamigos.append(torch.round(outputs.cpu()))\n",
    "            #expectedoutputamigos.append(l[i:i+batch_sz])\n",
    "            actualoutputamigos.append(torch.argmax(torch.softmax(outputs.cpu(),dim=1),dim=1))\n",
    "            expectedoutputamigos.append(torch.argmax(l[i:i+batch_sz],dim=1).numpy())\n",
    "  val_loss_mean = torch.stack(val_loss).mean().cpu().detach().numpy()\n",
    "  val_loss_epoch.append(val_loss_mean)\n",
    "  expectedoutputamigos = np.concatenate( expectedoutputamigos, axis=0 )\n",
    "  actualoutputamigos = np.concatenate( actualoutputamigos, axis=0 )\n",
    "  #print(expectedoutput.shape)\n",
    "  #print(actualoutput.shape)\n",
    "  print(classification_report(expectedoutputamigos,actualoutputamigos))\n",
    "  print(confusion_matrix(expectedoutputamigos,actualoutputamigos))\n",
    "  print(f'Validation Loss for {newsubjectname[tr]} = {val_loss_mean}')\n",
    "plt.figure(figsize=(10,7))\n",
    "#print(len(train_loss_epoch))\n",
    "plt.plot(np.arange(epochs),train_loss_epoch,label='Train')\n",
    "plt.plot(np.arange(epochs),val_loss_epoch,label='Validation')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "629a6e47-a58b-496b-9740-4e35f730b5d6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
