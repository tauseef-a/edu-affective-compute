{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "lV6AUpSouNYI",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "lV6AUpSouNYI",
    "outputId": "e479380e-fbed-427b-87fd-cc146892b6da"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mounted at /content/drive\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "njT3xEyzuOSC",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2024-01-21T19:55:18.294674Z",
     "iopub.status.busy": "2024-01-21T19:55:18.294070Z",
     "iopub.status.idle": "2024-01-21T19:55:40.973243Z",
     "shell.execute_reply": "2024-01-21T19:55:40.972658Z",
     "shell.execute_reply.started": "2024-01-21T19:55:18.294651Z"
    },
    "id": "njT3xEyzuOSC",
    "outputId": "d85411f6-4f18-49ad-87f7-ea614f2e47f8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Archive:  AMIGOS.zip\n",
      "  inflating: AMIGOS/Data_Preprocessed_P01.mat  \n",
      "  inflating: AMIGOS/Data_Preprocessed_P02.mat  \n",
      "  inflating: AMIGOS/Data_Preprocessed_P03.mat  \n",
      "  inflating: AMIGOS/Data_Preprocessed_P04.mat  \n",
      "  inflating: AMIGOS/Data_Preprocessed_P05.mat  \n",
      "  inflating: AMIGOS/Data_Preprocessed_P06.mat  \n",
      "  inflating: AMIGOS/Data_Preprocessed_P07.mat  \n",
      "  inflating: AMIGOS/Data_Preprocessed_P08.mat  \n",
      "  inflating: AMIGOS/Data_Preprocessed_P09.mat  \n",
      "  inflating: AMIGOS/Data_Preprocessed_P10.mat  \n",
      "  inflating: AMIGOS/Data_Preprocessed_P11.mat  \n",
      "  inflating: AMIGOS/Data_Preprocessed_P12.mat  \n",
      "  inflating: AMIGOS/Data_Preprocessed_P13.mat  \n",
      "  inflating: AMIGOS/Data_Preprocessed_P14.mat  \n",
      "  inflating: AMIGOS/Data_Preprocessed_P15.mat  \n",
      "  inflating: AMIGOS/Data_Preprocessed_P16.mat  \n",
      "  inflating: AMIGOS/Data_Preprocessed_P17.mat  \n",
      "  inflating: AMIGOS/Data_Preprocessed_P18.mat  \n",
      "  inflating: AMIGOS/Data_Preprocessed_P19.mat  \n",
      "  inflating: AMIGOS/Data_Preprocessed_P20.mat  \n",
      "  inflating: AMIGOS/Data_Preprocessed_P21.mat  \n",
      "  inflating: AMIGOS/Data_Preprocessed_P22.mat  \n",
      "  inflating: AMIGOS/Data_Preprocessed_P23.mat  \n",
      "  inflating: AMIGOS/Data_Preprocessed_P24.mat  \n",
      "  inflating: AMIGOS/Data_Preprocessed_P25.mat  \n",
      "  inflating: AMIGOS/Data_Preprocessed_P26.mat  \n",
      "  inflating: AMIGOS/Data_Preprocessed_P27.mat  \n",
      "  inflating: AMIGOS/Data_Preprocessed_P28.mat  \n",
      "  inflating: AMIGOS/Data_Preprocessed_P29.mat  \n",
      "  inflating: AMIGOS/Data_Preprocessed_P30.mat  \n",
      "  inflating: AMIGOS/Data_Preprocessed_P31.mat  \n",
      "  inflating: AMIGOS/Data_Preprocessed_P32.mat  \n",
      "  inflating: AMIGOS/Data_Preprocessed_P33.mat  \n",
      "  inflating: AMIGOS/Data_Preprocessed_P34.mat  \n",
      "  inflating: AMIGOS/Data_Preprocessed_P35.mat  \n",
      "  inflating: AMIGOS/Data_Preprocessed_P36.mat  \n",
      "  inflating: AMIGOS/Data_Preprocessed_P37.mat  \n",
      "  inflating: AMIGOS/Data_Preprocessed_P38.mat  \n",
      "  inflating: AMIGOS/Data_Preprocessed_P39.mat  \n",
      "  inflating: AMIGOS/Data_Preprocessed_P40.mat  \n"
     ]
    }
   ],
   "source": [
    "!unzip \"AMIGOS.zip\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "GPftEcnHuJrY",
   "metadata": {
    "id": "GPftEcnHuJrY"
   },
   "outputs": [],
   "source": [
    "import scipy.io\n",
    "data = scipy.io.loadmat(\"AMIGOS/Data_Preprocessed_P32.mat\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "Hz_c9Dnoua7T",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Hz_c9Dnoua7T",
    "outputId": "09a9a543-7156-4279-eda3-45021ff3edf9"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 12)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#data['joined_data'][0][19].shape\n",
    "#data['labels_selfassessment'][0][15].shape\n",
    "#data['joined_data'].shape[1]\n",
    "#data['labels_selfassessment'][0][1][0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "SI3v-4-DTC60",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 463
    },
    "id": "SI3v-4-DTC60",
    "outputId": "390a5f34-c7ad-4e73-8513-95e2c0f068e7"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10191,)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.plot(data['joined_data'][0][16][384:,16])\n",
    "data['joined_data'][0][3][384:,16].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "WFGqncuxTz4s",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 463
    },
    "id": "WFGqncuxTz4s",
    "outputId": "2877bf49-f2b1-4a12-9a31-b245c833c2f6"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7bb4a0d7ec80>]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import scipy.io\n",
    "y1 = scipy.signal.resample(data['joined_data'][0][16][:,16], 8000)\n",
    "plt.plot(y1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "81e9e46f-88cc-4ba9-a64f-347034bea365",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2024-01-22T09:45:06.526933Z",
     "iopub.status.busy": "2024-01-22T09:45:06.526600Z",
     "iopub.status.idle": "2024-01-22T09:45:06.536947Z",
     "shell.execute_reply": "2024-01-22T09:45:06.536121Z",
     "shell.execute_reply.started": "2024-01-22T09:45:06.526906Z"
    },
    "id": "81e9e46f-88cc-4ba9-a64f-347034bea365",
    "outputId": "bcb347b1-3a4c-4281-e78d-5555e64d6a27"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['AMIGOS/Data_Preprocessed_P33.mat', 'AMIGOS/Data_Preprocessed_P30.mat', 'AMIGOS/Data_Preprocessed_P13.mat', 'AMIGOS/Data_Preprocessed_P26.mat', 'AMIGOS/Data_Preprocessed_P37.mat', 'AMIGOS/Data_Preprocessed_P31.mat', 'AMIGOS/Data_Preprocessed_P10.mat', 'AMIGOS/Data_Preprocessed_P09.mat', 'AMIGOS/Data_Preprocessed_P05.mat', 'AMIGOS/Data_Preprocessed_P40.mat', 'AMIGOS/Data_Preprocessed_P35.mat', 'AMIGOS/Data_Preprocessed_P32.mat', 'AMIGOS/Data_Preprocessed_P22.mat', 'AMIGOS/Data_Preprocessed_P23.mat', 'AMIGOS/Data_Preprocessed_P17.mat', 'AMIGOS/Data_Preprocessed_P04.mat', 'AMIGOS/Data_Preprocessed_P12.mat', 'AMIGOS/Data_Preprocessed_P34.mat', 'AMIGOS/Data_Preprocessed_P29.mat', 'AMIGOS/Data_Preprocessed_P15.mat', 'AMIGOS/Data_Preprocessed_P02.mat', 'AMIGOS/Data_Preprocessed_P25.mat', 'AMIGOS/Data_Preprocessed_P18.mat', 'AMIGOS/Data_Preprocessed_P36.mat', 'AMIGOS/Data_Preprocessed_P16.mat', 'AMIGOS/Data_Preprocessed_P28.mat', 'AMIGOS/Data_Preprocessed_P03.mat', 'AMIGOS/Data_Preprocessed_P38.mat', 'AMIGOS/Data_Preprocessed_P39.mat', 'AMIGOS/Data_Preprocessed_P27.mat', 'AMIGOS/Data_Preprocessed_P01.mat', 'AMIGOS/Data_Preprocessed_P19.mat', 'AMIGOS/Data_Preprocessed_P06.mat', 'AMIGOS/Data_Preprocessed_P24.mat', 'AMIGOS/Data_Preprocessed_P11.mat', 'AMIGOS/Data_Preprocessed_P08.mat', 'AMIGOS/Data_Preprocessed_P21.mat', 'AMIGOS/Data_Preprocessed_P07.mat', 'AMIGOS/Data_Preprocessed_P14.mat', 'AMIGOS/Data_Preprocessed_P20.mat']\n",
      "['P33', 'P30', 'P13', 'P26', 'P37', 'P31', 'P10', 'P09', 'P05', 'P40', 'P35', 'P32', 'P22', 'P23', 'P17', 'P04', 'P12', 'P34', 'P29', 'P15', 'P02', 'P25', 'P18', 'P36', 'P16', 'P28', 'P03', 'P38', 'P39', 'P27', 'P01', 'P19', 'P06', 'P24', 'P11', 'P08', 'P21', 'P07', 'P14', 'P20']\n"
     ]
    }
   ],
   "source": [
    "import glob\n",
    "import os\n",
    "filelist = glob.glob('AMIGOS/*.mat')\n",
    "print(filelist)\n",
    "subjectnames = [fr[25:28] for fr in filelist]\n",
    "print(subjectnames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "74fe1cd7-c31d-44dd-8537-27f357d17096",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2024-01-22T09:45:15.415584Z",
     "iopub.status.busy": "2024-01-22T09:45:15.415309Z",
     "iopub.status.idle": "2024-01-22T09:45:39.127041Z",
     "shell.execute_reply": "2024-01-22T09:45:39.126417Z",
     "shell.execute_reply.started": "2024-01-22T09:45:15.415562Z"
    },
    "id": "74fe1cd7-c31d-44dd-8537-27f357d17096",
    "outputId": "b02ad912-56e9-45b3-dd39-d9d46bc0a2d4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "P33\n",
      "P30\n",
      "P13\n",
      "P26\n",
      "P37\n",
      "P31\n",
      "P10\n",
      "P09\n",
      "P05\n",
      "P40\n",
      "P35\n",
      "P22\n",
      "P23\n",
      "P17\n",
      "P04\n",
      "P12\n",
      "P34\n",
      "P29\n",
      "P15\n",
      "P02\n",
      "P25\n",
      "P18\n",
      "P36\n",
      "P16\n",
      "P03\n",
      "P38\n",
      "P39\n",
      "P27\n",
      "P01\n",
      "P19\n",
      "P06\n",
      "P11\n",
      "P21\n",
      "P07\n",
      "P14\n",
      "P20\n",
      "dict_keys(['P33', 'P30', 'P13', 'P26', 'P37', 'P31', 'P10', 'P09', 'P05', 'P40', 'P35', 'P22', 'P23', 'P17', 'P04', 'P12', 'P34', 'P29', 'P15', 'P02', 'P25', 'P18', 'P36', 'P16', 'P03', 'P38', 'P39', 'P27', 'P01', 'P19', 'P06', 'P11', 'P21', 'P07', 'P14', 'P20'])\n"
     ]
    }
   ],
   "source": [
    "import scipy.io\n",
    "import numpy as np\n",
    "data_am = {}\n",
    "skiplist = ['P28','P08','P24','P32']\n",
    "newsubjectname = []\n",
    "for sname in subjectnames:\n",
    "    if sname in skiplist:\n",
    "      continue\n",
    "    newsubjectname.append(sname)\n",
    "    dname = \"AMIGOS/Data_Preprocessed_\"+sname+\".mat\"\n",
    "    x = scipy.io.loadmat(dname)\n",
    "    print(sname)\n",
    "    samples = []\n",
    "    samples_labels = []\n",
    "    for i in range(x['joined_data'].shape[1]):\n",
    "        x1 = x['joined_data'][0][i]\n",
    "        x2 = scipy.signal.resample(x1[384:,16], 8064)\n",
    "        y1 = x['labels_selfassessment'][0][i][0][0:2]\n",
    "        samples.append(x2)\n",
    "        samples_labels.append(y1)\n",
    "    samples_stack = np.vstack(samples)\n",
    "    samples_labels_stack = np.vstack(samples_labels)\n",
    "    data_am[sname] = [samples_stack,samples_labels_stack]\n",
    "\n",
    "print(data_am.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "qnHCy6Wra5Fu",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "qnHCy6Wra5Fu",
    "outputId": "9d1b17db-cde0-45d9-96ac-fdac666f660f"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([3237180.31474926, 3110649.65303398, 3179062.7496687 , ...,\n",
       "       3514282.08715568, 3478618.13315719, 3540966.49534216])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_am['P01'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8976cde3-bc3f-4fcb-a8af-d624fcde1675",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2024-01-22T09:46:37.496013Z",
     "iopub.status.busy": "2024-01-22T09:46:37.495244Z",
     "iopub.status.idle": "2024-01-22T09:46:37.534316Z",
     "shell.execute_reply": "2024-01-22T09:46:37.533526Z",
     "shell.execute_reply.started": "2024-01-22T09:46:37.495981Z"
    },
    "id": "8976cde3-bc3f-4fcb-a8af-d624fcde1675",
    "outputId": "35ec17fd-7d92-4bb3-a961-3339979bfbc7"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "data_cam = {}\n",
    "for k,v in data_am.items():\n",
    "    y = v[0]\n",
    "    ym = np.mean(y,axis=-1).reshape(20,1)\n",
    "    ystd = np.std(y,axis=-1).reshape(20,1)\n",
    "    z = (y-ym)/ystd\n",
    "    #print(z.shape)\n",
    "    data_cam[k] = [z,v[1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "kgzh85M-Zyyx",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 448
    },
    "execution": {
     "iopub.execute_input": "2024-01-22T09:46:41.740505Z",
     "iopub.status.busy": "2024-01-22T09:46:41.739848Z",
     "iopub.status.idle": "2024-01-22T09:46:41.864825Z",
     "shell.execute_reply": "2024-01-22T09:46:41.864185Z",
     "shell.execute_reply.started": "2024-01-22T09:46:41.740481Z"
    },
    "id": "kgzh85M-Zyyx",
    "outputId": "10010e12-e6d0-4189-ccc0-b9350a6cf1af"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f4326733d90>]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAiIAAAGhCAYAAABceN/BAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjYuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/av/WaAAAACXBIWXMAAA9hAAAPYQGoP6dpAABog0lEQVR4nO3dd5wTdfoH8Cfbsr2wwMLCssvSey8LiCAoIPauqKCeFc96KqiIdxb4qefpKWI5BTvqKeJJk96LlKWz1IWl7lK2s9mS+f2RTEsmyUwyk5lJPu/Xi5eTZJJ84+4mT77f5/s8FoZhGAIAAADQQYTeAwAAAIDwhUAEAAAAdINABAAAAHSDQAQAAAB0g0AEAAAAdINABAAAAHSDQAQAAAB0g0AEAAAAdINABAAAAHSDQAQAAAB0o2kgMm3aNOrXrx8lJSVR06ZN6YYbbqCCggItnxIAAABMRNNAZNWqVTRx4kTauHEjLVmyhOrq6uiqq66iqqoqLZ8WAAAATMISzKZ3JSUl1LRpU1q1ahUNHTrU5/l2u51OnTpFSUlJZLFYgjBCAAAACBTDMFRRUUGZmZkUEeF9ziMqSGMiIqKysjIiImrUqJHk7TabjWw2G3f55MmT1Llz56CMDQAAANRVVFRELVu29HpO0GZE7HY7XXfddVRaWkpr166VPOfVV1+lv//9727XFxUVUXJystZDBAAAABWUl5dTVlYWlZaWUkpKitdzgxaIPProo7Rw4UJau3atx+jIdUaEfSFlZWUIRAAAAEyivLycUlJSZH1+B2Vp5vHHH6fff/+dVq9e7XWKxmq1ktVqDcaQAAAAwAA0DUQYhqG//vWvNHfuXFq5ciW1bt1ay6cDAAAAk9E0EJk4cSJ99913NG/ePEpKSqIzZ84QEVFKSgrFxcVp+dQAAABgAprmiHjacjtr1iyaMGGCz/srWWMCAAAAYzBMjkgQS5QAAACACaHXDAAAAOgGgQgAAADoBoEIAAAA6AaBCAAAAOgGgQgAAADoBoEIAAAA6AaBCAAAAOgmKL1mAAAAwFh2FJXS3O0nqU3TRLpnYLZu48CMCAAAQBg6WFxJs9cX0pK9Z3UdBwIRAACAMCbdjCV4EIgAAIAmlu07S3/5cgudr7TpPRSQYJQ2LAhEAABAEw98uYWW7jtLj367Te+hgAQ2DPHQnzZoEIgAAIDq5uWf5I43H71gmG/fIOD8kWBpBgAAQs6Tc/JFlz9aeVifgYBPFp2nRBCIAACAqqRmP95eXKDDSMAbhowxS4VABAAAVDV3+0nfJ4HuSqvriIjoTFmNruNAIAIAAKp65scdeg8BZJi2cD8REe09Xa7rOBCIAAAAgG4QiAAAgGq81QypqWsI4kjALBCIAACAavq8vtTjbZW2+iCOBLxZc7BE7yFwEIgAAIAqymvqRJez0+Npxl29ucu3fbwh2EMCD+75fLPeQ+AgEAEAAFXc/NF60eWVfxtGY7s35y4fOVcV7CGBCSAQAQAAVRwsrhRd1rtQFpgDAhEwhdp6O035dTct3nNG76EAgARbvTgRdekzl+s0EjCbKL0HAOCL3c5Q+5cXEhHR1xuP0bYpV1KjhBidRwUAQrPWFYout26coM9AwCe73RgVVVmYEQHD+2T1EdHl3q8toYqaOtpRVErHz1fTj1uKqL7BrtPoAMBuZ2i6szgWEVHLtDiKjOCXZZ4c0Y47rq3H36recl9coPcQRDAjAob3f4v2u13X7dU/RJc/WH6Q1jx/RbCGBAACy/YXiy6veX646PLt/bLo/WUHiYjoyTnbaebdfYI2NjA+zIhASCi6cEnvIQCErb2nxCXCXZNUGydaueOFu5HnpafrZ6xzu044e6UHBCJgaEdKKn2f5PTknO0ajgQAPPnX0gNeb4+JwkeNEdTUNdCOolLRda9e25lWPTdMl/Gw8NsBhnbFP1fJPnde/ikNRwIAciTERHq9vUdWanAGAm6OX6h2u27C4NbUMi1eh9HwEIiAYVW5lIOeck1nnUYCAJ6UVIh7yzw/uqPkeR2bJRERuX0jh+D5cPkhvYcgCYEIGFaXqYtFlx8Y0preva2HTqMBACn93hD3lrk3L1vyvIG56cEYDnjx2w7xrPGvEwfrNBIxBCJgCs2SY4mI6KbeLalw+liP56G7J4B+tr480mM11a4tUrjjnSdKgzQiYK09eM7tup4GWSZDIAKGtOqAuDPkl/f3F12eOc7RSKt5Sqwo0QrdPQGCZ/8Z8W6ZdMHuGFddMpO543wszwTd3Z9v0nsIHqGOCBjS+C/EnSE7ONeXWWO6NZecGfljz1m6a0ArTccGAA5bCi/KPrdTcz4QuVSLmUvgYUYEDO+jcb19n+R0WMF2XwAITGp8tF/3+3FLkcojAW/mbD6u9xC8QiAChuOaVT+mazOf9+ndKpWIHEs1ABAcj3/H1+5Z/NRQ2fc7XFKlxXDAg0m/7NJ7CF4hEAHDca38J6eVeEfntG+VDVO+AHpwXT4FY7q5d0siInpC0P9Hb8gRgZAQH+0oolRdh2RVgGD43w4UEDSjt27pTpOv7igqu683zIhASIi3OmLqasyIAATFX79X3lIh0cp/92UYY7WiD1WunckjIyyGCkKIEIiAwbj+0fz2uLyCO/HOstLVyMYHCLptU66Udd5rN3Thjo+eQ55IMOwwQc0WBCKgmotVtXT9h2tpzubjfn/bmTDrT9Hl7i1TZd0vgQtEsDQDoDXXwoGNEmJk3a9DBr+F95dtJ1UdE0ib8use7nicQUsbIBAB1fR6bQntOFFGk37ZRe8u8d6N05O1h/jqf/97fIjs+8XFOKZ8qzAjAqC5mz5a79f9MpL5JQEktwbmsW+3Us6k+bRo92mP59TW22nvab7o3GvXdw3G0BRDIAIBq7LVU86k+aLrPlh+iIokOj0q0a1liu+TnNKc9QyKy2sCek4A8E344fb+HT1l309YefWD5QfVHFJYKS6voQW7zhAR0SPfbKOvNxRKnvfQ11tElyMifO9A1AMCEQjY499tk7z+srdWKHqcswEEEZmpcUTk3gkUALR1fc8Wft3vTBm+NPij0lZPw99ZKbpuyrw9kueuLOBbZTw2rI2WwwoIAhEICMMwtKKgxPeJMryzuMDv+0Y5I307MvEBNHWy9FJA92eXZ+7Ny1FhNOHnlXm7JZeg5+W759wMzG3EHf/tqg6ajisQCEQgIG/M36faYx07zy/lfOXS5M4XtuiZHXEIgKYGT18e0P3TExyByIcrDqkxnLDjKcn3yTn5btdtPHKBOzbqsgwRAhEI0H/WHhVd/nx8X9Fl1+24njTYGdpcyP/RDG3fRNE42L8xzIgABM/dA5XvwhDml4B27IJvZT2yUvUbiAwIREA1Ewbl0IhOGZTbOIG7bvcpeW86d3y6IaDnjmSXZjAlAqCZi1W1osv+7MK4sZd/OSXg3rV4zfPDRZeX7z/LHb88bzd3fM/AbG0HFiAEIuC3L9cXii4/c1V7IiJ6ciTfw0Buu+8/Be3EWzgTT5VgJ0KqahsQjABoxHU2Q04fKFcjO2UQEVH/nEY+zgRXF6v5QHD6Td0oq1G86Pb7Z/O7ZL7bxHfczWuTrv3gAoBABPw29TdxpnZyrGMLrTCL/s7PNip+3HF+TPcK/0DPVWHnDIAWCs5UcMfXdG/u12NYoxwfO7Z61PxRqkHwJWtUF0dX8pV/GyY6x3XWisi/L3fBhEAEVHF1t2Z+3/fERXG9kZt6tVT8GJ2a8xUb6xowIwKghX/8vpc7/vt1Xbyc6Zk1mg1E5OWPAU8YvKU5q9nmCJbCiYju+WJTUMekBgQioIoP7+zt931nrSsUXW6WEqv4MWKjIymG/aZVh29aAGr7eesJ0eV0PxunxUQ6/k73C2ZXQJ5LtY7grbmX98jdJ8tpryA37/nRxt22y0IgAn75ZuMx0eVAtoZ9Lth5s/+10X4/Drs0VCtzpw4AyPfsTztUeZyii3wdErm76sDhcEklERGddikGt/XlkaLLV/97TdDGpAYEIuCXl3/lM7Jz0uO9nCk/YZXIMbPhL27tuQ5vbgBqcm1i+e1fBvj9WN0FrRvQG0qZ33dK95XxNjt1XY9MrYajGgQiELCvH3B/UxK+UR0qrvR431oV14mx9gygjSPnqkSXB7dt7Pdjtc/gm91V2tAtW4kRnZoSEVGqs7eW0KguGZL3MXqiKhECEfBDflGp6LLrFjIi8RvVtR+u9fhYCwWdI3u1Sg1oXOzaM7LxAdR1tKTK90kKNHImWlbWIBBRgv3iNriNeyD4yT193a67a0Arv7ZYBxsCEVDs9k+UFR+7vW+Wx9tenssv8cy+T1lZd1dW57IOlmYA1PWXr7b4PkmB1DjHN/rSavetpuBZjTMRn5399eXNG7tpORzVIBABxYRLH1d0bOrz/OIKz102KwRTsylx7tONSkQ7E2brUdAMQDWuOV6F08cG/Jjs1tOLCEQUueQMRDzl0u35+yhKd/6/nX1fv6CNK1CaBiKrV6+ma6+9ljIzM8lisdCvv/6q5dOBDj69p4/Pc9TqzutLJBeIYEYEQC0/bilS/THT4h0fluclim+BtAY7Q+8tPUhERBuPnJc8J8EaRVunXEmF08fSsA6+vyQahaaBSFVVFfXo0YNmzJih5dNAEO0+WSa6HBXp+VeotUuhHa1FRToCkQbMiACoRlhBedwA5VWPpbDf2qWqgIK01Qf5L3RHVM7Z0VuUlg8+ZswYGjNmjJZPAUH21uIC7vihoblez72qSwZ9suoIETma0bnWGqkT1BAY0DrwvhNREY6gqB6VVQFUUVwuXladeq1/1VRdsUszF6rqVHm8cHDfrD/1HoJmDJUjYrPZqLy8XPQPjGX1AT4qv6u/929H13bn96//WXjB7faftvCVGoUl2v3FztbsOFEa8GMBAFGRS/sFtnpxoBolOPLB/MkRKa2uFfW8CUcPX+79S6DZGCoQmTZtGqWkpHD/srI877YA/WX7KGQmLNX+3ebjbre/OHcXd/z0le0DHg+73vzVhmM+zgQAOW6eye+Q2/TiCNUel80RueDH0ky/N5bSqPdWi8qYh7qfXPJ0Jo/ppNNItGGoQGTy5MlUVlbG/SsqUj9JCvx3pERcmMzX/vTGgmp/vnbEBLpjBkApO3KJFMlIVt4DyhM2EPFnRoRtarn+8DnVxmN0z/13p95D0JShAhGr1UrJycmif2AcV/xzFXc8YVCOovsu31+s8mgA/JdfVEq5Ly6gnEnz9R6KYWnZByY+xrH9VEn7ByKiogv8UlFpdXjml8wy0bZcuQwViIB5vDxW2dTgCUGjKyKisjB9EwFjuGHGOu545srDOo7EuNq+tJA7zvSjI7Y3sWwgorBT9mVvreCO68Jkm36hS3n94SbaliuXpoFIZWUl5efnU35+PhERHT16lPLz8+n4cfd8ATAXb9t25ej35lLu+MWrOwY6HAC//d+i/XoPwfB+f+IyVR8vNsoRiNQEUAXZ9QM6VO0+xZdMiI40frl2f2i6fXfLli00fPhw7vIzzzxDRETjx4+n2bNna/nUoLLq2sB7QjAMw+WVCJvdXdejRcCPDRCI4vIaaqpiDoTZueaDpaqcwxUXw7Zj8L8v1OI9Z9UajqE9/t127vjHh/N0HIl2NJ0RGTZsGDEM4/YPQYj57Pdzu9xrN3Tljt/5o0DynGYqT/sCePPdJvcZ2ed/Du1kQKX+t0Pcbt61BlCgEpyBSFVtveykYdeaJuGoS2aK3kPQBHJEQJaDZ/lAZOkzl8u+3x39+C3YM1YcJlt9g+iN54aemVJ3A9CMcNs4a+3B8NmBIccuQQXlLya4d3UNVIqzjb2dEfeb8qb/m8tUH4fZqFXHxWhC81WB6l74mX/zbts0Ufb9ol1ySdYcOEcHi/lp3woV24C/c2sPIiJq0yS4peXB/NAoUWzpPn7Zo0+rwKseu7JG8U3bMNMBCETAJ4ZR7036L19toVHvreYuq1HIjJXm/JaVaNU09QlCUJTKSw9m5vr3zs5eaGXaQiQLy5Gq8c9BTwhEwpDSwOKwIHFN7Tfsri3UW/Nkd/LUotcMKIQZEd6KguDW/Nl2/GJQn89MhKXsu6n4Xmk0CETCzDUfrKHWkxdQflGp7PuMfJefwfjwrl6Kn/PtW7orvo8/2K1tWhZiAuPbfvwiHSmplEyCPItlAJ+W7uMDkb9e0Vbz57vTR88qIqLiCv7nNmmMY7t/v5w0zcZkFHO3n+SOh7ZrouNItIVAJMzsPunozyAs6KTEqC7NFN/n1r7SPYMykq2S1/uLzUepQyAStjYcPk83frServjnKmr/8kK32wcIEh7HdmtOV3bOCObwTKFUUHb9Ng9/u2q4Ny+biIiiZcyy9n+D/7nlOHtcVdn83/prFh+v4ovtjVdYzdpMEIiAIr76yyjx4GXqdpDkAxFMs4erOz/byB3X2xnRrIhrNd/37+hJDw11/A5aQ3Q3gj8W7DrDHWc18t7YMhANzp/NhiPnFd0v3dnDSmlVVjPqk83P+oTqjhkiBCIQJFJfepT2q/GFzV/BjEh4klqSy31xAXfc4x9/iG6LiozgAhBbvR1N8EjdxHRfvnXWc/mz0HuOiOuY2J+ZsChiqNp6LDzyZxCIhBHXkshyGk4JKyz2apXq93O7VgQseH10wGXiXbHfGJB4GJ6EW06FGIahskvSvY2EW9Hl1rMIZcFMVL2uh7waQuerxB16Y7jgMfRnRFhpIbxjhgiBSFgZ9s5K0eVOryzyeR9hx122Toc/+uY0oh1Tr6KnRraj7VOuFNURUAtmRMLbI99sk7y+9eQFNOztFaLrxg1wJEjGx/Bbvbdj9wYdKeG/rAiXBbRw4mK175OI6IBLMUX2vcMWQJ8aMzhVyjcKnTGut44j0R4CEZCtTRP5hcykpMRF01Mj21NaQoxKIxJDsmr48rUb5qJLfshTI93r17z2+15Vx6QXu52hihr/ulv/bydf2v1pif9HapLb2uGuzzZxx22bJoqW00KZcBYvPUHdxH6jQSASJg4VV/o+yeTYQKQeyaphp8YlcXHnq1d5PPe923tSkyT3N3YlFYONauOR85T74gLq9uoffs3w7BBs6x/SrrGKI3P3wJDWft2PyxFpCO28nqOCpfQWaXE6jkR7CETCwMWqWhr57irJ27y9WZX7+a1KL1wdETsT1KQ70N+nq49wx69c05mSYz2vqd/QS9ztuZVzZ8iQttp+8AbDHZ/yu4Zu/Gi9jiPxTdjeQckspjWaX9atDeHZz8e+5ZcaQ71aNAKREFfXYKdery3xePufhRc83tb9VX6XwY5XPH/DNAph8msov0GBu28FHXW7t3RUoDz0xhhZ92WTsM0+1W+22QHh1mBPycRShFutQz1PJFwgEAlxAyQ6VvpTCkTrfhNqiBEEIlieCR+uH8DtmiYRkSMw/fqB/qLbFj811O3+0ZH8VL+ZfbbmiNt1rktW3gh3yAWjcaQw5+zYeenEVeHP9vL2jsqiUREWrhyArSE0d86cr7TpPYSgQiAS4i64bH3b8cpVtOCJy7jL/1lzNNhD0gy7NEOEQCSczFpfKLosDJova9eEfnlsEOW/ciUVTh9LHZolud3/tx2niIjoq/XHNB2n1qSax+0X9CrxRbhD7pVru6gyJrmEFUSF8k+UcsdvOVtFWCwWfgtviM6ICLudhwMEIiGqtLqWcibNd7s+KTaKOjVP5i4XV0hH3nK31hlJZISFm+0x+7dbkG/2eu/BdO9WaZQa73mnFlsY64zJ+tAUV9T4XI7515IDfj02O/sQLJ6eb4FgF09KHB9gclt4Tb6c5smWY/yS+W+PD9ZxJMGBQCRE9fyHe17I5e2bUITM7rlfCr5l/vLYILWGpSmLxULREdjCG26ESY/+eGpkOyIiurqb8j5KellRUEz931hGT/6QT0REH608JHneqgMlQRyVcmyvnwgP68XCrf6xgiTVOOexnKKMZsMwDJUKtpvnNNZ+mUxvCERCDMMwkjMhRESv39BV8nqpD+3PBEs23U3UfppdnkEgEh4KzlSI3rRH+9GUMd35YWemjVYfrXAEHv/bcYpOlV6itxYVcLfJ6WZrFGxAUV0rHUwu3H1a8vp4q+N+VR7uZ2ZfrCsUXfa2AyxUIBAJMZ5KNL92fRdRlrqwvPLC3Wek7sJRuxS7lqKj0PgunDz/3x2iy/5UoGS/aZupiZowuXPQ9OWi2+4fnEN3D1QWjAiXeG7q3cLLmepKYAMKD5102W7hrtjtrFUhWJZfWFivS2aylzNDh3k+YUCWw8VVktffk5cjujwwN507fuL77aLbiivMtVYuFIWlmbCy40QZdzxhUA5Fylx6FIqLMdc0/6oDJR5zu4iI2mUk0eguzYmIqHGivIqcwu2zQ9sFLz8kyflt/2Spspy0BGdp/soQC0Q+WHZQdPmWPi11GklwIRAJMW8s2Ce6HBcdSXMlcjzu6Jcluizc5tf/DX7L732Dc9QdoMZisDQTtqZc09mv+8WZaEaEYRga/8Vmn+exS5TnKm2y/haEH+gJQSyete7QOSIi+nHLCbfbhN11Hx6aK7qNnUmpNknwKNc/XZKL7x6YrdNIgguBSAi7Z2A27XttNPVq5d68KiLCQlmN+LLBf/vJMcW995R4KnTcAHP9IWBpJnz5MxtCxH8rL1dQVEsvrScv8Hp7hwzH9uQGwVKL6xZ+KcIZkWEdgjcjsueU9NILkXiZ+dmrOohuY3fN1IbQrhmpHVDRJloWD0R4vMowMfmXnaLLo3wk7l0mmIL9fedpstU30NX/XiM6x2z9N9D4LnyoVcaf3RaqpLqnUbFfLqzR/Fu7nACLTQq1RkUE9cPPUwI9EZ+QS0Rc3RDXy6H0dz5vx0m9h6AbBCIhouhCNX2/uUh0na8viDe7JKV5+3ZiFlERWJoJF8LZgcsCaNDGBiLlNfWG7lEkr0qq4/e/QzM+yfFcpe8ZkRkrHAXFgl2XIzudT6B3nREQ5v+4YpeeQqGOyH+3nqDrP1xLT/+ww/fJIQqBSIiw1bu/SfmqGdInu5Ho8k0uTbJapJqv42MoflMC3z68S/luGRa7FbTBzhi6EF7HKYtElxc/NZTuzRMvnbLlOBKtUdTRWUX2fJVxy4VXCmrAKJmRCpWZzwY7Q3/7aYdk0HVTr+DtXtIbApEQYZEoCOSpSJBca18YHtD99cC/QRn3my0Ebv8Z8eydsOqmUlGCgL3BJI3j3r+jJ3VolkRPj2xP/XP4LxTCv/hcZ7+Y8z5mRIRbYEd0bKrqOH2JjeGLlCkJKtgvHGbPEVl1QLrcAhHRP2/rEcSR6AuBSIj4n7NfhpCc3D1Pb+APX54rGdwYHZZmwsPXG9TrC8Nu+SYyT57IiE6OiqRpCTH04yN53PXCP9n0BMfWXV8N1I6e47f8PzWyvYqj9C1SMODDJdKlB6TEhMiMyP2zt7hd99vjg6lw+lhTvv/6C4FIiPhopXTTKF8ectkWx3r2yg6S1xsdlmbCQ2tB2evcADvFCmdE9p02Zp6Ua42TRA9bbC2COZH0REfF2BOll7w+9m2fbOCOI4L8idA7m9/R99JcvtGbMF9EOOPDCpUZESldM81TyVotCERChL9/kI8Na+N23UfjertlqZsFlmbCw+vz+Xo5X93fP6DHEuZSxUZFejlTP8KlqKXPDPV4XpxgqeN0qaMw4S/bvO/GENbi8HcLtL+EAdWpMj5gEnYNnnVfP7f7sX/ntSb+O5cqa//a9V1k9wMLJeb8tAHVSE3/Xd2tuQ4jUQeWZkLf+sPnRJdbpsV7OFO+HlmpRERUpVKBrHOVNo/9U/xx7+d8EbO2TZPcbn/thq7UISOJXhjdkbvOn8Tb9hKPHSw1dfx4hU03pQqshcKMyJNz8kWXC6ePdauAHS6CV0IPNFPsoX15s5RYxY+16cURgQ5HV1xBMxO/QYF3d322SfXHTIjx3nxNLoZhqO/rS+m8s4jY4TevVmWWocJHKfN7BmbTPS5VOG/t25Lmbj/JjUtOzoFRvo3/sKXI6+1m3zVTXF5DS/ae5S7HhEnhMk/C+9WHCOEa7yvXdKafH82jz8f3lf1Nka3B0DTJShnJyoMXI2H/oOtNsvsBlHGtpTFhUI4qjxvv7F0SSMnwKls9tZ68gAtCiIjavOi9EqqW2KUZIvFSRygw+4zIey49ZeZOdG/DEU4wIxICCgWdOO8bnKM423rWhH5UeL6a2gSY9GcEbKEjI9eDAP/9/X97RJenXutffxlX8TFsF1j/Z0S6TF0seX3BmQrq0Cz4Sx7DBVtxP1t9hN69vafbOUYr4CZ35sbsPaUOna0UXe4ShgmqQpgRCTH+bPmKioygtk0TQ2K7WBQ7ZVtvrDdYo1q+/6xbfyEjE1YP/uDOXqr9zgbaRG39oXMebxv13mq/HpO1aPcZ7vjju/vIvl+jhBju+ECx9IxIaTW/XfnbvwzwY3SB+8f1Xbjjg8WVsoIjbkbEpIHI5sILeg/BUBCImNzuk57LIIejUKkvEAwbj5yn+2dvcesvZET5RaWUM2m+6LoRndQrvhXo0sxd/1E/b4U1bSG/Q6hbS/++OV/TPVPy+q838vVY+klskw2GoYKeV6sPlIiSVj3hds2YdGlG6IsJffUegu4QiJjc9uMX9R6CobBLM3V2879BaenY+Sq649ONeg9DthtmrHO7jg0e1BBIsqpU0Lvib8MCHRLnmGDptbnCHC62BsdCwayK0LuCtvPs306w5Qhqwrw+fx+dLvNe94TI3F84XMd8RccMnUZiHMgRMbkp8/g18ydHtNNxJMaApRl5Ln97pd5DCAi73VYtcc6gpsqmfEbkT5dp9iNvXu22+6SmroFiowOvUaJ0V8vhEkcuwo6iUrfbXPtTGWVp9p9/HPB5TrSJl2Z+2nJC7yEYDmZEQsjE4W31HoLuzL6tTy/echyMaOY4/5vcSWFzRC7VKZ8ROVQsTjxkg4XpN3Xjrpu1rtD/wQWgcaKVO653+ZtQs0y+mnbJWG6OMfEXjvwifhY7yiDbpfWGQMTEXNtmm7UaqpqinX/Y9Via8aiixr2fipY5DlrIVLkzdHwAMyKvCGYl/3kr36jspt4tueMjJeJgRS5h8CBV6tyXF8d24o73nRYnrAqr017drZkfo9PG8QvVPs8xa7LqlsIL9KNgRmT5s8P0G4yB4JPLxJB57S4KJd596vbqH3oPQZGlgsJPRERv3dxd9efwN0fEtVvvzX344EP4xeCnrf5Nxy/fz3dnffhy6b5Q3rQQBGxz/jzu8bxeWWkebwuGZ69U1mzPrMmqt3y8QXS5VXrgVYFDAQIRExNOrQq/iYUzNuHOdRoazOsvX4k7lN7Qq4XqzxHH1RFRNiNSrnG33jUH+SWzwW0bK76/sDbQt5s8ByKxMfr22Hn8CmXLyjGR5pwRERrcNl3vIRgGAhETm7/rNHcs/CYWziK5pRnMiEhxrUxqdK41Jd66ubsmS5BsP5NLCv///LbjlOpjERJur7X68bpdE1BdZ3BYIzqqtxXaH54SZa/rIb3tOCbKfAXNXP/23ru9l04jMR4EIhBS2KWZeizNSBLu8HCtpGu0KptERNMX7hddvq1flibP429l1am/8fkhW18eqeqYXKmxq+XV3/ZIXh+nwo4eLVzhIUCKiXSM10xLM8K/vfF52dQkyerl7PCCQMSkjPihYQRIVvXuHkEX11kT+otuM2JezSerj3DHL13dycuZgUlQoddMeqL7B8uMu9Td3eMPYW4JO8NSWl0rOic5LjqoY5LLU+wVHcUuwRrvd9YT4d+esHYKIBAxrb2nzVOWO5iQrCpfViPxzhOjr7ff7dJdVk3cjEhtvapBforgA951l5svnpZRlHpgcGu36x7/brvoshodgtWWkx5Po7pI7+aJiuBzRMzwpcz1Z49tu2IIREyq6AJfffCbB/TpEWFEXLIqZkTcuG7btVgs9PYt/A4Um8HzR+I0TKiMd+aIMAyRTeZ0v5x8m86ZydzxNoVVkIX1NLID2F3R2GWmptJWT2sNWDdm3sTBossrnxvusQgcm6xKpF7ApqXpi8RLjC0bYbeMEAIRk3rkm63ccf/W+vSIMCL2mx1mRNxd8c9V3HFeriNjX9hfRO4HcLAcEjRqu72vNrkhLGGOhNw8kf1n+PHd1Ft6J0+8IHg6VVajaEwbj5znjt+9zf9dca7VWAvOiGdTu/vZv0Ztwmq5Y7s193pulKAcvRn+1j8VLDE+NDSXhrVv4uXs8IMS7yEAhcx47JStGb4lBVtJhY07/vedjox94Vq10QKRke/yXWu1rhocGWGh2OgIqqmzU3VtA8nZWPnvZQe54+dGdZA8R/iNflVBicddIFJWFvA1RHq3CqzOR8u0ODpx0TGL6pr0+t9HBgX02GraOHkEnau0UdcW3oOjaMGMSJ3dTnFkzGRbIqJdJ8SVYl/UMNfJrPAJBiEFdUTkEWbss1P3rr1HjMQ1n0ULbMJqlcyiZsJiY8mxvpM9f96mrKjZxiP8LotAd8yIKr5+tF50m5G+yDRLifUZhBCJG/TVGSyAdnXth2v1HoLhGec3EPySGm/MbHe9IFlVmrfALC7G8f8skB0jWgtGQ7Z4K1tdVfn/B7YOiVG1y0jSewiqslgsXMKnUWsG1dbb6W6X1gkbJ4/QaTTGhkDEhLYLkt66yfj2EE6wfVfa+sN8vkEPl5yA1LgYInLf0hluuC28fvSbMbpGCTGS1392b98gj0Q9bJ6IUWuJPP1jvltScLOUWJ1GY2wIREzoRsHU6nQN+m6YGVdZFTMiIn/5ki+T/vDlbUS3pTk/pC5UaVuuXIlVB0q4Y0/5F2qLE2zh9aVSYeEzpbR4/DFd3bfCXtk5Q/XnCRY2T8SIMyKl1bU0f+dp0XWYvfYMgYjJtVC5C6nZRTvXu42WeKk3YY2QEZ3E1SobOd8gL1YZZ0Zk/Bd88ae7B2hXP0SIL2rmOwj4dftJ7riLYIuuWu6bxb/+h4cqb3Yn5aNx4uJqT45op8rj6iWaW4Y11t/6oeJK6vmPJW7XY1nGMwQiJmO2XiHBxiYNSrW6D1euBZ+sUeIdBmxezbebjpERpQTpm2R8jPwckR/+LOKOp1zT2eu5uX5U0fyzkF9+VauQm8ViobZNE7nLTyvseGs0bMKq0QKRke+ukrzen15B4cLYGVbg5vO1R7njeJ07ZhoRm8BmwNla3fy4hf/QbJ+R6Hb7f50t6gvPVwdtTN4UXdBnHGzCqZwcEWGxsYG53jf7vn1rD7p5pmM5lWEYxYm3LdPUm/Vc+szldL7SJlmO3mzYrfpGSkw/dr5K8vr1k64ISsK1WSFEM5m3Fxdwx18/0N/LmeGJzRFBHRHeCz/v4o4fHdbGy5nG8H+CKpTCPilaU5IjooSwueC5SuXLX2p/gIVCEELEbzs20lb9ZfuKJa/PxBK6VwhETCzQIkehCIGId9f3cK8A+n83d9NhJJ79Lkjyu7a7/AJggUpwBiKXVN7GnBrP71g5W66suip4xs5+GqlH0qGSSrfrjrx5tQ4jMRcEIiaGqT537JtTgwkaYQWDa36Ia7lvIqLcJo7lmtYG7Agqp7iVWuIVFjQjIpo8pqOi5/jnHwU+zzHSN3wj43bNGGhp5rtNx0WXC6ePlfybA7GgBCIzZsygnJwcio2NpQEDBtDmzZt93wncmKHLpN4iBDMi+P9F9OHyQ9zxVR62arJv6EatxxAsCWxBMx85IsJOqkq3ZMqZxVxz0HgN6YzIqMmqrCVPD9V7CKaheSDyww8/0DPPPENTp06lbdu2UY8ePWjUqFFUXCy9lgaeFZyt8H1SmBO218bqDNE/lxzgjj+5p4/kOWwnUyNsedZzSS1O5ozIwt1nuOM2TdyTf735bccpn+cIlxo+vlv6ZwaCmkEG+UPfeaJUdDnUqtlqSfNA5N1336UHH3yQ7rvvPurcuTN9/PHHFB8fT1988YXWTx1yRr+3hjte9dww/QZiYMJpUFRXFfO0lMcm/dUaoNfML4J+LIF0nPVHgsztuxO/28Yd98lWlqd1sNg9h8CVMCBUc8dMqGG3nRslH+wDwewjKKNpIFJbW0tbt26lkSNH8k8YEUEjR46kDRs2uJ1vs9movLxc9A+kZacbbz3fCIQzIkZ5g9KL3KUptr6BEbZBChvJXd/TPbFWS/FcQTP5AZkWeVqfCVrGRyK/wCP2b90oSzNL9p7ljpujlLsimgYi586do4aGBsrIEK9NZ2Rk0JkzZ9zOnzZtGqWkpHD/srKytByeqSDfQZ4ICwIRlqethK7YVvU19Q26J0oKlz2C/SHM5ohUaVBePUlBU7wTF/k6KilxKAvuiZFmRFzfnxcjP0QRQ+2amTx5MpWVlXH/ioqKfN8pTKwU9N4QVkcEMcyI8P7yFd9fZv4TQzyexyZcMgxRlY4N39bqnKQpp7JqWbV/FXsrFAQ3FwXPgfoTnhmp+67rz5et8AzyaFpZtXHjxhQZGUlnz54VXX/27Flq1sy9AZPVaiWrNTSK7ajt2438trCP7+7t5czwFolAhIjcv6F1yfS8DTY6MoIiIyzUYGeopr6BUkifN9G7P9/k+yQNyVmaKRe0DmicKN3RVkrn5sm09zSWmtVkpAaXwt5DoJymMyIxMTHUp08fWrZsGXed3W6nZcuWUV5enpZPHXKW7uODubZNkY3ticViITYWCedAZMOR84rOj3XmiRill9GchwYG/TnlNL277K0V3PEVHZt6PM/VB3f14o49lQEHZdjtuw0GSEp/Zd4e7tjb7CNI07zXzDPPPEPjx4+nvn37Uv/+/em9996jqqoquu+++7R+aghTURERVNtgD+uiZsKERzlioyOpqraBLukUiLguefjq36KFOMHSjN3O+CxEdZeCrsBpguqqlV6WaYwSCJpBpLPXjBGWZoS8zT6CNM0Dkdtvv51KSkrolVdeoTNnzlDPnj1p0aJFbgms4BkSVZWJiCCiBmNM2eplRQGfU5T/ypU+z+cSVuv0+XbZ4x9/6PK8QmyyKhHRpboGrgmeJ1EKkmkbJfCByEcrD9OMu6SXV38WbF8G76IMtDQDgQlKsurjjz9Ox44dI5vNRps2baIBAwYE42kN7WJVLU1buI8OFfsuUvatS9lg8I7tymlHAEdE4l4nnlijg780Y7cz1P7lhZQzab7o+pfHdgraGIRioyKJ3XQlZwsvW5FWqfmCXjqu5mxGgr5cRklWPXoOS22BMtSumXBy08z19MmqIzTy3dU+z335193cce9WqRqOKjSwdTH0WmbQ25bCC4rvE8fNiATv/9kHyw9JlpW/Ny8naGMQioiwUHw0uzzje5dL+wz1d6/tOlnGHf/r9uAWdDObKIPkiFz/4VruGPkh/kEgooMGOyOKojcc9pxY6LosM/v+/pqNK1Swa/16LTPo7ZaP+WKBTZLk7UIL9tJMfYOd/rX0gNv19+Zlc5Ve9cCVeZexjVnrppPINfAukitopu+MSHkNH7R2apas40jMC4GIDtq8uEB0+c7PNno898BZcUlo7E/3jevAa4Bser29fUt3WefFRrP9ZoIzI/KJh2Taf1zfNSjP78m5ShsREW06qmzXkRbao1eJV+wSrJF2x6HTrn8QiBhcsD4YQomR6gsEm+sMWudMed/QKpzf6s6W16g+JilvLy4IyvP46+//2+t2nZpJ41JLYEhKV4Yr8a7jF47TZZd0e+5QgkAkyLYfv6jo/G3H+PN//yvWH+Uw4jelYFl3SPxNvmmSvJ4XO084chNmrStUe0iyWKMiaNerV+ny3HIdLgksKfGDO/laIs/+tMPtdmGCbHZ6fEDPFQ4i2RwRHb9wPDCbr1485ZrOuo3D7BCIBNmNH62XvF7YX0LoVcE3s64tsGYsh9HagwfTp2v4JY/WjeU3RmznbBvQN6eR6mNy5frNv3D6WCp4fQwlGXzZceS7q7jjuwe2Unz/js34pRapnTOv/sYXxVr8FHqV+BJtgDoiwmq59w3K0W0cZodAREfCUu2j/uV79wzIw2fTh1cgUlPXQKsFPYkWPXWZ7PuyVUKbJWvfYsFTfogRsP8ffAUafbOVB2y+ekT9tJWvIcImD4Nn/BcOY+SCIT/EfwhEgqiiRlw9Mq9NY+64SqJuwSXBdUq6d4a7cJ0RufJfq0SXrVHyP8zYnSpS22nVNn3hfu74/Tt6av58SnSTOet4dbfmih/bdZdNSYWNOz5faXM9HXzgk9L1+TsvuiA9iw3KIRAJom6v8tUjv39woM8W38Ltjb88NkizcYWacN01U3TB/8S5GGdxrtqG4P4/u75ni6A+ny9sdVVfBc3U2GJcdqmWOz5fVevlTJAS5fyd1Sspfasgf2/i8Da6jCFUIBDRycBc31O7nwqmsNthK59s4TojIjTrvn6Kzmc/WG1BmBExsniujojvgmb+mDSmI3e8/wxfVXlePt+99Y5+WZo8d6jRu7LqD3/yVXBv6t1SlzGECgQiOmGnaXOb8AmF5S5LN+CfcNw1U+yy7XZ4B/mdYYmCtzSzoqCYO+7e0njJ1+yMiGtBM7WWToQdex//bjt3vKOIr6h690D5zfTCmd5fOIQdrnMVJIaDOwQiQeJpPfGHh/K44/9u4ZPVsD/df+FYR+SjlYcDuj/bN+VQcaWPMwNz36w/ueN/39HLy5n6iHB+QVh76Jzo+rnb+RmLKzv737CznYeEVeHzdZFZ+yXcRRukxDuR9lV2Qx0CkSB5Y/4+7vjZK9tzx8IS3P/4nd+qOzPAD5ZwpncSmx5mry/kjpc/e7ni+xc7EyeFywVqc13uaJkWp9lz+Wv78VLJ64U7fd640f/qr64fWOU1dbRb0F9G6hyQFumc+dS7xDsEDoFIkGSm8m+69w1p7fP8rzYc03I4IU3vKdtgc92NldtEeTM2YY2LQJwsvUSfrz1KlRI5Fq4zVFF+dq/V0qA26dyxMHAS7nCRWyROjrs+20jXfLDW94ngRs8vHMJaOMLlNvCP8d4JQtQX645yx4letuLWSexayEGVRUWM0pUzWNQIWlPjHTu4PC0dyDV4+nJ67fe9NPDNZW632U1Qwly47FJ6SZucrR5Zqdzx7pPlott+nThYk+cMRezfuR5fOM6W84HpeBQyCxgCEQMQFp66WF3rljD4n/HKdkCEu0gDVFwMJuFywu19/dtxwXXfVam3kdSMyHUz+G/+6yZdocrzqM1isVDjRMdyaWk1v6W2f2vHLjc1Zo6+fsBzB+2egiAFvONzwYL/hUOYSzW0XWMvZ4IcCESC4JKPmgQdBFtz//G/vVwHUJaviowgFm45Ikv3neWO7xygvPQ4kaPXCxGRrU69N3XXgFpY56RFqvHyQ1js39+K/fwOHzZr41Y/Az0hdNBWB5tgrccXjtec+Xx9stOQ06MCBCJB8Nfv+W16/7m3r9vtwl/k33eeputnrOMu5+Wmu50P3oVbjoiQv9+o2SqsgdQRsbv8/y7QMPE1GN75gy8ouOnoBSIit8RSf82TWILZ94/Rqjx2uIjU8QtHwVnH77awqBn4D4FIEAi/sY6UsfVPmBj3/UMDNRlTKAunGZFDxep82MdGO94KpNrTy1FRU0e5Ly4QXXfth6GXhHmmrMb3STL0yEql4R2acJfnPzGE4mLQX0aJKJ2WZoS/A0PbN/FyJsiFBiYQcsKpjsieU3yy43cPDvD7cYQzIgzDKJ5unrWuUPL62no7xURFiDrXmo1wFuT1ALbuupp1n+dcEfAtSqelmTcX8KUYnh/VIajPHaowI2IQ/7q9h9t1wqqrIF849Zp5ae5u7rh3qzS/H4edESHyr9/MQQ+F0N5fdoAYhhEl9/UwYEVVb+bvOs0dt07H36RR6DXz+cfeM9wxis+pA4GIxtYc5Nuy//WKth7Pu0Gi+deCJ+S3cQdeOO2aEe5OCaR1vLBTb40fCatHSqQDkRkrDlPryeIlmydHtlP8+HoSFhdEq3fjYGc+pUoeaEn494FEVXUgENHYPZ9v5o6fGtne43lSv9CBfLCEM76OSOgHImqJjrQQ+yto82MLr+tOL28ub2/sAlBSs5NgPNH4Ow8ZCESCKNLHt6nNL40gIqK0+GjaNuXKYAwpJIXzrhl/WSwWimXzRPyYEREWeBrc1vtOL19/B3rrmcUvcR0/L90jCvSnd4n3sd2a6/K8oQiBiIYYhZUkmybFUuH0sbT9lauoUUKMRqMKfcedDQaFa7mhSDglHUj/E5bVmSfiz4yI0Fu3mHtGQVjJ+O0/CnQcCXijR46I8LleHNspaM8b6hCIaGh7USl3nNXIuAWcQs38nY7kQmEBrVD00Qo+d6F9RuAVP9miZv7kiAi1SI2jO/tLF1br3So1oMcOBuEy6f92nOKOsVXTWPQo8S4sxdAsWb2eQ+EOgYiGDgt2Crx1s7m/JZpJ/5xGeg8hKGauOsQd91PhNbM5SUpnRM4L8kPYUuhvepih+fnRQX6OTn+vXNNZ7yGAAFdHJIi74x7+eit3bPQlRjNBIKKhwvNV3PHA3PD4cDSCm3o7diCN7OS7eJyZBTpz4crfMu/sUhgR0UOX5RKRY1YhSuKN2sy7DNBqwVjYHJGGMKgXFOoQiGhohmDq3MxvwGYTqcM3pVDgb5n3efnSyxeH3rxa1M030M6+AEJRSEoPGQhENOJvqWwIHLbv+sffMu8rCvjmcDFR4reUJc9cTrf0aUlE5qsfAsbG54gE5wuHsMLuA0NaB+U5wwVKvGvkCUGjOwiuKG5bX3jMiFymUhtyf2dEjvnY4vr2Ld3puVEdKMPEyX1v39Jd7yGAi2Bv07/mA7530tNXeq4JBcphRkQjf+zls6tRITW4wqHpnbCi6hs3dFPlMWP92L4r3KLeONEqeY7FYjFdEDLrvn7ccYvUOLq1b5aOowEp0c4vHAzj3vlZawloUKgqBCIaqKipE13ujH4EQcU2w9Kr0FEwzNl8nDtuJah7EQh2RkRJEuwlwTLOlGtCp67C8A5NuYD2nVux482IIiP5vLu6IOeDIedPXVia0UC3V//QewhhLRxmRF6fv8/3SQqxSzJny+W3uv9+cxF3fE33TNXHpKetL19Jxy9UUzeTNekLF8JdWVr/rR8T7IAE9WFGRGOjuoT2FlIjYpPYwiVHRC1ssab/rDkq+z6v/b6XOw61ugop8dEIQgyMzQUj0j5P5Okf8rnjfjn+d7kGaQhEVFbusizz0bg+Oo0kfEWGwYyIFtgeMb1MUP0UQDgjUq/xMuy246XcscLOHSADlmZUcqm2gUa9t1pU3Iko9L4lmkG0M0ckVOsLCLfX3urcGquGga3Tad2h85TbJEG1xwTQSkSEhSIsRHYmuDWDLmuHUv9qw4yISjq9ssgtCOnUHEmqegiFgmY7T5TS0LdWUNEF962xwnoGA3K9d7pVItpZA6S2PjQDOAg97PJMMGc/b+7TImjPFS4QiKjgTJl0ct/vfx0S5JEAkaDiokl3zVysqqXrPlxHxy9U02VvrXC7fd/pcu5YzRyk6Ehl9VeEb/5m7iED5hWpw996yzR1dqkBD0szAbpU20ADpy2TvA3LMvpgvyWZbWmmwc5Qpa2eer22xOt5U+bt4Y6TYqNVe/4YhUm+p8v47sbxqKsAOoiKtBDVafu3fqo0tLt4GwECkQBNWyi9jXLD5CuCPBJgcaWfTbRrZv3hc/TA7C2iuhysmroGrjOulpTOiFTX8mPt2CxJkzEBeMNv1dfub/3qf6/hjp8cgTYFWsDSTIC+2nBMdPmtm7vTnr+PouYpcTqNCMzYDOuhr7ZKBiFERB+v4psnuu7KUhMbiNTKnOb+dftJ7hgFnkAPkRHaFy8sreb/5h4amqvZ84QzBCIB2HTkvOjy/93cjW7rl0UJVkw06YlbmjFRjoiwZLur95Ye5I7HfbaJO3712s6qjoFNVq2T2WvGU+AEECzRQW5wifd2bSAQCcDtn24UX+7XSqeRgFAodt8tqbAREdEuwY6ZO/qr+/vG5ojUylyambWuUNXnB1CKzcND8UJzQyDip/WHzuk9BPCAXZoJdv8JLfV7Y6nbm63aeSPst73KGs+zMwBGEg7tHMIBAhE/3fPFZtHldk0TdRoJuGKb3unRlVMta54f7nbdmwvU7y8jxO58qVHQfRdAT1EaFy9cWVDMHf/0SJ4mzwEIRPxitzNuEfi8xwfrNBpwJdw2bYZZkb2nykWX174wnLIaudcqEC6FDGnbWPVxsN13bTK67wp3JI3shH5KoA+tawZNmPUnd9wrK1WT5wAEIn7ZXHjB7br4GCQxGUV0ZPC6cqrho5WHRJfZgklv3tjN431m3ddP9XFYncmqNhkzIiWVNu747Vu6qz4WADm0rKLMuDSVYWdfQH34P+sHYcdRIqIHhrTWaSQgRTQjYoKdM7/vPM0dPzasDXd814BW1D+nkeR9ojV4U4zhSrz7flO/WOXY0pgQE0lpCTGqjwVADjY40OILx0zBtnnQFgIRP+xxmUp/8epOOo0EpAjbgxt9RsT1Q//50R1Fl38M4ro0tzQjIxBZsMsRPFXVIp8E9MMlpmvwheOtRQXcMQr2aQuBiApQyt1YIiMsxNbXMnp11dnrj/o8Z8KgHNHl7VOu1GQs7NJMvUQOlCtslwQjiAzSrpnXbuiq6eOHOwQiCqHvgDnwVUKN/YGZX1TKHafFS/eNefW6LtQi1VGp951be2i2FMIuzRD5Xp5Zd9ixfb1NkwRNxgIgB5sPpnaOSHG5uJFpPw9LpKAOZFgqtGx/sejyqueG6TMQ8MoaGUG19XZZ+Q56KauuowW7znCX5z7meefVuklXEMMwmpZStwoCkXOVNsmdO6zdJx3Lk4dLqjQbD4AvkRpVURYuOSbH4mNSa5gRUaC+wU5Tft0tui47Hd8IjcgabfwZkf9uOyG67O2Dn0j7fi7CXQErD5Ro+lwAatCqoNkLP+/kjh++vI2XM0ENCEQUmDJPHIT87ar2Oo0EfImJlL8DRC/TXAqUGSnXqHPzZFnnvX9HT20HAuCFVg0uNx/lSzQ8ikBEcwhEFPh+c5Ho8uNXoCW0UXEN3Aw8IyJ88/zq/v46joSX29gxw+frGyZbhbVHy1SthwTgUZQGOSL7z4h3RUYY6AtCqEIgIpNrcRvMhhibltv6tDC0fRO9h0BEgiRfLzNJ5yttVO1cQ2+abA3KuACkaNFpe/R7a7jjZ67E+3wwIBCRac6f4tmQB4fm6jQSkIP9QDXqjIgwsE03UEEwrqhZg+f6IMI6OqgoDHpSO0fE9QvnEyMw6x0MCERk+sSlyh5b/AmMiQ1E/Pmm9P3m43Tlu6uouKLG98l+OlhcyR3/8fRQzZ5HKb66quf/b2p3/QXwV6TKnbbPVdaq8jigDAIRmTKSY7njP18aqeNIQA527VjpjAjDMDT5l110sLiS+r+xTIuhERHRVf9azR2nJxpneSNGRv2VPyV6LQHogSvxrtLSzHpnfRwiout6ZKrymOCbZoHIG2+8QYMGDaL4+HhKTU3V6mmCZpMgi7pJknE+OEAavzSj7A3KLDklWpHTb+btxQUebwMIJi4XTKWlmZOCgpX/vK2HKo8JvmkWiNTW1tKtt95Kjz76qFZPETS7T5bpPQRQyN+Ki4Xnw7tAl5LGdwB640u8q/P7Kuwvo0VjSZCmWabZ3//+dyIimj17tlZPETTvLT3IHaOktTmw2fRKZzhWFogr59bW20Wlz9U2pG1jzR7bH3wg4jlZtXFiDNbSwRD4LxzhPZNpdoZKebfZbGSz2bjL5eXlXs4OnqX7znLHEwa31nEkIJe/u2beXLBfdLm0upaaCvKD1HBJUD76dYM105KTI4IgBIxCzRLvVbZ67vjlseioHkyGmnuaNm0apaSkcP+ysrL0HpKbqzpn6D0EkIH7phTg9l0tPnQ3Hj3PHbdMi1P98QOhpCLtTb1baD0cAK/U3L47f+dp7vjGXvjdDiZFgcikSZPIYrF4/bd//37fD+TB5MmTqaysjPtXVFTk+05B1hSJqqYQ5Weyqquz5epv4V24i3/DizLYOjRfR8Tz/ze2E/D4vJxgDAnAIzUrqz4v6C/TyEC1fcKBoqWZZ599liZMmOD1nNxc/wt9Wa1WslqN9UHvGmlr3XgM1BHt5/ZdVzV1nnMl/BVh4N8hX8mqDMNwOwsS0ZUUdMb1mlF5txve54NL0TtJkyZNqEkTY5SiDpZNR877PgkMJ5pdO1YwZSvcusf6fedpGtOtuWrjIuKr9Box8dlXIHJGMEPUKB7fGkFfkX78nYPxaPaV5vjx43ThwgU6fvw4NTQ0UH5+PhERtW3blhITE7V6WtWptT8dgis6yvGNRsk21D/2nHG7bv6u0zRDtVGJ3T0wW6NH9h+frCo9E7SjqJQ7TsP0NeiMnflUq8Q7EdFfhmBDQrBpFoi88sor9OWXX3KXe/XqRUREK1asoGHDhmn1tKqLFWzd/GJCXx1HAkpEy9j94SolLlqr4XDsgjfM3q3SNH8+pdgZkZo66f9v/916IpjDAfCKK/Ee4BJsSQW/W/OO/q0CeixQTrNMudmzZxPDMG7/zBSEEBGdr+J3TVzRETtmzIL9QK1TMCNSdMGxNJMUG8UlZKrtXBX/hte2qfFmBveedmyZ9xRwdG6eHMzhAHil1q6Zhbv5BPLkOOQ+BZuxUvYN6Og5R6XNm7Cdy1SsfsyI/GvpASIiqqipp79e0ZaISPWAZOEufvknwWq8N7w1B0q83r54j6OmDnaPgRGwu84CzRF5Zd4e7jg9Ab/bwYZAxIdftjm+GWanGy+xEDwLtFR5c2cAovZyzdTf9vg+SUdTr+3i9faCsxVERFQsmMoG0EtkhDr1gqQeE4IHgYgPh0scMyLHwrwHidkEGojEOVvda7F918hapccTEVGO878ARsZt38WmAlNDIOJF2aU67jguJlLHkYBS/iSrCsVGO+5/KcwCESWVVQH0xi7NqLlrBoIPgYgXv+88xR0/P7qjjiMBpZTOiAjfyCaN6ajJjIhwLP+515g7sPjKqghEwPjULmjWMytVlccBZRCIePHS3N3ccTC2doJ65DRvE9p1sow7vqNfFsU6AxE1Z0QWCeqUDGlnrK67LKszELFJBHAMw7/Z98023tZjCD/80oz/gbPwC8L0m7sFPCZQznhp+wAqUDoj8tGKQ9xxqqBiaE2dnWrqGrjAJBBPfL+dO1bj8bTA/n+rqKl3u+3ERb7y7OPOXUUAeopSoaDZ24v5/mhJsfjCqQfMiEBIUprrIKwXQ+SYAWMf41xleO4QKauuE13ec6qcOx7UxpgzOhBe2BLvgTS3/GzNUe5Yq/pB4B0CERkaJ2JfudlwBc1kLs1sPXZRdNlisVCC1bk8U6t8eaamroFWHSjhljPsJkmmy0zh34hr6sWvu1lKLHccE4W3DtBftEoFzUBfWJrxQLge/q/be+g4EvCHr1LlQp62ZsfHRNHF6jqq8iMQ6ThlEXe85OmhFG/A4mVSIiIsFBcdSZfqGsjm8v9u/eFzOo0KQBpX4j2AHBHQnzneHXWw/jDfdbdvdiMdRwL+SHPmeVyorvVxJtHDX2/ljkd14cv4s8Fotc09X8Ibm8tMwpX/Wq3o/nqLjY6gS3UNbjMiby0q0GlEANLUyBFJiImkqtoGemJEO7WGBQphftWDbYKperamBJhHfIz87bf7z1RwxxcFeRGnyhwt7xdJdOX1pt/rS73ebvQdWGwireuMCIDRRDlzRALZvsvOeHZrkaLKmEA5fMJ68M8lB7hjiwUlf80mTkEgIvTgZblu1ynd4VIuseNE6OdH8xQ9XrCxr9d1RgTAaCID3L57spTfCbbvdLmXM0FLCEQgJLEFyeoaGEUtwq/szC/NXN8zk4iUNXgT5hZJGdO1GbVtmiT78fRg5fJrEIiAsQW6NLNbUD+odWP0E9MLAhEfbkTXXVMSzmJ4+0AVBg59XIp0xUYpn1W5aeZ60eWWaeLtgO/e1lP2Y+mFXao6XVqj80gAvOOWZvwMRH74s4g7vqZ7c1XGBMohEJGQX1TKHSeaZLcDiFmjIohdUfNUHfWuzzbSnZ9t5C4PapMuup3NDZKz84a1/XgpdzxhUA6teX646HYz9Syatb5Q7yEAeBVoiffl+4u5YyzB6wefshLum7WZO06Kxf8iM7JYHNtQq2sbqKbWPZB4c8E+0c4oIqL7B7cWXY6NUVbm/aJLUbRXr+uiZMiGkWSNogpbvWiZSgg1RMAoAs0RAWPAO4oE4c6JO/u30nEkEIg4L0mXn64+4nZdWkKM6HJCjCMIrZZZR+RfSw94vX1grjm2gV/dzTFFbRUEHMKCbEueHhr0MQFIiUb33ZCAr/s+ZDWK13sI4Cf2m7trZdSiC9Wy7s9uAb5UK6+OiDBPVZjg+s0DA+i3HSfpjRvN0VCLXZIS/n8ru8QH58IKqwB64gqaNTDEMAyWV0wKgQiErNPOOiBbj12kHoL23sJOu97EO2dE/KmsumHyCO54SLvGhu22K4XbvitYknr0W77omzXKPHkuENrYHBEiIjtDFKkgDhH2ofrgzl5qDgsUwtKMi1IZlTjBXM5XiZvWnRLUDvCG7TVTLXNG5OuNx7jjyAjzfjNLsLIBGP+6Nx65oNdwADyKEkQeSvNEhM0sm2OWT1cIRFwsFlTRvKNflo4jgUANbd+EiIiyG4nrA7w+f5/buQueuMztOm5GxBZe9TTYBG1fhdkA9MZu3yVSvnOmQvD73btVmpczQWsIRFz8vvM0d3z/kNZezgSjS3DmeLj2fpHSOTPZ4/2Vdt8dn5et6HyjSYp1lKCvQCACBieceVRaS0TYcTvCxDOYoQA5Ii6EfUDaZxi7AiZ4x+c6iKdsm6fEcvkjPz6c53Falq35USVjaUaYtT+2e6Zf4zUKbkZEkKAKYETCHBGlO2dmrDik9nDATwhEBBiGEc2IgLmxgYTr9ls2CHn2yvbUv7XnLbVsroSc7bsVNfyHdk9BYqwZJXMzIvxryki20tlyG90z0NyzPRBaIiIsFGFxJKrWK2jlQCTuMwP6wtKMQIXCdu9gbCcuOt5ovtt8TPL2A8WVXu8fHyM/WXVlQQl3bPaCX+yMiHBp5my5I7Hvik5NdRkTgCdRkYGVeQf9mfsdU2UXKvkdM2gJbX6rDziCA/ZDlEi8JfWxYW283p9NVq2ps/uc9v141WF/h2k47IxIuXNGRPjaK5E3AgbDLs/4W9QswURtF0IVAhGBtxbv547nTRys40hADSM6un97Py4oZtaxmfccoHjBG5SvWRG2UVwoYGdEaursVNdgpy/WHuVu87aUBaAHvqiZf2XeHxrq/QsJaA+BiMCCXfzWXWRRm9/NfVoSEVH/HP7D88VfdnHHvqowWqMiuDc5uTtnzFw/hCXsr1R+qY4W7ObzplLjo6XuAqAbf8q8Hz1XxR2PRddd3YVlILLu0Dnq/MoiuumjdXoPBTTE9poRNq3bItiy54vFYqH4aHbnjPdAhK3c+v4dPZUN0oCiIiMo2RmMFFfY6IwzuZcIVVXBeIRl3uU6eo7PD7OaPKcrFITlT6DBzji6sipo7w7mEysRiCgV76yuWuUjkflchSMPpXlKnN/PZSRNnL1ySqvruF1GAEbkT47Iy3N3c8doT6O/sAxEpNiRcR1ypJq3sfrlyKukyHbg9RbMMAxDxRWOD+tQaQjH1tMpQy0RMDi2zLuSEu+nBMF1qHx5MLOwDkSEoccFQY8ZX0mMYA5SPVNYfxbKW6Lhipp5mRG5UFXLTQs3SbR6PM9MkuPEO2eIiK7u1kyv4QB4xJZ593f7bijkdZldWAYiUlNxhwU1Jb56oH8QRwNaYQOR0uo6t4z6JKu8Wn7sjIi3omanSvlvV2avIcJiZ0SOn+d3GT1yOXYXgPGwgYTSXjNgHKHxrqmCA2f57ZdNk0Jjej3cCesDbD12UVRDZPb9/WQ9RrxVujqrkHDbd6hgg7gPBWWw0+Jj9BoOgEeB1BHpgDYehoBAxGnKvD16DwFUliiY9YiNjqT1h89xl3tlycsRkVNd1VciqxmxxeCEWqZhLR2Mh80RqVOQI8IqOBs69X/MLKwDEYbBVF4oE25DrW+w06/bT3G3ya0Tw1ZXrbJ5nhHZdrzU/0Ea1F0DWrld56vuCoAeIp05Ig1+LM1Mvbaz2sMBP4RlIGIhvKGGCzbgKK2uo4G56Yrvzy7vXJLRbyaU9GyZqvcQAGSJZnNEZC7NCL+ANkrAcqMRhGUg4kr4i/nsle11HAmorbTasevj520nyO78OUuVfvckjp0RkVFZ9bXru/gxQmPqnS1eunr3th46jQTAOy5ZVebSTKVgKbVjs2RNxgTKIBAhog1HznPH4wfn6DcQUB37JtUiNY7emL+PiIiW7S+Wff+EGN/JquwqT//WymdcjIotBse6oWcLnUYC4B2bIyI3WfViFb8lvQNKNRgCAhEiWrCL76URH40S1qHkjn5ZRESUFBvNFSVTUtI53spu35Vemim7VEfs+1+o9WHZMfUq6peTRu/e1gO9l8CwuDoiMnNE2JpRLVKRfG0U8oophBjXnLtvNh7njqMiEZuFErY3Sk09P6MxeUxH2feP5wqaSc+ICJtnhdr21pS4aPrpkUF6DwPAqyiFSzMXqxyBSKh9cTAzfOpCSLM6y7yfr7Rx1ylpfMcGIpfqpGdESir4xw2VYmYAZhKpMFm19JIjEAm1Lw5mFtbvnNi9G/pinTMiZ8v5gCEnPUH2/RN8bN/ddbIsgNEBQKCinV8AauvlzYj8Z81RIiIqPF/l40wIlrAORFxd1q6x3kMAlbEzIqsEBbqkamR4IqegGRFRtxYpfowOAAIVp7DL9p5T5UREdOLiJc3GBMqEZSAiTBERbt19aWyn4A8GNLVJsCOKlakgSY1PVpV+k2PXm9lOvwAQXNHOvL66emVT3Eq28YO2wv7dc3tRKXfMZl9D6GjVKD6g+/vavnuy1PGtakjbJgE9DwD4JzpSWbJq71apRER0a98srYYECoX1Jy9DDE34YjN3uW3TRB1HA1q4o7/8ZRgpcdyuGemlmeXOmiRZjbAVEEAP7BfIOpnbd9mWDEmxYblp1JDCOhAhIiqvCa/S3eEm0Mx4NlnVVm93K5gkzBs5U14T0PMAgH+4GZEG3zMip0r5vJCUOGzfNYrwDEQESSJ5fvQfAfMI9M0m3soXuHNNWK0UBLFjujYP6HkAwD9RkfK375Zd4quqoo6IcYRnIOLEMEQHiyuJiOjtW7rrPBrQgmsS6ZRrlHXbjImM4OoUuOaJsP1nkqxR1Lqx/C3BAKAeLllVxoxIjWBnTcu0wPLHQD1hHYgUV9jonLPQVeMkq86jAS24tq6/Ny9b8f3jPSSssnkjwlkTAAguNhCRU+L9xo/Waz0c8ENYByLCaTr0mAld858YQkRED1+ey71pKcEXNRMvzVxwbt0VFksDgOBiS7zXydw1A8YTlmnDFnJv4NUvp5EOI4Fg6JKZQoXTx/p9f08zIv9edjCgcQFA4KIUzIiAMYX1jIgQuouCJ+zSi2uy6pFzKBENoDd214ycHBEwJgQiAD7Ex0hXV2WXZgBAP0rriBARvYwq2oaCQATAh3gfRc0GtMayHoBe4mIcH2M1PnrN2AXbe9s0QfFKIwnLQMSCVRhQIMEqnazaJTOZiIgeGdYm6GMCAIckq6MeSEVNndfzKgR/v/3x5cFQwjIQAVAikd0147I0U+EsaJYci8JIAHphO2zX+liaWbL3LHcch12ShqJZIFJYWEgPPPAAtW7dmuLi4qhNmzY0depUqq013rr6LX1a6j0EMLBEZ0+KCpd2AOXOb2ApcWG5+QzAECKcU9zCTupS5uWf5O+DzQmGotk76P79+8lut9Mnn3xCbdu2pd27d9ODDz5IVVVV9M4772j1tH65a0BgjdEgtEktzdTW26m02hGIYEYEQD/sUvv+MxVez8MsiHFpFoiMHj2aRo8ezV3Ozc2lgoICmjlzpu6BiGss3D4jSZdxgDkkOrfvVgoCkWd+zOeOk9E8C0A3+UWlss7rnJlMf+w9S7lox2A4QZ1TLisro0aNPCcJ2Ww2stn4KpXl5eXBGBYlWjG1Dp7FS1RWFWboW6OQagWgF3Zm0pf3ljoKEKL+j/EE7R300KFD9MEHH9DDDz/s8Zxp06ZRSkoK9y8rK0uTsew7HZwAB0IDG2jUCgomnSyt4Y5d+9kAQPBEId/D9BQHIpMmTSKLxeL13/79+0X3OXnyJI0ePZpuvfVWevDBBz0+9uTJk6msrIz7V1RUpPwVyXAUETEoYHWuLdvq+ECkZVocERG67gLoLDud76LbYPecsJqR7GhseltfbE4wGsVrEs8++yxNmDDB6zm5ubnc8alTp2j48OE0aNAg+vTTT73ez2q1ktWqfRdcfIMFJdgZEVs9vxzDbgVEUAugrzHdmtMLP+8iIkeZ98gI6aTUnPQEOltuo7w26cEcHsigOBBp0qQJNWnSRNa5J0+epOHDh1OfPn1o1qxZFBGBtXQwHz4Q4WdEoiIsVG9n8O0KQGcxgo7adQ12ivWwO2bT0QuOc+rRHM9oNMvSPHnyJA0bNoyys7PpnXfeoZKSEu62Zs2aafW0spRfkpfcBEBEFOMMRM6W84nU9c4p4DHdmusyJgBwiBYEInI68BZX1Pg8B4JLs0BkyZIldOjQITp06BC1bCn+1uir8IzWbIKkw07Nk3UcCZgB++t6rtJGdjtDR8/zyzGoTQCgr8gIC0VYiOyM5w689YLrb+2rzSYI8J9mayUTJkwghmEk/+ktQpAj8voNXXQcCZjBJUFp96raejpSgkAEwEjYWZFaD4FItWC7fWo86v4YTVgmbQhTVaOQtwI+DOvA50SVVteJmms1SojRY0gAIMDmidR5WJqptjkCkagIiyinBIwhLCt5RQr2nUdiDzr4ECV44/pi3VH6ZRvfs6JJkva7vADAu+ioCCKb56WZi9WOHmep8dHYNWlAYRmICH8NE1BVFRSYta5QdNlThj4ABE90pONdvbbeQyBSxQYimME0orCcoxJO3qEgFShx/+DWeg8BAFxEc0sz0oHIBeeMSCMEIoYUnoGIARJmwVyeGtmOiBxLMwBgLL5yRIqdW++R02VMYRmIYI0QlKoW7JwBAGNha/14WpopqXQEImyZdzCWsAxEumSidggo0yQRb2AARuVraYbtnJ0ch627RhSWgQh2yoBSg9qiPwWAUXHJqh4CkcoaRyCSiM0JhhSWgQhSRECpLpkpbtf98tggHUYCAK4uOHfFeGrf8ct2x5Z7LLEaU1gGIgBq6N0qTe8hAAARFZ6vJiKirzce83re3O0nvd4O+gjLQAQTIuCPHx4ayB3v+8doHUcCAFJ6ZaV6vf36npnBGQgoggUzAJkG5KbT0WlXY9cVgMHc3jeLfthSRE2TY72eN6YrumUbUXjOiCBJBPyEIATAeNjtuzaJ7bvCnTSnyy4FbUwgX1gGIvExmAgCAAgV3rbvsjtmiIgGtWkctDGBfGH5iXxznxa0eM8ZuqwdfikBAMzOW0GzSmcNkdjoCIqLQW8oIwrLQMQaFUlf3t9f72EAAIAKvAUi5TWOLb2JVhQzM6qwXJoBAIDQEeOl++65SkeNkbR4BCJGhUAEAABMjZ0RkcoRqXDOiKDhnXEhEAEAAFNju+/avCSrJsWGZSaCKSAQAQAAU4v2kiPy87YTRER0uKQqqGMC+RCIAACAqcV42b77Z+FFIiI6eg6BiFEhEAEAAFPztmsmytltvU82ekMZFQIRAAAwNaszENl1sszttnq7o5J2x2ZJQR0TyIdABAAATG17USkREVUIqqi62nu6PEijAaUQiAAAgKlFeOkB5VyZoedGdQjSaEApBCIAAGBqN/du4fG2DGdH3iRUVjUsBCIAAGBq1ihHD5nYaPePtNNlNURE6DNjYAhEAADA1KzOAMRWbyeGYbjr2aqqRPzuGTAeBCIAAGBq7IwIwxDVNfCBSLkgeTUlDkszRoVABAAATI3dvktEZKtv4I5r6vjjNPSaMSwEIgAAYGriQIQvalZtcwQizVNigz4mkA+BCAAAmJrFYpGsrlpV61iaiUeiqqEhEAEAANNjZ0WEMyJs590EKzrvGhkCEQAAMD02YVWYI1J2ybFrBomqxoZABAAATI+bEanjZ0TYQCQZgYihIRABAADTE9YSYbGBSCoCEUNDIAIAAKaXEOPIAxEWMcPSjDkgEAEAANNLdCakVtUiR8RsEIgAAIDpcUszdQhEzAaBCAAAmB6brFrbIJEjEo9AxMgQiAAAgOnFsNt3BbtmSqtriQi7ZowOgQgAAJgeG3SsP3yOu67skqOgGZZmjA2BCAAAmN6ag44AZOm+YiIiYhiGyrmlGTS8MzIEIgAAEHJs9XYuXyQpFiXejQyBCAAAmF6/nDTR5UpbPXfM1hgBY0IgAgAApte9Zaro8k9bTnDHkRGWII8GlEAgAgAApndDzxaiy/PyT+o0ElAKgQgAAJhegtWxfZfNB9l/pkLP4YACCEQAAMD04p15INW1DcQwDN03OIeIiNJQzMzwEIgAAIDpxTtnRBrsDNXU2SnKmRdya98sPYcFMiAQAQAA00sU7Iw5eq6KKmocu2aSrNgxY3T4CQEAgOlFCHbGfLm+kCprnYEIaogYHn5CAAAQUg6VVFKCcyYkMRY5IkaHpRkAAAgpafHRVFHjKO+OGRHjQyACAAAhIdkZdAzMTedzRBCIGB4CEQAACAldW6QQEdG6Q+foUHElERElY2nG8BCIAABASFh/+DwREa0oKNF5JKAEAhEAAAgJqRLFy7pkJuswElACgQgAAISEvtlpbtdZLGh4Z3SaBiLXXXcdtWrVimJjY6l58+Z0zz330KlTp7R8SgAACFPjBmTrPQTwg6aByPDhw+nHH3+kgoIC+vnnn+nw4cN0yy23aPmUAAAQpvLapOs9BPCDpvuann76ae44OzubJk2aRDfccAPV1dVRdDQymQEAQD2x0ZGiy9np8TqNBJQI2gbrCxcu0LfffkuDBg3yGITYbDay2Wzc5fLy8mANDwAAQsw3DwzQewggg+bJqi+88AIlJCRQeno6HT9+nObNm+fx3GnTplFKSgr3LysLXRMBAMA/LdPi9B4CyKA4EJk0aRJZLBav//bv38+d/9xzz9H27dvpjz/+oMjISLr33nuJYRjJx548eTKVlZVx/4qKivx/ZQAAEHY2TL6CRnbKoJV/G4YdMyZhYTxFBR6UlJTQ+fPnvZ6Tm5tLMTExbtefOHGCsrKyaP369ZSXl+fzucrLyyklJYXKysooORl7wQEAAMxAyee34hyRJk2aUJMmTfwamN1uJyIS5YEAAABA+NIsWXXTpk30559/0pAhQygtLY0OHz5MU6ZMoTZt2siaDQEAAIDQp1myanx8PP3yyy80YsQI6tChAz3wwAPUvXt3WrVqFVmtVq2eFgAAAExEsxmRbt260fLly7V6eAAAAAgB6DUDAAAAukEgAgAAALpBIAIAAAC6QSACAAAAukEgAgAAALpBIAIAAAC6QSACAAAAukEgAgAAALpBIAIAAAC60ayyqhrYxsDl5eU6jwQAAADkYj+32c9xbwwdiFRUVBARUVZWls4jAQAAAKUqKiooJSXF6zkWRk64ohO73U6nTp2ipKQkslgsqj52eXk5ZWVlUVFRESUnJ6v62EaA12duofz6Qvm1EeH1mR1enzoYhqGKigrKzMykiAjvWSCGnhGJiIigli1bavocycnJIfnLxsLrM7dQfn2h/NqI8PrMDq8vcL5mQlhIVgUAAADdIBABAAAA3YRtIGK1Wmnq1KlktVr1Hoom8PrMLZRfXyi/NiK8PrPD6ws+QyerAgAAQGgL2xkRAAAA0B8CEQAAANANAhEAAADQDQIRAAAA0E1YBiIzZsygnJwcio2NpQEDBtDmzZv1HpKk1atX07XXXkuZmZlksVjo119/Fd3OMAy98sor1Lx5c4qLi6ORI0fSwYMHRedcuHCBxo0bR8nJyZSamkoPPPAAVVZWis7ZuXMnXXbZZRQbG0tZWVn01ltvaf3SaNq0adSvXz9KSkqipk2b0g033EAFBQWic2pqamjixImUnp5OiYmJdPPNN9PZs2dF5xw/fpzGjh1L8fHx1LRpU3ruueeovr5edM7KlSupd+/eZLVaqW3btjR79mytXx7NnDmTunfvzhUNysvLo4ULF4bEa5Myffp0slgs9NRTT3HXmfk1vvrqq2SxWET/OnbsGBKvjXXy5Em6++67KT09neLi4qhbt260ZcsW7nYzv7/k5OS4/fwsFgtNnDiRiMz/82toaKApU6ZQ69atKS4ujtq0aUOvvfaaqK+LqX5+TJiZM2cOExMTw3zxxRfMnj17mAcffJBJTU1lzp49q/fQ3CxYsIB56aWXmF9++YUhImbu3Lmi26dPn86kpKQwv/76K7Njxw7muuuuY1q3bs1cunSJO2f06NFMjx49mI0bNzJr1qxh2rZty9x5553c7WVlZUxGRgYzbtw4Zvfu3cz333/PxMXFMZ988ommr23UqFHMrFmzmN27dzP5+fnM1VdfzbRq1YqprKzkznnkkUeYrKwsZtmyZcyWLVuYgQMHMoMGDeJur6+vZ7p27cqMHDmS2b59O7NgwQKmcePGzOTJk7lzjhw5wsTHxzPPPPMMs3fvXuaDDz5gIiMjmUWLFmn6+n777Tdm/vz5zIEDB5iCggLmxRdfZKKjo5ndu3eb/rW52rx5M5OTk8N0796defLJJ7nrzfwap06dynTp0oU5ffo096+kpCQkXhvDMMyFCxeY7OxsZsKECcymTZuYI0eOMIsXL2YOHTrEnWPm95fi4mLRz27JkiUMETErVqxgGMb8P7833niDSU9PZ37//Xfm6NGjzE8//cQkJiYy77//PneOmX5+YReI9O/fn5k4cSJ3uaGhgcnMzGSmTZum46h8cw1E7HY706xZM+btt9/mristLWWsVivz/fffMwzDMHv37mWIiPnzzz+5cxYuXMhYLBbm5MmTDMMwzEcffcSkpaUxNpuNO+eFF15gOnTooPErEisuLmaIiFm1ahXDMI7XEh0dzfz000/cOfv27WOIiNmwYQPDMI5ALSIigjlz5gx3zsyZM5nk5GTu9Tz//PNMly5dRM91++23M6NGjdL6JblJS0tj/vOf/4TUa6uoqGDatWvHLFmyhLn88su5QMTsr3Hq1KlMjx49JG8z+2tjGMff+JAhQzzeHmrvL08++STTpk0bxm63h8TPb+zYscz9998vuu6mm25ixo0bxzCM+X5+YbU0U1tbS1u3bqWRI0dy10VERNDIkSNpw4YNOo5MuaNHj9KZM2dEryUlJYUGDBjAvZYNGzZQamoq9e3blztn5MiRFBERQZs2beLOGTp0KMXExHDnjBo1igoKCujixYtBejVEZWVlRETUqFEjIiLaunUr1dXViV5fx44dqVWrVqLX161bN8rIyBCNvby8nPbs2cOdI3wM9pxg/rwbGhpozpw5VFVVRXl5eSH12iZOnEhjx451G0covMaDBw9SZmYm5ebm0rhx4+j48eNEFBqv7bfffqO+ffvSrbfeSk2bNqVevXrRZ599xt0eSu8vtbW19M0339D9999PFoslJH5+gwYNomXLltGBAweIiGjHjh20du1aGjNmDBGZ7+cXVoHIuXPnqKGhQfTLRUSUkZFBZ86c0WlU/mHH6+21nDlzhpo2bSq6PSoqiho1aiQ6R+oxhM+hNbvdTk899RQNHjyYunbtyj13TEwMpaamuo1Nydg9nVNeXk6XLl3S4uVwdu3aRYmJiWS1WumRRx6huXPnUufOnUPitRERzZkzh7Zt20bTpk1zu83sr3HAgAE0e/ZsWrRoEc2cOZOOHj1Kl112GVVUVJj+tRERHTlyhGbOnEnt2rWjxYsX06OPPkpPPPEEffnll6IxhsL7y6+//kqlpaU0YcIE7nnN/vObNGkS3XHHHdSxY0eKjo6mXr160VNPPUXjxo0TjdEsPz9Dd9+F8DBx4kTavXs3rV27Vu+hqKpDhw6Un59PZWVl9N///pfGjx9Pq1at0ntYqigqKqInn3ySlixZQrGxsXoPR3XsN0siou7du9OAAQMoOzubfvzxR4qLi9NxZOqw2+3Ut29fevPNN4mIqFevXrR79276+OOPafz48TqPTl2ff/45jRkzhjIzM/Ueimp+/PFH+vbbb+m7776jLl26UH5+Pj311FOUmZlpyp9fWM2ING7cmCIjI92yo8+ePUvNmjXTaVT+Ycfr7bU0a9aMiouLRbfX19fThQsXROdIPYbwObT0+OOP0++//04rVqygli1bctc3a9aMamtrqbS01G1sSsbu6Zzk5GTNP1BiYmKobdu21KdPH5o2bRr16NGD3n///ZB4bVu3bqXi4mLq3bs3RUVFUVRUFK1atYr+/e9/U1RUFGVkZJj+NQqlpqZS+/bt6dChQyHx82vevDl17txZdF2nTp245adQeX85duwYLV26lP7yl79w14XCz++5557jZkW6detG99xzDz399NPc7KTZfn5hFYjExMRQnz59aNmyZdx1drudli1bRnl5eTqOTLnWrVtTs2bNRK+lvLycNm3axL2WvLw8Ki0tpa1bt3LnLF++nOx2Ow0YMIA7Z/Xq1VRXV8eds2TJEurQoQOlpaVpNn6GYejxxx+nuXPn0vLly6l169ai2/v06UPR0dGi11dQUEDHjx8Xvb5du3aJ/piWLFlCycnJ3JtsXl6e6DHYc/T4edvtdrLZbCHx2kaMGEG7du2i/Px87l/fvn1p3Lhx3LHZX6NQZWUlHT58mJo3bx4SP7/Bgwe7bZc/cOAAZWdnE5H5319Ys2bNoqZNm9LYsWO560Lh51ddXU0REeKP78jISLLb7URkwp+fqqmvJjBnzhzGarUys2fPZvbu3cs89NBDTGpqqig72igqKiqY7du3M9u3b2eIiHn33XeZ7du3M8eOHWMYxrE9KzU1lZk3bx6zc+dO5vrrr5fcntWrVy9m06ZNzNq1a5l27dqJtmeVlpYyGRkZzD333MPs3r2bmTNnDhMfH6/59rpHH32USUlJYVauXCnaZlddXc2d88gjjzCtWrVili9fzmzZsoXJy8tj8vLyuNvZLXZXXXUVk5+fzyxatIhp0qSJ5Ba75557jtm3bx8zY8aMoGyxmzRpErNq1Srm6NGjzM6dO5lJkyYxFouF+eOPP0z/2jwR7pphGHO/xmeffZZZuXIlc/ToUWbdunXMyJEjmcaNGzPFxcWmf20M49hyHRUVxbzxxhvMwYMHmW+//ZaJj49nvvnmG+4cM7+/MIxjR2SrVq2YF154we02s//8xo8fz7Ro0YLbvvvLL78wjRs3Zp5//nnuHDP9/MIuEGEYhvnggw+YVq1aMTExMUz//v2ZjRs36j0kSStWrGCIyO3f+PHjGYZxbNGaMmUKk5GRwVitVmbEiBFMQUGB6DHOnz/P3HnnnUxiYiKTnJzM3HfffUxFRYXonB07djBDhgxhrFYr06JFC2b69Omavzap10VEzKxZs7hzLl26xDz22GNMWloaEx8fz9x4443M6dOnRY9TWFjIjBkzhomLi2MaN27MPPvss0xdXZ3onBUrVjA9e/ZkYmJimNzcXNFzaOX+++9nsrOzmZiYGKZJkybMiBEjuCDE7K/NE9dAxMyv8fbbb2eaN2/OxMTEMC1atGBuv/12UY0NM7821v/+9z+ma9eujNVqZTp27Mh8+umnotvN/P7CMAyzePFihojcxsww5v/5lZeXM08++STTqlUrJjY2lsnNzWVeeukl0TZbM/38LAwjKMUGAAAAEERhlSMCAAAAxoJABAAAAHSDQAQAAAB0g0AEAAAAdINABAAAAHSDQAQAAAB0g0AEAAAAdINABAAAAHSDQAQAAAB0g0AEAAAAdINABAAAAHSDQAQAAAB08//GW92TpSPs0wAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(data_cam['P01'][0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "56JG3ogz-LUE",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2024-01-22T09:46:48.780624Z",
     "iopub.status.busy": "2024-01-22T09:46:48.780330Z",
     "iopub.status.idle": "2024-01-22T09:46:49.643681Z",
     "shell.execute_reply": "2024-01-22T09:46:49.643003Z",
     "shell.execute_reply.started": "2024-01-22T09:46:48.780602Z"
    },
    "id": "56JG3ogz-LUE",
    "outputId": "d239a446-2b69-4f9c-f45e-c880f8c64511"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 8064])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "data_c1d = {}\n",
    "BLOCK_SIZE=640\n",
    "BLOCK_STRIDE=60\n",
    "for k,v in data_cam.items():\n",
    "    datablocki = []\n",
    "    v1 = v[0]\n",
    "    v1 = v1[:,np.newaxis,:]\n",
    "    #print(v1.shape)\n",
    "    data_c1d[k] = torch.tensor(v1)\n",
    "print(data_c1d['P01'][0].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ce1ed7be-a882-45ec-810d-6b1c43af0af3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-22T09:47:33.860418Z",
     "iopub.status.busy": "2024-01-22T09:47:33.859405Z",
     "iopub.status.idle": "2024-01-22T09:47:33.867660Z",
     "shell.execute_reply": "2024-01-22T09:47:33.866843Z",
     "shell.execute_reply.started": "2024-01-22T09:47:33.860385Z"
    },
    "id": "ce1ed7be-a882-45ec-810d-6b1c43af0af3"
   },
   "outputs": [],
   "source": [
    "data_c2 = {}\n",
    "for k,v in data_cam.items():\n",
    "    y = v[1]\n",
    "    x_label = np.zeros((y.shape[0]),dtype='float64')\n",
    "    for i in range(y.shape[0]):\n",
    "        if (y[i][0] > 5):\n",
    "            x_label[i] = 1\n",
    "        else:\n",
    "            x_label[i] = 0\n",
    "\n",
    "    x_l = x_label\n",
    "    x_l = x_l.reshape(-1,1)\n",
    "    x_l = torch.tensor(x_l)\n",
    "    data_c2[k] = x_l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "fa943a48-8252-4c85-ab48-4e6cb0c101a4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-21T20:26:35.503245Z",
     "iopub.status.busy": "2024-01-21T20:26:35.502318Z",
     "iopub.status.idle": "2024-01-21T20:26:35.509003Z",
     "shell.execute_reply": "2024-01-21T20:26:35.508226Z",
     "shell.execute_reply.started": "2024-01-21T20:26:35.503218Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1.],\n",
       "        [1.],\n",
       "        [0.],\n",
       "        [1.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [0.],\n",
       "        [1.],\n",
       "        [0.],\n",
       "        [1.]], dtype=torch.float64)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_c2['P02']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "Pm5zhOqDgK79",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-21T19:58:31.185851Z",
     "iopub.status.busy": "2024-01-21T19:58:31.184977Z",
     "iopub.status.idle": "2024-01-21T19:58:31.193553Z",
     "shell.execute_reply": "2024-01-21T19:58:31.192760Z",
     "shell.execute_reply.started": "2024-01-21T19:58:31.185828Z"
    },
    "id": "Pm5zhOqDgK79"
   },
   "outputs": [],
   "source": [
    "data_c2 = {}\n",
    "maxnum = 3\n",
    "for k,v in data_cam.items():\n",
    "    y = v[1]\n",
    "    x_label = np.zeros((y.shape[0]),dtype='int32')\n",
    "    for i in range(y.shape[0]):\n",
    "        if (y[i][1] > 5 and y[i][0] > 5):\n",
    "            x_label[i] = 3\n",
    "        elif (y[i][1] <= 5 and y[i][0] > 5):\n",
    "            x_label[i] = 2\n",
    "        elif (y[i][1] > 5 and y[i][0] <= 5):\n",
    "            x_label[i] = 1\n",
    "        elif (y[i][1] <= 5 and y[i][0] <= 5):\n",
    "            x_label[i] = 0\n",
    "\n",
    "    x_l = np.zeros((x_label.size, maxnum+1))\n",
    "    x_l[np.arange(x_label.size), x_label] = 1\n",
    "\n",
    "    x_l = torch.tensor(x_l)\n",
    "    data_c2[k] = x_l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "48a74ab5-e71d-441a-b786-630c4abc3685",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-22T09:47:43.659824Z",
     "iopub.status.busy": "2024-01-22T09:47:43.659210Z",
     "iopub.status.idle": "2024-01-22T09:47:43.683794Z",
     "shell.execute_reply": "2024-01-22T09:47:43.682963Z",
     "shell.execute_reply.started": "2024-01-22T09:47:43.659800Z"
    },
    "id": "48a74ab5-e71d-441a-b786-630c4abc3685"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "#from torchinfo import Summary\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.c1=nn.Conv1d(1, 34, 10,stride=1)\n",
    "        self.mp1=nn.MaxPool1d(2)\n",
    "        self.norm1 = nn.BatchNorm1d(34)\n",
    "        self.d = nn.Dropout(p=0.63)\n",
    "        self.c2=nn.Conv1d(34, 30, 10,stride=1)\n",
    "        self.mp2=nn.MaxPool1d(2)\n",
    "        self.c3=nn.Conv1d(30, 10, 10,stride=1)\n",
    "        self.norm3 = nn.BatchNorm1d(10)\n",
    "        self.mp3=nn.MaxPool1d(2)\n",
    "        self.ft = nn.Flatten()\n",
    "\n",
    "        self.n1 = nn.Linear(20070,110)\n",
    "        #self.n1 = nn.Linear(19590,110)\n",
    "        self.normfc1=nn.BatchNorm1d(110)\n",
    "        self.d = nn.Dropout(p=0.63)\n",
    "        #self.d = nn.Dropout()\n",
    "        self.n2 = nn.Linear(110,100)\n",
    "        self.n3 = nn.Linear(100,1)\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.d(self.norm1(F.tanh(self.c1(x))))\n",
    "        #x=F.tanh(self.c1(x))\n",
    "        x = self.mp2(F.tanh(self.c2(x)))\n",
    "        #print(x.shape)\n",
    "        x = self.mp3(F.tanh(self.c3(x)))\n",
    "\n",
    "        #print(x.shape)\n",
    "        x = self.ft(x)\n",
    "        #print(x.shape)\n",
    "        x = F.tanh(self.n1(x))\n",
    "        x=self.normfc1(x)\n",
    "        #x=self.norm3(x)\n",
    "        x=self.d(x)\n",
    "\n",
    "        #x = F.softmax(self.n2(x),dim=-1)\n",
    "        x = F.tanh(self.n2(x))\n",
    "        x = F.sigmoid(self.n3(x))\n",
    "\n",
    "        #x = (self.n3(x))\n",
    "        #print(x.shape)\n",
    "        return x\n",
    "\n",
    "\n",
    "#criterion = nn.CrossEntropyLoss()\n",
    "criterion = nn.BCELoss()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "624818a4-e9ca-4f32-9930-8ade33ca95df",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "execution": {
     "iopub.execute_input": "2024-01-21T20:39:25.503661Z",
     "iopub.status.busy": "2024-01-21T20:39:25.503127Z",
     "iopub.status.idle": "2024-01-21T20:39:41.152046Z",
     "shell.execute_reply": "2024-01-21T20:39:41.151535Z",
     "shell.execute_reply.started": "2024-01-21T20:39:25.503640Z"
    },
    "id": "624818a4-e9ca-4f32-9930-8ade33ca95df",
    "outputId": "7b50a269-a030-4ad0-b013-e506e2fb1233"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 0:\n",
      "  Train: index=[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23\n",
      " 24 25 26 27 28 29 30 31 32 33 34 35]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_203/3472248682.py:38: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1960: UserWarning: nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\n",
      "  warnings.warn(\"nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/60, Train Loss: 0.6609741449356079\n",
      "Epoch 2/60, Train Loss: 0.6968510746955872\n",
      "Epoch 3/60, Train Loss: 0.7063091397285461\n",
      "Epoch 4/60, Train Loss: 0.7129724025726318\n",
      "Epoch 5/60, Train Loss: 0.6755002737045288\n",
      "Epoch 6/60, Train Loss: 0.677463948726654\n",
      "Epoch 7/60, Train Loss: 0.7001715302467346\n",
      "Epoch 8/60, Train Loss: 0.641160249710083\n",
      "Epoch 9/60, Train Loss: 0.6524507403373718\n",
      "Epoch 10/60, Train Loss: 0.6981868147850037\n",
      "Epoch 11/60, Train Loss: 0.7125951051712036\n",
      "Epoch 12/60, Train Loss: 0.6761418581008911\n",
      "Epoch 13/60, Train Loss: 0.6650707125663757\n",
      "Epoch 14/60, Train Loss: 0.6498364806175232\n",
      "Epoch 15/60, Train Loss: 0.6750850081443787\n",
      "Epoch 16/60, Train Loss: 0.7362504005432129\n",
      "Epoch 17/60, Train Loss: 0.6782377362251282\n",
      "Epoch 18/60, Train Loss: 0.6005708575248718\n",
      "Epoch 19/60, Train Loss: 0.6484631896018982\n",
      "Epoch 20/60, Train Loss: 0.6615355610847473\n",
      "Epoch 21/60, Train Loss: 0.7476146817207336\n",
      "Epoch 22/60, Train Loss: 0.6450007557868958\n",
      "Epoch 23/60, Train Loss: 0.6990272998809814\n",
      "Epoch 24/60, Train Loss: 0.6960132718086243\n",
      "Epoch 25/60, Train Loss: 0.6487043499946594\n",
      "Epoch 26/60, Train Loss: 0.6940182447433472\n",
      "Epoch 27/60, Train Loss: 0.7425288558006287\n",
      "Epoch 28/60, Train Loss: 0.7695755958557129\n",
      "Epoch 29/60, Train Loss: 0.6488133072853088\n",
      "Epoch 30/60, Train Loss: 0.6783266067504883\n",
      "Epoch 31/60, Train Loss: 0.6386670470237732\n",
      "Epoch 32/60, Train Loss: 0.6566615700721741\n",
      "Epoch 33/60, Train Loss: 0.6245983242988586\n",
      "Epoch 34/60, Train Loss: 0.6381314396858215\n",
      "Epoch 35/60, Train Loss: 0.6594816446304321\n",
      "Epoch 36/60, Train Loss: 0.6990213394165039\n",
      "Epoch 37/60, Train Loss: 0.7033595442771912\n",
      "Epoch 38/60, Train Loss: 0.72736656665802\n",
      "Epoch 39/60, Train Loss: 0.6317784190177917\n",
      "Epoch 40/60, Train Loss: 0.695755660533905\n",
      "Epoch 41/60, Train Loss: 0.5978154540061951\n",
      "Epoch 42/60, Train Loss: 0.7467979788780212\n",
      "Epoch 43/60, Train Loss: 0.6905636191368103\n",
      "Epoch 44/60, Train Loss: 0.6623584628105164\n",
      "Epoch 45/60, Train Loss: 0.6861650347709656\n",
      "Epoch 46/60, Train Loss: 0.6978986859321594\n",
      "Epoch 47/60, Train Loss: 0.69769287109375\n",
      "Epoch 48/60, Train Loss: 0.6886689066886902\n",
      "Epoch 49/60, Train Loss: 0.6211285591125488\n",
      "Epoch 50/60, Train Loss: 0.7211494445800781\n",
      "Epoch 51/60, Train Loss: 0.645512580871582\n",
      "Epoch 52/60, Train Loss: 0.6711452603340149\n",
      "Epoch 53/60, Train Loss: 0.6328474283218384\n",
      "Epoch 54/60, Train Loss: 0.6318807005882263\n",
      "Epoch 55/60, Train Loss: 0.6630229353904724\n",
      "Epoch 56/60, Train Loss: 0.7082170844078064\n",
      "Epoch 57/60, Train Loss: 0.6603700518608093\n",
      "Epoch 58/60, Train Loss: 0.6021323204040527\n",
      "Epoch 59/60, Train Loss: 0.6721572875976562\n",
      "Epoch 60/60, Train Loss: 0.6605284214019775\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import confusion_matrix,classification_report\n",
    "from sklearn import preprocessing\n",
    "import matplotlib.pyplot as plt\n",
    "#subjectnames\n",
    "file_list_num = np.arange(len(newsubjectname))\n",
    "kf = KFold(n_splits=12)\n",
    "torch.manual_seed(42)\n",
    "torch.cuda.manual_seed(42)\n",
    "modellist = []\n",
    "modelid = 1\n",
    "#file_list_num\n",
    "#for i, (train_index, test_index) in enumerate(kf.split(file_list_num)):\n",
    "#for train_index in file_list_num:\n",
    "train_index = file_list_num\n",
    "print(f\"Fold {i}:\")\n",
    "print(f\"  Train: index={train_index}\")\n",
    "#print(f\"  Test:  index={test_index}\")\n",
    "net = Net()\n",
    "net.to(device)\n",
    "optimizer = optim.Adam(net.parameters(), lr=0.000001)\n",
    "epochs = 60\n",
    "batch_sz = 20\n",
    "train_loss_epoch = []\n",
    "val_loss_epoch = []\n",
    "for epoch in range(epochs):\n",
    "  train_loss = []\n",
    "  for tr in train_index:\n",
    "    v = data_c1d[newsubjectname[tr]]\n",
    "    l = data_c2[newsubjectname[tr]]\n",
    "    #print(v[0].shape)\n",
    "    net.train()\n",
    "    for i in range(0,len(v),batch_sz):\n",
    "      #print(v[i].shape)\n",
    "      #for j in range(0,v[i].shape[0],batch_sz):\n",
    "      #print(newsubjectname[tr])\n",
    "      optimizer.zero_grad()\n",
    "      outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
    "      #print(\"Expout {}\",outputs.shape)\n",
    "      #print(\"Actual {}\",l[i:i+batch_sz].shape)\n",
    "      #print(l[i].shape)\n",
    "      loss = criterion(outputs, l[i:i+batch_sz].to(device, dtype=torch.float))\n",
    "      loss.backward()\n",
    "      train_loss.append(loss)\n",
    "      optimizer.step()\n",
    "  print(f'Epoch {epoch + 1}/{epochs}, Train Loss: {loss.item()}')\n",
    "  train_loss_epoch.append(torch.stack(train_loss).mean().cpu().detach().numpy())\n",
    "\n",
    "  '''\n",
    "  for tr in test_index:\n",
    "      net.eval()\n",
    "      v = data_c1d[newsubjectname[tr]]\n",
    "      l = data_c2[newsubjectname[tr]]\n",
    "      net.eval()\n",
    "      with torch.no_grad():\n",
    "          for i in range(0,len(v),batch_sz):\n",
    "            #print(v[i].shape)\n",
    "            #for j in range(0,v[i].shape[0],batch_sz):\n",
    "            optimizer.zero_grad()\n",
    "            outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
    "            #print(outputs.shape)\n",
    "            #print(l[i].shape)\n",
    "            #outputs1 = torch.softmax(outputs,dim=-1)\n",
    "            loss = criterion(outputs, l[i:i+batch_sz].to(device, dtype=torch.float))\n",
    "            val_loss.append(loss)\n",
    "            #loss.backward()\n",
    "            actualoutput.append(torch.round(outputs.cpu()))\n",
    "            expectedoutput.append(l[i:i+batch_sz])\n",
    "            #actualoutput.append(torch.argmax(torch.softmax(outputs.cpu(),dim=1),dim=1))\n",
    "            #expectedoutput.append(torch.argmax(l[i:i+batch_sz],dim=1).numpy())\n",
    "  val_loss_mean = torch.stack(val_loss).mean().cpu().detach().numpy()\n",
    "  val_loss_epoch.append(val_loss_mean)\n",
    "  expectedoutput = np.concatenate( expectedoutput, axis=0 )\n",
    "  actualoutput = np.concatenate( actualoutput, axis=0 )\n",
    "  print(expectedoutput.shape)\n",
    "  print(actualoutput.shape)\n",
    "  print(classification_report(expectedoutput,actualoutput))\n",
    "  print(confusion_matrix(expectedoutput,actualoutput))\n",
    "  print(f'Validation Loss for {subjectnames[tr]} = {val_loss_mean}')\n",
    "  #break\n",
    "  '''\n",
    "#plt.figure(figsize=(10,7))\n",
    "#print(len(train_loss_epoch))\n",
    "#plt.plot(np.arange(epochs),train_loss_epoch,label='Train')\n",
    "#plt.plot(np.arange(epochs),val_loss_epoch,label='Validation')\n",
    "#plt.legend()\n",
    "#path = \"Model\"+str(modelid) +\".pt\"\n",
    "#path = \"ModelAMIGOS_Aro.pt\"\n",
    "#modelid = modelid+1\n",
    "#print(path)\n",
    "#torch.save(net.state_dict(), path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "5P36UViqRcul",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5P36UViqRcul",
    "outputId": "e071c001-0c26-4c44-ee20-9a315b022829"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-27-7929d1561c85>:33: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs_val = netValence(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "<ipython-input-27-7929d1561c85>:35: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs_aro = netArousal(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.39      0.22      0.28        41\n",
      "           2       0.56      0.12      0.20        42\n",
      "           3       0.24      0.52      0.33        27\n",
      "           4       0.36      0.50      0.42        50\n",
      "\n",
      "    accuracy                           0.33       160\n",
      "   macro avg       0.39      0.34      0.31       160\n",
      "weighted avg       0.40      0.33      0.31       160\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-27-7929d1561c85>:33: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs_val = netValence(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "<ipython-input-27-7929d1561c85>:35: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs_aro = netArousal(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.50      0.17      0.25        42\n",
      "           2       1.00      0.10      0.18        30\n",
      "           3       0.34      0.83      0.48        41\n",
      "           4       0.40      0.36      0.38        47\n",
      "\n",
      "    accuracy                           0.38       160\n",
      "   macro avg       0.56      0.36      0.32       160\n",
      "weighted avg       0.52      0.38      0.33       160\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-27-7929d1561c85>:33: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs_val = netValence(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "<ipython-input-27-7929d1561c85>:35: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs_aro = netArousal(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.21      0.19      0.20        31\n",
      "           2       0.57      0.12      0.20        34\n",
      "           3       0.29      0.53      0.37        43\n",
      "           4       0.48      0.40      0.44        52\n",
      "\n",
      "    accuracy                           0.34       160\n",
      "   macro avg       0.39      0.31      0.30       160\n",
      "weighted avg       0.39      0.34      0.32       160\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-27-7929d1561c85>:33: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs_val = netValence(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "<ipython-input-27-7929d1561c85>:35: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs_aro = netArousal(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.36      0.12      0.19        32\n",
      "           2       0.67      0.05      0.10        39\n",
      "           3       0.30      0.67      0.42        39\n",
      "           4       0.52      0.62      0.56        50\n",
      "\n",
      "    accuracy                           0.39       160\n",
      "   macro avg       0.46      0.37      0.32       160\n",
      "weighted avg       0.47      0.39      0.34       160\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-27-7929d1561c85>:33: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs_val = netValence(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "<ipython-input-27-7929d1561c85>:35: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs_aro = netArousal(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.44      0.10      0.16        42\n",
      "           2       0.33      0.07      0.12        28\n",
      "           3       0.21      0.77      0.33        26\n",
      "           4       0.48      0.36      0.41        64\n",
      "\n",
      "    accuracy                           0.31       160\n",
      "   macro avg       0.37      0.32      0.25       160\n",
      "weighted avg       0.40      0.31      0.28       160\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-27-7929d1561c85>:33: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs_val = netValence(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "<ipython-input-27-7929d1561c85>:35: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs_aro = netArousal(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.56      0.18      0.27        28\n",
      "           2       0.00      0.00      0.00        22\n",
      "           3       0.31      0.71      0.43        48\n",
      "           4       0.55      0.35      0.43        62\n",
      "\n",
      "    accuracy                           0.38       160\n",
      "   macro avg       0.35      0.31      0.28       160\n",
      "weighted avg       0.40      0.38      0.34       160\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-27-7929d1561c85>:33: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs_val = netValence(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "<ipython-input-27-7929d1561c85>:35: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs_aro = netArousal(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "<ipython-input-27-7929d1561c85>:33: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs_val = netValence(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "<ipython-input-27-7929d1561c85>:35: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs_aro = netArousal(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.17      0.03      0.05        33\n",
      "           2       0.00      0.00      0.00        37\n",
      "           3       0.27      0.76      0.39        41\n",
      "           4       0.37      0.29      0.32        49\n",
      "\n",
      "    accuracy                           0.29       160\n",
      "   macro avg       0.20      0.27      0.19       160\n",
      "weighted avg       0.22      0.29      0.21       160\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.26      0.20      0.23        25\n",
      "           2       1.00      0.14      0.24        37\n",
      "           3       0.20      0.55      0.29        33\n",
      "           4       0.50      0.34      0.40        65\n",
      "\n",
      "    accuracy                           0.31       160\n",
      "   macro avg       0.49      0.30      0.29       160\n",
      "weighted avg       0.52      0.31      0.31       160\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import confusion_matrix,classification_report\n",
    "from sklearn import preprocessing\n",
    "import matplotlib.pyplot as plt\n",
    "#subjectnames\n",
    "batch_sz = 20\n",
    "file_list_num = np.arange(len(subjectnames))\n",
    "modelid = 1\n",
    "netValence = Net()\n",
    "valmodelname = \"Valence_Model4\"+\".pt\"\n",
    "netValence.load_state_dict(torch.load(valmodelname))\n",
    "netValence.to(device)\n",
    "netArousal = Net()\n",
    "aromodelname = \"Model5\"+\".pt\"\n",
    "netArousal.load_state_dict(torch.load(aromodelname))\n",
    "netArousal.to(device)\n",
    "for i in range(0,32,4):\n",
    "\n",
    "    #optimizer = optim.Adam(net.parameters(), lr=0.000001)\n",
    "    expectedoutput = []\n",
    "    actualoutput = []\n",
    "    for tr in file_list_num[i:i+4]:\n",
    "        #net.eval()\n",
    "        v = data_c1d[subjectnames[tr]]\n",
    "        l = data_c3[subjectnames[tr]]\n",
    "        netValence.eval()\n",
    "        netArousal.eval()\n",
    "        with torch.no_grad():\n",
    "            for i in range(0,len(v),batch_sz):\n",
    "              #print(v[i].shape)\n",
    "              #for j in range(0,v[i].shape[0],batch_sz):\n",
    "              #optimizer.zero_grad()\n",
    "              outputs_val = netValence(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
    "              outputs_val1 = torch.round(outputs_val)\n",
    "              outputs_aro = netArousal(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
    "              outputs_aro1 = torch.round(outputs_aro)\n",
    "\n",
    "              #print(outputs_val1)\n",
    "              for j in range(0,outputs_aro1.shape[0]):\n",
    "                res = 0\n",
    "                if (outputs_val1[j][0] >= 1 and outputs_aro1[j][0] >= 1):\n",
    "                    res = 4\n",
    "                elif (outputs_val1[j][0] < 1 and outputs_aro1[j][0] >= 1):\n",
    "                    res = 3\n",
    "                elif (outputs_val1[j][0] >= 1 and outputs_aro1[j][0] < 1):\n",
    "                    res = 2\n",
    "                elif (outputs_val1[j][0] < 1 and outputs_aro1[j][0] < 1):\n",
    "                    res = 1\n",
    "                actualoutput.append(res)\n",
    "              #loss = criterion(outputs, l[i:i+batch_sz].to(device, dtype=torch.float))\n",
    "              #val_loss.append(loss)\n",
    "              #loss.backward()\n",
    "              #print(outputs.shape)\n",
    "              #print(l[i:i+batch_sz])\n",
    "              expectedoutput.append(l[i:i+batch_sz])\n",
    "              #actualoutput.append(actualoutput)\n",
    "      #val_loss_mean = torch.stack(val_loss).mean().cpu().detach().numpy()\n",
    "      #val_loss_epoch.append(val_loss_mean)\n",
    "    expectedoutput = np.concatenate( expectedoutput, axis=0 )\n",
    "      #actualoutput = np.concatenate( actualoutput, axis=0 )\n",
    "      #print(actualoutput)\n",
    "    #print(expectedoutput)\n",
    "    #print(actualoutput)\n",
    "    print(classification_report(expectedoutput,actualoutput))\n",
    "      #print(f'Validation Loss for {subjectnames[tr]} = {val_loss_mean}')\n",
    "      #break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9XuinMzzRq3R",
   "metadata": {
    "id": "9XuinMzzRq3R"
   },
   "outputs": [],
   "source": [
    "rm -rf Model*.pt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "8-a4aWI1C7If",
   "metadata": {
    "id": "8-a4aWI1C7If"
   },
   "outputs": [],
   "source": [
    "data_c3 = {}\n",
    "for k,v in data_c.items():\n",
    "    y = data_c[k][1]\n",
    "    x_label = np.zeros((y.shape[0]),dtype='int8')\n",
    "    for i in range(y.shape[0]):\n",
    "        if (y[i][0] > 5 and y[i][1] > 5):\n",
    "            x_label[i] = 4\n",
    "        elif (y[i][0] <= 5 and y[i][1] > 5):\n",
    "            x_label[i] = 3\n",
    "        elif (y[i][0] > 5 and y[i][1] <= 5):\n",
    "            x_label[i] = 2\n",
    "        elif (y[i][0] <= 5 and y[i][1] <= 5):\n",
    "            x_label[i] = 1\n",
    "    #x_l = np.zeros((x_label.size, x_label.max()+1))\n",
    "    #x_l[np.arange(x_label.size), x_label] = 1\n",
    "    #\n",
    "    #print(x_l.shape)\n",
    "    #x_l = x_l.reshape(-1,1,4)\n",
    "    #x_l = np.repeat(x_l, 117, axis=1)\n",
    "    #print(x_l.shape)\n",
    "    x_l = torch.tensor(x_label)\n",
    "    data_c3[k] = x_l\n",
    "    #print(data_c3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "538f2018-fa74-4426-9c36-d56fbeea2f5d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-22T09:47:57.951546Z",
     "iopub.status.busy": "2024-01-22T09:47:57.951037Z",
     "iopub.status.idle": "2024-01-22T09:47:57.961187Z",
     "shell.execute_reply": "2024-01-22T09:47:57.960636Z",
     "shell.execute_reply.started": "2024-01-22T09:47:57.951523Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['DEAP/s21.dat', 'DEAP/s25.dat', 'DEAP/s07.dat', 'DEAP/s22.dat', 'DEAP/s32.dat', 'DEAP/s10.dat', 'DEAP/s04.dat', 'DEAP/s23.dat', 'DEAP/s30.dat', 'DEAP/s06.dat', 'DEAP/s31.dat', 'DEAP/s16.dat', 'DEAP/s15.dat', 'DEAP/s08.dat', 'DEAP/s28.dat', 'DEAP/s17.dat', 'DEAP/s26.dat', 'DEAP/s02.dat', 'DEAP/s19.dat', 'DEAP/s18.dat', 'DEAP/s03.dat', 'DEAP/s29.dat', 'DEAP/s24.dat', 'DEAP/s05.dat', 'DEAP/s14.dat', 'DEAP/s12.dat', 'DEAP/s11.dat', 'DEAP/s27.dat', 'DEAP/s20.dat', 'DEAP/s09.dat', 'DEAP/s13.dat', 'DEAP/s01.dat']\n",
      "['s21', 's25', 's07', 's22', 's32', 's10', 's04', 's23', 's30', 's06', 's31', 's16', 's15', 's08', 's28', 's17', 's26', 's02', 's19', 's18', 's03', 's29', 's24', 's05', 's14', 's12', 's11', 's27', 's20', 's09', 's13', 's01']\n"
     ]
    }
   ],
   "source": [
    "import glob\n",
    "import os\n",
    "filelistd = glob.glob('DEAP/*.dat')\n",
    "print(filelistd)\n",
    "subjectnamesd = [fr[5:8] for fr in filelistd]\n",
    "print(subjectnamesd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "dcb43263-e6f0-4f6f-97fd-ffd8fe6efb21",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-22T09:48:00.906551Z",
     "iopub.status.busy": "2024-01-22T09:48:00.905921Z",
     "iopub.status.idle": "2024-01-22T09:48:11.405695Z",
     "shell.execute_reply": "2024-01-22T09:48:11.404912Z",
     "shell.execute_reply.started": "2024-01-22T09:48:00.906527Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['s21', 's25', 's07', 's22', 's32', 's10', 's04', 's23', 's30', 's06', 's31', 's16', 's15', 's08', 's28', 's17', 's26', 's02', 's19', 's18', 's03', 's29', 's24', 's05', 's14', 's12', 's11', 's27', 's20', 's09', 's13', 's01'])\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "datad = {}\n",
    "for sname in subjectnamesd:\n",
    "    dname = \"DEAP/\"+sname+\".dat\"\n",
    "    f = open(dname, 'rb')\n",
    "    x = pickle.load(f, encoding='latin1')\n",
    "    datad[sname] = x\n",
    "print(datad.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9e192455-a6bc-45f1-b641-9fde46b3586c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-22T09:48:14.208653Z",
     "iopub.status.busy": "2024-01-22T09:48:14.208340Z",
     "iopub.status.idle": "2024-01-22T09:48:14.266068Z",
     "shell.execute_reply": "2024-01-22T09:48:14.265190Z",
     "shell.execute_reply.started": "2024-01-22T09:48:14.208622Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "data_de = {}\n",
    "for k,v in datad.items():\n",
    "    y = datad[k]['data'][:,36,:]\n",
    "    ym = np.mean(y,axis=-1).reshape(40,1)\n",
    "    ystd = np.std(y,axis=-1).reshape(40,1)\n",
    "    z = (y-ym)/ystd\n",
    "    data_de[k] = [z,datad[k]['labels']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b1f12cea-e417-4f5d-b827-53bc3a41b517",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-22T09:48:19.964372Z",
     "iopub.status.busy": "2024-01-22T09:48:19.964091Z",
     "iopub.status.idle": "2024-01-22T09:48:20.034023Z",
     "shell.execute_reply": "2024-01-22T09:48:20.033375Z",
     "shell.execute_reply.started": "2024-01-22T09:48:19.964351Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 8064])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "data_de1 = {}\n",
    "for k,v in data_de.items():\n",
    "    datablocki = []\n",
    "    v1=np.vstack(v[0])\n",
    "    v1 = v1[:,np.newaxis,:]\n",
    "    data_de1[k] = torch.tensor(v1)\n",
    "print(data_de1['s01'][0].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "79b2bfa1-9d78-4f7d-b0f0-17c05654fbaa",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-22T09:48:24.364187Z",
     "iopub.status.busy": "2024-01-22T09:48:24.363522Z",
     "iopub.status.idle": "2024-01-22T09:48:24.373615Z",
     "shell.execute_reply": "2024-01-22T09:48:24.372981Z",
     "shell.execute_reply.started": "2024-01-22T09:48:24.364153Z"
    }
   },
   "outputs": [],
   "source": [
    "data_del = {}\n",
    "for k,v in data_de.items():\n",
    "    y = data_de[k][1]\n",
    "    x_label = np.zeros((y.shape[0]),dtype='float64')\n",
    "    for i in range(y.shape[0]):\n",
    "        if (y[i][1] > 5):\n",
    "            x_label[i] = 1\n",
    "        else:\n",
    "            x_label[i] = 0\n",
    "\n",
    "    #x_l = np.zeros((x_label.size, x_label.max()+1))\n",
    "    #x_l[np.arange(x_label.size), x_label] = 1\n",
    "    x_l = x_label\n",
    "    #\n",
    "    #print(x_l.shape)\n",
    "    x_l = x_l.reshape(-1,1)\n",
    "\n",
    "    x_l = torch.tensor(x_l)\n",
    "    data_del[k] = x_l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3510574e-92c7-4f83-8ea3-b1c842ec8792",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-21T21:37:10.299163Z",
     "iopub.status.busy": "2024-01-21T21:37:10.298856Z",
     "iopub.status.idle": "2024-01-21T21:37:10.304081Z",
     "shell.execute_reply": "2024-01-21T21:37:10.303507Z",
     "shell.execute_reply.started": "2024-01-21T21:37:10.299140Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([40, 1])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_del['s01'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "00a549ca-dc77-4ef8-a2ce-948a31cb944d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-21T21:26:54.344614Z",
     "iopub.status.busy": "2024-01-21T21:26:54.343936Z",
     "iopub.status.idle": "2024-01-21T21:26:55.114174Z",
     "shell.execute_reply": "2024-01-21T21:26:55.113433Z",
     "shell.execute_reply.started": "2024-01-21T21:26:54.344580Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 20:\n",
      "  Train: index=[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23\n",
      " 24 25 26 27 28 29 30 31]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_410/3061022090.py:39: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1960: UserWarning: nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\n",
      "  warnings.warn(\"nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.45      1.00      0.62       572\n",
      "         1.0       0.00      0.00      0.00       708\n",
      "\n",
      "    accuracy                           0.45      1280\n",
      "   macro avg       0.22      0.50      0.31      1280\n",
      "weighted avg       0.20      0.45      0.28      1280\n",
      "\n",
      "[[572   0]\n",
      " [708   0]]\n",
      "Validation Loss for s01 = 0.6970333456993103\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.9/dist-packages/sklearn/metrics/_classification.py:1334: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.9/dist-packages/sklearn/metrics/_classification.py:1334: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.9/dist-packages/sklearn/metrics/_classification.py:1334: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import confusion_matrix,classification_report\n",
    "from sklearn import preprocessing\n",
    "import matplotlib.pyplot as plt\n",
    "#subjectnames\n",
    "file_list_numd = np.arange(len(subjectnamesd))\n",
    "net = Net()\n",
    "net.to(device)\n",
    "optimizer = optim.Adam(net.parameters(), lr=0.000001)\n",
    "torch.manual_seed(42)\n",
    "torch.cuda.manual_seed(42)\n",
    "expectedoutputdeap = []\n",
    "actualoutputdeap = []\n",
    "val_loss = []\n",
    "expectedoutput = []\n",
    "actualoutput = []\n",
    "test_index = file_list_numd\n",
    "print(f\"Fold {i}:\")\n",
    "print(f\"  Train: index={test_index}\")\n",
    "#print(f\"  Test:  index={test_index}\")\n",
    "#net = Net()\n",
    "#net.to(device)\n",
    "#optimizer = optim.Adam(net.parameters(), lr=0.000001)\n",
    "#epochs = 60\n",
    "batch_sz = 20\n",
    "train_loss_epoch = []\n",
    "val_loss_epoch = []\n",
    "\n",
    "for tr in test_index:\n",
    "    net.eval()\n",
    "    v = data_de1[subjectnamesd[tr]]\n",
    "    l = data_del[subjectnamesd[tr]]\n",
    "    net.eval()\n",
    "    with torch.no_grad():\n",
    "        for i in range(0,len(v),batch_sz):\n",
    "          #print(v[i].shape)\n",
    "          #for j in range(0,v[i].shape[0],batch_sz):\n",
    "          optimizer.zero_grad()\n",
    "          outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
    "          #print(outputs.shape)\n",
    "          #print(l[i:i+batch_sz].shape)\n",
    "          loss = criterion(outputs, l[i:i+batch_sz].to(device, dtype=torch.float))\n",
    "          val_loss.append(loss)\n",
    "          actualoutputdeap.append(torch.round(outputs.cpu()))\n",
    "          expectedoutputdeap.append(l[i:i+batch_sz])\n",
    "          #actualoutput.append(torch.argmax(torch.softmax(outputs.cpu(),dim=1),dim=1))\n",
    "          #expectedoutput.append(torch.argmax(l[i:i+batch_sz],dim=1).numpy())\n",
    "val_loss_mean = torch.stack(val_loss).mean().cpu().detach().numpy()\n",
    "val_loss_epoch.append(val_loss_mean)\n",
    "expectedoutputdeap = np.concatenate( expectedoutputdeap, axis=0 )\n",
    "actualoutputdeap = np.concatenate( actualoutputdeap, axis=0 )\n",
    "#print(expectedoutput.shape)\n",
    "#print(actualoutput.shape)\n",
    "print(classification_report(expectedoutputdeap,actualoutputdeap))\n",
    "print(confusion_matrix(expectedoutputdeap,actualoutputdeap))\n",
    "print(f'Validation Loss for {subjectnamesd[tr]} = {val_loss_mean}')\n",
    "#break\n",
    "\n",
    "#plt.figure(figsize=(10,7))\n",
    "#print(len(train_loss_epoch))\n",
    "#plt.plot(np.arange(epochs),train_loss_epoch,label='Train')\n",
    "#plt.plot(np.arange(epochs),val_loss_epoch,label='Validation')\n",
    "#plt.legend()\n",
    "#path = \"Model\"+str(modelid) +\".pt\"\n",
    "#path = \"ModelAMIGOS_Aro.pt\"\n",
    "#modelid = modelid+1\n",
    "#print(path)\n",
    "#torch.save(net.state_dict(), path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "44278dac-15a4-400c-8676-184267c3942e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-21T22:42:54.306420Z",
     "iopub.status.busy": "2024-01-21T22:42:54.305804Z",
     "iopub.status.idle": "2024-01-21T22:44:05.512597Z",
     "shell.execute_reply": "2024-01-21T22:44:05.511853Z",
     "shell.execute_reply.started": "2024-01-21T22:42:54.306398Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 39:\n",
      "  Train: index=[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23\n",
      " 24 25 26 27 28 29 30 31 32 33 34 35]\n",
      "  Test:  index=[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23\n",
      " 24 25 26 27 28 29 30 31]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_32/3575763110.py:40: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1960: UserWarning: nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\n",
      "  warnings.warn(\"nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100, Train Loss: 0.6254265904426575\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.43      0.81      0.56       543\n",
      "         1.0       0.61      0.22      0.32       737\n",
      "\n",
      "    accuracy                           0.47      1280\n",
      "   macro avg       0.52      0.51      0.44      1280\n",
      "weighted avg       0.53      0.47      0.42      1280\n",
      "\n",
      "[[438 105]\n",
      " [576 161]]\n",
      "Validation Loss for s01 = 0.6921438574790955\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_32/3575763110.py:66: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/tmp/ipykernel_32/3575763110.py:40: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1960: UserWarning: nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\n",
      "  warnings.warn(\"nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/100, Train Loss: 0.6329383254051208\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.43      0.77      0.55       543\n",
      "         1.0       0.59      0.25      0.35       737\n",
      "\n",
      "    accuracy                           0.47      1280\n",
      "   macro avg       0.51      0.51      0.45      1280\n",
      "weighted avg       0.52      0.47      0.44      1280\n",
      "\n",
      "[[417 126]\n",
      " [553 184]]\n",
      "Validation Loss for s01 = 0.6993991732597351\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_32/3575763110.py:66: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/tmp/ipykernel_32/3575763110.py:40: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1960: UserWarning: nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\n",
      "  warnings.warn(\"nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/100, Train Loss: 0.6513366103172302\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.43      0.77      0.55       543\n",
      "         1.0       0.59      0.24      0.35       737\n",
      "\n",
      "    accuracy                           0.47      1280\n",
      "   macro avg       0.51      0.51      0.45      1280\n",
      "weighted avg       0.52      0.47      0.43      1280\n",
      "\n",
      "[[417 126]\n",
      " [557 180]]\n",
      "Validation Loss for s01 = 0.7214118242263794\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_32/3575763110.py:66: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/tmp/ipykernel_32/3575763110.py:40: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1960: UserWarning: nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\n",
      "  warnings.warn(\"nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/100, Train Loss: 0.6435428857803345\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_32/3575763110.py:66: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.43      0.77      0.55       543\n",
      "         1.0       0.60      0.25      0.35       737\n",
      "\n",
      "    accuracy                           0.47      1280\n",
      "   macro avg       0.52      0.51      0.45      1280\n",
      "weighted avg       0.53      0.47      0.44      1280\n",
      "\n",
      "[[420 123]\n",
      " [553 184]]\n",
      "Validation Loss for s01 = 0.7300715446472168\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_32/3575763110.py:40: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1960: UserWarning: nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\n",
      "  warnings.warn(\"nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/100, Train Loss: 0.7167419791221619\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_32/3575763110.py:66: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.43      0.78      0.56       543\n",
      "         1.0       0.61      0.26      0.36       737\n",
      "\n",
      "    accuracy                           0.48      1280\n",
      "   macro avg       0.52      0.52      0.46      1280\n",
      "weighted avg       0.53      0.48      0.44      1280\n",
      "\n",
      "[[422 121]\n",
      " [549 188]]\n",
      "Validation Loss for s01 = 0.7386218309402466\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_32/3575763110.py:40: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1960: UserWarning: nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\n",
      "  warnings.warn(\"nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6/100, Train Loss: 0.6830275058746338\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.43      0.78      0.56       543\n",
      "         1.0       0.61      0.26      0.36       737\n",
      "\n",
      "    accuracy                           0.48      1280\n",
      "   macro avg       0.52      0.52      0.46      1280\n",
      "weighted avg       0.53      0.48      0.44      1280\n",
      "\n",
      "[[421 122]\n",
      " [548 189]]\n",
      "Validation Loss for s01 = 0.7441049814224243\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_32/3575763110.py:66: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/tmp/ipykernel_32/3575763110.py:40: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1960: UserWarning: nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\n",
      "  warnings.warn(\"nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7/100, Train Loss: 0.6668974757194519\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.43      0.78      0.55       543\n",
      "         1.0       0.60      0.25      0.35       737\n",
      "\n",
      "    accuracy                           0.47      1280\n",
      "   macro avg       0.52      0.51      0.45      1280\n",
      "weighted avg       0.53      0.47      0.44      1280\n",
      "\n",
      "[[421 122]\n",
      " [554 183]]\n",
      "Validation Loss for s01 = 0.7543298602104187\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_32/3575763110.py:66: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/tmp/ipykernel_32/3575763110.py:40: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1960: UserWarning: nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\n",
      "  warnings.warn(\"nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8/100, Train Loss: 0.7026538848876953\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_32/3575763110.py:66: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.43      0.77      0.55       543\n",
      "         1.0       0.60      0.25      0.35       737\n",
      "\n",
      "    accuracy                           0.47      1280\n",
      "   macro avg       0.51      0.51      0.45      1280\n",
      "weighted avg       0.53      0.47      0.44      1280\n",
      "\n",
      "[[418 125]\n",
      " [551 186]]\n",
      "Validation Loss for s01 = 0.7541047930717468\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_32/3575763110.py:40: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1960: UserWarning: nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\n",
      "  warnings.warn(\"nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9/100, Train Loss: 0.695386528968811\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_32/3575763110.py:66: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.43      0.76      0.55       543\n",
      "         1.0       0.60      0.26      0.36       737\n",
      "\n",
      "    accuracy                           0.47      1280\n",
      "   macro avg       0.51      0.51      0.46      1280\n",
      "weighted avg       0.53      0.47      0.44      1280\n",
      "\n",
      "[[414 129]\n",
      " [547 190]]\n",
      "Validation Loss for s01 = 0.7543724775314331\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_32/3575763110.py:40: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1960: UserWarning: nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\n",
      "  warnings.warn(\"nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10/100, Train Loss: 0.657189667224884\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_32/3575763110.py:66: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.43      0.76      0.55       543\n",
      "         1.0       0.60      0.27      0.37       737\n",
      "\n",
      "    accuracy                           0.48      1280\n",
      "   macro avg       0.52      0.51      0.46      1280\n",
      "weighted avg       0.53      0.48      0.45      1280\n",
      "\n",
      "[[414 129]\n",
      " [541 196]]\n",
      "Validation Loss for s01 = 0.7524122595787048\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_32/3575763110.py:40: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1960: UserWarning: nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\n",
      "  warnings.warn(\"nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11/100, Train Loss: 0.6590602993965149\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_32/3575763110.py:66: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.43      0.77      0.55       543\n",
      "         1.0       0.60      0.25      0.36       737\n",
      "\n",
      "    accuracy                           0.47      1280\n",
      "   macro avg       0.52      0.51      0.45      1280\n",
      "weighted avg       0.53      0.47      0.44      1280\n",
      "\n",
      "[[418 125]\n",
      " [550 187]]\n",
      "Validation Loss for s01 = 0.7537333369255066\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_32/3575763110.py:40: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1960: UserWarning: nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\n",
      "  warnings.warn(\"nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12/100, Train Loss: 0.6205658316612244\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_32/3575763110.py:66: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.43      0.77      0.55       543\n",
      "         1.0       0.60      0.25      0.35       737\n",
      "\n",
      "    accuracy                           0.47      1280\n",
      "   macro avg       0.51      0.51      0.45      1280\n",
      "weighted avg       0.53      0.47      0.44      1280\n",
      "\n",
      "[[419 124]\n",
      " [554 183]]\n",
      "Validation Loss for s01 = 0.7596138119697571\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_32/3575763110.py:40: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1960: UserWarning: nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\n",
      "  warnings.warn(\"nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13/100, Train Loss: 0.6226426362991333\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_32/3575763110.py:66: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.43      0.77      0.55       543\n",
      "         1.0       0.60      0.25      0.35       737\n",
      "\n",
      "    accuracy                           0.47      1280\n",
      "   macro avg       0.51      0.51      0.45      1280\n",
      "weighted avg       0.53      0.47      0.44      1280\n",
      "\n",
      "[[419 124]\n",
      " [554 183]]\n",
      "Validation Loss for s01 = 0.7676873207092285\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_32/3575763110.py:40: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1960: UserWarning: nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\n",
      "  warnings.warn(\"nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14/100, Train Loss: 0.6550549864768982\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_32/3575763110.py:66: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.43      0.76      0.55       543\n",
      "         1.0       0.59      0.25      0.35       737\n",
      "\n",
      "    accuracy                           0.47      1280\n",
      "   macro avg       0.51      0.51      0.45      1280\n",
      "weighted avg       0.52      0.47      0.43      1280\n",
      "\n",
      "[[414 129]\n",
      " [553 184]]\n",
      "Validation Loss for s01 = 0.7621177434921265\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_32/3575763110.py:40: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1960: UserWarning: nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\n",
      "  warnings.warn(\"nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15/100, Train Loss: 0.6586475372314453\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.43      0.76      0.55       543\n",
      "         1.0       0.59      0.25      0.35       737\n",
      "\n",
      "    accuracy                           0.47      1280\n",
      "   macro avg       0.51      0.51      0.45      1280\n",
      "weighted avg       0.52      0.47      0.44      1280\n",
      "\n",
      "[[413 130]\n",
      " [551 186]]\n",
      "Validation Loss for s01 = 0.7615396976470947\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_32/3575763110.py:66: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/tmp/ipykernel_32/3575763110.py:40: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1960: UserWarning: nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\n",
      "  warnings.warn(\"nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16/100, Train Loss: 0.7287800312042236\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.43      0.76      0.55       543\n",
      "         1.0       0.59      0.25      0.35       737\n",
      "\n",
      "    accuracy                           0.47      1280\n",
      "   macro avg       0.51      0.51      0.45      1280\n",
      "weighted avg       0.52      0.47      0.44      1280\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_32/3575763110.py:66: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[415 128]\n",
      " [552 185]]\n",
      "Validation Loss for s01 = 0.7647521495819092\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_32/3575763110.py:40: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1960: UserWarning: nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\n",
      "  warnings.warn(\"nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17/100, Train Loss: 0.717319667339325\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_32/3575763110.py:66: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.43      0.76      0.55       543\n",
      "         1.0       0.59      0.26      0.36       737\n",
      "\n",
      "    accuracy                           0.47      1280\n",
      "   macro avg       0.51      0.51      0.45      1280\n",
      "weighted avg       0.52      0.47      0.44      1280\n",
      "\n",
      "[[412 131]\n",
      " [549 188]]\n",
      "Validation Loss for s01 = 0.7604794502258301\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_32/3575763110.py:40: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1960: UserWarning: nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\n",
      "  warnings.warn(\"nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 18/100, Train Loss: 0.6887262463569641\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_32/3575763110.py:66: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.43      0.76      0.55       543\n",
      "         1.0       0.59      0.25      0.35       737\n",
      "\n",
      "    accuracy                           0.47      1280\n",
      "   macro avg       0.51      0.51      0.45      1280\n",
      "weighted avg       0.52      0.47      0.43      1280\n",
      "\n",
      "[[414 129]\n",
      " [554 183]]\n",
      "Validation Loss for s01 = 0.7643703818321228\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_32/3575763110.py:40: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1960: UserWarning: nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\n",
      "  warnings.warn(\"nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19/100, Train Loss: 0.6445534229278564\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_32/3575763110.py:66: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.43      0.76      0.55       543\n",
      "         1.0       0.59      0.25      0.35       737\n",
      "\n",
      "    accuracy                           0.47      1280\n",
      "   macro avg       0.51      0.50      0.45      1280\n",
      "weighted avg       0.52      0.47      0.43      1280\n",
      "\n",
      "[[414 129]\n",
      " [555 182]]\n",
      "Validation Loss for s01 = 0.7652432918548584\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_32/3575763110.py:40: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1960: UserWarning: nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\n",
      "  warnings.warn(\"nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20/100, Train Loss: 0.6778649091720581\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_32/3575763110.py:66: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.43      0.76      0.55       543\n",
      "         1.0       0.59      0.25      0.35       737\n",
      "\n",
      "    accuracy                           0.47      1280\n",
      "   macro avg       0.51      0.50      0.45      1280\n",
      "weighted avg       0.52      0.47      0.43      1280\n",
      "\n",
      "[[415 128]\n",
      " [556 181]]\n",
      "Validation Loss for s01 = 0.7608133554458618\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_32/3575763110.py:40: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1960: UserWarning: nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\n",
      "  warnings.warn(\"nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 21/100, Train Loss: 0.6467194557189941\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_32/3575763110.py:66: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.43      0.76      0.55       543\n",
      "         1.0       0.58      0.24      0.34       737\n",
      "\n",
      "    accuracy                           0.46      1280\n",
      "   macro avg       0.51      0.50      0.45      1280\n",
      "weighted avg       0.52      0.46      0.43      1280\n",
      "\n",
      "[[415 128]\n",
      " [557 180]]\n",
      "Validation Loss for s01 = 0.7602121829986572\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_32/3575763110.py:40: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1960: UserWarning: nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\n",
      "  warnings.warn(\"nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 22/100, Train Loss: 0.6175727248191833\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_32/3575763110.py:66: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.43      0.76      0.55       543\n",
      "         1.0       0.58      0.24      0.34       737\n",
      "\n",
      "    accuracy                           0.46      1280\n",
      "   macro avg       0.50      0.50      0.45      1280\n",
      "weighted avg       0.52      0.46      0.43      1280\n",
      "\n",
      "[[415 128]\n",
      " [558 179]]\n",
      "Validation Loss for s01 = 0.7634924054145813\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_32/3575763110.py:40: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1960: UserWarning: nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\n",
      "  warnings.warn(\"nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 23/100, Train Loss: 0.5991201400756836\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_32/3575763110.py:66: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.43      0.76      0.55       543\n",
      "         1.0       0.59      0.25      0.35       737\n",
      "\n",
      "    accuracy                           0.47      1280\n",
      "   macro avg       0.51      0.51      0.45      1280\n",
      "weighted avg       0.52      0.47      0.44      1280\n",
      "\n",
      "[[415 128]\n",
      " [553 184]]\n",
      "Validation Loss for s01 = 0.7609373927116394\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_32/3575763110.py:40: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1960: UserWarning: nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\n",
      "  warnings.warn(\"nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 24/100, Train Loss: 0.6131755709648132\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_32/3575763110.py:66: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.43      0.76      0.55       543\n",
      "         1.0       0.59      0.25      0.35       737\n",
      "\n",
      "    accuracy                           0.47      1280\n",
      "   macro avg       0.51      0.50      0.45      1280\n",
      "weighted avg       0.52      0.47      0.43      1280\n",
      "\n",
      "[[415 128]\n",
      " [556 181]]\n",
      "Validation Loss for s01 = 0.7622840404510498\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_32/3575763110.py:40: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1960: UserWarning: nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\n",
      "  warnings.warn(\"nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 25/100, Train Loss: 0.6244475245475769\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.43      0.76      0.55       543\n",
      "         1.0       0.59      0.25      0.35       737\n",
      "\n",
      "    accuracy                           0.47      1280\n",
      "   macro avg       0.51      0.51      0.45      1280\n",
      "weighted avg       0.52      0.47      0.44      1280\n",
      "\n",
      "[[414 129]\n",
      " [552 185]]\n",
      "Validation Loss for s01 = 0.765120804309845\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_32/3575763110.py:66: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/tmp/ipykernel_32/3575763110.py:40: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1960: UserWarning: nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\n",
      "  warnings.warn(\"nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 26/100, Train Loss: 0.6138948798179626\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_32/3575763110.py:66: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.43      0.76      0.55       543\n",
      "         1.0       0.59      0.25      0.35       737\n",
      "\n",
      "    accuracy                           0.47      1280\n",
      "   macro avg       0.51      0.51      0.45      1280\n",
      "weighted avg       0.52      0.47      0.44      1280\n",
      "\n",
      "[[415 128]\n",
      " [552 185]]\n",
      "Validation Loss for s01 = 0.7671107053756714\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_32/3575763110.py:40: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1960: UserWarning: nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\n",
      "  warnings.warn(\"nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 27/100, Train Loss: 0.6788482666015625\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_32/3575763110.py:66: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.43      0.77      0.55       543\n",
      "         1.0       0.59      0.25      0.35       737\n",
      "\n",
      "    accuracy                           0.47      1280\n",
      "   macro avg       0.51      0.51      0.45      1280\n",
      "weighted avg       0.52      0.47      0.43      1280\n",
      "\n",
      "[[416 127]\n",
      " [554 183]]\n",
      "Validation Loss for s01 = 0.7701491117477417\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_32/3575763110.py:40: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1960: UserWarning: nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\n",
      "  warnings.warn(\"nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 28/100, Train Loss: 0.6385879516601562\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_32/3575763110.py:66: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.43      0.77      0.55       543\n",
      "         1.0       0.59      0.25      0.35       737\n",
      "\n",
      "    accuracy                           0.47      1280\n",
      "   macro avg       0.51      0.51      0.45      1280\n",
      "weighted avg       0.52      0.47      0.43      1280\n",
      "\n",
      "[[417 126]\n",
      " [556 181]]\n",
      "Validation Loss for s01 = 0.7646596431732178\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_32/3575763110.py:40: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1960: UserWarning: nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\n",
      "  warnings.warn(\"nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 29/100, Train Loss: 0.6283921599388123\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_32/3575763110.py:66: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.43      0.78      0.55       543\n",
      "         1.0       0.60      0.25      0.35       737\n",
      "\n",
      "    accuracy                           0.47      1280\n",
      "   macro avg       0.51      0.51      0.45      1280\n",
      "weighted avg       0.53      0.47      0.44      1280\n",
      "\n",
      "[[421 122]\n",
      " [556 181]]\n",
      "Validation Loss for s01 = 0.7669671773910522\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_32/3575763110.py:40: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1960: UserWarning: nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\n",
      "  warnings.warn(\"nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 30/100, Train Loss: 0.6315593123435974\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_32/3575763110.py:66: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.43      0.78      0.55       543\n",
      "         1.0       0.60      0.24      0.35       737\n",
      "\n",
      "    accuracy                           0.47      1280\n",
      "   macro avg       0.51      0.51      0.45      1280\n",
      "weighted avg       0.53      0.47      0.43      1280\n",
      "\n",
      "[[421 122]\n",
      " [557 180]]\n",
      "Validation Loss for s01 = 0.7701692581176758\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_32/3575763110.py:40: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1960: UserWarning: nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\n",
      "  warnings.warn(\"nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 31/100, Train Loss: 0.6281326413154602\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_32/3575763110.py:66: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.43      0.77      0.55       543\n",
      "         1.0       0.60      0.25      0.35       737\n",
      "\n",
      "    accuracy                           0.47      1280\n",
      "   macro avg       0.51      0.51      0.45      1280\n",
      "weighted avg       0.53      0.47      0.43      1280\n",
      "\n",
      "[[420 123]\n",
      " [556 181]]\n",
      "Validation Loss for s01 = 0.770138144493103\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_32/3575763110.py:40: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1960: UserWarning: nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\n",
      "  warnings.warn(\"nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 32/100, Train Loss: 0.6363617777824402\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.43      0.76      0.55       543\n",
      "         1.0       0.59      0.25      0.35       737\n",
      "\n",
      "    accuracy                           0.47      1280\n",
      "   macro avg       0.51      0.51      0.45      1280\n",
      "weighted avg       0.52      0.47      0.44      1280\n",
      "\n",
      "[[415 128]\n",
      " [552 185]]\n",
      "Validation Loss for s01 = 0.7690116167068481\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_32/3575763110.py:66: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/tmp/ipykernel_32/3575763110.py:40: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1960: UserWarning: nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\n",
      "  warnings.warn(\"nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 33/100, Train Loss: 0.647023618221283\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.43      0.76      0.55       543\n",
      "         1.0       0.59      0.25      0.36       737\n",
      "\n",
      "    accuracy                           0.47      1280\n",
      "   macro avg       0.51      0.51      0.45      1280\n",
      "weighted avg       0.52      0.47      0.44      1280\n",
      "\n",
      "[[414 129]\n",
      " [550 187]]\n",
      "Validation Loss for s01 = 0.7677376866340637\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_32/3575763110.py:66: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/tmp/ipykernel_32/3575763110.py:40: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1960: UserWarning: nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\n",
      "  warnings.warn(\"nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 34/100, Train Loss: 0.6905393600463867\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.43      0.77      0.55       543\n",
      "         1.0       0.59      0.24      0.35       737\n",
      "\n",
      "    accuracy                           0.47      1280\n",
      "   macro avg       0.51      0.51      0.45      1280\n",
      "weighted avg       0.52      0.47      0.43      1280\n",
      "\n",
      "[[418 125]\n",
      " [557 180]]\n",
      "Validation Loss for s01 = 0.7778984308242798\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_32/3575763110.py:66: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/tmp/ipykernel_32/3575763110.py:40: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1960: UserWarning: nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\n",
      "  warnings.warn(\"nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 35/100, Train Loss: 0.6917165517807007\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.43      0.77      0.55       543\n",
      "         1.0       0.59      0.25      0.35       737\n",
      "\n",
      "    accuracy                           0.47      1280\n",
      "   macro avg       0.51      0.51      0.45      1280\n",
      "weighted avg       0.52      0.47      0.44      1280\n",
      "\n",
      "[[416 127]\n",
      " [551 186]]\n",
      "Validation Loss for s01 = 0.7705255150794983\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_32/3575763110.py:66: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/tmp/ipykernel_32/3575763110.py:40: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1960: UserWarning: nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\n",
      "  warnings.warn(\"nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 36/100, Train Loss: 0.623077392578125\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_32/3575763110.py:66: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.43      0.77      0.55       543\n",
      "         1.0       0.60      0.25      0.35       737\n",
      "\n",
      "    accuracy                           0.47      1280\n",
      "   macro avg       0.51      0.51      0.45      1280\n",
      "weighted avg       0.53      0.47      0.44      1280\n",
      "\n",
      "[[419 124]\n",
      " [554 183]]\n",
      "Validation Loss for s01 = 0.7742001414299011\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_32/3575763110.py:40: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1960: UserWarning: nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\n",
      "  warnings.warn(\"nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 37/100, Train Loss: 0.6943680644035339\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.43      0.77      0.55       543\n",
      "         1.0       0.59      0.25      0.35       737\n",
      "\n",
      "    accuracy                           0.47      1280\n",
      "   macro avg       0.51      0.51      0.45      1280\n",
      "weighted avg       0.52      0.47      0.43      1280\n",
      "\n",
      "[[419 124]\n",
      " [556 181]]\n",
      "Validation Loss for s01 = 0.7758888006210327\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_32/3575763110.py:66: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/tmp/ipykernel_32/3575763110.py:40: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1960: UserWarning: nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\n",
      "  warnings.warn(\"nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 38/100, Train Loss: 0.6780388355255127\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_32/3575763110.py:66: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.43      0.77      0.55       543\n",
      "         1.0       0.60      0.25      0.36       737\n",
      "\n",
      "    accuracy                           0.47      1280\n",
      "   macro avg       0.51      0.51      0.45      1280\n",
      "weighted avg       0.53      0.47      0.44      1280\n",
      "\n",
      "[[417 126]\n",
      " [550 187]]\n",
      "Validation Loss for s01 = 0.7630783319473267\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_32/3575763110.py:40: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1960: UserWarning: nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\n",
      "  warnings.warn(\"nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 39/100, Train Loss: 0.697835385799408\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.43      0.77      0.55       543\n",
      "         1.0       0.60      0.25      0.35       737\n",
      "\n",
      "    accuracy                           0.47      1280\n",
      "   macro avg       0.51      0.51      0.45      1280\n",
      "weighted avg       0.53      0.47      0.44      1280\n",
      "\n",
      "[[417 126]\n",
      " [551 186]]\n",
      "Validation Loss for s01 = 0.7620947360992432\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_32/3575763110.py:66: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/tmp/ipykernel_32/3575763110.py:40: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1960: UserWarning: nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\n",
      "  warnings.warn(\"nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 40/100, Train Loss: 0.719265878200531\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_32/3575763110.py:66: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.43      0.77      0.55       543\n",
      "         1.0       0.60      0.25      0.35       737\n",
      "\n",
      "    accuracy                           0.47      1280\n",
      "   macro avg       0.51      0.51      0.45      1280\n",
      "weighted avg       0.53      0.47      0.44      1280\n",
      "\n",
      "[[418 125]\n",
      " [553 184]]\n",
      "Validation Loss for s01 = 0.7653250694274902\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_32/3575763110.py:40: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1960: UserWarning: nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\n",
      "  warnings.warn(\"nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 41/100, Train Loss: 0.6484021544456482\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.43      0.77      0.55       543\n",
      "         1.0       0.59      0.25      0.35       737\n",
      "\n",
      "    accuracy                           0.47      1280\n",
      "   macro avg       0.51      0.51      0.45      1280\n",
      "weighted avg       0.52      0.47      0.43      1280\n",
      "\n",
      "[[419 124]\n",
      " [556 181]]\n",
      "Validation Loss for s01 = 0.7664178609848022\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_32/3575763110.py:66: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/tmp/ipykernel_32/3575763110.py:40: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1960: UserWarning: nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\n",
      "  warnings.warn(\"nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 42/100, Train Loss: 0.7136654257774353\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_32/3575763110.py:66: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.43      0.77      0.55       543\n",
      "         1.0       0.60      0.25      0.35       737\n",
      "\n",
      "    accuracy                           0.47      1280\n",
      "   macro avg       0.51      0.51      0.45      1280\n",
      "weighted avg       0.53      0.47      0.44      1280\n",
      "\n",
      "[[420 123]\n",
      " [555 182]]\n",
      "Validation Loss for s01 = 0.7594252824783325\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_32/3575763110.py:40: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1960: UserWarning: nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\n",
      "  warnings.warn(\"nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 43/100, Train Loss: 0.6653256416320801\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_32/3575763110.py:66: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.43      0.77      0.55       543\n",
      "         1.0       0.59      0.24      0.34       737\n",
      "\n",
      "    accuracy                           0.47      1280\n",
      "   macro avg       0.51      0.51      0.45      1280\n",
      "weighted avg       0.52      0.47      0.43      1280\n",
      "\n",
      "[[420 123]\n",
      " [558 179]]\n",
      "Validation Loss for s01 = 0.7655988931655884\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_32/3575763110.py:40: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1960: UserWarning: nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\n",
      "  warnings.warn(\"nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 44/100, Train Loss: 0.6979792714118958\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_32/3575763110.py:66: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.43      0.77      0.55       543\n",
      "         1.0       0.60      0.25      0.35       737\n",
      "\n",
      "    accuracy                           0.47      1280\n",
      "   macro avg       0.51      0.51      0.45      1280\n",
      "weighted avg       0.53      0.47      0.44      1280\n",
      "\n",
      "[[418 125]\n",
      " [553 184]]\n",
      "Validation Loss for s01 = 0.7611653208732605\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_32/3575763110.py:40: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1960: UserWarning: nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\n",
      "  warnings.warn(\"nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 45/100, Train Loss: 0.6632940769195557\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_32/3575763110.py:66: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.43      0.77      0.55       543\n",
      "         1.0       0.59      0.24      0.34       737\n",
      "\n",
      "    accuracy                           0.47      1280\n",
      "   macro avg       0.51      0.51      0.45      1280\n",
      "weighted avg       0.52      0.47      0.43      1280\n",
      "\n",
      "[[420 123]\n",
      " [558 179]]\n",
      "Validation Loss for s01 = 0.768255352973938\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_32/3575763110.py:40: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1960: UserWarning: nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\n",
      "  warnings.warn(\"nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 46/100, Train Loss: 0.6281082034111023\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_32/3575763110.py:66: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.43      0.77      0.55       543\n",
      "         1.0       0.60      0.25      0.35       737\n",
      "\n",
      "    accuracy                           0.47      1280\n",
      "   macro avg       0.52      0.51      0.45      1280\n",
      "weighted avg       0.53      0.47      0.44      1280\n",
      "\n",
      "[[419 124]\n",
      " [552 185]]\n",
      "Validation Loss for s01 = 0.7585955858230591\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_32/3575763110.py:40: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1960: UserWarning: nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\n",
      "  warnings.warn(\"nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 47/100, Train Loss: 0.6755558848381042\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.43      0.77      0.55       543\n",
      "         1.0       0.59      0.25      0.35       737\n",
      "\n",
      "    accuracy                           0.47      1280\n",
      "   macro avg       0.51      0.51      0.45      1280\n",
      "weighted avg       0.52      0.47      0.43      1280\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_32/3575763110.py:66: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[418 125]\n",
      " [556 181]]\n",
      "Validation Loss for s01 = 0.7624230980873108\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_32/3575763110.py:40: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1960: UserWarning: nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\n",
      "  warnings.warn(\"nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 48/100, Train Loss: 0.6702927947044373\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.43      0.77      0.55       543\n",
      "         1.0       0.59      0.24      0.34       737\n",
      "\n",
      "    accuracy                           0.47      1280\n",
      "   macro avg       0.51      0.51      0.45      1280\n",
      "weighted avg       0.52      0.47      0.43      1280\n",
      "\n",
      "[[420 123]\n",
      " [559 178]]\n",
      "Validation Loss for s01 = 0.7656406164169312\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_32/3575763110.py:66: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/tmp/ipykernel_32/3575763110.py:40: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1960: UserWarning: nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\n",
      "  warnings.warn(\"nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 49/100, Train Loss: 0.7109683156013489\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.43      0.77      0.55       543\n",
      "         1.0       0.59      0.24      0.35       737\n",
      "\n",
      "    accuracy                           0.47      1280\n",
      "   macro avg       0.51      0.51      0.45      1280\n",
      "weighted avg       0.52      0.47      0.43      1280\n",
      "\n",
      "[[420 123]\n",
      " [557 180]]\n",
      "Validation Loss for s01 = 0.7668026685714722\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_32/3575763110.py:66: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/tmp/ipykernel_32/3575763110.py:40: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1960: UserWarning: nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\n",
      "  warnings.warn(\"nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 50/100, Train Loss: 0.7166356444358826\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_32/3575763110.py:66: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.43      0.77      0.55       543\n",
      "         1.0       0.60      0.25      0.35       737\n",
      "\n",
      "    accuracy                           0.47      1280\n",
      "   macro avg       0.51      0.51      0.45      1280\n",
      "weighted avg       0.53      0.47      0.43      1280\n",
      "\n",
      "[[420 123]\n",
      " [556 181]]\n",
      "Validation Loss for s01 = 0.7716360688209534\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_32/3575763110.py:40: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1960: UserWarning: nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\n",
      "  warnings.warn(\"nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 51/100, Train Loss: 0.6864690184593201\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.43      0.77      0.55       543\n",
      "         1.0       0.60      0.25      0.35       737\n",
      "\n",
      "    accuracy                           0.47      1280\n",
      "   macro avg       0.52      0.51      0.45      1280\n",
      "weighted avg       0.53      0.47      0.44      1280\n",
      "\n",
      "[[419 124]\n",
      " [552 185]]\n",
      "Validation Loss for s01 = 0.767868161201477\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_32/3575763110.py:66: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/tmp/ipykernel_32/3575763110.py:40: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1960: UserWarning: nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\n",
      "  warnings.warn(\"nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 52/100, Train Loss: 0.604030966758728\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_32/3575763110.py:66: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.43      0.77      0.55       543\n",
      "         1.0       0.60      0.25      0.35       737\n",
      "\n",
      "    accuracy                           0.47      1280\n",
      "   macro avg       0.52      0.51      0.45      1280\n",
      "weighted avg       0.53      0.47      0.44      1280\n",
      "\n",
      "[[420 123]\n",
      " [553 184]]\n",
      "Validation Loss for s01 = 0.7661932706832886\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_32/3575763110.py:40: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1960: UserWarning: nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\n",
      "  warnings.warn(\"nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 53/100, Train Loss: 0.6776286959648132\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.43      0.76      0.55       543\n",
      "         1.0       0.59      0.25      0.35       737\n",
      "\n",
      "    accuracy                           0.47      1280\n",
      "   macro avg       0.51      0.51      0.45      1280\n",
      "weighted avg       0.52      0.47      0.44      1280\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_32/3575763110.py:66: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[415 128]\n",
      " [552 185]]\n",
      "Validation Loss for s01 = 0.763084888458252\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_32/3575763110.py:40: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1960: UserWarning: nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\n",
      "  warnings.warn(\"nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 54/100, Train Loss: 0.6642383933067322\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_32/3575763110.py:66: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.43      0.77      0.55       543\n",
      "         1.0       0.59      0.25      0.35       737\n",
      "\n",
      "    accuracy                           0.47      1280\n",
      "   macro avg       0.51      0.51      0.45      1280\n",
      "weighted avg       0.52      0.47      0.43      1280\n",
      "\n",
      "[[419 124]\n",
      " [556 181]]\n",
      "Validation Loss for s01 = 0.7655931115150452\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_32/3575763110.py:40: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1960: UserWarning: nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\n",
      "  warnings.warn(\"nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 55/100, Train Loss: 0.6709189414978027\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_32/3575763110.py:66: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.43      0.77      0.55       543\n",
      "         1.0       0.59      0.25      0.35       737\n",
      "\n",
      "    accuracy                           0.47      1280\n",
      "   macro avg       0.51      0.51      0.45      1280\n",
      "weighted avg       0.52      0.47      0.43      1280\n",
      "\n",
      "[[418 125]\n",
      " [556 181]]\n",
      "Validation Loss for s01 = 0.7610743045806885\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_32/3575763110.py:40: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1960: UserWarning: nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\n",
      "  warnings.warn(\"nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 56/100, Train Loss: 0.6810974478721619\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_32/3575763110.py:66: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.43      0.77      0.55       543\n",
      "         1.0       0.59      0.25      0.35       737\n",
      "\n",
      "    accuracy                           0.47      1280\n",
      "   macro avg       0.51      0.51      0.45      1280\n",
      "weighted avg       0.52      0.47      0.44      1280\n",
      "\n",
      "[[417 126]\n",
      " [553 184]]\n",
      "Validation Loss for s01 = 0.7625638842582703\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_32/3575763110.py:40: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1960: UserWarning: nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\n",
      "  warnings.warn(\"nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 57/100, Train Loss: 0.6430944800376892\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_32/3575763110.py:66: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.43      0.77      0.55       543\n",
      "         1.0       0.60      0.25      0.35       737\n",
      "\n",
      "    accuracy                           0.47      1280\n",
      "   macro avg       0.51      0.51      0.45      1280\n",
      "weighted avg       0.53      0.47      0.44      1280\n",
      "\n",
      "[[418 125]\n",
      " [553 184]]\n",
      "Validation Loss for s01 = 0.7591494917869568\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_32/3575763110.py:40: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1960: UserWarning: nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\n",
      "  warnings.warn(\"nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 58/100, Train Loss: 0.6498996019363403\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_32/3575763110.py:66: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.43      0.77      0.55       543\n",
      "         1.0       0.59      0.25      0.35       737\n",
      "\n",
      "    accuracy                           0.47      1280\n",
      "   macro avg       0.51      0.51      0.45      1280\n",
      "weighted avg       0.52      0.47      0.43      1280\n",
      "\n",
      "[[418 125]\n",
      " [556 181]]\n",
      "Validation Loss for s01 = 0.7661039233207703\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_32/3575763110.py:40: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1960: UserWarning: nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\n",
      "  warnings.warn(\"nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 59/100, Train Loss: 0.6124952435493469\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_32/3575763110.py:66: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.43      0.77      0.55       543\n",
      "         1.0       0.59      0.25      0.35       737\n",
      "\n",
      "    accuracy                           0.47      1280\n",
      "   macro avg       0.51      0.51      0.45      1280\n",
      "weighted avg       0.52      0.47      0.43      1280\n",
      "\n",
      "[[418 125]\n",
      " [556 181]]\n",
      "Validation Loss for s01 = 0.7677444219589233\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_32/3575763110.py:40: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1960: UserWarning: nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\n",
      "  warnings.warn(\"nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 60/100, Train Loss: 0.6824191808700562\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.43      0.77      0.55       543\n",
      "         1.0       0.59      0.25      0.35       737\n",
      "\n",
      "    accuracy                           0.47      1280\n",
      "   macro avg       0.51      0.51      0.45      1280\n",
      "weighted avg       0.52      0.47      0.44      1280\n",
      "\n",
      "[[417 126]\n",
      " [553 184]]\n",
      "Validation Loss for s01 = 0.7617424726486206\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_32/3575763110.py:66: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/tmp/ipykernel_32/3575763110.py:40: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1960: UserWarning: nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\n",
      "  warnings.warn(\"nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 61/100, Train Loss: 0.6873204112052917\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_32/3575763110.py:66: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.43      0.77      0.55       543\n",
      "         1.0       0.59      0.25      0.35       737\n",
      "\n",
      "    accuracy                           0.47      1280\n",
      "   macro avg       0.51      0.51      0.45      1280\n",
      "weighted avg       0.52      0.47      0.44      1280\n",
      "\n",
      "[[416 127]\n",
      " [553 184]]\n",
      "Validation Loss for s01 = 0.7594742774963379\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_32/3575763110.py:40: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1960: UserWarning: nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\n",
      "  warnings.warn(\"nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 62/100, Train Loss: 0.6278077363967896\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_32/3575763110.py:66: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.43      0.77      0.55       543\n",
      "         1.0       0.59      0.25      0.35       737\n",
      "\n",
      "    accuracy                           0.47      1280\n",
      "   macro avg       0.51      0.51      0.45      1280\n",
      "weighted avg       0.53      0.47      0.44      1280\n",
      "\n",
      "[[417 126]\n",
      " [552 185]]\n",
      "Validation Loss for s01 = 0.760638952255249\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_32/3575763110.py:40: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1960: UserWarning: nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\n",
      "  warnings.warn(\"nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 63/100, Train Loss: 0.669555127620697\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.43      0.77      0.55       543\n",
      "         1.0       0.59      0.25      0.35       737\n",
      "\n",
      "    accuracy                           0.47      1280\n",
      "   macro avg       0.51      0.51      0.45      1280\n",
      "weighted avg       0.53      0.47      0.44      1280\n",
      "\n",
      "[[417 126]\n",
      " [552 185]]\n",
      "Validation Loss for s01 = 0.7658336758613586\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_32/3575763110.py:66: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/tmp/ipykernel_32/3575763110.py:40: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1960: UserWarning: nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\n",
      "  warnings.warn(\"nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 64/100, Train Loss: 0.7174664735794067\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_32/3575763110.py:66: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.43      0.76      0.55       543\n",
      "         1.0       0.59      0.26      0.36       737\n",
      "\n",
      "    accuracy                           0.47      1280\n",
      "   macro avg       0.51      0.51      0.45      1280\n",
      "weighted avg       0.52      0.47      0.44      1280\n",
      "\n",
      "[[414 129]\n",
      " [548 189]]\n",
      "Validation Loss for s01 = 0.7611130475997925\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_32/3575763110.py:40: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1960: UserWarning: nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\n",
      "  warnings.warn(\"nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 65/100, Train Loss: 0.6608578562736511\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_32/3575763110.py:66: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.43      0.76      0.55       543\n",
      "         1.0       0.59      0.26      0.36       737\n",
      "\n",
      "    accuracy                           0.47      1280\n",
      "   macro avg       0.51      0.51      0.45      1280\n",
      "weighted avg       0.52      0.47      0.44      1280\n",
      "\n",
      "[[413 130]\n",
      " [549 188]]\n",
      "Validation Loss for s01 = 0.7558221817016602\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_32/3575763110.py:40: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1960: UserWarning: nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\n",
      "  warnings.warn(\"nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 66/100, Train Loss: 0.6499595642089844\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.43      0.76      0.55       543\n",
      "         1.0       0.58      0.25      0.35       737\n",
      "\n",
      "    accuracy                           0.46      1280\n",
      "   macro avg       0.50      0.50      0.45      1280\n",
      "weighted avg       0.52      0.46      0.43      1280\n",
      "\n",
      "[[411 132]\n",
      " [553 184]]\n",
      "Validation Loss for s01 = 0.7614157199859619\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_32/3575763110.py:66: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/tmp/ipykernel_32/3575763110.py:40: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1960: UserWarning: nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\n",
      "  warnings.warn(\"nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 67/100, Train Loss: 0.6731989979743958\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_32/3575763110.py:66: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.43      0.76      0.55       543\n",
      "         1.0       0.58      0.25      0.35       737\n",
      "\n",
      "    accuracy                           0.47      1280\n",
      "   macro avg       0.51      0.50      0.45      1280\n",
      "weighted avg       0.52      0.47      0.43      1280\n",
      "\n",
      "[[412 131]\n",
      " [553 184]]\n",
      "Validation Loss for s01 = 0.7638481855392456\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_32/3575763110.py:40: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1960: UserWarning: nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\n",
      "  warnings.warn(\"nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 68/100, Train Loss: 0.6199194192886353\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_32/3575763110.py:66: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.43      0.76      0.54       543\n",
      "         1.0       0.58      0.25      0.35       737\n",
      "\n",
      "    accuracy                           0.46      1280\n",
      "   macro avg       0.50      0.50      0.45      1280\n",
      "weighted avg       0.52      0.46      0.43      1280\n",
      "\n",
      "[[410 133]\n",
      " [552 185]]\n",
      "Validation Loss for s01 = 0.7581473588943481\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_32/3575763110.py:40: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1960: UserWarning: nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\n",
      "  warnings.warn(\"nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 69/100, Train Loss: 0.6981672048568726\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_32/3575763110.py:66: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.43      0.76      0.55       543\n",
      "         1.0       0.59      0.25      0.35       737\n",
      "\n",
      "    accuracy                           0.47      1280\n",
      "   macro avg       0.51      0.51      0.45      1280\n",
      "weighted avg       0.52      0.47      0.43      1280\n",
      "\n",
      "[[413 130]\n",
      " [553 184]]\n",
      "Validation Loss for s01 = 0.7604258060455322\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_32/3575763110.py:40: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1960: UserWarning: nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\n",
      "  warnings.warn(\"nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 70/100, Train Loss: 0.6335961818695068\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_32/3575763110.py:66: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.43      0.76      0.55       543\n",
      "         1.0       0.59      0.26      0.36       737\n",
      "\n",
      "    accuracy                           0.47      1280\n",
      "   macro avg       0.51      0.51      0.45      1280\n",
      "weighted avg       0.52      0.47      0.44      1280\n",
      "\n",
      "[[410 133]\n",
      " [549 188]]\n",
      "Validation Loss for s01 = 0.758737325668335\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_32/3575763110.py:40: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1960: UserWarning: nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\n",
      "  warnings.warn(\"nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 71/100, Train Loss: 0.7060639262199402\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_32/3575763110.py:66: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.43      0.76      0.55       543\n",
      "         1.0       0.59      0.25      0.35       737\n",
      "\n",
      "    accuracy                           0.47      1280\n",
      "   macro avg       0.51      0.50      0.45      1280\n",
      "weighted avg       0.52      0.47      0.43      1280\n",
      "\n",
      "[[412 131]\n",
      " [552 185]]\n",
      "Validation Loss for s01 = 0.7615333795547485\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_32/3575763110.py:40: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1960: UserWarning: nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\n",
      "  warnings.warn(\"nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 72/100, Train Loss: 0.6631054282188416\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_32/3575763110.py:66: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.43      0.76      0.55       543\n",
      "         1.0       0.59      0.25      0.35       737\n",
      "\n",
      "    accuracy                           0.47      1280\n",
      "   macro avg       0.51      0.50      0.45      1280\n",
      "weighted avg       0.52      0.47      0.43      1280\n",
      "\n",
      "[[412 131]\n",
      " [552 185]]\n",
      "Validation Loss for s01 = 0.761833906173706\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_32/3575763110.py:40: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1960: UserWarning: nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\n",
      "  warnings.warn(\"nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 73/100, Train Loss: 0.5906029343605042\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.43      0.76      0.55       543\n",
      "         1.0       0.59      0.25      0.35       737\n",
      "\n",
      "    accuracy                           0.47      1280\n",
      "   macro avg       0.51      0.51      0.45      1280\n",
      "weighted avg       0.52      0.47      0.44      1280\n",
      "\n",
      "[[412 131]\n",
      " [550 187]]\n",
      "Validation Loss for s01 = 0.7656362056732178\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_32/3575763110.py:66: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/tmp/ipykernel_32/3575763110.py:40: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1960: UserWarning: nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\n",
      "  warnings.warn(\"nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 74/100, Train Loss: 0.645348846912384\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.43      0.76      0.55       543\n",
      "         1.0       0.59      0.25      0.35       737\n",
      "\n",
      "    accuracy                           0.47      1280\n",
      "   macro avg       0.51      0.51      0.45      1280\n",
      "weighted avg       0.52      0.47      0.44      1280\n",
      "\n",
      "[[414 129]\n",
      " [552 185]]\n",
      "Validation Loss for s01 = 0.7714424729347229\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_32/3575763110.py:66: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/tmp/ipykernel_32/3575763110.py:40: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1960: UserWarning: nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\n",
      "  warnings.warn(\"nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 75/100, Train Loss: 0.7250844836235046\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_32/3575763110.py:66: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.43      0.76      0.55       543\n",
      "         1.0       0.59      0.26      0.36       737\n",
      "\n",
      "    accuracy                           0.47      1280\n",
      "   macro avg       0.51      0.51      0.45      1280\n",
      "weighted avg       0.52      0.47      0.44      1280\n",
      "\n",
      "[[413 130]\n",
      " [549 188]]\n",
      "Validation Loss for s01 = 0.763552725315094\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_32/3575763110.py:40: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1960: UserWarning: nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\n",
      "  warnings.warn(\"nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 76/100, Train Loss: 0.6575458645820618\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.43      0.76      0.55       543\n",
      "         1.0       0.59      0.25      0.35       737\n",
      "\n",
      "    accuracy                           0.47      1280\n",
      "   macro avg       0.51      0.51      0.45      1280\n",
      "weighted avg       0.52      0.47      0.44      1280\n",
      "\n",
      "[[413 130]\n",
      " [551 186]]\n",
      "Validation Loss for s01 = 0.7705312967300415\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_32/3575763110.py:66: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/tmp/ipykernel_32/3575763110.py:40: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1960: UserWarning: nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\n",
      "  warnings.warn(\"nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 77/100, Train Loss: 0.6508354544639587\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_32/3575763110.py:66: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.43      0.76      0.55       543\n",
      "         1.0       0.58      0.25      0.35       737\n",
      "\n",
      "    accuracy                           0.47      1280\n",
      "   macro avg       0.51      0.50      0.45      1280\n",
      "weighted avg       0.52      0.47      0.43      1280\n",
      "\n",
      "[[411 132]\n",
      " [551 186]]\n",
      "Validation Loss for s01 = 0.7723766565322876\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_32/3575763110.py:40: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1960: UserWarning: nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\n",
      "  warnings.warn(\"nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 78/100, Train Loss: 0.6598929762840271\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_32/3575763110.py:66: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.43      0.76      0.55       543\n",
      "         1.0       0.59      0.25      0.35       737\n",
      "\n",
      "    accuracy                           0.47      1280\n",
      "   macro avg       0.51      0.51      0.45      1280\n",
      "weighted avg       0.52      0.47      0.44      1280\n",
      "\n",
      "[[413 130]\n",
      " [550 187]]\n",
      "Validation Loss for s01 = 0.7758009433746338\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_32/3575763110.py:40: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1960: UserWarning: nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\n",
      "  warnings.warn(\"nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 79/100, Train Loss: 0.6968404650688171\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_32/3575763110.py:66: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.43      0.76      0.55       543\n",
      "         1.0       0.59      0.25      0.35       737\n",
      "\n",
      "    accuracy                           0.47      1280\n",
      "   macro avg       0.51      0.51      0.45      1280\n",
      "weighted avg       0.52      0.47      0.44      1280\n",
      "\n",
      "[[411 132]\n",
      " [550 187]]\n",
      "Validation Loss for s01 = 0.771257758140564\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_32/3575763110.py:40: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1960: UserWarning: nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\n",
      "  warnings.warn(\"nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 80/100, Train Loss: 0.6161978244781494\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_32/3575763110.py:66: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.43      0.76      0.55       543\n",
      "         1.0       0.58      0.25      0.35       737\n",
      "\n",
      "    accuracy                           0.47      1280\n",
      "   macro avg       0.51      0.50      0.45      1280\n",
      "weighted avg       0.52      0.47      0.44      1280\n",
      "\n",
      "[[410 133]\n",
      " [550 187]]\n",
      "Validation Loss for s01 = 0.7696883678436279\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_32/3575763110.py:40: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1960: UserWarning: nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\n",
      "  warnings.warn(\"nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 81/100, Train Loss: 0.6271018385887146\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_32/3575763110.py:66: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.43      0.76      0.55       543\n",
      "         1.0       0.59      0.25      0.35       737\n",
      "\n",
      "    accuracy                           0.47      1280\n",
      "   macro avg       0.51      0.51      0.45      1280\n",
      "weighted avg       0.52      0.47      0.44      1280\n",
      "\n",
      "[[412 131]\n",
      " [551 186]]\n",
      "Validation Loss for s01 = 0.7701404094696045\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_32/3575763110.py:40: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1960: UserWarning: nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\n",
      "  warnings.warn(\"nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 82/100, Train Loss: 0.6605101823806763\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_32/3575763110.py:66: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.43      0.76      0.55       543\n",
      "         1.0       0.59      0.26      0.36       737\n",
      "\n",
      "    accuracy                           0.47      1280\n",
      "   macro avg       0.51      0.51      0.45      1280\n",
      "weighted avg       0.52      0.47      0.44      1280\n",
      "\n",
      "[[411 132]\n",
      " [547 190]]\n",
      "Validation Loss for s01 = 0.7654953598976135\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_32/3575763110.py:40: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1960: UserWarning: nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\n",
      "  warnings.warn(\"nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 83/100, Train Loss: 0.6180766224861145\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.43      0.76      0.55       543\n",
      "         1.0       0.59      0.26      0.36       737\n",
      "\n",
      "    accuracy                           0.47      1280\n",
      "   macro avg       0.51      0.51      0.45      1280\n",
      "weighted avg       0.52      0.47      0.44      1280\n",
      "\n",
      "[[410 133]\n",
      " [546 191]]\n",
      "Validation Loss for s01 = 0.7669090032577515\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_32/3575763110.py:66: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/tmp/ipykernel_32/3575763110.py:40: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1960: UserWarning: nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\n",
      "  warnings.warn(\"nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 84/100, Train Loss: 0.6818034052848816\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.43      0.75      0.54       543\n",
      "         1.0       0.58      0.25      0.35       737\n",
      "\n",
      "    accuracy                           0.46      1280\n",
      "   macro avg       0.50      0.50      0.45      1280\n",
      "weighted avg       0.51      0.46      0.43      1280\n",
      "\n",
      "[[409 134]\n",
      " [553 184]]\n",
      "Validation Loss for s01 = 0.7706606388092041\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_32/3575763110.py:66: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/tmp/ipykernel_32/3575763110.py:40: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1960: UserWarning: nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\n",
      "  warnings.warn(\"nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 85/100, Train Loss: 0.6395217776298523\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_32/3575763110.py:66: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.43      0.76      0.54       543\n",
      "         1.0       0.58      0.25      0.35       737\n",
      "\n",
      "    accuracy                           0.46      1280\n",
      "   macro avg       0.50      0.50      0.45      1280\n",
      "weighted avg       0.51      0.46      0.43      1280\n",
      "\n",
      "[[410 133]\n",
      " [553 184]]\n",
      "Validation Loss for s01 = 0.7718051671981812\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_32/3575763110.py:40: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1960: UserWarning: nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\n",
      "  warnings.warn(\"nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 86/100, Train Loss: 0.6926355957984924\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_32/3575763110.py:66: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.43      0.76      0.55       543\n",
      "         1.0       0.58      0.25      0.35       737\n",
      "\n",
      "    accuracy                           0.47      1280\n",
      "   macro avg       0.50      0.50      0.45      1280\n",
      "weighted avg       0.52      0.47      0.43      1280\n",
      "\n",
      "[[410 133]\n",
      " [551 186]]\n",
      "Validation Loss for s01 = 0.7661998867988586\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_32/3575763110.py:40: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1960: UserWarning: nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\n",
      "  warnings.warn(\"nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 87/100, Train Loss: 0.6293601393699646\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_32/3575763110.py:66: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.43      0.75      0.54       543\n",
      "         1.0       0.58      0.25      0.35       737\n",
      "\n",
      "    accuracy                           0.47      1280\n",
      "   macro avg       0.50      0.50      0.45      1280\n",
      "weighted avg       0.52      0.47      0.43      1280\n",
      "\n",
      "[[409 134]\n",
      " [550 187]]\n",
      "Validation Loss for s01 = 0.7626380920410156\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_32/3575763110.py:40: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1960: UserWarning: nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\n",
      "  warnings.warn(\"nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 88/100, Train Loss: 0.6645578742027283\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.43      0.76      0.55       543\n",
      "         1.0       0.58      0.25      0.35       737\n",
      "\n",
      "    accuracy                           0.47      1280\n",
      "   macro avg       0.51      0.50      0.45      1280\n",
      "weighted avg       0.52      0.47      0.43      1280\n",
      "\n",
      "[[411 132]\n",
      " [551 186]]\n",
      "Validation Loss for s01 = 0.7693678140640259\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_32/3575763110.py:66: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/tmp/ipykernel_32/3575763110.py:40: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1960: UserWarning: nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\n",
      "  warnings.warn(\"nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 89/100, Train Loss: 0.6724210977554321\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_32/3575763110.py:66: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.43      0.76      0.55       543\n",
      "         1.0       0.59      0.26      0.36       737\n",
      "\n",
      "    accuracy                           0.47      1280\n",
      "   macro avg       0.51      0.51      0.45      1280\n",
      "weighted avg       0.52      0.47      0.44      1280\n",
      "\n",
      "[[410 133]\n",
      " [547 190]]\n",
      "Validation Loss for s01 = 0.7670571208000183\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_32/3575763110.py:40: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1960: UserWarning: nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\n",
      "  warnings.warn(\"nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 90/100, Train Loss: 0.6520082354545593\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_32/3575763110.py:66: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.43      0.76      0.55       543\n",
      "         1.0       0.59      0.25      0.35       737\n",
      "\n",
      "    accuracy                           0.47      1280\n",
      "   macro avg       0.51      0.50      0.45      1280\n",
      "weighted avg       0.52      0.47      0.43      1280\n",
      "\n",
      "[[412 131]\n",
      " [552 185]]\n",
      "Validation Loss for s01 = 0.7682204842567444\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_32/3575763110.py:40: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1960: UserWarning: nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\n",
      "  warnings.warn(\"nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 91/100, Train Loss: 0.6696372628211975\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_32/3575763110.py:66: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.43      0.76      0.55       543\n",
      "         1.0       0.60      0.26      0.36       737\n",
      "\n",
      "    accuracy                           0.47      1280\n",
      "   macro avg       0.51      0.51      0.46      1280\n",
      "weighted avg       0.53      0.47      0.44      1280\n",
      "\n",
      "[[413 130]\n",
      " [546 191]]\n",
      "Validation Loss for s01 = 0.7632932066917419\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_32/3575763110.py:40: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1960: UserWarning: nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\n",
      "  warnings.warn(\"nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 92/100, Train Loss: 0.6607741713523865\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_32/3575763110.py:66: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.43      0.76      0.55       543\n",
      "         1.0       0.59      0.26      0.36       737\n",
      "\n",
      "    accuracy                           0.47      1280\n",
      "   macro avg       0.51      0.51      0.46      1280\n",
      "weighted avg       0.52      0.47      0.44      1280\n",
      "\n",
      "[[411 132]\n",
      " [544 193]]\n",
      "Validation Loss for s01 = 0.760953962802887\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_32/3575763110.py:40: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1960: UserWarning: nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\n",
      "  warnings.warn(\"nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 93/100, Train Loss: 0.5923132300376892\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_32/3575763110.py:66: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.43      0.77      0.55       543\n",
      "         1.0       0.60      0.26      0.37       737\n",
      "\n",
      "    accuracy                           0.48      1280\n",
      "   macro avg       0.52      0.51      0.46      1280\n",
      "weighted avg       0.53      0.48      0.45      1280\n",
      "\n",
      "[[416 127]\n",
      " [544 193]]\n",
      "Validation Loss for s01 = 0.7607110738754272\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_32/3575763110.py:40: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1960: UserWarning: nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\n",
      "  warnings.warn(\"nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 94/100, Train Loss: 0.673134982585907\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_32/3575763110.py:66: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.43      0.77      0.55       543\n",
      "         1.0       0.60      0.26      0.36       737\n",
      "\n",
      "    accuracy                           0.47      1280\n",
      "   macro avg       0.52      0.51      0.46      1280\n",
      "weighted avg       0.53      0.47      0.44      1280\n",
      "\n",
      "[[419 124]\n",
      " [549 188]]\n",
      "Validation Loss for s01 = 0.7647584676742554\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_32/3575763110.py:40: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1960: UserWarning: nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\n",
      "  warnings.warn(\"nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 95/100, Train Loss: 0.6088253259658813\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.43      0.76      0.55       543\n",
      "         1.0       0.60      0.26      0.37       737\n",
      "\n",
      "    accuracy                           0.47      1280\n",
      "   macro avg       0.52      0.51      0.46      1280\n",
      "weighted avg       0.53      0.47      0.44      1280\n",
      "\n",
      "[[413 130]\n",
      " [543 194]]\n",
      "Validation Loss for s01 = 0.7561044692993164\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_32/3575763110.py:66: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/tmp/ipykernel_32/3575763110.py:40: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1960: UserWarning: nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\n",
      "  warnings.warn(\"nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 96/100, Train Loss: 0.6240304112434387\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_32/3575763110.py:66: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.43      0.76      0.55       543\n",
      "         1.0       0.60      0.26      0.36       737\n",
      "\n",
      "    accuracy                           0.47      1280\n",
      "   macro avg       0.51      0.51      0.46      1280\n",
      "weighted avg       0.53      0.47      0.44      1280\n",
      "\n",
      "[[413 130]\n",
      " [544 193]]\n",
      "Validation Loss for s01 = 0.7630923986434937\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_32/3575763110.py:40: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1960: UserWarning: nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\n",
      "  warnings.warn(\"nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 97/100, Train Loss: 0.7087463736534119\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.43      0.76      0.55       543\n",
      "         1.0       0.60      0.26      0.36       737\n",
      "\n",
      "    accuracy                           0.47      1280\n",
      "   macro avg       0.51      0.51      0.46      1280\n",
      "weighted avg       0.53      0.47      0.44      1280\n",
      "\n",
      "[[414 129]\n",
      " [547 190]]\n",
      "Validation Loss for s01 = 0.7608875036239624\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_32/3575763110.py:66: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/tmp/ipykernel_32/3575763110.py:40: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1960: UserWarning: nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\n",
      "  warnings.warn(\"nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 98/100, Train Loss: 0.6991190314292908\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_32/3575763110.py:66: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.43      0.76      0.55       543\n",
      "         1.0       0.60      0.26      0.36       737\n",
      "\n",
      "    accuracy                           0.47      1280\n",
      "   macro avg       0.51      0.51      0.46      1280\n",
      "weighted avg       0.53      0.47      0.44      1280\n",
      "\n",
      "[[415 128]\n",
      " [547 190]]\n",
      "Validation Loss for s01 = 0.7609009146690369\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_32/3575763110.py:40: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1960: UserWarning: nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\n",
      "  warnings.warn(\"nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 99/100, Train Loss: 0.6898341178894043\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_32/3575763110.py:66: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.43      0.76      0.55       543\n",
      "         1.0       0.60      0.26      0.36       737\n",
      "\n",
      "    accuracy                           0.47      1280\n",
      "   macro avg       0.52      0.51      0.46      1280\n",
      "weighted avg       0.53      0.47      0.44      1280\n",
      "\n",
      "[[415 128]\n",
      " [546 191]]\n",
      "Validation Loss for s01 = 0.7577250003814697\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_32/3575763110.py:40: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1960: UserWarning: nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\n",
      "  warnings.warn(\"nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 100/100, Train Loss: 0.6842050552368164\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_32/3575763110.py:66: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.43      0.77      0.55       543\n",
      "         1.0       0.60      0.26      0.36       737\n",
      "\n",
      "    accuracy                           0.47      1280\n",
      "   macro avg       0.52      0.51      0.46      1280\n",
      "weighted avg       0.53      0.47      0.44      1280\n",
      "\n",
      "[[416 127]\n",
      " [547 190]]\n",
      "Validation Loss for s01 = 0.7615162134170532\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x7f10b14e4df0>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1000x700 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import confusion_matrix,classification_report\n",
    "from sklearn import preprocessing\n",
    "import matplotlib.pyplot as plt\n",
    "#subjectnames\n",
    "file_list_num = np.arange(len(newsubjectname))\n",
    "file_list_numd = np.arange(len(subjectnamesd))\n",
    "test_index = file_list_numd\n",
    "kf = KFold(n_splits=12)\n",
    "torch.manual_seed(42)\n",
    "torch.cuda.manual_seed(42)\n",
    "modellist = []\n",
    "modelid = 1\n",
    "#file_list_num\n",
    "#for i, (train_index, test_index) in enumerate(kf.split(file_list_num)):\n",
    "#for train_index in file_list_num:\n",
    "train_index = file_list_num\n",
    "print(f\"Fold {i}:\")\n",
    "print(f\"  Train: index={train_index}\")\n",
    "print(f\"  Test:  index={test_index}\")\n",
    "net = Net()\n",
    "net.to(device)\n",
    "optimizer = optim.Adam(net.parameters(), lr=0.000001)\n",
    "epochs = 100\n",
    "batch_sz = 20\n",
    "train_loss_epoch = []\n",
    "val_loss_epoch = []\n",
    "for epoch in range(epochs):\n",
    "  train_loss = []\n",
    "  for tr in train_index:\n",
    "    v = data_c1d[newsubjectname[tr]]\n",
    "    l = data_c2[newsubjectname[tr]]\n",
    "    #print(v[0].shape)\n",
    "    net.train()\n",
    "    for i in range(0,len(v),batch_sz):\n",
    "      #print(v[i].shape)\n",
    "      #for j in range(0,v[i].shape[0],batch_sz):\n",
    "      #print(newsubjectname[tr])\n",
    "      optimizer.zero_grad()\n",
    "      outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
    "      #print(\"Expout {}\",outputs.shape)\n",
    "      #print(\"Actual {}\",l[i:i+batch_sz].shape)\n",
    "      #print(l[i].shape)\n",
    "      loss = criterion(outputs, l[i:i+batch_sz].to(device, dtype=torch.float))\n",
    "      loss.backward()\n",
    "      train_loss.append(loss)\n",
    "      optimizer.step()\n",
    "  print(f'Epoch {epoch + 1}/{epochs}, Train Loss: {loss.item()}')\n",
    "  train_loss_epoch.append(torch.stack(train_loss).mean().cpu().detach().numpy())\n",
    "  #print(train_loss_epoch)\n",
    "  batch_sz = 20\n",
    "  expectedoutputdeap = []\n",
    "  actualoutputdeap = []\n",
    "\n",
    "  for tr in test_index:\n",
    "      net.eval()\n",
    "      v = data_de1[subjectnamesd[tr]]\n",
    "      l = data_del[subjectnamesd[tr]]\n",
    "      net.eval()\n",
    "      val_loss = []\n",
    "      with torch.no_grad():\n",
    "          for i in range(0,len(v),batch_sz):\n",
    "            #print(v[i].shape)\n",
    "            #for j in range(0,v[i].shape[0],batch_sz):\n",
    "            optimizer.zero_grad()\n",
    "            outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
    "            #print(outputs.shape)\n",
    "            #print(l[i:i+batch_sz].shape)\n",
    "            loss = criterion(outputs, l[i:i+batch_sz].to(device, dtype=torch.float))\n",
    "            val_loss.append(loss)\n",
    "            actualoutputdeap.append(torch.round(outputs.cpu()))\n",
    "            expectedoutputdeap.append(l[i:i+batch_sz])\n",
    "            #actualoutput.append(torch.argmax(torch.softmax(outputs.cpu(),dim=1),dim=1))\n",
    "            #expectedoutput.append(torch.argmax(l[i:i+batch_sz],dim=1).numpy())\n",
    "  val_loss_mean = torch.stack(val_loss).mean().cpu().detach().numpy()\n",
    "  val_loss_epoch.append(val_loss_mean)\n",
    "  expectedoutputdeap = np.concatenate( expectedoutputdeap, axis=0 )\n",
    "  actualoutputdeap = np.concatenate( actualoutputdeap, axis=0 )\n",
    "  #print(expectedoutput.shape)\n",
    "  #print(actualoutput.shape)\n",
    "  print(classification_report(expectedoutputdeap,actualoutputdeap))\n",
    "  print(confusion_matrix(expectedoutputdeap,actualoutputdeap))\n",
    "  print(f'Validation Loss for {subjectnamesd[tr]} = {val_loss_mean}')\n",
    "plt.figure(figsize=(10,7))\n",
    "#print(len(train_loss_epoch))\n",
    "plt.plot(np.arange(epochs),train_loss_epoch,label='Train')\n",
    "plt.plot(np.arange(epochs),val_loss_epoch,label='Validation')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "82511330-d09b-4538-a8f5-32a8c2e5d91e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-22T09:54:53.163350Z",
     "iopub.status.busy": "2024-01-22T09:54:53.162643Z",
     "iopub.status.idle": "2024-01-22T09:56:51.108563Z",
     "shell.execute_reply": "2024-01-22T09:56:51.104980Z",
     "shell.execute_reply.started": "2024-01-22T09:54:53.163325Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 0:\n",
      "  Train: index=[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23\n",
      " 24 25 26 27 28 29 30 31]\n",
      "  Test:  index=[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23\n",
      " 24 25 26 27 28 29 30 31 32 33 34 35]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_116/2804007043.py:41: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1960: UserWarning: nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\n",
      "  warnings.warn(\"nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100, Train Loss: 0.6725417971611023\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_116/2804007043.py:68: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.48      0.61      0.54       333\n",
      "         1.0       0.57      0.44      0.49       387\n",
      "\n",
      "    accuracy                           0.52       720\n",
      "   macro avg       0.52      0.52      0.52       720\n",
      "weighted avg       0.53      0.52      0.51       720\n",
      "\n",
      "[[203 130]\n",
      " [218 169]]\n",
      "Validation Loss for P20 = 0.6979684233665466\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_116/2804007043.py:41: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1960: UserWarning: nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\n",
      "  warnings.warn(\"nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/100, Train Loss: 0.6840779185295105\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_116/2804007043.py:68: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.51      0.56      0.53       333\n",
      "         1.0       0.58      0.53      0.56       387\n",
      "\n",
      "    accuracy                           0.54       720\n",
      "   macro avg       0.55      0.55      0.54       720\n",
      "weighted avg       0.55      0.54      0.55       720\n",
      "\n",
      "[[187 146]\n",
      " [182 205]]\n",
      "Validation Loss for P20 = 0.7010468244552612\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_116/2804007043.py:41: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1960: UserWarning: nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\n",
      "  warnings.warn(\"nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/100, Train Loss: 0.7422818541526794\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_116/2804007043.py:68: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.50      0.52      0.51       333\n",
      "         1.0       0.58      0.56      0.57       387\n",
      "\n",
      "    accuracy                           0.54       720\n",
      "   macro avg       0.54      0.54      0.54       720\n",
      "weighted avg       0.54      0.54      0.54       720\n",
      "\n",
      "[[172 161]\n",
      " [169 218]]\n",
      "Validation Loss for P20 = 0.7045450806617737\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_116/2804007043.py:41: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1960: UserWarning: nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\n",
      "  warnings.warn(\"nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/100, Train Loss: 0.7833914160728455\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.52      0.48      0.50       333\n",
      "         1.0       0.58      0.61      0.59       387\n",
      "\n",
      "    accuracy                           0.55       720\n",
      "   macro avg       0.55      0.55      0.55       720\n",
      "weighted avg       0.55      0.55      0.55       720\n",
      "\n",
      "[[160 173]\n",
      " [150 237]]\n",
      "Validation Loss for P20 = 0.7097647786140442\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_116/2804007043.py:68: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/tmp/ipykernel_116/2804007043.py:41: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1960: UserWarning: nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\n",
      "  warnings.warn(\"nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/100, Train Loss: 0.7094191908836365\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.52      0.49      0.50       333\n",
      "         1.0       0.58      0.60      0.59       387\n",
      "\n",
      "    accuracy                           0.55       720\n",
      "   macro avg       0.55      0.55      0.55       720\n",
      "weighted avg       0.55      0.55      0.55       720\n",
      "\n",
      "[[164 169]\n",
      " [153 234]]\n",
      "Validation Loss for P20 = 0.7058501839637756\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_116/2804007043.py:68: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/tmp/ipykernel_116/2804007043.py:41: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1960: UserWarning: nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\n",
      "  warnings.warn(\"nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6/100, Train Loss: 0.682039201259613\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.52      0.46      0.48       333\n",
      "         1.0       0.58      0.63      0.60       387\n",
      "\n",
      "    accuracy                           0.55       720\n",
      "   macro avg       0.55      0.54      0.54       720\n",
      "weighted avg       0.55      0.55      0.55       720\n",
      "\n",
      "[[152 181]\n",
      " [142 245]]\n",
      "Validation Loss for P20 = 0.7127459049224854\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_116/2804007043.py:68: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/tmp/ipykernel_116/2804007043.py:41: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1960: UserWarning: nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\n",
      "  warnings.warn(\"nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7/100, Train Loss: 0.7546268701553345\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.51      0.46      0.48       333\n",
      "         1.0       0.57      0.62      0.59       387\n",
      "\n",
      "    accuracy                           0.54       720\n",
      "   macro avg       0.54      0.54      0.54       720\n",
      "weighted avg       0.54      0.54      0.54       720\n",
      "\n",
      "[[153 180]\n",
      " [148 239]]\n",
      "Validation Loss for P20 = 0.7078396081924438\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_116/2804007043.py:68: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/tmp/ipykernel_116/2804007043.py:41: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1960: UserWarning: nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\n",
      "  warnings.warn(\"nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8/100, Train Loss: 0.7809420824050903\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.52      0.50      0.51       333\n",
      "         1.0       0.59      0.61      0.60       387\n",
      "\n",
      "    accuracy                           0.56       720\n",
      "   macro avg       0.55      0.55      0.55       720\n",
      "weighted avg       0.56      0.56      0.56       720\n",
      "\n",
      "[[165 168]\n",
      " [150 237]]\n",
      "Validation Loss for P20 = 0.7021138072013855\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_116/2804007043.py:68: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/tmp/ipykernel_116/2804007043.py:41: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1960: UserWarning: nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\n",
      "  warnings.warn(\"nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9/100, Train Loss: 0.7571689486503601\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.52      0.47      0.49       333\n",
      "         1.0       0.58      0.63      0.60       387\n",
      "\n",
      "    accuracy                           0.55       720\n",
      "   macro avg       0.55      0.55      0.55       720\n",
      "weighted avg       0.55      0.55      0.55       720\n",
      "\n",
      "[[157 176]\n",
      " [145 242]]\n",
      "Validation Loss for P20 = 0.7118372321128845\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_116/2804007043.py:68: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/tmp/ipykernel_116/2804007043.py:41: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1960: UserWarning: nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\n",
      "  warnings.warn(\"nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10/100, Train Loss: 0.6721872687339783\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.52      0.46      0.49       333\n",
      "         1.0       0.58      0.63      0.60       387\n",
      "\n",
      "    accuracy                           0.55       720\n",
      "   macro avg       0.55      0.55      0.55       720\n",
      "weighted avg       0.55      0.55      0.55       720\n",
      "\n",
      "[[153 180]\n",
      " [142 245]]\n",
      "Validation Loss for P20 = 0.7091631889343262\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_116/2804007043.py:68: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/tmp/ipykernel_116/2804007043.py:41: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1960: UserWarning: nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\n",
      "  warnings.warn(\"nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11/100, Train Loss: 0.6727056503295898\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.52      0.45      0.48       333\n",
      "         1.0       0.58      0.64      0.61       387\n",
      "\n",
      "    accuracy                           0.55       720\n",
      "   macro avg       0.55      0.55      0.55       720\n",
      "weighted avg       0.55      0.55      0.55       720\n",
      "\n",
      "[[150 183]\n",
      " [138 249]]\n",
      "Validation Loss for P20 = 0.7098256349563599\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_116/2804007043.py:68: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/tmp/ipykernel_116/2804007043.py:41: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1960: UserWarning: nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\n",
      "  warnings.warn(\"nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12/100, Train Loss: 0.6737130880355835\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.51      0.40      0.45       333\n",
      "         1.0       0.56      0.66      0.61       387\n",
      "\n",
      "    accuracy                           0.54       720\n",
      "   macro avg       0.53      0.53      0.53       720\n",
      "weighted avg       0.54      0.54      0.53       720\n",
      "\n",
      "[[133 200]\n",
      " [130 257]]\n",
      "Validation Loss for P20 = 0.7214980721473694\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_116/2804007043.py:68: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/tmp/ipykernel_116/2804007043.py:41: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1960: UserWarning: nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\n",
      "  warnings.warn(\"nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13/100, Train Loss: 0.7127220034599304\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.49      0.35      0.41       333\n",
      "         1.0       0.55      0.68      0.61       387\n",
      "\n",
      "    accuracy                           0.53       720\n",
      "   macro avg       0.52      0.52      0.51       720\n",
      "weighted avg       0.52      0.53      0.52       720\n",
      "\n",
      "[[118 215]\n",
      " [122 265]]\n",
      "Validation Loss for P20 = 0.7293581962585449\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_116/2804007043.py:68: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/tmp/ipykernel_116/2804007043.py:41: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1960: UserWarning: nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\n",
      "  warnings.warn(\"nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14/100, Train Loss: 0.6696133017539978\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.48      0.34      0.40       333\n",
      "         1.0       0.55      0.68      0.61       387\n",
      "\n",
      "    accuracy                           0.53       720\n",
      "   macro avg       0.51      0.51      0.50       720\n",
      "weighted avg       0.52      0.53      0.51       720\n",
      "\n",
      "[[113 220]\n",
      " [122 265]]\n",
      "Validation Loss for P20 = 0.7267202734947205\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_116/2804007043.py:68: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/tmp/ipykernel_116/2804007043.py:41: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1960: UserWarning: nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\n",
      "  warnings.warn(\"nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15/100, Train Loss: 0.6953903436660767\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_116/2804007043.py:68: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.47      0.31      0.37       333\n",
      "         1.0       0.54      0.70      0.61       387\n",
      "\n",
      "    accuracy                           0.52       720\n",
      "   macro avg       0.50      0.50      0.49       720\n",
      "weighted avg       0.51      0.52      0.50       720\n",
      "\n",
      "[[104 229]\n",
      " [118 269]]\n",
      "Validation Loss for P20 = 0.729658305644989\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_116/2804007043.py:41: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1960: UserWarning: nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\n",
      "  warnings.warn(\"nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16/100, Train Loss: 0.7141572833061218\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_116/2804007043.py:68: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.48      0.35      0.40       333\n",
      "         1.0       0.54      0.67      0.60       387\n",
      "\n",
      "    accuracy                           0.52       720\n",
      "   macro avg       0.51      0.51      0.50       720\n",
      "weighted avg       0.51      0.52      0.51       720\n",
      "\n",
      "[[117 216]\n",
      " [129 258]]\n",
      "Validation Loss for P20 = 0.7207202315330505\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_116/2804007043.py:41: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1960: UserWarning: nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\n",
      "  warnings.warn(\"nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17/100, Train Loss: 0.6844080090522766\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_116/2804007043.py:68: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.50      0.38      0.43       333\n",
      "         1.0       0.56      0.68      0.61       387\n",
      "\n",
      "    accuracy                           0.54       720\n",
      "   macro avg       0.53      0.53      0.52       720\n",
      "weighted avg       0.53      0.54      0.53       720\n",
      "\n",
      "[[125 208]\n",
      " [125 262]]\n",
      "Validation Loss for P20 = 0.7260238528251648\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_116/2804007043.py:41: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1960: UserWarning: nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\n",
      "  warnings.warn(\"nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 18/100, Train Loss: 0.8276511430740356\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_116/2804007043.py:68: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.47      0.33      0.39       333\n",
      "         1.0       0.54      0.68      0.61       387\n",
      "\n",
      "    accuracy                           0.52       720\n",
      "   macro avg       0.51      0.51      0.50       720\n",
      "weighted avg       0.51      0.52      0.50       720\n",
      "\n",
      "[[109 224]\n",
      " [122 265]]\n",
      "Validation Loss for P20 = 0.7303277850151062\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_116/2804007043.py:41: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1960: UserWarning: nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\n",
      "  warnings.warn(\"nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19/100, Train Loss: 0.7394701838493347\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.47      0.29      0.36       333\n",
      "         1.0       0.54      0.72      0.62       387\n",
      "\n",
      "    accuracy                           0.52       720\n",
      "   macro avg       0.50      0.50      0.49       720\n",
      "weighted avg       0.51      0.52      0.50       720\n",
      "\n",
      "[[ 97 236]\n",
      " [110 277]]\n",
      "Validation Loss for P20 = 0.7381169199943542\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_116/2804007043.py:68: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/tmp/ipykernel_116/2804007043.py:41: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1960: UserWarning: nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\n",
      "  warnings.warn(\"nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20/100, Train Loss: 0.6746159195899963\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.49      0.34      0.40       333\n",
      "         1.0       0.55      0.70      0.61       387\n",
      "\n",
      "    accuracy                           0.53       720\n",
      "   macro avg       0.52      0.52      0.51       720\n",
      "weighted avg       0.52      0.53      0.52       720\n",
      "\n",
      "[[113 220]\n",
      " [118 269]]\n",
      "Validation Loss for P20 = 0.7335891127586365\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_116/2804007043.py:68: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/tmp/ipykernel_116/2804007043.py:41: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1960: UserWarning: nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\n",
      "  warnings.warn(\"nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 21/100, Train Loss: 0.7029844522476196\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.50      0.34      0.41       333\n",
      "         1.0       0.55      0.70      0.62       387\n",
      "\n",
      "    accuracy                           0.54       720\n",
      "   macro avg       0.53      0.52      0.51       720\n",
      "weighted avg       0.53      0.54      0.52       720\n",
      "\n",
      "[[114 219]\n",
      " [115 272]]\n",
      "Validation Loss for P20 = 0.7473781704902649\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_116/2804007043.py:68: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/tmp/ipykernel_116/2804007043.py:41: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1960: UserWarning: nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\n",
      "  warnings.warn(\"nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 22/100, Train Loss: 0.7648965120315552\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.51      0.35      0.42       333\n",
      "         1.0       0.56      0.70      0.62       387\n",
      "\n",
      "    accuracy                           0.54       720\n",
      "   macro avg       0.53      0.53      0.52       720\n",
      "weighted avg       0.53      0.54      0.53       720\n",
      "\n",
      "[[118 215]\n",
      " [115 272]]\n",
      "Validation Loss for P20 = 0.7451741099357605\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_116/2804007043.py:68: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/tmp/ipykernel_116/2804007043.py:41: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1960: UserWarning: nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\n",
      "  warnings.warn(\"nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 23/100, Train Loss: 0.6803342700004578\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.49      0.31      0.38       333\n",
      "         1.0       0.55      0.72      0.62       387\n",
      "\n",
      "    accuracy                           0.53       720\n",
      "   macro avg       0.52      0.51      0.50       720\n",
      "weighted avg       0.52      0.53      0.51       720\n",
      "\n",
      "[[102 231]\n",
      " [107 280]]\n",
      "Validation Loss for P20 = 0.7453150749206543\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_116/2804007043.py:68: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/tmp/ipykernel_116/2804007043.py:41: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1960: UserWarning: nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\n",
      "  warnings.warn(\"nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 24/100, Train Loss: 0.6784123778343201\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.48      0.30      0.37       333\n",
      "         1.0       0.54      0.72      0.62       387\n",
      "\n",
      "    accuracy                           0.52       720\n",
      "   macro avg       0.51      0.51      0.49       720\n",
      "weighted avg       0.51      0.52      0.50       720\n",
      "\n",
      "[[100 233]\n",
      " [110 277]]\n",
      "Validation Loss for P20 = 0.7439695000648499\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_116/2804007043.py:68: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/tmp/ipykernel_116/2804007043.py:41: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1960: UserWarning: nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\n",
      "  warnings.warn(\"nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 25/100, Train Loss: 0.7191561460494995\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.50      0.29      0.37       333\n",
      "         1.0       0.55      0.75      0.63       387\n",
      "\n",
      "    accuracy                           0.54       720\n",
      "   macro avg       0.52      0.52      0.50       720\n",
      "weighted avg       0.53      0.54      0.51       720\n",
      "\n",
      "[[ 97 236]\n",
      " [ 98 289]]\n",
      "Validation Loss for P20 = 0.7563400864601135\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_116/2804007043.py:68: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/tmp/ipykernel_116/2804007043.py:41: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1960: UserWarning: nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\n",
      "  warnings.warn(\"nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 26/100, Train Loss: 0.7421056628227234\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.50      0.33      0.40       333\n",
      "         1.0       0.55      0.71      0.62       387\n",
      "\n",
      "    accuracy                           0.54       720\n",
      "   macro avg       0.53      0.52      0.51       720\n",
      "weighted avg       0.53      0.54      0.52       720\n",
      "\n",
      "[[110 223]\n",
      " [111 276]]\n",
      "Validation Loss for P20 = 0.7451534271240234\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_116/2804007043.py:68: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/tmp/ipykernel_116/2804007043.py:41: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1960: UserWarning: nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\n",
      "  warnings.warn(\"nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 27/100, Train Loss: 0.7317146062850952\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.51      0.33      0.40       333\n",
      "         1.0       0.56      0.72      0.63       387\n",
      "\n",
      "    accuracy                           0.54       720\n",
      "   macro avg       0.53      0.53      0.52       720\n",
      "weighted avg       0.54      0.54      0.52       720\n",
      "\n",
      "[[111 222]\n",
      " [107 280]]\n",
      "Validation Loss for P20 = 0.7531870007514954\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_116/2804007043.py:68: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/tmp/ipykernel_116/2804007043.py:41: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1960: UserWarning: nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\n",
      "  warnings.warn(\"nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 28/100, Train Loss: 0.7039533257484436\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_116/2804007043.py:68: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.48      0.26      0.34       333\n",
      "         1.0       0.54      0.76      0.63       387\n",
      "\n",
      "    accuracy                           0.53       720\n",
      "   macro avg       0.51      0.51      0.48       720\n",
      "weighted avg       0.51      0.53      0.49       720\n",
      "\n",
      "[[ 86 247]\n",
      " [ 94 293]]\n",
      "Validation Loss for P20 = 0.7659246325492859\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_116/2804007043.py:41: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1960: UserWarning: nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\n",
      "  warnings.warn(\"nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 29/100, Train Loss: 0.6861473321914673\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_116/2804007043.py:68: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.48      0.26      0.34       333\n",
      "         1.0       0.54      0.76      0.63       387\n",
      "\n",
      "    accuracy                           0.53       720\n",
      "   macro avg       0.51      0.51      0.49       720\n",
      "weighted avg       0.52      0.53      0.50       720\n",
      "\n",
      "[[ 88 245]\n",
      " [ 94 293]]\n",
      "Validation Loss for P20 = 0.7684219479560852\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_116/2804007043.py:41: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1960: UserWarning: nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\n",
      "  warnings.warn(\"nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 30/100, Train Loss: 0.7059593200683594\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_116/2804007043.py:68: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.49      0.31      0.38       333\n",
      "         1.0       0.55      0.72      0.62       387\n",
      "\n",
      "    accuracy                           0.53       720\n",
      "   macro avg       0.52      0.52      0.50       720\n",
      "weighted avg       0.52      0.53      0.51       720\n",
      "\n",
      "[[104 229]\n",
      " [107 280]]\n",
      "Validation Loss for P20 = 0.7562812566757202\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_116/2804007043.py:41: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1960: UserWarning: nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\n",
      "  warnings.warn(\"nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 31/100, Train Loss: 0.6901684999465942\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_116/2804007043.py:68: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.46      0.23      0.31       333\n",
      "         1.0       0.54      0.77      0.63       387\n",
      "\n",
      "    accuracy                           0.52       720\n",
      "   macro avg       0.50      0.50      0.47       720\n",
      "weighted avg       0.50      0.52      0.48       720\n",
      "\n",
      "[[ 77 256]\n",
      " [ 89 298]]\n",
      "Validation Loss for P20 = 0.7738975882530212\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_116/2804007043.py:41: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1960: UserWarning: nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\n",
      "  warnings.warn(\"nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 32/100, Train Loss: 0.7188003659248352\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.48      0.25      0.33       333\n",
      "         1.0       0.54      0.77      0.64       387\n",
      "\n",
      "    accuracy                           0.53       720\n",
      "   macro avg       0.51      0.51      0.48       720\n",
      "weighted avg       0.51      0.53      0.49       720\n",
      "\n",
      "[[ 83 250]\n",
      " [ 90 297]]\n",
      "Validation Loss for P20 = 0.7745208144187927\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_116/2804007043.py:68: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/tmp/ipykernel_116/2804007043.py:41: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1960: UserWarning: nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\n",
      "  warnings.warn(\"nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 33/100, Train Loss: 0.7739545106887817\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.47      0.25      0.33       333\n",
      "         1.0       0.54      0.75      0.63       387\n",
      "\n",
      "    accuracy                           0.52       720\n",
      "   macro avg       0.50      0.50      0.48       720\n",
      "weighted avg       0.51      0.52      0.49       720\n",
      "\n",
      "[[ 84 249]\n",
      " [ 95 292]]\n",
      "Validation Loss for P20 = 0.7665965557098389\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_116/2804007043.py:68: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/tmp/ipykernel_116/2804007043.py:41: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1960: UserWarning: nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\n",
      "  warnings.warn(\"nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 34/100, Train Loss: 0.6358105540275574\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.48      0.24      0.32       333\n",
      "         1.0       0.54      0.78      0.64       387\n",
      "\n",
      "    accuracy                           0.53       720\n",
      "   macro avg       0.51      0.51      0.48       720\n",
      "weighted avg       0.51      0.53      0.49       720\n",
      "\n",
      "[[ 79 254]\n",
      " [ 85 302]]\n",
      "Validation Loss for P20 = 0.7812924385070801\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_116/2804007043.py:68: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/tmp/ipykernel_116/2804007043.py:41: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1960: UserWarning: nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\n",
      "  warnings.warn(\"nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 35/100, Train Loss: 0.6873697638511658\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.49      0.24      0.32       333\n",
      "         1.0       0.54      0.78      0.64       387\n",
      "\n",
      "    accuracy                           0.53       720\n",
      "   macro avg       0.51      0.51      0.48       720\n",
      "weighted avg       0.52      0.53      0.49       720\n",
      "\n",
      "[[ 81 252]\n",
      " [ 86 301]]\n",
      "Validation Loss for P20 = 0.7769344449043274\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_116/2804007043.py:68: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/tmp/ipykernel_116/2804007043.py:41: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1960: UserWarning: nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\n",
      "  warnings.warn(\"nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 36/100, Train Loss: 0.7128864526748657\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.47      0.23      0.31       333\n",
      "         1.0       0.54      0.78      0.64       387\n",
      "\n",
      "    accuracy                           0.52       720\n",
      "   macro avg       0.50      0.50      0.47       720\n",
      "weighted avg       0.51      0.52      0.48       720\n",
      "\n",
      "[[ 76 257]\n",
      " [ 87 300]]\n",
      "Validation Loss for P20 = 0.7824925184249878\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_116/2804007043.py:68: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/tmp/ipykernel_116/2804007043.py:41: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1960: UserWarning: nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\n",
      "  warnings.warn(\"nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 37/100, Train Loss: 0.7026640772819519\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.47      0.22      0.30       333\n",
      "         1.0       0.54      0.79      0.64       387\n",
      "\n",
      "    accuracy                           0.53       720\n",
      "   macro avg       0.51      0.50      0.47       720\n",
      "weighted avg       0.51      0.53      0.48       720\n",
      "\n",
      "[[ 72 261]\n",
      " [ 81 306]]\n",
      "Validation Loss for P20 = 0.7899739742279053\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_116/2804007043.py:68: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/tmp/ipykernel_116/2804007043.py:41: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1960: UserWarning: nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\n",
      "  warnings.warn(\"nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 38/100, Train Loss: 0.6441836357116699\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.47      0.22      0.30       333\n",
      "         1.0       0.54      0.79      0.64       387\n",
      "\n",
      "    accuracy                           0.53       720\n",
      "   macro avg       0.51      0.51      0.47       720\n",
      "weighted avg       0.51      0.53      0.48       720\n",
      "\n",
      "[[ 74 259]\n",
      " [ 82 305]]\n",
      "Validation Loss for P20 = 0.7898890376091003\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_116/2804007043.py:68: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/tmp/ipykernel_116/2804007043.py:41: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1960: UserWarning: nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\n",
      "  warnings.warn(\"nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 39/100, Train Loss: 0.7521233558654785\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.47      0.21      0.29       333\n",
      "         1.0       0.54      0.79      0.64       387\n",
      "\n",
      "    accuracy                           0.53       720\n",
      "   macro avg       0.50      0.50      0.47       720\n",
      "weighted avg       0.51      0.53      0.48       720\n",
      "\n",
      "[[ 71 262]\n",
      " [ 80 307]]\n",
      "Validation Loss for P20 = 0.7980331182479858\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_116/2804007043.py:68: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/tmp/ipykernel_116/2804007043.py:41: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1960: UserWarning: nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\n",
      "  warnings.warn(\"nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 40/100, Train Loss: 0.7421184778213501\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.47      0.21      0.29       333\n",
      "         1.0       0.54      0.80      0.65       387\n",
      "\n",
      "    accuracy                           0.53       720\n",
      "   macro avg       0.51      0.50      0.47       720\n",
      "weighted avg       0.51      0.53      0.48       720\n",
      "\n",
      "[[ 69 264]\n",
      " [ 77 310]]\n",
      "Validation Loss for P20 = 0.8006372451782227\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_116/2804007043.py:68: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/tmp/ipykernel_116/2804007043.py:41: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1960: UserWarning: nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\n",
      "  warnings.warn(\"nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 41/100, Train Loss: 0.795099139213562\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.47      0.23      0.31       333\n",
      "         1.0       0.54      0.79      0.64       387\n",
      "\n",
      "    accuracy                           0.53       720\n",
      "   macro avg       0.51      0.51      0.47       720\n",
      "weighted avg       0.51      0.53      0.49       720\n",
      "\n",
      "[[ 75 258]\n",
      " [ 83 304]]\n",
      "Validation Loss for P20 = 0.7952650785446167\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_116/2804007043.py:68: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/tmp/ipykernel_116/2804007043.py:41: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1960: UserWarning: nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\n",
      "  warnings.warn(\"nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 42/100, Train Loss: 0.7673959136009216\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.48      0.21      0.29       333\n",
      "         1.0       0.54      0.80      0.65       387\n",
      "\n",
      "    accuracy                           0.53       720\n",
      "   macro avg       0.51      0.51      0.47       720\n",
      "weighted avg       0.51      0.53      0.48       720\n",
      "\n",
      "[[ 70 263]\n",
      " [ 77 310]]\n",
      "Validation Loss for P20 = 0.8036807179450989\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_116/2804007043.py:68: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/tmp/ipykernel_116/2804007043.py:41: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1960: UserWarning: nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\n",
      "  warnings.warn(\"nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 43/100, Train Loss: 0.7501412034034729\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_116/2804007043.py:68: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.47      0.21      0.29       333\n",
      "         1.0       0.54      0.80      0.64       387\n",
      "\n",
      "    accuracy                           0.53       720\n",
      "   macro avg       0.51      0.50      0.47       720\n",
      "weighted avg       0.51      0.53      0.48       720\n",
      "\n",
      "[[ 70 263]\n",
      " [ 78 309]]\n",
      "Validation Loss for P20 = 0.8016977310180664\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_116/2804007043.py:41: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1960: UserWarning: nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\n",
      "  warnings.warn(\"nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 44/100, Train Loss: 0.7424687743186951\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_116/2804007043.py:68: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.48      0.21      0.29       333\n",
      "         1.0       0.54      0.80      0.65       387\n",
      "\n",
      "    accuracy                           0.53       720\n",
      "   macro avg       0.51      0.51      0.47       720\n",
      "weighted avg       0.51      0.53      0.48       720\n",
      "\n",
      "[[ 70 263]\n",
      " [ 77 310]]\n",
      "Validation Loss for P20 = 0.8022125363349915\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_116/2804007043.py:41: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1960: UserWarning: nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\n",
      "  warnings.warn(\"nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 45/100, Train Loss: 0.6900778412818909\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.49      0.22      0.30       333\n",
      "         1.0       0.54      0.80      0.65       387\n",
      "\n",
      "    accuracy                           0.53       720\n",
      "   macro avg       0.52      0.51      0.48       720\n",
      "weighted avg       0.52      0.53      0.49       720\n",
      "\n",
      "[[ 73 260]\n",
      " [ 76 311]]\n",
      "Validation Loss for P20 = 0.8038837313652039\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_116/2804007043.py:68: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/tmp/ipykernel_116/2804007043.py:41: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1960: UserWarning: nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\n",
      "  warnings.warn(\"nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 46/100, Train Loss: 0.7224294543266296\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.50      0.23      0.32       333\n",
      "         1.0       0.55      0.80      0.65       387\n",
      "\n",
      "    accuracy                           0.54       720\n",
      "   macro avg       0.52      0.52      0.48       720\n",
      "weighted avg       0.53      0.54      0.50       720\n",
      "\n",
      "[[ 77 256]\n",
      " [ 77 310]]\n",
      "Validation Loss for P20 = 0.8023203015327454\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_116/2804007043.py:68: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/tmp/ipykernel_116/2804007043.py:41: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1960: UserWarning: nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\n",
      "  warnings.warn(\"nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 47/100, Train Loss: 0.760988712310791\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.49      0.22      0.30       333\n",
      "         1.0       0.54      0.80      0.65       387\n",
      "\n",
      "    accuracy                           0.53       720\n",
      "   macro avg       0.52      0.51      0.47       720\n",
      "weighted avg       0.52      0.53      0.49       720\n",
      "\n",
      "[[ 72 261]\n",
      " [ 76 311]]\n",
      "Validation Loss for P20 = 0.8049942255020142\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_116/2804007043.py:68: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/tmp/ipykernel_116/2804007043.py:41: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1960: UserWarning: nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\n",
      "  warnings.warn(\"nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 48/100, Train Loss: 0.7075980305671692\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.48      0.20      0.28       333\n",
      "         1.0       0.54      0.81      0.65       387\n",
      "\n",
      "    accuracy                           0.53       720\n",
      "   macro avg       0.51      0.51      0.47       720\n",
      "weighted avg       0.51      0.53      0.48       720\n",
      "\n",
      "[[ 67 266]\n",
      " [ 73 314]]\n",
      "Validation Loss for P20 = 0.8175856471061707\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_116/2804007043.py:68: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/tmp/ipykernel_116/2804007043.py:41: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1960: UserWarning: nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\n",
      "  warnings.warn(\"nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 49/100, Train Loss: 0.6876972913742065\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.47      0.20      0.29       333\n",
      "         1.0       0.54      0.80      0.65       387\n",
      "\n",
      "    accuracy                           0.53       720\n",
      "   macro avg       0.51      0.50      0.47       720\n",
      "weighted avg       0.51      0.53      0.48       720\n",
      "\n",
      "[[ 68 265]\n",
      " [ 76 311]]\n",
      "Validation Loss for P20 = 0.8111673593521118\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_116/2804007043.py:68: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/tmp/ipykernel_116/2804007043.py:41: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1960: UserWarning: nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\n",
      "  warnings.warn(\"nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 50/100, Train Loss: 0.6920136213302612\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.49      0.22      0.31       333\n",
      "         1.0       0.54      0.80      0.65       387\n",
      "\n",
      "    accuracy                           0.53       720\n",
      "   macro avg       0.52      0.51      0.48       720\n",
      "weighted avg       0.52      0.53      0.49       720\n",
      "\n",
      "[[ 74 259]\n",
      " [ 77 310]]\n",
      "Validation Loss for P20 = 0.8084902167320251\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_116/2804007043.py:68: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/tmp/ipykernel_116/2804007043.py:41: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1960: UserWarning: nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\n",
      "  warnings.warn(\"nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 51/100, Train Loss: 0.68045574426651\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.49      0.21      0.29       333\n",
      "         1.0       0.54      0.81      0.65       387\n",
      "\n",
      "    accuracy                           0.53       720\n",
      "   macro avg       0.52      0.51      0.47       720\n",
      "weighted avg       0.52      0.53      0.49       720\n",
      "\n",
      "[[ 69 264]\n",
      " [ 72 315]]\n",
      "Validation Loss for P20 = 0.8144022226333618\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_116/2804007043.py:68: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/tmp/ipykernel_116/2804007043.py:41: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1960: UserWarning: nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\n",
      "  warnings.warn(\"nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 52/100, Train Loss: 0.7276391983032227\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_116/2804007043.py:68: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.49      0.21      0.29       333\n",
      "         1.0       0.54      0.81      0.65       387\n",
      "\n",
      "    accuracy                           0.53       720\n",
      "   macro avg       0.52      0.51      0.47       720\n",
      "weighted avg       0.52      0.53      0.49       720\n",
      "\n",
      "[[ 69 264]\n",
      " [ 72 315]]\n",
      "Validation Loss for P20 = 0.8191707730293274\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_116/2804007043.py:41: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1960: UserWarning: nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\n",
      "  warnings.warn(\"nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 53/100, Train Loss: 0.7478491067886353\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_116/2804007043.py:68: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.48      0.20      0.28       333\n",
      "         1.0       0.54      0.82      0.65       387\n",
      "\n",
      "    accuracy                           0.53       720\n",
      "   macro avg       0.51      0.51      0.47       720\n",
      "weighted avg       0.51      0.53      0.48       720\n",
      "\n",
      "[[ 65 268]\n",
      " [ 70 317]]\n",
      "Validation Loss for P20 = 0.8232583999633789\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_116/2804007043.py:41: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1960: UserWarning: nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\n",
      "  warnings.warn(\"nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 54/100, Train Loss: 0.7425850033760071\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_116/2804007043.py:68: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.48      0.21      0.29       333\n",
      "         1.0       0.54      0.81      0.65       387\n",
      "\n",
      "    accuracy                           0.53       720\n",
      "   macro avg       0.51      0.51      0.47       720\n",
      "weighted avg       0.51      0.53      0.48       720\n",
      "\n",
      "[[ 69 264]\n",
      " [ 74 313]]\n",
      "Validation Loss for P20 = 0.815356433391571\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_116/2804007043.py:41: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1960: UserWarning: nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\n",
      "  warnings.warn(\"nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 55/100, Train Loss: 0.7607060670852661\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_116/2804007043.py:68: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.50      0.23      0.31       333\n",
      "         1.0       0.55      0.80      0.65       387\n",
      "\n",
      "    accuracy                           0.54       720\n",
      "   macro avg       0.52      0.51      0.48       720\n",
      "weighted avg       0.52      0.54      0.49       720\n",
      "\n",
      "[[ 75 258]\n",
      " [ 76 311]]\n",
      "Validation Loss for P20 = 0.807952344417572\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_116/2804007043.py:41: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1960: UserWarning: nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\n",
      "  warnings.warn(\"nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 56/100, Train Loss: 0.7213819622993469\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_116/2804007043.py:68: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.49      0.21      0.29       333\n",
      "         1.0       0.54      0.81      0.65       387\n",
      "\n",
      "    accuracy                           0.53       720\n",
      "   macro avg       0.52      0.51      0.47       720\n",
      "weighted avg       0.52      0.53      0.49       720\n",
      "\n",
      "[[ 69 264]\n",
      " [ 72 315]]\n",
      "Validation Loss for P20 = 0.817950427532196\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_116/2804007043.py:41: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1960: UserWarning: nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\n",
      "  warnings.warn(\"nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 57/100, Train Loss: 0.7086052298545837\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_116/2804007043.py:68: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.49      0.20      0.29       333\n",
      "         1.0       0.54      0.82      0.65       387\n",
      "\n",
      "    accuracy                           0.53       720\n",
      "   macro avg       0.52      0.51      0.47       720\n",
      "weighted avg       0.52      0.53      0.48       720\n",
      "\n",
      "[[ 67 266]\n",
      " [ 70 317]]\n",
      "Validation Loss for P20 = 0.828316330909729\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_116/2804007043.py:41: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1960: UserWarning: nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\n",
      "  warnings.warn(\"nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 58/100, Train Loss: 0.6884118318557739\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_116/2804007043.py:68: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.49      0.20      0.29       333\n",
      "         1.0       0.54      0.82      0.65       387\n",
      "\n",
      "    accuracy                           0.53       720\n",
      "   macro avg       0.52      0.51      0.47       720\n",
      "weighted avg       0.52      0.53      0.48       720\n",
      "\n",
      "[[ 67 266]\n",
      " [ 70 317]]\n",
      "Validation Loss for P20 = 0.825415313243866\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_116/2804007043.py:41: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1960: UserWarning: nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\n",
      "  warnings.warn(\"nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 59/100, Train Loss: 0.7196404337882996\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_116/2804007043.py:68: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.50      0.21      0.30       333\n",
      "         1.0       0.55      0.82      0.65       387\n",
      "\n",
      "    accuracy                           0.54       720\n",
      "   macro avg       0.52      0.51      0.47       720\n",
      "weighted avg       0.52      0.54      0.49       720\n",
      "\n",
      "[[ 70 263]\n",
      " [ 71 316]]\n",
      "Validation Loss for P20 = 0.8213052749633789\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_116/2804007043.py:41: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1960: UserWarning: nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\n",
      "  warnings.warn(\"nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 60/100, Train Loss: 0.7337867021560669\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_116/2804007043.py:68: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.49      0.20      0.28       333\n",
      "         1.0       0.54      0.82      0.65       387\n",
      "\n",
      "    accuracy                           0.53       720\n",
      "   macro avg       0.51      0.51      0.47       720\n",
      "weighted avg       0.52      0.53      0.48       720\n",
      "\n",
      "[[ 67 266]\n",
      " [ 71 316]]\n",
      "Validation Loss for P20 = 0.8245810866355896\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_116/2804007043.py:41: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1960: UserWarning: nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\n",
      "  warnings.warn(\"nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 61/100, Train Loss: 0.7495428919792175\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_116/2804007043.py:68: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.48      0.20      0.29       333\n",
      "         1.0       0.54      0.81      0.65       387\n",
      "\n",
      "    accuracy                           0.53       720\n",
      "   macro avg       0.51      0.51      0.47       720\n",
      "weighted avg       0.51      0.53      0.48       720\n",
      "\n",
      "[[ 68 265]\n",
      " [ 75 312]]\n",
      "Validation Loss for P20 = 0.8191578984260559\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_116/2804007043.py:41: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1960: UserWarning: nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\n",
      "  warnings.warn(\"nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 62/100, Train Loss: 0.6956062912940979\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.48      0.21      0.29       333\n",
      "         1.0       0.54      0.81      0.65       387\n",
      "\n",
      "    accuracy                           0.53       720\n",
      "   macro avg       0.51      0.51      0.47       720\n",
      "weighted avg       0.51      0.53      0.48       720\n",
      "\n",
      "[[ 70 263]\n",
      " [ 75 312]]\n",
      "Validation Loss for P20 = 0.8188294768333435\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_116/2804007043.py:68: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/tmp/ipykernel_116/2804007043.py:41: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1960: UserWarning: nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\n",
      "  warnings.warn(\"nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 63/100, Train Loss: 0.7780949473381042\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.49      0.20      0.28       333\n",
      "         1.0       0.54      0.82      0.65       387\n",
      "\n",
      "    accuracy                           0.53       720\n",
      "   macro avg       0.51      0.51      0.47       720\n",
      "weighted avg       0.52      0.53      0.48       720\n",
      "\n",
      "[[ 67 266]\n",
      " [ 71 316]]\n",
      "Validation Loss for P20 = 0.8260372281074524\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_116/2804007043.py:68: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/tmp/ipykernel_116/2804007043.py:41: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1960: UserWarning: nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\n",
      "  warnings.warn(\"nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 64/100, Train Loss: 0.7723557949066162\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.50      0.20      0.28       333\n",
      "         1.0       0.55      0.83      0.66       387\n",
      "\n",
      "    accuracy                           0.54       720\n",
      "   macro avg       0.52      0.51      0.47       720\n",
      "weighted avg       0.52      0.54      0.48       720\n",
      "\n",
      "[[ 66 267]\n",
      " [ 67 320]]\n",
      "Validation Loss for P20 = 0.8293868899345398\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_116/2804007043.py:68: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/tmp/ipykernel_116/2804007043.py:41: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1960: UserWarning: nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\n",
      "  warnings.warn(\"nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 65/100, Train Loss: 0.7324371337890625\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_116/2804007043.py:68: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.49      0.20      0.28       333\n",
      "         1.0       0.54      0.82      0.66       387\n",
      "\n",
      "    accuracy                           0.53       720\n",
      "   macro avg       0.52      0.51      0.47       720\n",
      "weighted avg       0.52      0.53      0.48       720\n",
      "\n",
      "[[ 66 267]\n",
      " [ 68 319]]\n",
      "Validation Loss for P20 = 0.8305844664573669\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_116/2804007043.py:41: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1960: UserWarning: nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\n",
      "  warnings.warn(\"nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 66/100, Train Loss: 0.7760495543479919\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_116/2804007043.py:68: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.48      0.19      0.27       333\n",
      "         1.0       0.54      0.83      0.66       387\n",
      "\n",
      "    accuracy                           0.53       720\n",
      "   macro avg       0.51      0.51      0.46       720\n",
      "weighted avg       0.52      0.53      0.48       720\n",
      "\n",
      "[[ 62 271]\n",
      " [ 66 321]]\n",
      "Validation Loss for P20 = 0.8418915867805481\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_116/2804007043.py:41: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1960: UserWarning: nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\n",
      "  warnings.warn(\"nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 67/100, Train Loss: 0.7214493155479431\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_116/2804007043.py:68: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.48      0.19      0.27       333\n",
      "         1.0       0.54      0.83      0.66       387\n",
      "\n",
      "    accuracy                           0.53       720\n",
      "   macro avg       0.51      0.51      0.46       720\n",
      "weighted avg       0.52      0.53      0.48       720\n",
      "\n",
      "[[ 62 271]\n",
      " [ 66 321]]\n",
      "Validation Loss for P20 = 0.8398600816726685\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_116/2804007043.py:41: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1960: UserWarning: nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\n",
      "  warnings.warn(\"nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 68/100, Train Loss: 0.7430471777915955\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_116/2804007043.py:68: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.49      0.20      0.29       333\n",
      "         1.0       0.54      0.82      0.65       387\n",
      "\n",
      "    accuracy                           0.53       720\n",
      "   macro avg       0.52      0.51      0.47       720\n",
      "weighted avg       0.52      0.53      0.49       720\n",
      "\n",
      "[[ 68 265]\n",
      " [ 70 317]]\n",
      "Validation Loss for P20 = 0.8338825106620789\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_116/2804007043.py:41: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1960: UserWarning: nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\n",
      "  warnings.warn(\"nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 69/100, Train Loss: 0.7288035154342651\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_116/2804007043.py:68: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.49      0.20      0.29       333\n",
      "         1.0       0.54      0.82      0.65       387\n",
      "\n",
      "    accuracy                           0.53       720\n",
      "   macro avg       0.52      0.51      0.47       720\n",
      "weighted avg       0.52      0.53      0.48       720\n",
      "\n",
      "[[ 67 266]\n",
      " [ 69 318]]\n",
      "Validation Loss for P20 = 0.8350088000297546\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_116/2804007043.py:41: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1960: UserWarning: nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\n",
      "  warnings.warn(\"nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 70/100, Train Loss: 0.7392114400863647\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.48      0.20      0.28       333\n",
      "         1.0       0.54      0.82      0.65       387\n",
      "\n",
      "    accuracy                           0.53       720\n",
      "   macro avg       0.51      0.51      0.47       720\n",
      "weighted avg       0.51      0.53      0.48       720\n",
      "\n",
      "[[ 66 267]\n",
      " [ 71 316]]\n",
      "Validation Loss for P20 = 0.837878406047821\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_116/2804007043.py:68: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/tmp/ipykernel_116/2804007043.py:41: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1960: UserWarning: nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\n",
      "  warnings.warn(\"nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 71/100, Train Loss: 0.7562517523765564\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.48      0.19      0.28       333\n",
      "         1.0       0.54      0.82      0.65       387\n",
      "\n",
      "    accuracy                           0.53       720\n",
      "   macro avg       0.51      0.51      0.46       720\n",
      "weighted avg       0.52      0.53      0.48       720\n",
      "\n",
      "[[ 64 269]\n",
      " [ 68 319]]\n",
      "Validation Loss for P20 = 0.8518125414848328\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_116/2804007043.py:68: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/tmp/ipykernel_116/2804007043.py:41: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1960: UserWarning: nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\n",
      "  warnings.warn(\"nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 72/100, Train Loss: 0.6599990129470825\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.48      0.20      0.28       333\n",
      "         1.0       0.54      0.82      0.65       387\n",
      "\n",
      "    accuracy                           0.53       720\n",
      "   macro avg       0.51      0.51      0.47       720\n",
      "weighted avg       0.51      0.53      0.48       720\n",
      "\n",
      "[[ 65 268]\n",
      " [ 70 317]]\n",
      "Validation Loss for P20 = 0.8485538363456726\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_116/2804007043.py:68: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/tmp/ipykernel_116/2804007043.py:41: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1960: UserWarning: nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\n",
      "  warnings.warn(\"nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 73/100, Train Loss: 0.7398813366889954\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.48      0.20      0.28       333\n",
      "         1.0       0.54      0.82      0.65       387\n",
      "\n",
      "    accuracy                           0.53       720\n",
      "   macro avg       0.51      0.51      0.47       720\n",
      "weighted avg       0.51      0.53      0.48       720\n",
      "\n",
      "[[ 65 268]\n",
      " [ 70 317]]\n",
      "Validation Loss for P20 = 0.8461368680000305\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_116/2804007043.py:68: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/tmp/ipykernel_116/2804007043.py:41: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1960: UserWarning: nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\n",
      "  warnings.warn(\"nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 74/100, Train Loss: 0.7006458044052124\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.48      0.19      0.27       333\n",
      "         1.0       0.54      0.82      0.65       387\n",
      "\n",
      "    accuracy                           0.53       720\n",
      "   macro avg       0.51      0.51      0.46       720\n",
      "weighted avg       0.51      0.53      0.48       720\n",
      "\n",
      "[[ 64 269]\n",
      " [ 69 318]]\n",
      "Validation Loss for P20 = 0.8532297015190125\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_116/2804007043.py:68: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/tmp/ipykernel_116/2804007043.py:41: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1960: UserWarning: nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\n",
      "  warnings.warn(\"nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 75/100, Train Loss: 0.6914193034172058\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.49      0.20      0.28       333\n",
      "         1.0       0.54      0.83      0.66       387\n",
      "\n",
      "    accuracy                           0.53       720\n",
      "   macro avg       0.52      0.51      0.47       720\n",
      "weighted avg       0.52      0.53      0.48       720\n",
      "\n",
      "[[ 65 268]\n",
      " [ 67 320]]\n",
      "Validation Loss for P20 = 0.8567724227905273\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_116/2804007043.py:68: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/tmp/ipykernel_116/2804007043.py:41: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1960: UserWarning: nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\n",
      "  warnings.warn(\"nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 76/100, Train Loss: 0.7435727119445801\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.50      0.19      0.28       333\n",
      "         1.0       0.55      0.84      0.66       387\n",
      "\n",
      "    accuracy                           0.54       720\n",
      "   macro avg       0.53      0.51      0.47       720\n",
      "weighted avg       0.53      0.54      0.48       720\n",
      "\n",
      "[[ 64 269]\n",
      " [ 63 324]]\n",
      "Validation Loss for P20 = 0.8583800196647644\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_116/2804007043.py:68: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/tmp/ipykernel_116/2804007043.py:41: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1960: UserWarning: nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\n",
      "  warnings.warn(\"nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 77/100, Train Loss: 0.6994243860244751\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.51      0.19      0.28       333\n",
      "         1.0       0.55      0.84      0.66       387\n",
      "\n",
      "    accuracy                           0.54       720\n",
      "   macro avg       0.53      0.52      0.47       720\n",
      "weighted avg       0.53      0.54      0.48       720\n",
      "\n",
      "[[ 63 270]\n",
      " [ 61 326]]\n",
      "Validation Loss for P20 = 0.8672162890434265\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_116/2804007043.py:68: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/tmp/ipykernel_116/2804007043.py:41: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1960: UserWarning: nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\n",
      "  warnings.warn(\"nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 78/100, Train Loss: 0.7575953602790833\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.50      0.19      0.28       333\n",
      "         1.0       0.55      0.84      0.66       387\n",
      "\n",
      "    accuracy                           0.54       720\n",
      "   macro avg       0.53      0.51      0.47       720\n",
      "weighted avg       0.53      0.54      0.48       720\n",
      "\n",
      "[[ 64 269]\n",
      " [ 63 324]]\n",
      "Validation Loss for P20 = 0.8620076179504395\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_116/2804007043.py:68: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/tmp/ipykernel_116/2804007043.py:41: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1960: UserWarning: nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\n",
      "  warnings.warn(\"nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 79/100, Train Loss: 0.7776303291320801\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.50      0.20      0.28       333\n",
      "         1.0       0.55      0.83      0.66       387\n",
      "\n",
      "    accuracy                           0.54       720\n",
      "   macro avg       0.52      0.51      0.47       720\n",
      "weighted avg       0.52      0.54      0.49       720\n",
      "\n",
      "[[ 66 267]\n",
      " [ 66 321]]\n",
      "Validation Loss for P20 = 0.8544443249702454\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_116/2804007043.py:68: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/tmp/ipykernel_116/2804007043.py:41: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1960: UserWarning: nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\n",
      "  warnings.warn(\"nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 80/100, Train Loss: 0.7845127582550049\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_116/2804007043.py:68: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.50      0.20      0.29       333\n",
      "         1.0       0.55      0.83      0.66       387\n",
      "\n",
      "    accuracy                           0.54       720\n",
      "   macro avg       0.53      0.52      0.47       720\n",
      "weighted avg       0.53      0.54      0.49       720\n",
      "\n",
      "[[ 67 266]\n",
      " [ 66 321]]\n",
      "Validation Loss for P20 = 0.8549907803535461\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_116/2804007043.py:41: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1960: UserWarning: nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\n",
      "  warnings.warn(\"nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 81/100, Train Loss: 0.7150977849960327\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_116/2804007043.py:68: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.50      0.20      0.28       333\n",
      "         1.0       0.55      0.83      0.66       387\n",
      "\n",
      "    accuracy                           0.54       720\n",
      "   macro avg       0.53      0.51      0.47       720\n",
      "weighted avg       0.53      0.54      0.49       720\n",
      "\n",
      "[[ 65 268]\n",
      " [ 64 323]]\n",
      "Validation Loss for P20 = 0.8621799349784851\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_116/2804007043.py:41: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1960: UserWarning: nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\n",
      "  warnings.warn(\"nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 82/100, Train Loss: 0.7234095931053162\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_116/2804007043.py:68: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.49      0.19      0.27       333\n",
      "         1.0       0.54      0.83      0.66       387\n",
      "\n",
      "    accuracy                           0.53       720\n",
      "   macro avg       0.52      0.51      0.47       720\n",
      "weighted avg       0.52      0.53      0.48       720\n",
      "\n",
      "[[ 63 270]\n",
      " [ 65 322]]\n",
      "Validation Loss for P20 = 0.8750292062759399\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_116/2804007043.py:41: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1960: UserWarning: nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\n",
      "  warnings.warn(\"nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 83/100, Train Loss: 0.7954224944114685\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_116/2804007043.py:68: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.50      0.17      0.26       333\n",
      "         1.0       0.54      0.85      0.66       387\n",
      "\n",
      "    accuracy                           0.54       720\n",
      "   macro avg       0.52      0.51      0.46       720\n",
      "weighted avg       0.52      0.54      0.48       720\n",
      "\n",
      "[[ 58 275]\n",
      " [ 59 328]]\n",
      "Validation Loss for P20 = 0.8820759057998657\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_116/2804007043.py:41: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1960: UserWarning: nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\n",
      "  warnings.warn(\"nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 84/100, Train Loss: 0.7257756590843201\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_116/2804007043.py:68: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.49      0.18      0.26       333\n",
      "         1.0       0.54      0.84      0.66       387\n",
      "\n",
      "    accuracy                           0.53       720\n",
      "   macro avg       0.52      0.51      0.46       720\n",
      "weighted avg       0.52      0.53      0.47       720\n",
      "\n",
      "[[ 59 274]\n",
      " [ 62 325]]\n",
      "Validation Loss for P20 = 0.8807036280632019\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_116/2804007043.py:41: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1960: UserWarning: nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\n",
      "  warnings.warn(\"nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 85/100, Train Loss: 0.7086753845214844\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_116/2804007043.py:68: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.49      0.18      0.26       333\n",
      "         1.0       0.54      0.84      0.66       387\n",
      "\n",
      "    accuracy                           0.53       720\n",
      "   macro avg       0.52      0.51      0.46       720\n",
      "weighted avg       0.52      0.53      0.48       720\n",
      "\n",
      "[[ 59 274]\n",
      " [ 61 326]]\n",
      "Validation Loss for P20 = 0.8823305368423462\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_116/2804007043.py:41: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1960: UserWarning: nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\n",
      "  warnings.warn(\"nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 86/100, Train Loss: 0.6655054688453674\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_116/2804007043.py:68: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.49      0.18      0.27       333\n",
      "         1.0       0.54      0.84      0.66       387\n",
      "\n",
      "    accuracy                           0.53       720\n",
      "   macro avg       0.52      0.51      0.46       720\n",
      "weighted avg       0.52      0.53      0.48       720\n",
      "\n",
      "[[ 61 272]\n",
      " [ 63 324]]\n",
      "Validation Loss for P20 = 0.875034511089325\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_116/2804007043.py:41: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1960: UserWarning: nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\n",
      "  warnings.warn(\"nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 87/100, Train Loss: 0.7469764947891235\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_116/2804007043.py:68: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.49      0.20      0.28       333\n",
      "         1.0       0.54      0.82      0.66       387\n",
      "\n",
      "    accuracy                           0.53       720\n",
      "   macro avg       0.52      0.51      0.47       720\n",
      "weighted avg       0.52      0.53      0.48       720\n",
      "\n",
      "[[ 65 268]\n",
      " [ 68 319]]\n",
      "Validation Loss for P20 = 0.8677730560302734\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_116/2804007043.py:41: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1960: UserWarning: nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\n",
      "  warnings.warn(\"nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 88/100, Train Loss: 0.6395699381828308\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_116/2804007043.py:68: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.50      0.20      0.28       333\n",
      "         1.0       0.55      0.83      0.66       387\n",
      "\n",
      "    accuracy                           0.54       720\n",
      "   macro avg       0.52      0.51      0.47       720\n",
      "weighted avg       0.52      0.54      0.49       720\n",
      "\n",
      "[[ 66 267]\n",
      " [ 66 321]]\n",
      "Validation Loss for P20 = 0.8713249564170837\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_116/2804007043.py:41: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1960: UserWarning: nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\n",
      "  warnings.warn(\"nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 89/100, Train Loss: 0.764862060546875\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_116/2804007043.py:68: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.50      0.19      0.28       333\n",
      "         1.0       0.55      0.84      0.66       387\n",
      "\n",
      "    accuracy                           0.54       720\n",
      "   macro avg       0.53      0.51      0.47       720\n",
      "weighted avg       0.53      0.54      0.48       720\n",
      "\n",
      "[[ 64 269]\n",
      " [ 63 324]]\n",
      "Validation Loss for P20 = 0.8809704780578613\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_116/2804007043.py:41: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1960: UserWarning: nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\n",
      "  warnings.warn(\"nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 90/100, Train Loss: 0.7114413976669312\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_116/2804007043.py:68: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.50      0.19      0.27       333\n",
      "         1.0       0.54      0.84      0.66       387\n",
      "\n",
      "    accuracy                           0.54       720\n",
      "   macro avg       0.52      0.51      0.47       720\n",
      "weighted avg       0.52      0.54      0.48       720\n",
      "\n",
      "[[ 62 271]\n",
      " [ 63 324]]\n",
      "Validation Loss for P20 = 0.8763975501060486\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_116/2804007043.py:41: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1960: UserWarning: nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\n",
      "  warnings.warn(\"nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 91/100, Train Loss: 0.7104569673538208\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_116/2804007043.py:68: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.50      0.19      0.27       333\n",
      "         1.0       0.54      0.84      0.66       387\n",
      "\n",
      "    accuracy                           0.54       720\n",
      "   macro avg       0.52      0.51      0.47       720\n",
      "weighted avg       0.52      0.54      0.48       720\n",
      "\n",
      "[[ 62 271]\n",
      " [ 63 324]]\n",
      "Validation Loss for P20 = 0.8699626326560974\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_116/2804007043.py:41: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1960: UserWarning: nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\n",
      "  warnings.warn(\"nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 92/100, Train Loss: 0.6991980075836182\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_116/2804007043.py:68: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.50      0.19      0.27       333\n",
      "         1.0       0.54      0.84      0.66       387\n",
      "\n",
      "    accuracy                           0.54       720\n",
      "   macro avg       0.52      0.51      0.47       720\n",
      "weighted avg       0.52      0.54      0.48       720\n",
      "\n",
      "[[ 62 271]\n",
      " [ 63 324]]\n",
      "Validation Loss for P20 = 0.8812741637229919\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_116/2804007043.py:41: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1960: UserWarning: nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\n",
      "  warnings.warn(\"nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 93/100, Train Loss: 0.7331850528717041\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_116/2804007043.py:68: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.50      0.19      0.27       333\n",
      "         1.0       0.55      0.84      0.66       387\n",
      "\n",
      "    accuracy                           0.54       720\n",
      "   macro avg       0.53      0.51      0.47       720\n",
      "weighted avg       0.53      0.54      0.48       720\n",
      "\n",
      "[[ 62 271]\n",
      " [ 61 326]]\n",
      "Validation Loss for P20 = 0.8754560351371765\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_116/2804007043.py:41: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1960: UserWarning: nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\n",
      "  warnings.warn(\"nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 94/100, Train Loss: 0.7827847003936768\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_116/2804007043.py:68: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.49      0.17      0.25       333\n",
      "         1.0       0.54      0.85      0.66       387\n",
      "\n",
      "    accuracy                           0.53       720\n",
      "   macro avg       0.52      0.51      0.46       720\n",
      "weighted avg       0.52      0.53      0.47       720\n",
      "\n",
      "[[ 56 277]\n",
      " [ 58 329]]\n",
      "Validation Loss for P20 = 0.8868892788887024\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_116/2804007043.py:41: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1960: UserWarning: nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\n",
      "  warnings.warn(\"nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 95/100, Train Loss: 0.6752459406852722\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.48      0.18      0.26       333\n",
      "         1.0       0.54      0.83      0.66       387\n",
      "\n",
      "    accuracy                           0.53       720\n",
      "   macro avg       0.51      0.51      0.46       720\n",
      "weighted avg       0.51      0.53      0.47       720\n",
      "\n",
      "[[ 59 274]\n",
      " [ 64 323]]\n",
      "Validation Loss for P20 = 0.879594624042511\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_116/2804007043.py:68: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/tmp/ipykernel_116/2804007043.py:41: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1960: UserWarning: nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\n",
      "  warnings.warn(\"nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 96/100, Train Loss: 0.7193449139595032\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_116/2804007043.py:68: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.48      0.17      0.26       333\n",
      "         1.0       0.54      0.84      0.66       387\n",
      "\n",
      "    accuracy                           0.53       720\n",
      "   macro avg       0.51      0.51      0.46       720\n",
      "weighted avg       0.51      0.53      0.47       720\n",
      "\n",
      "[[ 58 275]\n",
      " [ 62 325]]\n",
      "Validation Loss for P20 = 0.8842639923095703\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_116/2804007043.py:41: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1960: UserWarning: nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\n",
      "  warnings.warn(\"nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 97/100, Train Loss: 0.7559655904769897\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_116/2804007043.py:68: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.48      0.17      0.25       333\n",
      "         1.0       0.54      0.85      0.66       387\n",
      "\n",
      "    accuracy                           0.53       720\n",
      "   macro avg       0.51      0.51      0.45       720\n",
      "weighted avg       0.51      0.53      0.47       720\n",
      "\n",
      "[[ 55 278]\n",
      " [ 59 328]]\n",
      "Validation Loss for P20 = 0.8880365490913391\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_116/2804007043.py:41: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1960: UserWarning: nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\n",
      "  warnings.warn(\"nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 98/100, Train Loss: 0.6659654974937439\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_116/2804007043.py:68: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.50      0.18      0.26       333\n",
      "         1.0       0.54      0.84      0.66       387\n",
      "\n",
      "    accuracy                           0.54       720\n",
      "   macro avg       0.52      0.51      0.46       720\n",
      "weighted avg       0.52      0.54      0.48       720\n",
      "\n",
      "[[ 59 274]\n",
      " [ 60 327]]\n",
      "Validation Loss for P20 = 0.8847713470458984\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_116/2804007043.py:41: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1960: UserWarning: nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\n",
      "  warnings.warn(\"nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 99/100, Train Loss: 0.7357078194618225\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_116/2804007043.py:68: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.50      0.18      0.26       333\n",
      "         1.0       0.54      0.84      0.66       387\n",
      "\n",
      "    accuracy                           0.54       720\n",
      "   macro avg       0.52      0.51      0.46       720\n",
      "weighted avg       0.52      0.54      0.48       720\n",
      "\n",
      "[[ 59 274]\n",
      " [ 60 327]]\n",
      "Validation Loss for P20 = 0.8885484933853149\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_116/2804007043.py:41: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1949: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n",
      "/usr/local/lib/python3.9/dist-packages/torch/nn/functional.py:1960: UserWarning: nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\n",
      "  warnings.warn(\"nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 100/100, Train Loss: 0.7660141587257385\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_116/2804007043.py:68: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.49      0.17      0.25       333\n",
      "         1.0       0.54      0.85      0.66       387\n",
      "\n",
      "    accuracy                           0.53       720\n",
      "   macro avg       0.51      0.51      0.46       720\n",
      "weighted avg       0.52      0.53      0.47       720\n",
      "\n",
      "[[ 56 277]\n",
      " [ 59 328]]\n",
      "Validation Loss for P20 = 0.8976070284843445\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x7f42905d11c0>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1000x700 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import confusion_matrix,classification_report\n",
    "from sklearn import preprocessing\n",
    "import matplotlib.pyplot as plt\n",
    "#subjectnames\n",
    "file_list_num = np.arange(len(newsubjectname))\n",
    "file_list_numd = np.arange(len(subjectnamesd))\n",
    "\n",
    "kf = KFold(n_splits=12)\n",
    "torch.manual_seed(42)\n",
    "torch.cuda.manual_seed(42)\n",
    "modellist = []\n",
    "modelid = 1\n",
    "#file_list_num\n",
    "#for i, (train_index, test_index) in enumerate(kf.split(file_list_num)):\n",
    "#for train_index in file_list_num:\n",
    "train_index = file_list_numd\n",
    "test_index = file_list_num\n",
    "print(f\"Fold {i}:\")\n",
    "print(f\"  Train: index={train_index}\")\n",
    "print(f\"  Test:  index={test_index}\")\n",
    "net = Net()\n",
    "net.to(device)\n",
    "optimizer = optim.Adam(net.parameters(), lr=0.000001)\n",
    "epochs = 100\n",
    "batch_sz = 20\n",
    "train_loss_epoch = []\n",
    "val_loss_epoch = []\n",
    "for epoch in range(epochs):\n",
    "  train_loss = []\n",
    "  for tr in train_index:\n",
    "    v = data_de1[subjectnamesd[tr]]\n",
    "    l = data_del[subjectnamesd[tr]]\n",
    "    #print(v[0].shape)\n",
    "    net.train()\n",
    "    for i in range(0,len(v),batch_sz):\n",
    "      #print(v[i].shape)\n",
    "      #for j in range(0,v[i].shape[0],batch_sz):\n",
    "      #print(newsubjectname[tr])\n",
    "      optimizer.zero_grad()\n",
    "      outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
    "      #print(\"Expout {}\",outputs.shape)\n",
    "      #print(\"Actual {}\",l[i:i+batch_sz].shape)\n",
    "      #print(l[i].shape)\n",
    "      loss = criterion(outputs, l[i:i+batch_sz].to(device, dtype=torch.float))\n",
    "      loss.backward()\n",
    "      train_loss.append(loss)\n",
    "      optimizer.step()\n",
    "  print(f'Epoch {epoch + 1}/{epochs}, Train Loss: {loss.item()}')\n",
    "  train_loss_epoch.append(torch.stack(train_loss).mean().cpu().detach().numpy())\n",
    "  #print(train_loss_epoch)\n",
    "  batch_sz = 20\n",
    "  expectedoutputamigos = []\n",
    "  actualoutputamigos = []\n",
    "\n",
    "  for tr in test_index:\n",
    "      net.eval()\n",
    "\n",
    "      v = data_c1d[newsubjectname[tr]]\n",
    "      l = data_c2[newsubjectname[tr]]\n",
    "      net.eval()\n",
    "      val_loss = []\n",
    "      with torch.no_grad():\n",
    "          for i in range(0,len(v),batch_sz):\n",
    "            #print(v[i].shape)\n",
    "            #for j in range(0,v[i].shape[0],batch_sz):\n",
    "            optimizer.zero_grad()\n",
    "            outputs = net(torch.tensor(v[i:i+batch_sz]).to(device, dtype=torch.float))\n",
    "            #print(outputs.shape)\n",
    "            #print(l[i:i+batch_sz].shape)\n",
    "            loss = criterion(outputs, l[i:i+batch_sz].to(device, dtype=torch.float))\n",
    "            val_loss.append(loss)\n",
    "            actualoutputamigos.append(torch.round(outputs.cpu()))\n",
    "            expectedoutputamigos.append(l[i:i+batch_sz])\n",
    "            #actualoutput.append(torch.argmax(torch.softmax(outputs.cpu(),dim=1),dim=1))\n",
    "            #expectedoutput.append(torch.argmax(l[i:i+batch_sz],dim=1).numpy())\n",
    "  val_loss_mean = torch.stack(val_loss).mean().cpu().detach().numpy()\n",
    "  val_loss_epoch.append(val_loss_mean)\n",
    "  expectedoutputamigos = np.concatenate( expectedoutputamigos, axis=0 )\n",
    "  actualoutputamigos = np.concatenate( actualoutputamigos, axis=0 )\n",
    "  #print(expectedoutput.shape)\n",
    "  #print(actualoutput.shape)\n",
    "  print(classification_report(expectedoutputamigos,actualoutputamigos))\n",
    "  print(confusion_matrix(expectedoutputamigos,actualoutputamigos))\n",
    "  print(f'Validation Loss for {newsubjectname[tr]} = {val_loss_mean}')\n",
    "plt.figure(figsize=(10,7))\n",
    "#print(len(train_loss_epoch))\n",
    "plt.plot(np.arange(epochs),train_loss_epoch,label='Train')\n",
    "plt.plot(np.arange(epochs),val_loss_epoch,label='Validation')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "629a6e47-a58b-496b-9740-4e35f730b5d6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
